id	titre	auteur	date	url	texte	origin
889	Spark NLP: Natural Language Understanding at Scale	['Veysel Kocaman', 'David Talby']	2021-01-26 15:11:52+00:00	http://arxiv.org/abs/2101.10848v1	"Spark NLP is a Natural Language Processing (NLP) library built on top of
Apache Spark ML. It provides simple, performant and accurate NLP annotations
for machine learning pipelines that can scale easily in a distributed
environment. Spark NLP comes with 1100 pre trained pipelines and models in more
than 192 languages. It supports nearly all the NLP tasks and modules that can
be used seamlessly in a cluster. Downloaded more than 2.7 million times and
experiencing nine times growth since January 2020, Spark NLP is used by 54% of
healthcare organizations as the worlds most widely used NLP library in the
enterprise."	ArXiv
890	"Training an NLP Scholar at a Small Liberal Arts College: A Backwards
  Designed Course Proposal"	['Grusha Prasad', 'Forrest Davis']	2024-08-11 00:50:59+00:00	http://arxiv.org/abs/2408.05664v1	"The rapid growth in natural language processing (NLP) over the last couple
years has generated student interest and excitement in learning more about the
field. In this paper, we present two types of students that NLP courses might
want to train. First, an ""NLP engineer"" who is able to flexibly design, build
and apply new technologies in NLP for a wide range of tasks. Second, an ""NLP
scholar"" who is able to pose, refine and answer questions in NLP and how it
relates to the society, while also learning to effectively communicate these
answers to a broader audience. While these two types of skills are not mutually
exclusive -- NLP engineers should be able to think critically, and NLP scholars
should be able to build systems -- we think that courses can differ in the
balance of these skills. As educators at Small Liberal Arts Colleges, the
strengths of our students and our institution favors an approach that is better
suited to train NLP scholars. In this paper we articulate what kinds of skills
an NLP scholar should have, and then adopt a backwards design to propose course
components that can aid the acquisition of these skills."	ArXiv
891	Towards Systematic Monolingual NLP Surveys: GenA of Greek NLP	['Juli Bakagianni', 'Kanella Pouli', 'Maria Gavriilidou', 'John Pavlopoulos']	2024-07-13 12:01:52+00:00	http://arxiv.org/abs/2407.09861v2	"Natural Language Processing (NLP) research has traditionally been
predominantly focused on English, driven by the availability of resources, the
size of the research community, and market demands. Recently, there has been a
noticeable shift towards multilingualism in NLP, recognizing the need for
inclusivity and effectiveness across diverse languages and cultures.
Monolingual surveys have the potential to complement the broader trend towards
multilingualism in NLP by providing foundational insights and resources
necessary for effectively addressing the linguistic diversity of global
communication. However, monolingual NLP surveys are extremely rare in
literature. This study fills the gap by introducing a method for creating
systematic and comprehensive monolingual NLP surveys. Characterized by a
structured search protocol, it can be used to select publications and organize
them through a taxonomy of NLP tasks. We include a classification of Language
Resources (LRs), according to their availability, and datasets, according to
their annotation, to highlight publicly-available and machine-actionable LRs.
By applying our method, we conducted a systematic literature review of Greek
NLP from 2012 to 2022, providing a comprehensive overview of the current state
and challenges of Greek NLP research. We discuss the progress of Greek NLP and
outline encountered Greek LRs, classified by availability and usability. As we
show, our proposed method helps avoid common pitfalls, such as data leakage and
contamination, and to assess language support per NLP task. We consider this
systematic literature review of Greek NLP an application of our method that
showcases the benefits of a monolingual NLP survey. Similar applications could
be regard the myriads of languages whose progress in NLP lags behind that of
well-supported languages."	ArXiv
892	"Sejarah dan Perkembangan Teknik Natural Language Processing (NLP) Bahasa
  Indonesia: Tinjauan tentang sejarah, perkembangan teknologi, dan aplikasi NLP
  dalam bahasa Indonesia"	['Mukhlis Amien']	2023-03-28 02:31:47+00:00	http://arxiv.org/abs/2304.02746v1	"This study provides an overview of the history of the development of Natural
Language Processing (NLP) in the context of the Indonesian language, with a
focus on the basic technologies, methods, and practical applications that have
been developed. This review covers developments in basic NLP technologies such
as stemming, part-of-speech tagging, and related methods; practical
applications in cross-language information retrieval systems, information
extraction, and sentiment analysis; and methods and techniques used in
Indonesian language NLP research, such as machine learning, statistics-based
machine translation, and conflict-based approaches. This study also explores
the application of NLP in Indonesian language industry and research and
identifies challenges and opportunities in Indonesian language NLP research and
development. Recommendations for future Indonesian language NLP research and
development include developing more efficient methods and technologies,
expanding NLP applications, increasing sustainability, further research into
the potential of NLP, and promoting interdisciplinary collaboration. It is
hoped that this review will help researchers, practitioners, and the government
to understand the development of Indonesian language NLP and identify
opportunities for further research and development."	ArXiv
893	GR-NLP-TOOLKIT: An Open-Source NLP Toolkit for Modern Greek	['Lefteris Loukas', 'Nikolaos Smyrnioudis', 'Chrysa Dikonomaki', 'Spyros Barbakos', 'Anastasios Toumazatos', 'John Koutsikakis', 'Manolis Kyriakakis', 'Mary Georgiou', 'Stavros Vassos', 'John Pavlopoulos', 'Ion Androutsopoulos']	2024-12-11 16:34:23+00:00	http://arxiv.org/abs/2412.08520v1	"We present GR-NLP-TOOLKIT, an open-source natural language processing (NLP)
toolkit developed specifically for modern Greek. The toolkit provides
state-of-the-art performance in five core NLP tasks, namely part-of-speech
tagging, morphological tagging, dependency parsing, named entity recognition,
and Greeklishto-Greek transliteration. The toolkit is based on pre-trained
Transformers, it is freely available, and can be easily installed in Python
(pip install gr-nlp-toolkit). It is also accessible through a demonstration
platform on HuggingFace, along with a publicly available API for non-commercial
use. We discuss the functionality provided for each task, the underlying
methods, experiments against comparable open-source toolkits, and future
possible enhancements. The toolkit is available at:
https://github.com/nlpaueb/gr-nlp-toolkit"	ArXiv
894	The Law and NLP: Bridging Disciplinary Disconnects	"['Robert Mahari', 'Dominik Stammbach', 'Elliott Ash', ""Alex 'Sandy' Pentland""]"	2023-10-22 16:34:31+00:00	http://arxiv.org/abs/2310.14346v1	"Legal practice is intrinsically rooted in the fabric of language, yet legal
practitioners and scholars have been slow to adopt tools from natural language
processing (NLP). At the same time, the legal system is experiencing an access
to justice crisis, which could be partially alleviated with NLP. In this
position paper, we argue that the slow uptake of NLP in legal practice is
exacerbated by a disconnect between the needs of the legal community and the
focus of NLP researchers. In a review of recent trends in the legal NLP
literature, we find limited overlap between the legal NLP community and legal
academia. Our interpretation is that some of the most popular legal NLP tasks
fail to address the needs of legal practitioners. We discuss examples of legal
NLP tasks that promise to bridge disciplinary disconnects and highlight
interesting areas for legal NLP research that remain underexplored."	ArXiv
895	A Survey on Recognizing Textual Entailment as an NLP Evaluation	['Adam Poliak']	2020-10-06 22:23:00+00:00	http://arxiv.org/abs/2010.03061v1	"Recognizing Textual Entailment (RTE) was proposed as a unified evaluation
framework to compare semantic understanding of different NLP systems. In this
survey paper, we provide an overview of different approaches for evaluating and
understanding the reasoning capabilities of NLP systems. We then focus our
discussion on RTE by highlighting prominent RTE datasets as well as advances in
RTE dataset that focus on specific linguistic phenomena that can be used to
evaluate NLP systems on a fine-grained level. We conclude by arguing that when
evaluating NLP systems, the community should utilize newly introduced RTE
datasets that focus on specific linguistic phenomena."	ArXiv
896	Natural Language Processing for Human Resources: A Survey	['Naoki Otani', 'Nikita Bhutani', 'Estevam Hruschka']	2024-10-21 20:41:00+00:00	http://arxiv.org/abs/2410.16498v1	"The domain of human resources (HR) includes a broad spectrum of tasks related
to natural language processing (NLP) techniques. Recent breakthroughs in NLP
have generated significant interest in its industrial applications in this
domain and potentially alleviate challenges such as the difficulty of resource
acquisition and the complexity of problems. At the same time, the HR domain can
also present unique challenges that drive state-of-the-art in NLP research. To
support this, we provide NLP researchers and practitioners with an overview of
key HR tasks from an NLP perspective, illustrating how specific sub-tasks
(e.g., skill extraction) contribute to broader objectives (e.g., job matching).
Through this survey, we identify opportunities in NLP for HR and suggest
directions for future exploration."	ArXiv
897	A Survey of Race, Racism, and Anti-Racism in NLP	['Anjalie Field', 'Su Lin Blodgett', 'Zeerak Waseem', 'Yulia Tsvetkov']	2021-06-21 20:59:06+00:00	http://arxiv.org/abs/2106.11410v2	"Despite inextricable ties between race and language, little work has
considered race in NLP research and development. In this work, we survey 79
papers from the ACL anthology that mention race. These papers reveal various
types of race-related bias in all stages of NLP model development, highlighting
the need for proactive consideration of how NLP systems can uphold racial
hierarchies. However, persistent gaps in research on race and NLP remain: race
has been siloed as a niche topic and remains ignored in many NLP tasks; most
work operationalizes race as a fixed single-dimensional variable with a
ground-truth label, which risks reinforcing differences produced by historical
racism; and the voices of historically marginalized people are nearly absent in
NLP literature. By identifying where and how NLP literature has and has not
considered race, especially in comparison to related fields, our work calls for
inclusion and racial justice in NLP research practices."	ArXiv
898	Large Language Models Meet NLP: A Survey	['Libo Qin', 'Qiguang Chen', 'Xiachong Feng', 'Yang Wu', 'Yongheng Zhang', 'Yinghui Li', 'Min Li', 'Wanxiang Che', 'Philip S. Yu']	2024-05-21 14:24:01+00:00	http://arxiv.org/abs/2405.12819v1	"While large language models (LLMs) like ChatGPT have shown impressive
capabilities in Natural Language Processing (NLP) tasks, a systematic
investigation of their potential in this field remains largely unexplored. This
study aims to address this gap by exploring the following questions: (1) How
are LLMs currently applied to NLP tasks in the literature? (2) Have traditional
NLP tasks already been solved with LLMs? (3) What is the future of the LLMs for
NLP? To answer these questions, we take the first step to provide a
comprehensive overview of LLMs in NLP. Specifically, we first introduce a
unified taxonomy including (1) parameter-frozen application and (2)
parameter-tuning application to offer a unified perspective for understanding
the current progress of LLMs in NLP. Furthermore, we summarize the new
frontiers and the associated challenges, aiming to inspire further
groundbreaking advancements. We hope this work offers valuable insights into
the {potential and limitations} of LLMs in NLP, while also serving as a
practical guide for building effective LLMs in NLP."	ArXiv
899	Speciesism in Natural Language Processing Research	['Masashi Takeshita', 'Rafal Rzepka']	2024-10-18 06:09:41+00:00	http://arxiv.org/abs/2410.14194v1	"Natural Language Processing (NLP) research on AI Safety and social bias in AI
has focused on safety for humans and social bias against human minorities.
However, some AI ethicists have argued that the moral significance of nonhuman
animals has been ignored in AI research. Therefore, the purpose of this study
is to investigate whether there is speciesism, i.e., discrimination against
nonhuman animals, in NLP research. First, we explain why nonhuman animals are
relevant in NLP research. Next, we survey the findings of existing research on
speciesism in NLP researchers, data, and models and further investigate this
problem in this study. The findings of this study suggest that speciesism
exists within researchers, data, and models, respectively. Specifically, our
survey and experiments show that (a) among NLP researchers, even those who
study social bias in AI, do not recognize speciesism or speciesist bias; (b)
among NLP data, speciesist bias is inherent in the data annotated in the
datasets used to evaluate NLP models; (c) OpenAI GPTs, recent NLP models,
exhibit speciesist bias by default. Finally, we discuss how we can reduce
speciesism in NLP research."	ArXiv
900	"NLP Methods in Host-based Intrusion Detection Systems: A Systematic
  Review and Future Directions"	['Zarrin Tasnim Sworna', 'Zahra Mousavi', 'Muhammad Ali Babar']	2022-01-20 09:05:34+00:00	http://arxiv.org/abs/2201.08066v2	"Host based Intrusion Detection System (HIDS) is an effective last line of
defense for defending against cyber security attacks after perimeter defenses
(e.g., Network based Intrusion Detection System and Firewall) have failed or
been bypassed. HIDS is widely adopted in the industry as HIDS is ranked among
the top two most used security tools by Security Operation Centers (SOC) of
organizations. Although effective and efficient HIDS is highly desirable for
industrial organizations, the evolution of increasingly complex attack patterns
causes several challenges resulting in performance degradation of HIDS (e.g.,
high false alert rate creating alert fatigue for SOC staff). Since Natural
Language Processing (NLP) methods are better suited for identifying complex
attack patterns, an increasing number of HIDS are leveraging the advances in
NLP that have shown effective and efficient performance in precisely detecting
low footprint, zero day attacks and predicting the next steps of attackers.
This active research trend of using NLP in HIDS demands a synthesized and
comprehensive body of knowledge of NLP based HIDS. Thus, we conducted a
systematic review of the literature on the end to end pipeline of the use of
NLP in HIDS development. For the end to end NLP based HIDS development
pipeline, we identify, taxonomically categorize and systematically compare the
state of the art of NLP methods usage in HIDS, attacks detected by these NLP
methods, datasets and evaluation metrics which are used to evaluate the NLP
based HIDS. We highlight the relevant prevalent practices, considerations,
advantages and limitations to support the HIDS developers. We also outline the
future research directions for the NLP based HIDS development."	ArXiv
901	"We are Who We Cite: Bridges of Influence Between Natural Language
  Processing and Other Academic Fields"	['Jan Philip Wahle', 'Terry Ruas', 'Mohamed Abdalla', 'Bela Gipp', 'Saif M. Mohammad']	2023-10-23 12:42:06+00:00	http://arxiv.org/abs/2310.14870v3	"Natural Language Processing (NLP) is poised to substantially influence the
world. However, significant progress comes hand-in-hand with substantial risks.
Addressing them requires broad engagement with various fields of study. Yet,
little empirical work examines the state of such engagement (past or current).
In this paper, we quantify the degree of influence between 23 fields of study
and NLP (on each other). We analyzed ~77k NLP papers, ~3.1m citations from NLP
papers to other papers, and ~1.8m citations from other papers to NLP papers. We
show that, unlike most fields, the cross-field engagement of NLP, measured by
our proposed Citation Field Diversity Index (CFDI), has declined from 0.58 in
1980 to 0.31 in 2022 (an all-time low). In addition, we find that NLP has grown
more insular -- citing increasingly more NLP papers and having fewer papers
that act as bridges between fields. NLP citations are dominated by computer
science; Less than 8% of NLP citations are to linguistics, and less than 3% are
to math and psychology. These findings underscore NLP's urgent need to reflect
on its engagement with various fields."	ArXiv
902	"Thoughtful Adoption of NLP for Civic Participation: Understanding
  Differences Among Policymakers"	['Jose A. Guridi', 'Cristobal Cheyre', 'Qian Yang']	2024-10-30 11:46:26+00:00	http://arxiv.org/abs/2410.22937v1	"Natural language processing (NLP) tools have the potential to boost civic
participation and enhance democratic processes because they can significantly
increase governments' capacity to gather and analyze citizen opinions. However,
their adoption in government remains limited, and harnessing their benefits
while preventing unintended consequences remains a challenge. While prior work
has focused on improving NLP performance, this work examines how different
internal government stakeholders influence NLP tools' thoughtful adoption. We
interviewed seven politicians (politically appointed officials as heads of
government institutions) and thirteen public servants (career government
employees who design and administrate policy interventions), inquiring how they
choose whether and how to use NLP tools to support civic participation
processes. The interviews suggest that policymakers across both groups focused
on their needs for career advancement and the need to showcase the legitimacy
and fairness of their work when considering NLP tool adoption and use. Because
these needs vary between politicians and public servants, their preferred NLP
features and tool designs also differ. Interestingly, despite their differing
needs and opinions, neither group clearly identifies who should advocate for
NLP adoption to enhance civic participation or address the unintended
consequences of a poorly considered adoption. This lack of clarity in
responsibility might have caused the governments' low adoption of NLP tools. We
discuss how these findings reveal new insights for future HCI research. They
inform the design of NLP tools for increasing civic participation efficiency
and capacity, the design of other tools and methods that ensure thoughtful
adoption of AI tools in government, and the design of NLP tools for
collaborative use among users with different incentives and needs."	ArXiv
903	NLP-ADBench: NLP Anomaly Detection Benchmark	['Yuangang Li', 'Jiaqi Li', 'Zhuo Xiao', 'Tiankai Yang', 'Yi Nian', 'Xiyang Hu', 'Yue Zhao']	2024-12-06 05:30:41+00:00	http://arxiv.org/abs/2412.04784v1	"Anomaly detection (AD) is a critical machine learning task with diverse
applications in web systems, including fraud detection, content moderation, and
user behavior analysis. Despite its significance, AD in natural language
processing (NLP) remains underexplored, limiting advancements in detecting
anomalies in text data such as harmful content, phishing attempts, or spam
reviews. In this paper, we introduce NLP-ADBench, the most comprehensive
benchmark for NLP anomaly detection (NLP-AD), comprising eight curated datasets
and evaluations of nineteen state-of-the-art algorithms. These include three
end-to-end methods and sixteen two-step algorithms that apply traditional
anomaly detection techniques to language embeddings generated by
bert-base-uncased and OpenAI's text-embedding-3-large models.
  Our results reveal critical insights and future directions for NLP-AD.
Notably, no single model excels across all datasets, highlighting the need for
automated model selection. Moreover, two-step methods leveraging
transformer-based embeddings consistently outperform specialized end-to-end
approaches, with OpenAI embeddings demonstrating superior performance over BERT
embeddings. By releasing NLP-ADBench at
https://github.com/USC-FORTIS/NLP-ADBench, we provide a standardized framework
for evaluating NLP-AD methods, fostering the development of innovative
approaches. This work fills a crucial gap in the field and establishes a
foundation for advancing NLP anomaly detection, particularly in the context of
improving the safety and reliability of web-based systems."	ArXiv
904	Notes on Deep Learning for NLP	['Antoine J. -P. Tixier']	2018-08-29 12:58:45+00:00	http://arxiv.org/abs/1808.09772v2	My notes on Deep Learning for NLP.	ArXiv
905	"Translational NLP: A New Paradigm and General Principles for Natural
  Language Processing Research"	['Denis Newman-Griffis', 'Jill Fain Lehman', 'Carolyn Rosé', 'Harry Hochheiser']	2021-04-16 03:46:10+00:00	http://arxiv.org/abs/2104.07874v1	"Natural language processing (NLP) research combines the study of universal
principles, through basic science, with applied science targeting specific use
cases and settings. However, the process of exchange between basic NLP and
applications is often assumed to emerge naturally, resulting in many
innovations going unapplied and many important questions left unstudied. We
describe a new paradigm of Translational NLP, which aims to structure and
facilitate the processes by which basic and applied NLP research inform one
another. Translational NLP thus presents a third research paradigm, focused on
understanding the challenges posed by application needs and how these
challenges can drive innovation in basic science and technology design. We show
that many significant advances in NLP research have emerged from the
intersection of basic principles with application needs, and present a
conceptual framework outlining the stakeholders and key questions in
translational research. Our framework provides a roadmap for developing
Translational NLP as a dedicated research area, and identifies general
translational principles to facilitate exchange between basic and applied
research."	ArXiv
906	"Natural Language Processing 4 All (NLP4All): A New Online Platform for
  Teaching and Learning NLP Concepts"	['Rebekah Baglini', 'Arthur Hjorth']	2021-05-28 09:57:22+00:00	http://arxiv.org/abs/2105.13704v1	"Natural Language Processing offers new insights into language data across
almost all disciplines and domains, and allows us to corroborate and/or
challenge existing knowledge. The primary hurdles to widening participation in
and use of these new research tools are, first, a lack of coding skills in
students across K-16, and in the population at large, and second, a lack of
knowledge of how NLP-methods can be used to answer questions of disciplinary
interest outside of linguistics and/or computer science. To broaden
participation in NLP and improve NLP-literacy, we introduced a new tool
web-based tool called Natural Language Processing 4 All (NLP4All). The intended
purpose of NLP4All is to help teachers facilitate learning with and about NLP,
by providing easy-to-use interfaces to NLP-methods, data, and analyses, making
it possible for non- and novice-programmers to learn NLP concepts
interactively."	ArXiv
907	"Classification of Natural Language Processing Techniques for
  Requirements Engineering"	['Liping Zhao', 'Waad Alhoshan', 'Alessio Ferrari', 'Keletso J. Letsholo']	2022-04-08 20:28:00+00:00	http://arxiv.org/abs/2204.04282v1	"Research in applying natural language processing (NLP) techniques to
requirements engineering (RE) tasks spans more than 40 years, from initial
efforts carried out in the 1980s to more recent attempts with machine learning
(ML) and deep learning (DL) techniques. However, in spite of the progress, our
recent survey shows that there is still a lack of systematic understanding and
organization of commonly used NLP techniques in RE. We believe one hurdle
facing the industry is lack of shared knowledge of NLP techniques and their
usage in RE tasks. In this paper, we present our effort to synthesize and
organize 57 most frequently used NLP techniques in RE. We classify these NLP
techniques in two ways: first, by their NLP tasks in typical pipelines and
second, by their linguist analysis levels. We believe these two ways of
classification are complementary, contributing to a better understanding of the
NLP techniques in RE and such understanding is crucial to the development of
better NLP tools for RE."	ArXiv
908	"NusaCrowd: A Call for Open and Reproducible NLP Research in Indonesian
  Languages"	['Samuel Cahyawijaya', 'Alham Fikri Aji', 'Holy Lovenia', 'Genta Indra Winata', 'Bryan Wilie', 'Rahmad Mahendra', 'Fajri Koto', 'David Moeljadi', 'Karissa Vincentio', 'Ade Romadhony', 'Ayu Purwarianti']	2022-07-21 15:05:42+00:00	http://arxiv.org/abs/2207.10524v2	"At the center of the underlying issues that halt Indonesian natural language
processing (NLP) research advancement, we find data scarcity. Resources in
Indonesian languages, especially the local ones, are extremely scarce and
underrepresented. Many Indonesian researchers do not publish their dataset.
Furthermore, the few public datasets that we have are scattered across
different platforms, thus makes performing reproducible and data-centric
research in Indonesian NLP even more arduous. Rising to this challenge, we
initiate the first Indonesian NLP crowdsourcing effort, NusaCrowd. NusaCrowd
strives to provide the largest datasheets aggregation with standardized data
loading for NLP tasks in all Indonesian languages. By enabling open and
centralized access to Indonesian NLP resources, we hope NusaCrowd can tackle
the data scarcity problem hindering NLP progress in Indonesia and bring NLP
practitioners to move towards collaboration."	ArXiv
909	A Partial Exact Penalty Function Approach for Constrained Optimization	['Nachuan Xiao', 'Xin Liu', 'Kim-Chuan Toh']	2023-04-04 02:13:18+00:00	http://arxiv.org/abs/2304.01467v1	"In this paper, we focus on a class of constrained nonlinear optimization
problems (NLP), where some of its equality constraints define a closed embedded
submanifold $\mathcal{M}$ in $\mathbb{R}^n$. Although NLP can be solved
directly by various existing approaches for constrained optimization in
Euclidean space, these approaches usually fail to recognize the manifold
structure of $\mathcal{M}$. To achieve better efficiency by utilizing the
manifold structure of $\mathcal{M}$ in directly applying these existing
optimization approaches, we propose a partial penalty function approach for
NLP. In our proposed penalty function approach, we transform NLP into the
corresponding constraint dissolving problem (CDP) in the Euclidean space, where
the constraints that define $\mathcal{M}$ are eliminated through exact
penalization. We establish the relationships on the constraint qualifications
between NLP and CDP, and prove that NLP and CDP have the same stationary points
and KKT points in a neighborhood of the feasible region under mild conditions.
Therefore, various existing optimization approaches developed for constrained
optimization in the Euclidean space can be directly applied to solve NLP
through CDP. Preliminary numerical experiments demonstrate that by dissolving
the constraints that define $\mathcal{M}$, CDP gains superior computational
efficiency when compared to directly applying existing optimization approaches
to solve NLP, especially in high dimensional scenarios."	ArXiv
910	"A Review of Digital Learning Environments for Teaching Natural Language
  Processing in K-12 Education"	['Xiaoyi Tian', 'Kristy Elizabeth Boyer']	2023-10-02 19:54:30+00:00	http://arxiv.org/abs/2310.01603v1	"Natural Language Processing (NLP) plays a significant role in our daily lives
and has become an essential part of Artificial Intelligence (AI) education in
K-12. As children grow up with NLP-powered applications, it is crucial to
introduce NLP concepts to them, fostering their understanding of language
processing, language generation, and ethical implications of AI and NLP. This
paper presents a comprehensive review of digital learning environments for
teaching NLP in K-12. Specifically, it explores existing digital learning
tools, discusses how they support specific NLP tasks and procedures, and
investigates their explainability and evaluation results in educational
contexts. By examining the strengths and limitations of these tools, this
literature review sheds light on the current state of NLP learning tools in
K-12 education. It aims to guide future research efforts to refine existing
tools, develop new ones, and explore more effective and inclusive strategies
for integrating NLP into K-12 educational contexts."	ArXiv
911	The Nature of NLP: Analyzing Contributions in NLP Papers	['Aniket Pramanick', 'Yufang Hou', 'Saif M. Mohammad', 'Iryna Gurevych']	2024-09-29 01:29:28+00:00	http://arxiv.org/abs/2409.19505v1	"Natural Language Processing (NLP) is a dynamic, interdisciplinary field that
integrates intellectual traditions from computer science, linguistics, social
science, and more. Despite its established presence, the definition of what
constitutes NLP research remains debated. In this work, we quantitatively
investigate what constitutes NLP by examining research papers. For this
purpose, we propose a taxonomy and introduce NLPContributions, a dataset of
nearly $2k$ research paper abstracts, expertly annotated to identify scientific
contributions and classify their types according to this taxonomy. We also
propose a novel task to automatically identify these elements, for which we
train a strong baseline on our dataset. We present experimental results from
this task and apply our model to $\sim$$29k$ NLP research papers to analyze
their contributions, aiding in the understanding of the nature of NLP research.
Our findings reveal a rising involvement of machine learning in NLP since the
early nineties, alongside a declining focus on adding knowledge about language
or people; again, in post-2020, there has been a resurgence of focus on
language and people. We hope this work will spark discussions on our community
norms and inspire efforts to consciously shape the future."	ArXiv
912	"The NLP Sandbox: an efficient model-to-data system to enable federated
  and unbiased evaluation of clinical NLP models"	['Yao Yan', 'Thomas Yu', 'Kathleen Muenzen', 'Sijia Liu', 'Connor Boyle', 'George Koslowski', 'Jiaxin Zheng', 'Nicholas Dobbins', 'Clement Essien', 'Hongfang Liu', 'Larsson Omberg', 'Meliha Yestigen', 'Bradley Taylor', 'James A Eddy', 'Justin Guinney', 'Sean Mooney', 'Thomas Schaffter']	2022-06-28 17:47:56+00:00	http://arxiv.org/abs/2206.14181v1	"Objective The evaluation of natural language processing (NLP) models for
clinical text de-identification relies on the availability of clinical notes,
which is often restricted due to privacy concerns. The NLP Sandbox is an
approach for alleviating the lack of data and evaluation frameworks for NLP
models by adopting a federated, model-to-data approach. This enables unbiased
federated model evaluation without the need for sharing sensitive data from
multiple institutions. Materials and Methods We leveraged the Synapse
collaborative framework, containerization software, and OpenAPI generator to
build the NLP Sandbox (nlpsandbox.io). We evaluated two state-of-the-art NLP
de-identification focused annotation models, Philter and NeuroNER, using data
from three institutions. We further validated model performance using data from
an external validation site. Results We demonstrated the usefulness of the NLP
Sandbox through de-identification clinical model evaluation. The external
developer was able to incorporate their model into the NLP Sandbox template and
provide user experience feedback. Discussion We demonstrated the feasibility of
using the NLP Sandbox to conduct a multi-site evaluation of clinical text
de-identification models without the sharing of data. Standardized model and
data schemas enable smooth model transfer and implementation. To generalize the
NLP Sandbox, work is required on the part of data owners and model developers
to develop suitable and standardized schemas and to adapt their data or model
to fit the schemas. Conclusions The NLP Sandbox lowers the barrier to utilizing
clinical data for NLP model evaluation and facilitates federated, multi-site,
unbiased evaluation of NLP models."	ArXiv
913	An NLP Assistant for Clide	['Tobias Kortkamp']	2014-09-07 02:31:03+00:00	http://arxiv.org/abs/1409.2073v1	"This report describes an NLP assistant for the collaborative development
environment Clide, that supports the development of NLP applications by
providing easy access to some common NLP data structures. The assistant
visualizes text fragments and their dependencies by displaying the semantic
graph of a sentence, the coreference chain of a paragraph and mined triples
that are extracted from a paragraph's semantic graphs and linked using its
coreference chain. Using this information and a logic programming library, we
create an NLP database which is used by a series of queries to mine the
triples. The algorithm is tested by translating a natural language text
describing a graph to an actual graph that is shown as an annotation in the
text editor."	ArXiv
914	The Current State of Finnish NLP	['Mika Hämäläinen', 'Khalid Alnajjar']	2021-09-23 12:19:56+00:00	http://arxiv.org/abs/2109.11326v1	"There are a lot of tools and resources available for processing Finnish. In
this paper, we survey recent papers focusing on Finnish NLP related to many
different subcategories of NLP such as parsing, generation, semantics and
speech. NLP research is conducted in many different research groups in Finland,
and it is frequently the case that NLP tools and models resulting from academic
research are made available for others to use on platforms such as Github."	ArXiv
915	Improving Interpretability via Explicit Word Interaction Graph Layer	['Arshdeep Sekhon', 'Hanjie Chen', 'Aman Shrivastava', 'Zhe Wang', 'Yangfeng Ji', 'Yanjun Qi']	2023-02-03 21:56:32+00:00	http://arxiv.org/abs/2302.02016v1	"Recent NLP literature has seen growing interest in improving model
interpretability. Along this direction, we propose a trainable neural network
layer that learns a global interaction graph between words and then selects
more informative words using the learned word interactions. Our layer, we call
WIGRAPH, can plug into any neural network-based NLP text classifiers right
after its word embedding layer. Across multiple SOTA NLP models and various NLP
datasets, we demonstrate that adding the WIGRAPH layer substantially improves
NLP models' interpretability and enhances models' prediction performance at the
same time."	ArXiv
916	"Towards a Holistic Approach: Understanding Sociodemographic Biases in
  NLP Models using an Interdisciplinary Lens"	['Pranav Narayanan Venkit']	2023-08-24 21:19:48+00:00	http://arxiv.org/abs/2308.13089v1	"The rapid growth in the usage and applications of Natural Language Processing
(NLP) in various sociotechnical solutions has highlighted the need for a
comprehensive understanding of bias and its impact on society. While research
on bias in NLP has expanded, several challenges persist that require attention.
These include the limited focus on sociodemographic biases beyond race and
gender, the narrow scope of analysis predominantly centered on models, and the
technocentric implementation approaches. This paper addresses these challenges
and advocates for a more interdisciplinary approach to understanding bias in
NLP. The work is structured into three facets, each exploring a specific aspect
of bias in NLP."	ArXiv
917	Ling-CL: Understanding NLP Models through Linguistic Curricula	['Mohamed Elgaar', 'Hadi Amiri']	2023-10-31 01:44:33+00:00	http://arxiv.org/abs/2310.20121v1	"We employ a characterization of linguistic complexity from psycholinguistic
and language acquisition research to develop data-driven curricula to
understand the underlying linguistic knowledge that models learn to address NLP
tasks. The novelty of our approach is in the development of linguistic
curricula derived from data, existing knowledge about linguistic complexity,
and model behavior during training. By analyzing several benchmark NLP
datasets, our curriculum learning approaches identify sets of linguistic
metrics (indices) that inform the challenges and reasoning required to address
each task. Our work will inform future research in all NLP areas, allowing
linguistic complexity to be considered early in the research and development
process. In addition, our work prompts an examination of gold standards and
fair evaluation in NLP."	ArXiv
918	"Shoulders of Giants: A Look at the Degree and Utility of Openness in NLP
  Research"	['Surangika Ranathunga', 'Nisansa de Silva', 'Dilith Jayakody', 'Aloka Fernando']	2024-06-10 04:47:27+00:00	http://arxiv.org/abs/2406.06021v1	"We analysed a sample of NLP research papers archived in ACL Anthology as an
attempt to quantify the degree of openness and the benefit of such an open
culture in the NLP community. We observe that papers published in different NLP
venues show different patterns related to artefact reuse. We also note that
more than 30% of the papers we analysed do not release their artefacts
publicly, despite promising to do so. Further, we observe a wide language-wise
disparity in publicly available NLP-related artefacts."	ArXiv
919	"How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social
  Impact"	['Zhijing Jin', 'Geeticka Chauhan', 'Brian Tse', 'Mrinmaya Sachan', 'Rada Mihalcea']	2021-06-04 09:17:15+00:00	http://arxiv.org/abs/2106.02359v3	"Recent years have seen many breakthroughs in natural language processing
(NLP), transitioning it from a mostly theoretical field to one with many
real-world applications. Noting the rising number of applications of other
machine learning and AI techniques with pervasive societal impact, we
anticipate the rising importance of developing NLP technologies for social
good. Inspired by theories in moral philosophy and global priorities research,
we aim to promote a guideline for social good in the context of NLP. We lay the
foundations via the moral philosophy definition of social good, propose a
framework to evaluate the direct and indirect real-world impact of NLP tasks,
and adopt the methodology of global priorities research to identify priority
causes for NLP research. Finally, we use our theoretical framework to provide
some practical guidelines for future NLP research for social good. Our data and
code are available at http://github.com/zhijing-jin/nlp4sg_acl2021. In
addition, we curate a list of papers and resources on NLP for social good at
https://github.com/zhijing-jin/NLP4SocialGood_Papers."	ArXiv
920	"Large-Scale News Classification using BERT Language Model: Spark NLP
  Approach"	['Kuncahyo Setyo Nugroho', 'Anantha Yullian Sukmadewa', 'Novanto Yudistira']	2021-07-14 15:42:15+00:00	http://arxiv.org/abs/2107.06785v2	"The rise of big data analytics on top of NLP increases the computational
burden for text processing at scale. The problems faced in NLP are very high
dimensional text, so it takes a high computation resource. The MapReduce allows
parallelization of large computations and can improve the efficiency of text
processing. This research aims to study the effect of big data processing on
NLP tasks based on a deep learning approach. We classify a big text of news
topics with fine-tuning BERT used pre-trained models. Five pre-trained models
with a different number of parameters were used in this study. To measure the
efficiency of this method, we compared the performance of the BERT with the
pipelines from Spark NLP. The result shows that BERT without Spark NLP gives
higher accuracy compared to BERT with Spark NLP. The accuracy average and
training time of all models using BERT is 0.9187 and 35 minutes while using
BERT with Spark NLP pipeline is 0.8444 and 9 minutes. The bigger model will
take more computation resources and need a longer time to complete the tasks.
However, the accuracy of BERT with Spark NLP only decreased by an average of
5.7%, while the training time was reduced significantly by 62.9% compared to
BERT without Spark NLP."	ArXiv
921	"Leveraging AI and NLP for Bank Marketing: A Systematic Review and Gap
  Analysis"	['Christopher Gerling', 'Stefan Lessmann']	2024-11-17 14:44:12+00:00	http://arxiv.org/abs/2411.14463v1	"This paper explores the growing impact of AI and NLP in bank marketing,
highlighting their evolving roles in enhancing marketing strategies, improving
customer engagement, and creating value within this sector. While AI and NLP
have been widely studied in general marketing, there is a notable gap in
understanding their specific applications and potential within the banking
sector. This research addresses this specific gap by providing a systematic
review and strategic analysis of AI and NLP applications in bank marketing,
focusing on their integration across the customer journey and operational
excellence. Employing the PRISMA methodology, this study systematically reviews
existing literature to assess the current landscape of AI and NLP in bank
marketing. Additionally, it incorporates semantic mapping using Sentence
Transformers and UMAP for strategic gap analysis to identify underexplored
areas and opportunities for future research.
  The systematic review reveals limited research specifically focused on NLP
applications in bank marketing. The strategic gap analysis identifies key areas
where NLP can further enhance marketing strategies, including customer-centric
applications like acquisition, retention, and personalized engagement, offering
valuable insights for both academic research and practical implementation. This
research contributes to the field of bank marketing by mapping the current
state of AI and NLP applications and identifying strategic gaps. The findings
provide actionable insights for developing NLP-driven growth and innovation
frameworks and highlight the role of NLP in improving operational efficiency
and regulatory compliance. This work has broader implications for enhancing
customer experience, profitability, and innovation in the banking industry."	ArXiv
922	"A Systematic Review of Natural Language Processing for Knowledge
  Management in Healthcare"	['Ganga Prasad Basyal', 'Bhaskar P. Rimal', 'David Zeng']	2020-07-17 17:50:50+00:00	http://arxiv.org/abs/2007.09134v1	"Driven by the visions of Data Science, recent years have seen a paradigm
shift in Natural Language Processing (NLP). NLP has set the milestone in text
processing and proved to be the preferred choice for researchers in the
healthcare domain. The objective of this paper is to identify the potential of
NLP, especially, how NLP is used to support the knowledge management process in
the healthcare domain, making data a critical and trusted component in
improving the health outcomes. This paper provides a comprehensive survey of
the state-of-the-art NLP research with a particular focus on how knowledge is
created, captured, shared, and applied in the healthcare domain. Our findings
suggest, first, the techniques of NLP those supporting knowledge management
extraction and knowledge capture processes in healthcare. Second, we propose a
conceptual model for the knowledge extraction process through NLP. Finally, we
discuss a set of issues, challenges, and proposed future research areas."	ArXiv
923	Towards Improving Adversarial Training of NLP Models	['Jin Yong Yoo', 'Yanjun Qi']	2021-09-01 17:14:26+00:00	http://arxiv.org/abs/2109.00544v2	"Adversarial training, a method for learning robust deep neural networks,
constructs adversarial examples during training. However, recent methods for
generating NLP adversarial examples involve combinatorial search and expensive
sentence encoders for constraining the generated instances. As a result, it
remains challenging to use vanilla adversarial training to improve NLP models'
performance, and the benefits are mainly uninvestigated. This paper proposes a
simple and improved vanilla adversarial training process for NLP models, which
we name Attacking to Training (A2T). The core part of A2T is a new and cheaper
word substitution attack optimized for vanilla adversarial training. We use A2T
to train BERT and RoBERTa models on IMDB, Rotten Tomatoes, Yelp, and SNLI
datasets. Our results empirically show that it is possible to train robust NLP
models using a much cheaper adversary. We demonstrate that vanilla adversarial
training with A2T can improve an NLP model's robustness to the attack it was
originally trained with and also defend the model against other types of word
substitution attacks. Furthermore, we show that A2T can improve NLP models'
standard accuracy, cross-domain generalization, and interpretability. Code is
available at https://github.com/QData/Textattack-A2T ."	ArXiv
924	"Teaching NLP outside Linguistics and Computer Science classrooms: Some
  challenges and some opportunities"	['Sowmya Vajjala']	2021-05-03 14:30:32+00:00	http://arxiv.org/abs/2105.00895v1	"NLP's sphere of influence went much beyond computer science research and the
development of software applications in the past decade. We see people using
NLP methods in a range of academic disciplines from Asian Studies to Clinical
Oncology. We also notice the presence of NLP as a module in most of the data
science curricula within and outside of regular university setups. These
courses are taken by students from very diverse backgrounds. This paper takes a
closer look at some issues related to teaching NLP to these diverse audiences
based on my classroom experiences, and identifies some challenges the
instructors face, particularly when there is no ecosystem of related courses
for the students. In this process, it also identifies a few challenge areas for
both NLP researchers and tool developers."	ArXiv
925	Model Explainability in Deep Learning Based Natural Language Processing	['Shafie Gholizadeh', 'Nengfeng Zhou']	2021-06-14 13:23:20+00:00	http://arxiv.org/abs/2106.07410v1	"Machine learning (ML) model explainability has received growing attention,
especially in the area related to model risk and regulations. In this paper, we
reviewed and compared some popular ML model explainability methodologies,
especially those related to Natural Language Processing (NLP) models. We then
applied one of the NLP explainability methods Layer-wise Relevance Propagation
(LRP) to a NLP classification model. We used the LRP method to derive a
relevance score for each word in an instance, which is a local explainability.
The relevance scores are then aggregated together to achieve global variable
importance of the model. Through the case study, we also demonstrated how to
apply the local explainability method to false positive and false negative
instances to discover the weakness of a NLP model. These analysis can help us
to understand NLP models better and reduce the risk due to the black-box nature
of NLP models. We also identified some common issues due to the special natures
of NLP models and discussed how explainability analysis can act as a control to
detect these issues after the model has been trained."	ArXiv
926	"An Empirical Survey of Data Augmentation for Limited Data Learning in
  NLP"	['Jiaao Chen', 'Derek Tam', 'Colin Raffel', 'Mohit Bansal', 'Diyi Yang']	2021-06-14 15:27:22+00:00	http://arxiv.org/abs/2106.07499v1	"NLP has achieved great progress in the past decade through the use of neural
models and large labeled datasets. The dependence on abundant data prevents NLP
models from being applied to low-resource settings or novel tasks where
significant time, money, or expertise is required to label massive amounts of
textual data. Recently, data augmentation methods have been explored as a means
of improving data efficiency in NLP. To date, there has been no systematic
empirical overview of data augmentation for NLP in the limited labeled data
setting, making it difficult to understand which methods work in which
settings. In this paper, we provide an empirical survey of recent progress on
data augmentation for NLP in the limited labeled data setting, summarizing the
landscape of methods (including token-level augmentations, sentence-level
augmentations, adversarial augmentations, and hidden-space augmentations) and
carrying out experiments on 11 datasets covering topics/news classification,
inference tasks, paraphrasing tasks, and single-sentence tasks. Based on the
results, we draw several conclusions to help practitioners choose appropriate
augmentations in different settings and discuss the current challenges and
future directions for limited data learning in NLP."	ArXiv
927	"BadPre: Task-agnostic Backdoor Attacks to Pre-trained NLP Foundation
  Models"	['Kangjie Chen', 'Yuxian Meng', 'Xiaofei Sun', 'Shangwei Guo', 'Tianwei Zhang', 'Jiwei Li', 'Chun Fan']	2021-10-06 02:48:58+00:00	http://arxiv.org/abs/2110.02467v1	"Pre-trained Natural Language Processing (NLP) models can be easily adapted to
a variety of downstream language tasks. This significantly accelerates the
development of language models. However, NLP models have been shown to be
vulnerable to backdoor attacks, where a pre-defined trigger word in the input
text causes model misprediction. Previous NLP backdoor attacks mainly focus on
some specific tasks. This makes those attacks less general and applicable to
other kinds of NLP models and tasks. In this work, we propose \Name, the first
task-agnostic backdoor attack against the pre-trained NLP models. The key
feature of our attack is that the adversary does not need prior information
about the downstream tasks when implanting the backdoor to the pre-trained
model. When this malicious model is released, any downstream models transferred
from it will also inherit the backdoor, even after the extensive transfer
learning process. We further design a simple yet effective strategy to bypass a
state-of-the-art defense. Experimental results indicate that our approach can
compromise a wide range of downstream NLP tasks in an effective and stealthy
way."	ArXiv
928	Meta Learning for Natural Language Processing: A Survey	['Hung-yi Lee', 'Shang-Wen Li', 'Ngoc Thang Vu']	2022-05-03 13:58:38+00:00	http://arxiv.org/abs/2205.01500v2	"Deep learning has been the mainstream technique in natural language
processing (NLP) area. However, the techniques require many labeled data and
are less generalizable across domains. Meta-learning is an arising field in
machine learning studying approaches to learn better learning algorithms.
Approaches aim at improving algorithms in various aspects, including data
efficiency and generalizability. Efficacy of approaches has been shown in many
NLP tasks, but there is no systematic survey of these approaches in NLP, which
hinders more researchers from joining the field. Our goal with this survey
paper is to offer researchers pointers to relevant meta-learning works in NLP
and attract more attention from the NLP community to drive future innovation.
This paper first introduces the general concepts of meta-learning and the
common approaches. Then we summarize task construction settings and application
of meta-learning for various NLP problems and review the development of
meta-learning in NLP community."	ArXiv
929	"Differentially Private Natural Language Models: Recent Advances and
  Future Directions"	['Lijie Hu', 'Ivan Habernal', 'Lei Shen', 'Di Wang']	2023-01-22 12:29:03+00:00	http://arxiv.org/abs/2301.09112v2	"Recent developments in deep learning have led to great success in various
natural language processing (NLP) tasks. However, these applications may
involve data that contain sensitive information. Therefore, how to achieve good
performance while also protecting the privacy of sensitive data is a crucial
challenge in NLP. To preserve privacy, Differential Privacy (DP), which can
prevent reconstruction attacks and protect against potential side knowledge, is
becoming a de facto technique for private data analysis. In recent years, NLP
in DP models (DP-NLP) has been studied from different perspectives, which
deserves a comprehensive review. In this paper, we provide the first systematic
review of recent advances in DP deep learning models in NLP. In particular, we
first discuss some differences and additional challenges of DP-NLP compared
with the standard DP deep learning. Then, we investigate some existing work on
DP-NLP and present its recent developments from three aspects: gradient
perturbation based methods, embedding vector perturbation based methods, and
ensemble model based methods. We also discuss some challenges and future
directions."	ArXiv
930	Synthesizing Human Gaze Feedback for Improved NLP Performance	['Varun Khurana', 'Yaman Kumar Singla', 'Nora Hollenstein', 'Rajesh Kumar', 'Balaji Krishnamurthy']	2023-02-11 15:34:23+00:00	http://arxiv.org/abs/2302.05721v1	"Integrating human feedback in models can improve the performance of natural
language processing (NLP) models. Feedback can be either explicit (e.g. ranking
used in training language models) or implicit (e.g. using human cognitive
signals in the form of eyetracking). Prior eye tracking and NLP research reveal
that cognitive processes, such as human scanpaths, gleaned from human gaze
patterns aid in the understanding and performance of NLP models. However, the
collection of real eyetracking data for NLP tasks is challenging due to the
requirement of expensive and precise equipment coupled with privacy invasion
issues. To address this challenge, we propose ScanTextGAN, a novel model for
generating human scanpaths over text. We show that ScanTextGAN-generated
scanpaths can approximate meaningful cognitive signals in human gaze patterns.
We include synthetically generated scanpaths in four popular NLP tasks spanning
six different datasets as proof of concept and show that the models augmented
with generated scanpaths improve the performance of all downstream NLP tasks."	ArXiv
931	On the Origins of Bias in NLP through the Lens of the Jim Code	['Fatma Elsafoury', 'Gavin Abercrombie']	2023-05-16 08:37:13+00:00	http://arxiv.org/abs/2305.09281v1	"In this paper, we trace the biases in current natural language processing
(NLP) models back to their origins in racism, sexism, and homophobia over the
last 500 years. We review literature from critical race theory, gender studies,
data ethics, and digital humanities studies, and summarize the origins of bias
in NLP models from these social science perspective. We show how the causes of
the biases in the NLP pipeline are rooted in social issues. Finally, we argue
that the only way to fix the bias and unfairness in NLP is by addressing the
social problems that caused them in the first place and by incorporating social
sciences and social scientists in efforts to mitigate bias in NLP models. We
provide actionable recommendations for the NLP research community to do so."	ArXiv
932	"Fairness Certification for Natural Language Processing and Large
  Language Models"	['Vincent Freiberger', 'Erik Buchmann']	2024-01-02 16:09:36+00:00	http://arxiv.org/abs/2401.01262v2	"Natural Language Processing (NLP) plays an important role in our daily lives,
particularly due to the enormous progress of Large Language Models (LLM).
However, NLP has many fairness-critical use cases, e.g., as an expert system in
recruitment or as an LLM-based tutor in education. Since NLP is based on human
language, potentially harmful biases can diffuse into NLP systems and produce
unfair results, discriminate against minorities or generate legal issues.
Hence, it is important to develop a fairness certification for NLP approaches.
We follow a qualitative research approach towards a fairness certification for
NLP. In particular, we have reviewed a large body of literature on algorithmic
fairness, and we have conducted semi-structured expert interviews with a wide
range of experts from that area. We have systematically devised six fairness
criteria for NLP, which can be further refined into 18 sub-categories. Our
criteria offer a foundation for operationalizing and testing processes to
certify fairness, both from the perspective of the auditor and the audited
organization."	ArXiv
933	"NLP for Knowledge Discovery and Information Extraction from Energetics
  Corpora"	['Francis G. VanGessel', 'Efrem Perry', 'Salil Mohan', 'Oliver M. Barham', 'Mark Cavolowsky']	2024-02-10 14:43:08+00:00	http://arxiv.org/abs/2402.06964v1	"We present a demonstration of the utility of NLP for aiding research into
energetic materials and associated systems. The NLP method enables machine
understanding of textual data, offering an automated route to knowledge
discovery and information extraction from energetics text. We apply three
established unsupervised NLP models: Latent Dirichlet Allocation, Word2Vec, and
the Transformer to a large curated dataset of energetics-related scientific
articles. We demonstrate that each NLP algorithm is capable of identifying
energetic topics and concepts, generating a language model which aligns with
Subject Matter Expert knowledge. Furthermore, we present a document
classification pipeline for energetics text. Our classification pipeline
achieves 59-76\% accuracy depending on the NLP model used, with the highest
performing Transformer model rivaling inter-annotator agreement metrics. The
NLP approaches studied in this work can identify concepts germane to energetics
and therefore hold promise as a tool for accelerating energetics research
efforts and energetics material development."	ArXiv
934	"NLP-KG: A System for Exploratory Search of Scientific Literature in
  Natural Language Processing"	['Tim Schopf', 'Florian Matthes']	2024-06-21 16:38:22+00:00	http://arxiv.org/abs/2406.15294v2	"Scientific literature searches are often exploratory, whereby users are not
yet familiar with a particular field or concept but are interested in learning
more about it. However, existing systems for scientific literature search are
typically tailored to keyword-based lookup searches, limiting the possibilities
for exploration. We propose NLP-KG, a feature-rich system designed to support
the exploration of research literature in unfamiliar natural language
processing (NLP) fields. In addition to a semantic search, NLP-KG allows users
to easily find survey papers that provide a quick introduction to a field of
interest. Further, a Fields of Study hierarchy graph enables users to
familiarize themselves with a field and its related areas. Finally, a chat
interface allows users to ask questions about unfamiliar concepts or specific
articles in NLP and obtain answers grounded in knowledge retrieved from
scientific publications. Our system provides users with comprehensive
exploration possibilities, supporting them in investigating the relationships
between different fields, understanding unfamiliar concepts in NLP, and finding
relevant research literature. Demo, video, and code are available at:
https://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp."	ArXiv
935	On the Equivalence between Logic Programming and SETAF	['João Alcântara', 'Renan Cordeiro', 'Samy Sá']	2024-07-08 01:03:53+00:00	http://arxiv.org/abs/2407.05538v1	"A framework with sets of attacking arguments (SETAF) is an extension of the
well-known Dung's Abstract Argumentation Frameworks (AAFs) that allows joint
attacks on arguments. In this paper, we provide a translation from Normal Logic
Programs (NLPs) to SETAFs and vice versa, from SETAFs to NLPs. We show that
there is pairwise equivalence between their semantics, including the
equivalence between L-stable and semi-stable semantics. Furthermore, for a
class of NLPs called Redundancy-Free Atomic Logic Programs (RFALPs), there is
also a structural equivalence as these back-and-forth translations are each
other's inverse. Then, we show that RFALPs are as expressive as NLPs by
transforming any NLP into an equivalent RFALP through a series of program
transformations already known in the literature. We also show that these
program transformations are confluent, meaning that every NLP will be
transformed into a unique RFALP. The results presented in this paper enhance
our understanding that NLPs and SETAFs are essentially the same formalism.
Under consideration in Theory and Practice of Logic Programming (TPLP)."	ArXiv
936	Noisy Text Data: Achilles' Heel of popular transformer based NLP models	['Kartikay Bagla', 'Ankit Kumar', 'Shivam Gupta', 'Anuj Gupta']	2021-10-07 11:45:31+00:00	http://arxiv.org/abs/2110.03353v1	"In the last few years, the ML community has created a number of new NLP
models based on transformer architecture. These models have shown great
performance for various NLP tasks on benchmark datasets, often surpassing SOTA
results. Buoyed with this success, one often finds industry practitioners
actively experimenting with fine-tuning these models to build NLP applications
for industry use cases. However, for most datasets that are used by
practitioners to build industrial NLP applications, it is hard to guarantee the
presence of any noise in the data. While most transformer based NLP models have
performed exceedingly well in transferring the learnings from one dataset to
another, it remains unclear how these models perform when fine-tuned on noisy
text. We address the open question by Kumar et al. (2020) to explore the
sensitivity of popular transformer based NLP models to noise in the text data.
We continue working with the noise as defined by them -- spelling mistakes &
typos (which are the most commonly occurring noise). We show (via experimental
results) that these models perform badly on most common NLP tasks namely text
classification, textual similarity, NER, question answering, text summarization
on benchmark datasets. We further show that as the noise in data increases, the
performance degrades. Our findings suggest that one must be vary of the
presence of noise in their datasets while fine-tuning popular transformer based
NLP models."	ArXiv
937	"STAMP 4 NLP -- An Agile Framework for Rapid Quality-Driven NLP
  Applications Development"	['Philipp Kohl', 'Oliver Schmidts', 'Lars Klöser', 'Henri Werth', 'Bodo Kraft', 'Albert Zündorf']	2021-11-16 12:20:47+00:00	http://arxiv.org/abs/2111.08408v1	"The progress in natural language processing (NLP) research over the last
years, offers novel business opportunities for companies, as automated user
interaction or improved data analysis. Building sophisticated NLP applications
requires dealing with modern machine learning (ML) technologies, which impedes
enterprises from establishing successful NLP projects. Our experience in
applied NLP research projects shows that the continuous integration of research
prototypes in production-like environments with quality assurance builds trust
in the software and shows convenience and usefulness regarding the business
goal. We introduce STAMP 4 NLP as an iterative and incremental process model
for developing NLP applications. With STAMP 4 NLP, we merge software
engineering principles with best practices from data science. Instantiating our
process model allows efficiently creating prototypes by utilizing templates,
conventions, and implementations, enabling developers and data scientists to
focus on the business goals. Due to our iterative-incremental approach,
businesses can deploy an enhanced version of the prototype to their software
environment after every iteration, maximizing potential business value and
trust early and avoiding the cost of successful yet never deployed experiments."	ArXiv
938	"From Insights to Actions: The Impact of Interpretability and Analysis
  Research on NLP"	['Marius Mosbach', 'Vagrant Gautam', 'Tomás Vergara-Browne', 'Dietrich Klakow', 'Mor Geva']	2024-06-18 13:45:07+00:00	http://arxiv.org/abs/2406.12618v2	"Interpretability and analysis (IA) research is a growing subfield within NLP
with the goal of developing a deeper understanding of the behavior or inner
workings of NLP systems and methods. Despite growing interest in the subfield,
a criticism of this work is that it lacks actionable insights and therefore has
little impact on NLP. In this paper, we seek to quantify the impact of IA
research on the broader field of NLP. We approach this with a mixed-methods
analysis of: (1) a citation graph of 185K+ papers built from all papers
published at ACL and EMNLP conferences from 2018 to 2023, and their references
and citations, and (2) a survey of 138 members of the NLP community. Our
quantitative results show that IA work is well-cited outside of IA, and central
in the NLP citation graph. Through qualitative analysis of survey responses and
manual annotation of 556 papers, we find that NLP researchers build on findings
from IA work and perceive it as important for progress in NLP, multiple
subfields, and rely on its findings and terminology for their own work. Many
novel methods are proposed based on IA findings and highly influenced by them,
but highly influential non-IA work cites IA findings without being driven by
them. We end by summarizing what is missing in IA work today and provide a call
to action, to pave the way for a more impactful future of IA research."	ArXiv
939	Appendix - Recommended Statistical Significance Tests for NLP Tasks	['Rotem Dror', 'Roi Reichart']	2018-09-05 11:55:05+00:00	http://arxiv.org/abs/1809.01448v1	"Statistical significance testing plays an important role when drawing
conclusions from experimental results in NLP papers. Particularly, it is a
valuable tool when one would like to establish the superiority of one algorithm
over another. This appendix complements the guide for testing statistical
significance in NLP presented in \cite{dror2018hitchhiker} by proposing valid
statistical tests for the common tasks and evaluation measures in the field."	ArXiv
940	Representation Learning for Natural Language Processing	['Zhiyuan Liu', 'Yankai Lin', 'Maosong Sun']	2021-02-07 07:37:07+00:00	http://arxiv.org/abs/2102.03732v1	"This book aims to review and present the recent advances of distributed
representation learning for NLP, including why representation learning can
improve NLP, how representation learning takes part in various important topics
of NLP, and what challenges are still not well addressed by distributed
representation."	ArXiv
941	Efficient transfer learning for NLP with ELECTRA	['François Mercier']	2021-04-06 19:34:36+00:00	http://arxiv.org/abs/2104.02756v1	"Clark et al. [2020] claims that the ELECTRA approach is highly efficient in
NLP performances relative to computation budget. As such, this reproducibility
study focus on this claim, summarized by the following question: Can we use
ELECTRA to achieve close to SOTA performances for NLP in low-resource settings,
in term of compute cost?"	ArXiv
942	Applied Language Technology: NLP for the Humanities	['Tuomo Hiippala']	2021-05-03 17:51:17+00:00	http://arxiv.org/abs/2105.01052v1	"This contribution describes a two-course module that seeks to provide
humanities majors with a basic understanding of language technology and its
applications using Python. The learning materials consist of interactive
Jupyter Notebooks and accompanying YouTube videos, which are openly available
with a Creative Commons licence."	ArXiv
943	"Evaluating neural network explanation methods using hybrid documents and
  morphological agreement"	['Nina Poerner', 'Benjamin Roth', 'Hinrich Schütze']	2018-01-19 14:41:45+00:00	http://arxiv.org/abs/1801.06422v3	"The behavior of deep neural networks (DNNs) is hard to understand. This makes
it necessary to explore post hoc explanation methods. We conduct the first
comprehensive evaluation of explanation methods for NLP. To this end, we design
two novel evaluation paradigms that cover two important classes of NLP
problems: small context and large context problems. Both paradigms require no
manual annotation and are therefore broadly applicable. We also introduce
LIMSSE, an explanation method inspired by LIME that is designed for NLP. We
show empirically that LIMSSE, LRP and DeepLIFT are the most effective
explanation methods and recommend them for explaining DNNs in NLP."	ArXiv
944	"What is SemEval evaluating? A Systematic Analysis of Evaluation
  Campaigns in NLP"	['Oskar Wysocki', 'Malina Florea', 'Andre Freitas']	2020-05-28 21:17:43+00:00	http://arxiv.org/abs/2005.14299v1	"SemEval is the primary venue in the NLP community for the proposal of new
challenges and for the systematic empirical evaluation of NLP systems. This
paper provides a systematic quantitative analysis of SemEval aiming to evidence
the patterns of the contributions behind SemEval. By understanding the
distribution of task types, metrics, architectures, participation and citations
over time we aim to answer the question on what is being evaluated by SemEval."	ArXiv
945	"Natural Language Processing: State of The Art, Current Trends and
  Challenges"	['Diksha Khurana', 'Aditya Koli', 'Kiran Khatter', 'Sukhdev Singh']	2017-08-17 06:42:03+00:00	http://arxiv.org/abs/1708.05148v1	"Natural language processing (NLP) has recently gained much attention for
representing and analysing human language computationally. It has spread its
applications in various fields such as machine translation, email spam
detection, information extraction, summarization, medical, and question
answering etc. The paper distinguishes four phases by discussing different
levels of NLP and components of Natural Language Generation (NLG) followed by
presenting the history and evolution of NLP, state of the art presenting the
various applications of NLP and current trends and challenges."	ArXiv
946	"Towards Linguistically Generalizable NLP Systems: A Workshop and Shared
  Task"	['Allyson Ettinger', 'Sudha Rao', 'Hal Daumé III', 'Emily M. Bender']	2017-11-04 22:46:54+00:00	http://arxiv.org/abs/1711.01505v1	"This paper presents a summary of the first Workshop on Building
Linguistically Generalizable Natural Language Processing Systems, and the
associated Build It Break It, The Language Edition shared task. The goal of
this workshop was to bring together researchers in NLP and linguistics with a
shared task aimed at testing the generalizability of NLP systems beyond the
distributions of their training data. We describe the motivation, setup, and
participation of the shared task, provide discussion of some highlighted
results, and discuss lessons learned."	ArXiv
947	Quantifying Reproducibility in NLP and ML	['Anya Belz']	2021-09-02 21:00:17+00:00	http://arxiv.org/abs/2109.01211v1	"Reproducibility has become an intensely debated topic in NLP and ML over
recent years, but no commonly accepted way of assessing reproducibility, let
alone quantifying it, has so far emerged. The assumption has been that wider
scientific reproducibility terminology and definitions are not applicable to
NLP/ML, with the result that many different terms and definitions have been
proposed, some diametrically opposed. In this paper, we test this assumption,
by taking the standard terminology and definitions from metrology and applying
them directly to NLP/ML. We find that we are able to straightforwardly derive a
practical framework for assessing reproducibility which has the desirable
property of yielding a quantified degree of reproducibility that is comparable
across different reproduction studies."	ArXiv
948	Comparative Study of CNN and RNN for Natural Language Processing	['Wenpeng Yin', 'Katharina Kann', 'Mo Yu', 'Hinrich Schütze']	2017-02-07 08:33:35+00:00	http://arxiv.org/abs/1702.01923v1	"Deep neural networks (DNN) have revolutionized the field of natural language
processing (NLP). Convolutional neural network (CNN) and recurrent neural
network (RNN), the two main types of DNN architectures, are widely explored to
handle various NLP tasks. CNN is supposed to be good at extracting
position-invariant features and RNN at modeling units in sequence. The state of
the art on many NLP tasks often switches due to the battle between CNNs and
RNNs. This work is the first systematic comparison of CNN and RNN on a wide
range of representative NLP tasks, aiming to give basic guidance for DNN
selection."	ArXiv
949	autoNLP: NLP Feature Recommendations for Text Analytics Applications	['Janardan Misra']	2020-02-08 00:42:21+00:00	http://arxiv.org/abs/2002.03056v1	"While designing machine learning based text analytics applications, often,
NLP data scientists manually determine which NLP features to use based upon
their knowledge and experience with related problems. This results in increased
efforts during feature engineering process and renders automated reuse of
features across semantically related applications inherently difficult. In this
paper, we argue for standardization in feature specification by outlining
structure of a language for specifying NLP features and present an approach for
their reuse across applications to increase likelihood of identifying optimal
features."	ArXiv
950	Methods for the Design and Evaluation of HCI+NLP Systems	['Hendrik Heuer', 'Daniel Buschek']	2021-02-26 13:37:10+00:00	http://arxiv.org/abs/2102.13461v1	"HCI and NLP traditionally focus on different evaluation methods. While HCI
involves a small number of people directly and deeply, NLP traditionally relies
on standardized benchmark evaluations that involve a larger number of people
indirectly. We present five methodological proposals at the intersection of HCI
and NLP and situate them in the context of ML-based NLP models. Our goal is to
foster interdisciplinary collaboration and progress in both fields by
emphasizing what the fields can learn from each other."	ArXiv
951	A dissemination workshop for introducing young Italian students to NLP	['Lucio Messina', 'Lucia Busso', 'Claudia Roberta Combei', 'Ludovica Pannitto', 'Alessio Miaschi', 'Gabriele Sarti', 'Malvina Nissim']	2021-04-26 09:00:56+00:00	http://arxiv.org/abs/2104.12405v2	"We describe and make available the game-based material developed for a
laboratory run at several Italian science festivals to popularize NLP among
young students."	ArXiv
952	Introducing Information Retrieval for Biomedical Informatics Students	['Sanya B. Taneja', 'Richard D. Boyce', 'William T. Reynolds', 'Denis Newman-Griffis']	2021-05-06 15:15:54+00:00	http://arxiv.org/abs/2105.02746v1	"Introducing biomedical informatics (BMI) students to natural language
processing (NLP) requires balancing technical depth with practical know-how to
address application-focused needs. We developed a set of three activities
introducing introductory BMI students to information retrieval with NLP,
covering document representation strategies and language models from TF-IDF to
BERT. These activities provide students with hands-on experience targeted
towards common use cases, and introduce fundamental components of NLP workflows
for a wide variety of applications."	ArXiv
953	End-to-End NLP Knowledge Graph Construction	['Ishani Mondal', 'Yufang Hou', 'Charles Jochim']	2021-06-02 14:03:06+00:00	http://arxiv.org/abs/2106.01167v1	"This paper studies the end-to-end construction of an NLP Knowledge Graph (KG)
from scientific papers. We focus on extracting four types of relations:
evaluatedOn between tasks and datasets, evaluatedBy between tasks and
evaluation metrics, as well as coreferent and related relations between the
same type of entities. For instance, F1-score is coreferent with F-measure. We
introduce novel methods for each of these relation types and apply our final
framework (SciNLP-KG) to 30,000 NLP papers from ACL Anthology to build a
large-scale KG, which can facilitate automatically constructing scientific
leaderboards for the NLP community. The results of our experiments indicate
that the resulting KG contains high-quality information."	ArXiv
954	The Role of Explanatory Value in Natural Language Processing	['Kees van Deemter']	2022-09-13 17:19:04+00:00	http://arxiv.org/abs/2209.06169v1	"A key aim of science is explanation, yet the idea of explaining language
phenomena has taken a backseat in mainstream Natural Language Processing (NLP)
and many other areas of Artificial Intelligence. I argue that explanation of
linguistic behaviour should be a main goal of NLP, and that this is not the
same as making NLP models explainable. To illustrate these ideas, some recent
models of human language production are compared with each other. I conclude by
asking what it would mean for NLP research and institutional policies if our
community took explanatory value seriously, while heeding some possible
pitfalls."	ArXiv
955	calamanCy: A Tagalog Natural Language Processing Toolkit	['Lester James V. Miranda']	2023-11-13 09:06:43+00:00	http://arxiv.org/abs/2311.07171v1	"We introduce calamanCy, an open-source toolkit for constructing natural
language processing (NLP) pipelines for Tagalog. It is built on top of spaCy,
enabling easy experimentation and integration with other frameworks. calamanCy
addresses the development gap by providing a consistent API for building NLP
applications and offering general-purpose multitask models with out-of-the-box
support for dependency parsing, parts-of-speech (POS) tagging, and named entity
recognition (NER). calamanCy aims to accelerate the progress of Tagalog NLP by
consolidating disjointed resources in a unified framework. The calamanCy
toolkit is available on GitHub: https://github.com/ljvmiranda921/calamanCy."	ArXiv
956	"Culturally Aware and Adapted NLP: A Taxonomy and a Survey of the State
  of the Art"	['Chen Cecilia Liu', 'Iryna Gurevych', 'Anna Korhonen']	2024-06-06 10:16:43+00:00	http://arxiv.org/abs/2406.03930v1	"The surge of interest in culturally aware and adapted Natural Language
Processing (NLP) has inspired much recent research. However, the lack of common
understanding of the concept of ""culture"" has made it difficult to evaluate
progress in this emerging area. Drawing on prior research in NLP and related
fields, we propose an extensive taxonomy of elements of culture that can
provide a systematic framework for analyzing and understanding research
progress. Using the taxonomy, we survey existing resources and models for
culturally aware and adapted NLP, providing an overview of the state of the art
and the research gaps that still need to be filled."	ArXiv
957	NLP for The Greek Language: A Longer Survey	['Katerina Papantoniou', 'Yannis Tzitzikas']	2024-08-20 15:57:18+00:00	http://arxiv.org/abs/2408.10962v1	"English language is in the spotlight of the Natural Language Processing (NLP)
community with other languages, like Greek, lagging behind in terms of offered
methods, tools and resources. Due to the increasing interest in NLP, in this
paper we try to condense research efforts for the automatic processing of Greek
language covering the last three decades. In particular, we list and briefly
discuss related works, resources and tools, categorized according to various
processing layers and contexts. We are not restricted to the modern form of
Greek language but also cover Ancient Greek and various Greek dialects. This
survey can be useful for researchers and students interested in NLP tasks,
Information Retrieval and Knowledge Management for the Greek language."	ArXiv
958	"Improving the robustness and accuracy of biomedical language models
  through adversarial training"	['Milad Moradi', 'Matthias Samwald']	2021-11-16 14:58:05+00:00	http://arxiv.org/abs/2111.08529v1	"Deep transformer neural network models have improved the predictive accuracy
of intelligent text processing systems in the biomedical domain. They have
obtained state-of-the-art performance scores on a wide variety of biomedical
and clinical Natural Language Processing (NLP) benchmarks. However, the
robustness and reliability of these models has been less explored so far.
Neural NLP models can be easily fooled by adversarial samples, i.e. minor
changes to input that preserve the meaning and understandability of the text
but force the NLP system to make erroneous decisions. This raises serious
concerns about the security and trust-worthiness of biomedical NLP systems,
especially when they are intended to be deployed in real-world use cases. We
investigated the robustness of several transformer neural language models, i.e.
BioBERT, SciBERT, BioMed-RoBERTa, and Bio-ClinicalBERT, on a wide range of
biomedical and clinical text processing tasks. We implemented various
adversarial attack methods to test the NLP systems in different attack
scenarios. Experimental results showed that the biomedical NLP models are
sensitive to adversarial samples; their performance dropped in average by 21
and 18.9 absolute percent on character-level and word-level adversarial noise,
respectively. Conducting extensive adversarial training experiments, we
fine-tuned the NLP models on a mixture of clean samples and adversarial inputs.
Results showed that adversarial training is an effective defense mechanism
against adversarial noise; the models robustness improved in average by 11.3
absolute percent. In addition, the models performance on clean data increased
in average by 2.4 absolute present, demonstrating that adversarial training can
boost generalization abilities of biomedical NLP systems."	ArXiv
959	SemEval-2023 Task 11: Learning With Disagreements (LeWiDi)	['Elisa Leonardelli', 'Alexandra Uma', 'Gavin Abercrombie', 'Dina Almanea', 'Valerio Basile', 'Tommaso Fornaciari', 'Barbara Plank', 'Verena Rieser', 'Massimo Poesio']	2023-04-28 12:20:35+00:00	http://arxiv.org/abs/2304.14803v1	"NLP datasets annotated with human judgments are rife with disagreements
between the judges. This is especially true for tasks depending on subjective
judgments such as sentiment analysis or offensive language detection.
Particularly in these latter cases, the NLP community has come to realize that
the approach of 'reconciling' these different subjective interpretations is
inappropriate. Many NLP researchers have therefore concluded that rather than
eliminating disagreements from annotated corpora, we should preserve
them-indeed, some argue that corpora should aim to preserve all annotator
judgments. But this approach to corpus creation for NLP has not yet been widely
accepted. The objective of the LeWiDi series of shared tasks is to promote this
approach to developing NLP models by providing a unified framework for training
and evaluating with such datasets. We report on the second LeWiDi shared task,
which differs from the first edition in three crucial respects: (i) it focuses
entirely on NLP, instead of both NLP and computer vision tasks in its first
edition; (ii) it focuses on subjective tasks, instead of covering different
types of disagreements-as training with aggregated labels for subjective NLP
tasks is a particularly obvious misrepresentation of the data; and (iii) for
the evaluation, we concentrate on soft approaches to evaluation. This second
edition of LeWiDi attracted a wide array of participants resulting in 13 shared
task submission papers."	ArXiv
960	"ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for
  Verification"	['Marco Casadio', 'Luca Arnaboldi', 'Matthew L. Daggitt', 'Omri Isac', 'Tanvi Dinkar', 'Daniel Kienitz', 'Verena Rieser', 'Ekaterina Komendantskaya']	2023-05-06 10:36:39+00:00	http://arxiv.org/abs/2305.04003v3	"Verification of machine learning models used in Natural Language Processing
(NLP) is known to be a hard problem. In particular, many known neural network
verification methods that work for computer vision and other numeric datasets
do not work for NLP. Here, we study technical reasons that underlie this
problem. Based on this analysis, we propose practical methods and heuristics
for preparing NLP datasets and models in a way that renders them amenable to
known verification methods based on abstract interpretation. We implement these
methods as a Python library called ANTONIO that links to the neural network
verifiers ERAN and Marabou. We perform evaluation of the tool using an NLP
dataset R-U-A-Robot suggested as a benchmark for verifying legally critical NLP
applications. We hope that, thanks to its general applicability, this work will
open novel possibilities for including NLP verification problems into neural
network verification competitions, and will popularise NLP problems within this
community."	ArXiv
961	"MatSci-NLP: Evaluating Scientific Language Models on Materials Science
  Language Tasks Using Text-to-Schema Modeling"	['Yu Song', 'Santiago Miret', 'Bang Liu']	2023-05-14 22:01:24+00:00	http://arxiv.org/abs/2305.08264v1	"We present MatSci-NLP, a natural language benchmark for evaluating the
performance of natural language processing (NLP) models on materials science
text. We construct the benchmark from publicly available materials science text
data to encompass seven different NLP tasks, including conventional NLP tasks
like named entity recognition and relation classification, as well as NLP tasks
specific to materials science, such as synthesis action retrieval which relates
to creating synthesis procedures for materials. We study various BERT-based
models pretrained on different scientific text corpora on MatSci-NLP to
understand the impact of pretraining strategies on understanding materials
science text. Given the scarcity of high-quality annotated data in the
materials science domain, we perform our fine-tuning experiments with limited
training data to encourage the generalize across MatSci-NLP tasks. Our
experiments in this low-resource training setting show that language models
pretrained on scientific text outperform BERT trained on general text. MatBERT,
a model pretrained specifically on materials science journals, generally
performs best for most tasks. Moreover, we propose a unified text-to-schema for
multitask learning on \benchmark and compare its performance with traditional
fine-tuning methods. In our analysis of different training methods, we find
that our proposed text-to-schema methods inspired by question-answering
consistently outperform single and multitask NLP fine-tuning methods. The code
and datasets are publicly available at
\url{https://github.com/BangLab-UdeM-Mila/NLP4MatSci-ACL23}."	ArXiv
962	"Survey of Natural Language Processing for Education: Taxonomy,
  Systematic Review, and Future Trends"	['Yunshi Lan', 'Xinyuan Li', 'Hanyue Du', 'Xuesong Lu', 'Ming Gao', 'Weining Qian', 'Aoying Zhou']	2024-01-15 07:48:42+00:00	http://arxiv.org/abs/2401.07518v3	"Natural Language Processing (NLP) aims to analyze text or speech via
techniques in the computer science field. It serves the applications in domains
of healthcare, commerce, education and so on. Particularly, NLP has been widely
applied to the education domain and its applications have enormous potential to
help teaching and learning. In this survey, we review recent advances in NLP
with the focus on solving problems relevant to the education domain. In detail,
we begin with introducing the related background and the real-world scenarios
in education where NLP techniques could contribute. Then, we present a taxonomy
of NLP in the education domain and highlight typical NLP applications including
question answering, question construction, automated assessment, and error
correction. Next, we illustrate the task definition, challenges, and
corresponding cutting-edge techniques based on the above taxonomy. In
particular, LLM-involved methods are included for discussion due to the wide
usage of LLMs in diverse NLP applications. After that, we showcase some
off-the-shelf demonstrations in this domain. At last, we conclude with six
promising directions for future research, including more datasets in education
domain, controllable usage of LLMs, intervention of difficulty-level control,
interpretable educational NLP, methods with adaptive learning, and integrated
systems for education. We organize all relevant datasets and papers in the
open-available Github Link for better
review~\url{https://github.com/LiXinyuan1015/NLP-for-Education}."	ArXiv
963	The Radiation Oncology NLP Database	['Zhengliang Liu', 'Jason Holmes', 'Wenxiong Liao', 'Chenbin Liu', 'Lian Zhang', 'Hongying Feng', 'Peilong Wang', 'Muhammad Ali Elahi', 'Hongmin Cai', 'Lichao Sun', 'Quanzheng Li', 'Xiang Li', 'Tianming Liu', 'Jiajian Shen', 'Wei Liu']	2024-01-19 19:23:37+00:00	http://arxiv.org/abs/2401.10995v1	"We present the Radiation Oncology NLP Database (ROND), the first dedicated
Natural Language Processing (NLP) dataset for radiation oncology, an important
medical specialty that has received limited attention from the NLP community in
the past. With the advent of Artificial General Intelligence (AGI), there is an
increasing need for specialized datasets and benchmarks to facilitate research
and development. ROND is specifically designed to address this gap in the
domain of radiation oncology, a field that offers many opportunities for NLP
exploration. It encompasses various NLP tasks including Logic Reasoning, Text
Classification, Named Entity Recognition (NER), Question Answering (QA), Text
Summarization, and Patient-Clinician Conversations, each with a distinct focus
on radiation oncology concepts and application cases. In addition, we have
developed an instruction-tuning dataset consisting of over 20k instruction
pairs (based on ROND) and trained a large language model, CancerChat. This
serves to demonstrate the potential of instruction-tuning large language models
within a highly-specialized medical domain. The evaluation results in this
study could serve as baseline results for future research. ROND aims to
stimulate advancements in radiation oncology and clinical NLP by offering a
platform for testing and improving algorithms and models in a domain-specific
context. The ROND dataset is a joint effort of multiple U.S. health
institutions. The data is available at
https://github.com/zl-liu/Radiation-Oncology-NLP-Database."	ArXiv
964	"The Pitfalls of Publishing in the Age of LLMs: Strange and Surprising
  Adventures with a High-Impact NLP Journal"	['Rakesh M. Verma', 'Nachum Dershowitz']	2024-06-28 10:58:42+00:00	http://arxiv.org/abs/2407.12026v1	"We show the fraught side of the academic publishing realm and illustrate it
through a recent case study with an NLP journal."	ArXiv
965	State of NLP in Kenya: A Survey	"['Cynthia Jayne Amol', 'Everlyn Asiko Chimoto', 'Rose Delilah Gesicho', 'Antony M. Gitau', 'Naome A. Etori', 'Caringtone Kinyanjui', ""Steven Ndung'u"", 'Lawrence Moruye', 'Samson Otieno Ooko', 'Kavengi Kitonga', 'Brian Muhia', 'Catherine Gitau', 'Antony Ndolo', 'Lilian D. A. Wanzare', 'Albert Njoroge Kahira', 'Ronald Tombe']"	2024-10-13 18:08:24+00:00	http://arxiv.org/abs/2410.09948v1	"Kenya, known for its linguistic diversity, faces unique challenges and
promising opportunities in advancing Natural Language Processing (NLP)
technologies, particularly for its underrepresented indigenous languages. This
survey provides a detailed assessment of the current state of NLP in Kenya,
emphasizing ongoing efforts in dataset creation, machine translation, sentiment
analysis, and speech recognition for local dialects such as Kiswahili, Dholuo,
Kikuyu, and Luhya. Despite these advancements, the development of NLP in Kenya
remains constrained by limited resources and tools, resulting in the
underrepresentation of most indigenous languages in digital spaces. This paper
uncovers significant gaps by critically evaluating the available datasets and
existing NLP models, most notably the need for large-scale language models and
the insufficient digital representation of Indigenous languages. We also
analyze key NLP applications: machine translation, information retrieval, and
sentiment analysis-examining how they are tailored to address local linguistic
needs. Furthermore, the paper explores the governance, policies, and
regulations shaping the future of AI and NLP in Kenya and proposes a strategic
roadmap to guide future research and development efforts. Our goal is to
provide a foundation for accelerating the growth of NLP technologies that meet
Kenya's diverse linguistic demands."	ArXiv
966	"Natural Language Processing for Analyzing Electronic Health Records and
  Clinical Notes in Cancer Research: A Review"	['Muhammad Bilal', 'Ameer Hamza', 'Nadia Malik']	2024-10-29 16:17:07+00:00	http://arxiv.org/abs/2410.22180v1	"Objective: This review aims to analyze the application of natural language
processing (NLP) techniques in cancer research using electronic health records
(EHRs) and clinical notes. This review addresses gaps in the existing
literature by providing a broader perspective than previous studies focused on
specific cancer types or applications. Methods: A comprehensive literature
search was conducted using the Scopus database, identifying 94 relevant studies
published between 2019 and 2024. Data extraction included study
characteristics, cancer types, NLP methodologies, dataset information,
performance metrics, challenges, and future directions. Studies were
categorized based on cancer types and NLP applications. Results: The results
showed a growing trend in NLP applications for cancer research, with breast,
lung, and colorectal cancers being the most studied. Information extraction and
text classification emerged as predominant NLP tasks. A shift from rule-based
to advanced machine learning techniques, particularly transformer-based models,
was observed. The Dataset sizes used in existing studies varied widely. Key
challenges included the limited generalizability of proposed solutions and the
need for improved integration into clinical workflows. Conclusion: NLP
techniques show significant potential in analyzing EHRs and clinical notes for
cancer research. However, future work should focus on improving model
generalizability, enhancing robustness in handling complex clinical language,
and expanding applications to understudied cancer types. Integration of NLP
tools into clinical practice and addressing ethical considerations remain
crucial for utilizing the full potential of NLP in enhancing cancer diagnosis,
treatment, and patient outcomes."	ArXiv
967	"Natural Language Processing in Biomedicine: A Unified System
  Architecture Overview"	['Son Doan', 'Mike Conway', 'Tu Minh Phuong', 'Lucila Ohno-Machado']	2014-01-03 00:57:13+00:00	http://arxiv.org/abs/1401.0569v2	"In modern electronic medical records (EMR) much of the clinically important
data - signs and symptoms, symptom severity, disease status, etc. - are not
provided in structured data fields, but rather are encoded in clinician
generated narrative text. Natural language processing (NLP) provides a means of
""unlocking"" this important data source for applications in clinical decision
support, quality assurance, and public health. This chapter provides an
overview of representative NLP systems in biomedicine based on a unified
architectural view. A general architecture in an NLP system consists of two
main components: background knowledge that includes biomedical knowledge
resources and a framework that integrates NLP tools to process text. Systems
differ in both components, which we will review briefly. Additionally,
challenges facing current research efforts in biomedical NLP include the
paucity of large, publicly available annotated corpora, although initiatives
that facilitate data sharing, system evaluation, and collaborative work between
researchers in clinical NLP are starting to emerge."	ArXiv
968	The NLP Engine: A Universal Turing Machine for NLP	['Jiwei Li', 'Eduard Hovy']	2015-02-28 19:46:50+00:00	http://arxiv.org/abs/1503.00168v1	"It is commonly accepted that machine translation is a more complex task than
part of speech tagging. But how much more complex? In this paper we make an
attempt to develop a general framework and methodology for computing the
informational and/or processing complexity of NLP applications and tasks. We
define a universal framework akin to a Turning Machine that attempts to fit
(most) NLP tasks into one paradigm. We calculate the complexities of various
NLP tasks using measures of Shannon Entropy, and compare `simple' ones such as
part of speech tagging to `complex' ones such as machine translation. This
paper provides a first, though far from perfect, attempt to quantify NLP tasks
under a uniform paradigm. We point out current deficiencies and suggest some
avenues for fruitful research."	ArXiv
969	The Interplay between Lexical Resources and Natural Language Processing	['Jose Camacho-Collados', 'Luis Espinosa-Anke', 'Mohammad Taher Pilehvar']	2018-07-02 09:53:50+00:00	http://arxiv.org/abs/1807.00571v1	"Incorporating linguistic, world and common sense knowledge into AI/NLP
systems is currently an important research area, with several open problems and
challenges. At the same time, processing and storing this knowledge in lexical
resources is not a straightforward task. This tutorial proposes to address
these complementary goals from two methodological perspectives: the use of NLP
methods to help the process of constructing and enriching lexical resources and
the use of lexical resources for improving NLP applications. Two main types of
audience can benefit from this tutorial: those working on language resources
who are interested in becoming acquainted with automatic NLP techniques, with
the end goal of speeding and/or easing up the process of resource curation; and
on the other hand, researchers in NLP who would like to benefit from the
knowledge of lexical resources to improve their systems and models. The slides
of the tutorial are available at https://bitbucket.org/luisespinosa/lr-nlp/"	ArXiv
970	"Next-to-leading power threshold effects for inclusive and exclusive
  processes with final state jets"	['Melissa van Beekveld', 'Wim Beenakker', 'Eric Laenen', 'Chris D. White']	2019-05-21 16:37:36+00:00	http://arxiv.org/abs/1905.08741v1	"It is well known that cross-sections in perturbative QCD receive large
corrections from soft and collinear radiation, whose properties must be
resummed to all orders in the coupling. Whether or not the universal properties
of this radiation can be extended to next-to-leading power (NLP) in the
threshold expansion has been the subject of much recent study. In this paper,
we consider two types of NLP effects: the interplay of next-to-soft and
collinear radiation in processes with final state jets and the NLP
contributions stemming from soft quarks. We derive an NLP amplitude for soft
gluons and quarks, valid for an arbitrary number of coloured or colourless
massless final state particles. We show explicitly that this framework can be
used to correctly obtain the dominant NLP effects in three different types of
processes at next-to-leading order: deep-inelastic scattering, hadroproduction
via electron-positron annihilation and prompt photon production. Our results
provide an important ingredient for developing a universal resummation
formalism for NLP effects."	ArXiv
971	"Lithium NLP: A System for Rich Information Extraction from Noisy User
  Generated Text on Social Media"	['Preeti Bhargava', 'Nemanja Spasojevic', 'Guoning Hu']	2017-07-13 17:52:51+00:00	http://arxiv.org/abs/1707.04244v1	"In this paper, we describe the Lithium Natural Language Processing (NLP)
system - a resource-constrained, high- throughput and language-agnostic system
for information extraction from noisy user generated text on social media.
Lithium NLP extracts a rich set of information including entities, topics,
hashtags and sentiment from text. We discuss several real world applications of
the system currently incorporated in Lithium products. We also compare our
system with existing commercial and academic NLP systems in terms of
performance, information extracted and languages supported. We show that
Lithium NLP is at par with and in some cases, outperforms state- of-the-art
commercial NLP systems."	ArXiv
972	"Is Machine Learning Speaking my Language? A Critical Look at the
  NLP-Pipeline Across 8 Human Languages"	['Esma Wali', 'Yan Chen', 'Christopher Mahoney', 'Thomas Middleton', 'Marzieh Babaeianjelodar', 'Mariama Njie', 'Jeanna Neefe Matthews']	2020-07-11 22:56:37+00:00	http://arxiv.org/abs/2007.05872v1	"Natural Language Processing (NLP) is increasingly used as a key ingredient in
critical decision-making systems such as resume parsers used in sorting a list
of job candidates. NLP systems often ingest large corpora of human text,
attempting to learn from past human behavior and decisions in order to produce
systems that will make recommendations about our future world. Over 7000 human
languages are being spoken today and the typical NLP pipeline underrepresents
speakers of most of them while amplifying the voices of speakers of other
languages. In this paper, a team including speakers of 8 languages - English,
Chinese, Urdu, Farsi, Arabic, French, Spanish, and Wolof - takes a critical
look at the typical NLP pipeline and how even when a language is technically
supported, substantial caveats remain to prevent full participation. Despite
huge and admirable investments in multilingual support in many tools and
resources, we are still making NLP-guided decisions that systematically and
dramatically underrepresent the voices of much of the world."	ArXiv
973	"Next-to-leading power threshold corrections for finite order and
  resummed colour-singlet cross sections"	['Melissa van Beekveld', 'Eric Laenen', 'Jort Sinninghe Damsté', 'Leonardo Vernazza']	2021-01-18 19:00:01+00:00	http://arxiv.org/abs/2101.07270v1	"We study next-to-leading-power (NLP) threshold corrections in colour-singlet
production processes, with particular emphasis on Drell-Yan (DY) and
single-Higgs production. We assess the quality of the partonic and hadronic
threshold expansions for each process up to NNLO. We determine numerically the
NLP leading-logarithmic (LL) resummed contribution in addition to the
leading-power next-to-next-to-leading logarithmic (LP NNLL) resummed DY and
Higgs cross sections, matched to NNLO. We find that the inclusion of NLP
logarithms is numerically more relevant than increasing the precision to
N$^3$LL at LP for these processes. We also perform an analytical and numerical
comparison of LP NNLL + NLP LL resummation in soft-collinear effective theory
and direct QCD, where we achieve excellent analytical and numerical agreement
once the NLP LL terms are included in both formalisms. Our results underline
the phenomenological importance of understanding the NLP structure of QCD cross
sections."	ArXiv
974	Putting Humans in the Natural Language Processing Loop: A Survey	['Zijie J. Wang', 'Dongjin Choi', 'Shenyu Xu', 'Diyi Yang']	2021-03-06 06:26:00+00:00	http://arxiv.org/abs/2103.04044v1	"How can we design Natural Language Processing (NLP) systems that learn from
human feedback? There is a growing research body of Human-in-the-loop (HITL)
NLP frameworks that continuously integrate human feedback to improve the model
itself. HITL NLP research is nascent but multifarious -- solving various NLP
problems, collecting diverse feedback from different people, and applying
different methods to learn from collected feedback. We present a survey of HITL
NLP work from both Machine Learning (ML) and Human-Computer Interaction (HCI)
communities that highlights its short yet inspiring history, and thoroughly
summarize recent frameworks focusing on their tasks, goals, human interactions,
and feedback learning methods. Finally, we discuss future directions for
integrating human feedback in the NLP development loop."	ArXiv
975	Preregistering NLP Research	['Emiel van Miltenburg', 'Chris van der Lee', 'Emiel Krahmer']	2021-03-11 20:44:31+00:00	http://arxiv.org/abs/2103.06944v2	"Preregistration refers to the practice of specifying what you are going to
do, and what you expect to find in your study, before carrying out the study.
This practice is increasingly common in medicine and psychology, but is rarely
discussed in NLP. This paper discusses preregistration in more detail, explores
how NLP researchers could preregister their work, and presents several
preregistration questions for different kinds of studies. Finally, we argue in
favour of registered reports, which could provide firmer grounds for slow
science in NLP research. The goal of this paper is to elicit a discussion in
the NLP community, which we hope to synthesise into a general NLP
preregistration form in future research."	ArXiv
976	"A Survey of Methods for Addressing Class Imbalance in Deep-Learning
  Based Natural Language Processing"	['Sophie Henning', 'William Beluch', 'Alexander Fraser', 'Annemarie Friedrich']	2022-10-10 13:26:40+00:00	http://arxiv.org/abs/2210.04675v2	"Many natural language processing (NLP) tasks are naturally imbalanced, as
some target categories occur much more frequently than others in the real
world. In such scenarios, current NLP models still tend to perform poorly on
less frequent classes. Addressing class imbalance in NLP is an active research
topic, yet, finding a good approach for a particular task and imbalance
scenario is difficult.
  With this survey, the first overview on class imbalance in deep-learning
based NLP, we provide guidance for NLP researchers and practitioners dealing
with imbalanced data. We first discuss various types of controlled and
real-world class imbalance. Our survey then covers approaches that have been
explicitly proposed for class-imbalanced NLP tasks or, originating in the
computer vision community, have been evaluated on them. We organize the methods
by whether they are based on sampling, data augmentation, choice of loss
function, staged learning, or model design. Finally, we discuss open problems
such as dealing with multi-label scenarios, and propose systematic benchmarking
and reporting in order to move forward on this problem as a community."	ArXiv
977	TextAttack: Lessons learned in designing Python frameworks for NLP	['John X. Morris', 'Jin Yong Yoo', 'Yanjun Qi']	2020-10-05 00:23:00+00:00	http://arxiv.org/abs/2010.01724v1	"TextAttack is an open-source Python toolkit for adversarial attacks,
adversarial training, and data augmentation in NLP. TextAttack unites 15+
papers from the NLP adversarial attack literature into a single framework, with
many components reused across attacks. This framework allows both researchers
and developers to test and study the weaknesses of their NLP models. To build
such an open-source NLP toolkit requires solving some common problems: How do
we enable users to supply models from different deep learning frameworks? How
can we build tools to support as many different datasets as possible? We share
our insights into developing a well-written, well-documented NLP Python
framework in hope that they can aid future development of similar packages."	ArXiv
978	Low-Resource Adaptation of Neural NLP Models	['Farhad Nooralahzadeh']	2020-11-09 12:13:55+00:00	http://arxiv.org/abs/2011.04372v1	"Real-world applications of natural language processing (NLP) are challenging.
NLP models rely heavily on supervised machine learning and require large
amounts of annotated data. These resources are often based on language data
available in large quantities, such as English newswire. However, in real-world
applications of NLP, the textual resources vary across several dimensions, such
as language, dialect, topic, and genre. It is challenging to find annotated
data of sufficient amount and quality. The objective of this thesis is to
investigate methods for dealing with such low-resource scenarios in information
extraction and natural language understanding. To this end, we study distant
supervision and sequential transfer learning in various low-resource settings.
We develop and adapt neural NLP models to explore a number of research
questions concerning NLP tasks with minimal or no training data."	ArXiv
979	Natural Language Processing for Smart Healthcare	['Binggui Zhou', 'Guanghua Yang', 'Zheng Shi', 'Shaodan Ma']	2021-10-19 02:48:44+00:00	http://arxiv.org/abs/2110.15803v3	"Smart healthcare has achieved significant progress in recent years. Emerging
artificial intelligence (AI) technologies enable various smart applications
across various healthcare scenarios. As an essential technology powered by AI,
natural language processing (NLP) plays a key role in smart healthcare due to
its capability of analysing and understanding human language. In this work, we
review existing studies that concern NLP for smart healthcare from the
perspectives of technique and application. We first elaborate on different NLP
approaches and the NLP pipeline for smart healthcare from the technical point
of view. Then, in the context of smart healthcare applications employing NLP
techniques, we introduce representative smart healthcare scenarios, including
clinical practice, hospital management, personal care, public health, and drug
development. We further discuss two specific medical issues, i.e., the
coronavirus disease 2019 (COVID-19) pandemic and mental health, in which
NLP-driven smart healthcare plays an important role. Finally, we discuss the
limitations of current works and identify the directions for future works."	ArXiv
980	"One Country, 700+ Languages: NLP Challenges for Underrepresented
  Languages and Dialects in Indonesia"	['Alham Fikri Aji', 'Genta Indra Winata', 'Fajri Koto', 'Samuel Cahyawijaya', 'Ade Romadhony', 'Rahmad Mahendra', 'Kemal Kurniawan', 'David Moeljadi', 'Radityo Eko Prasojo', 'Timothy Baldwin', 'Jey Han Lau', 'Sebastian Ruder']	2022-03-24 22:07:22+00:00	http://arxiv.org/abs/2203.13357v1	"NLP research is impeded by a lack of resources and awareness of the
challenges presented by underrepresented languages and dialects. Focusing on
the languages spoken in Indonesia, the second most linguistically diverse and
the fourth most populous nation of the world, we provide an overview of the
current state of NLP research for Indonesia's 700+ languages. We highlight
challenges in Indonesian NLP and how these affect the performance of current
NLP systems. Finally, we provide general recommendations to help develop NLP
technology not only for languages of Indonesia but also other underrepresented
languages."	ArXiv
981	Towards Climate Awareness in NLP Research	['Daniel Hershcovich', 'Nicolas Webersinke', 'Mathias Kraus', 'Julia Anna Bingler', 'Markus Leippold']	2022-05-10 17:56:23+00:00	http://arxiv.org/abs/2205.05071v4	"The climate impact of AI, and NLP research in particular, has become a
serious issue given the enormous amount of energy that is increasingly being
used for training and running computational models. Consequently, increasing
focus is placed on efficient NLP. However, this important initiative lacks
simple guidelines that would allow for systematic climate reporting of NLP
research. We argue that this deficiency is one of the reasons why very few
publications in NLP report key figures that would allow a more thorough
examination of environmental impact. As a remedy, we propose a climate
performance model card with the primary purpose of being practically usable
with only limited information about experiments and the underlying computer
hardware. We describe why this step is essential to increase awareness about
the environmental impact of NLP research and, thereby, paving the way for more
thorough discussions."	ArXiv
982	"Backdoor Learning for NLP: Recent Advances, Challenges, and Future
  Research Directions"	['Marwan Omar']	2023-02-14 02:56:29+00:00	http://arxiv.org/abs/2302.06801v1	"Although backdoor learning is an active research topic in the NLP domain, the
literature lacks studies that systematically categorize and summarize backdoor
attacks and defenses. To bridge the gap, we present a comprehensive and
unifying study of backdoor learning for NLP by summarizing the literature in a
systematic manner. We first present and motivate the importance of backdoor
learning for building robust NLP systems. Next, we provide a thorough account
of backdoor attack techniques, their applications, defenses against backdoor
attacks, and various mitigation techniques to remove backdoor attacks. We then
provide a detailed review and analysis of evaluation metrics, benchmark
datasets, threat models, and challenges related to backdoor learning in NLP.
Ultimately, our work aims to crystallize and contextualize the landscape of
existing literature in backdoor learning for the text domain and motivate
further research in the field. To this end, we identify troubling gaps in the
literature and offer insights and ideas into open challenges and future
research directions. Finally, we provide a GitHub repository with a list of
backdoor learning papers that will be continuously updated at
https://github.com/marwanomar1/Backdoor-Learning-for-NLP."	ArXiv
983	"Large Language Models as Annotators: Enhancing Generalization of NLP
  Models at Minimal Cost"	['Parikshit Bansal', 'Amit Sharma']	2023-06-27 19:29:55+00:00	http://arxiv.org/abs/2306.15766v1	"State-of-the-art supervised NLP models achieve high accuracy but are also
susceptible to failures on inputs from low-data regimes, such as domains that
are not represented in training data. As an approximation to collecting
ground-truth labels for the specific domain, we study the use of large language
models (LLMs) for annotating inputs and improving the generalization of NLP
models. Specifically, given a budget for LLM annotations, we present an
algorithm for sampling the most informative inputs to annotate and retrain the
NLP model. We find that popular active learning strategies such as
uncertainty-based sampling do not work well. Instead, we propose a sampling
strategy based on the difference in prediction scores between the base model
and the finetuned NLP model, utilizing the fact that most NLP models are
finetuned from a base model. Experiments with classification (semantic
similarity) and ranking (semantic search) tasks show that our sampling strategy
leads to significant gains in accuracy for both the training and target
domains."	ArXiv
984	"Thesis Distillation: Investigating The Impact of Bias in NLP Models on
  Hate Speech Detection"	['Fatma Elsafoury']	2023-08-31 08:40:41+00:00	http://arxiv.org/abs/2308.16549v2	"This paper is a summary of the work done in my PhD thesis. Where I
investigate the impact of bias in NLP models on the task of hate speech
detection from three perspectives: explainability, offensive stereotyping bias,
and fairness. Then, I discuss the main takeaways from my thesis and how they
can benefit the broader NLP community. Finally, I discuss important future
research directions. The findings of my thesis suggest that the bias in NLP
models impacts the task of hate speech detection from all three perspectives.
And that unless we start incorporating social sciences in studying bias in NLP
models, we will not effectively overcome the current limitations of measuring
and mitigating bias in NLP models."	ArXiv
985	"The Shifted and The Overlooked: A Task-oriented Investigation of
  User-GPT Interactions"	['Siru Ouyang', 'Shuohang Wang', 'Yang Liu', 'Ming Zhong', 'Yizhu Jiao', 'Dan Iter', 'Reid Pryzant', 'Chenguang Zhu', 'Heng Ji', 'Jiawei Han']	2023-10-19 02:12:17+00:00	http://arxiv.org/abs/2310.12418v1	"Recent progress in Large Language Models (LLMs) has produced models that
exhibit remarkable performance across a variety of NLP tasks. However, it
remains unclear whether the existing focus of NLP research accurately captures
the genuine requirements of human users. This paper provides a comprehensive
analysis of the divergence between current NLP research and the needs of
real-world NLP applications via a large-scale collection of user-GPT
conversations. We analyze a large-scale collection of real user queries to GPT.
We compare these queries against existing NLP benchmark tasks and identify a
significant gap between the tasks that users frequently request from LLMs and
the tasks that are commonly studied in academic research. For example, we find
that tasks such as ``design'' and ``planning'' are prevalent in user
interactions but are largely neglected or different from traditional NLP
benchmarks. We investigate these overlooked tasks, dissect the practical
challenges they pose, and provide insights toward a roadmap to make LLMs better
aligned with user needs."	ArXiv
986	A Material Lens on Coloniality in NLP	['William Held', 'Camille Harris', 'Michael Best', 'Diyi Yang']	2023-11-14 18:52:09+00:00	http://arxiv.org/abs/2311.08391v1	"Coloniality, the continuation of colonial harms beyond ""official""
colonization, has pervasive effects across society and scientific fields.
Natural Language Processing (NLP) is no exception to this broad phenomenon. In
this work, we argue that coloniality is implicitly embedded in and amplified by
NLP data, algorithms, and software. We formalize this analysis using
Actor-Network Theory (ANT): an approach to understanding social phenomena
through the network of relationships between human stakeholders and technology.
We use our Actor-Network to guide a quantitative survey of the geography of
different phases of NLP research, providing evidence that inequality along
colonial boundaries increases as NLP builds on itself. Based on this, we argue
that combating coloniality in NLP requires not only changing current values but
also active work to remove the accumulation of colonial ideals in our
foundational data and algorithms."	ArXiv
987	"Synergizing Machine Learning & Symbolic Methods: A Survey on Hybrid
  Approaches to Natural Language Processing"	['Rrubaa Panchendrarajan', 'Arkaitz Zubiaga']	2024-01-22 14:24:03+00:00	http://arxiv.org/abs/2401.11972v2	"The advancement of machine learning and symbolic approaches have underscored
their strengths and weaknesses in Natural Language Processing (NLP). While
machine learning approaches are powerful in identifying patterns in data, they
often fall short in learning commonsense and the factual knowledge required for
the NLP tasks. Meanwhile, the symbolic methods excel in representing
knowledge-rich data. However, they struggle to adapt dynamic data and
generalize the knowledge. Bridging these two paradigms through hybrid
approaches enables the alleviation of weaknesses in both while preserving their
strengths. Recent studies extol the virtues of this union, showcasing promising
results in a wide range of NLP tasks. In this paper, we present an overview of
hybrid approaches used for NLP. Specifically, we delve into the
state-of-the-art hybrid approaches used for a broad spectrum of NLP tasks
requiring natural language understanding, generation, and reasoning.
Furthermore, we discuss the existing resources available for hybrid approaches
for NLP along with the challenges and future directions, offering a roadmap for
future research avenues."	ArXiv
988	"Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP
  Models on Accuracy and Semantic Coherence"	['Mingyang Li', 'Maoqin Yuan', 'Luyao Li', 'Han Pengsihua']	2024-02-29 04:53:06+00:00	http://arxiv.org/abs/2402.18849v1	"This study discusses a new method combining image steganography technology
with Natural Language Processing (NLP) large models, aimed at improving the
accuracy and robustness of extracting steganographic text. Traditional Least
Significant Bit (LSB) steganography techniques face challenges in accuracy and
robustness of information extraction when dealing with complex character
encoding, such as Chinese characters. To address this issue, this study
proposes an innovative LSB-NLP hybrid framework. This framework integrates the
advanced capabilities of NLP large models, such as error detection, correction,
and semantic consistency analysis, as well as information reconstruction
techniques, thereby significantly enhancing the robustness of steganographic
text extraction. Experimental results show that the LSB-NLP hybrid framework
excels in improving the extraction accuracy of steganographic text, especially
in handling Chinese characters. The findings of this study not only confirm the
effectiveness of combining image steganography technology and NLP large models
but also propose new ideas for research and application in the field of
information hiding. The successful implementation of this interdisciplinary
approach demonstrates the great potential of integrating image steganography
technology with natural language processing technology in solving complex
information processing problems."	ArXiv
989	"DIALECTBENCH: A NLP Benchmark for Dialects, Varieties, and
  Closely-Related Languages"	['Fahim Faisal', 'Orevaoghene Ahia', 'Aarohi Srivastava', 'Kabir Ahuja', 'David Chiang', 'Yulia Tsvetkov', 'Antonios Anastasopoulos']	2024-03-16 20:18:36+00:00	http://arxiv.org/abs/2403.11009v2	"Language technologies should be judged on their usefulness in real-world use
cases. An often overlooked aspect in natural language processing (NLP) research
and evaluation is language variation in the form of non-standard dialects or
language varieties (hereafter, varieties). Most NLP benchmarks are limited to
standard language varieties. To fill this gap, we propose DIALECTBENCH, the
first-ever large-scale benchmark for NLP on varieties, which aggregates an
extensive set of task-varied variety datasets (10 text-level tasks covering 281
varieties). This allows for a comprehensive evaluation of NLP system
performance on different language varieties. We provide substantial evidence of
performance disparities between standard and non-standard language varieties,
and we also identify language clusters with large performance divergence across
tasks. We believe DIALECTBENCH provides a comprehensive view of the current
state of NLP for language varieties and one step towards advancing it further.
Code/data: https://github.com/ffaisal93/DialectBench"	ArXiv
990	"Striking a Balance between Classical and Deep Learning Approaches in
  Natural Language Processing Pedagogy"	['Aditya Joshi', 'Jake Renzella', 'Pushpak Bhattacharyya', 'Saurav Jha', 'Xiangyu Zhang']	2024-05-16 07:14:13+00:00	http://arxiv.org/abs/2405.09854v2	"While deep learning approaches represent the state-of-the-art of natural
language processing (NLP) today, classical algorithms and approaches still find
a place in NLP textbooks and courses of recent years. This paper discusses the
perspectives of conveners of two introductory NLP courses taught in Australia
and India, and examines how classical and deep learning approaches can be
balanced within the lecture plan and assessments of the courses. We also draw
parallels with the objects-first and objects-later debate in CS1 education. We
observe that teaching classical approaches adds value to student learning by
building an intuitive understanding of NLP problems, potential solutions, and
even deep learning models themselves. Despite classical approaches not being
state-of-the-art, the paper makes a case for their inclusion in NLP courses
today."	ArXiv
991	Application of Natural Language Processing in Financial Risk Detection	['Liyang Wang', 'Yu Cheng', 'Ao Xiang', 'Jingyu Zhang', 'Haowei Yang']	2024-06-14 07:06:24+00:00	http://arxiv.org/abs/2406.09765v2	"This paper explores the application of Natural Language Processing (NLP) in
financial risk detection. By constructing an NLP-based financial risk detection
model, this study aims to identify and predict potential risks in financial
documents and communications. First, the fundamental concepts of NLP and its
theoretical foundation, including text mining methods, NLP model design
principles, and machine learning algorithms, are introduced. Second, the
process of text data preprocessing and feature extraction is described.
Finally, the effectiveness and predictive performance of the model are
validated through empirical research. The results show that the NLP-based
financial risk detection model performs excellently in risk identification and
prediction, providing effective risk management tools for financial
institutions. This study offers valuable references for the field of financial
risk management, utilizing advanced NLP techniques to improve the accuracy and
efficiency of financial risk detection."	ArXiv
992	"NLPGuard: A Framework for Mitigating the Use of Protected Attributes by
  NLP Classifiers"	['Salvatore Greco', 'Ke Zhou', 'Licia Capra', 'Tania Cerquitelli', 'Daniele Quercia']	2024-07-01 18:08:17+00:00	http://arxiv.org/abs/2407.01697v1	"AI regulations are expected to prohibit machine learning models from using
sensitive attributes during training. However, the latest Natural Language
Processing (NLP) classifiers, which rely on deep learning, operate as black-box
systems, complicating the detection and remediation of such misuse. Traditional
bias mitigation methods in NLP aim for comparable performance across different
groups based on attributes like gender or race but fail to address the
underlying issue of reliance on protected attributes. To partly fix that, we
introduce NLPGuard, a framework for mitigating the reliance on protected
attributes in NLP classifiers. NLPGuard takes an unlabeled dataset, an existing
NLP classifier, and its training data as input, producing a modified training
dataset that significantly reduces dependence on protected attributes without
compromising accuracy. NLPGuard is applied to three classification tasks:
identifying toxic language, sentiment analysis, and occupation classification.
Our evaluation shows that current NLP classifiers heavily depend on protected
attributes, with up to $23\%$ of the most predictive words associated with
these attributes. However, NLPGuard effectively reduces this reliance by up to
$79\%$, while slightly improving accuracy."	ArXiv
993	"Exploring Interdisciplinary Team Collaboration in Clinical NLP Projects
  Through the Lens of Activity Theory"	['Bingsheng Yao', 'Yao Du', 'Yue Fu', 'Xuhai Xu', 'Yanjun Gao', 'Hong Yu', 'Dakuo Wang']	2024-09-30 19:25:16+00:00	http://arxiv.org/abs/2410.00174v1	"Natural Language Processing (NLP) techniques have been increasingly
integrated into clinical projects to advance clinical decision-making and
improve patient outcomes. Such projects benefit from interdisciplinary team
collaborations. This paper explores challenges and opportunities using two
clinical NLP projects as case studies, where speech-language pathologists
(SLPs) and NLP researchers jointly developed technology-based systems to
improve clinical workflow. Through semi-structured interviews with five SLPs
and four NLP researchers, we collected collaboration practices and challenges.
Using Activity Theory as an analytical framework, we examined collaborative
activities, challenges, and strategies to bridge interdisciplinary gaps. Our
findings revealed significant knowledge boundaries and terminological barriers
between SLPs and NLP researchers when both groups relied on clinical data as
boundary objects to facilitate collaboration, although this approach has
limitations. We highlight the potential opportunities of AI technologies as
knowledge brokers to overcome interdisciplinary collaboration challenges."	ArXiv
994	A Review of the Marathi Natural Language Processing	['Asang Dani', 'Shailesh R Sathe']	2024-12-20 00:56:13+00:00	http://arxiv.org/abs/2412.15471v2	"Marathi is one of the most widely used languages in the world. One might
expect that the latest advances in NLP research in languages like English reach
such a large community. However, NLP advancements in English didn't immediately
reach Indian languages like Marathi. There were several reasons for this. They
included diversity of scripts used, lack of (publicly available) resources like
tokenization strategies, high quality datasets \& benchmarks, and evaluation
metrics. In addition to this, the morphologically rich nature of Marathi, made
NLP tasks challenging. Advances in Neural Network (NN) based models and tools
since the early 2000s helped improve this situation and make NLP research more
accessible. In the past 10 years, significant efforts were made to improve
language resources for all 22 scheduled languages of India. This paper presents
a broad overview of evolution of NLP research in Indic languages with a focus
on Marathi and state-of-the-art resources and tools available to the research
community. It also provides an overview of tools \& techniques associated with
Marathi NLP tasks."	ArXiv
995	"Privacy-Preserving Outsourcing of Large-Scale Nonlinear Programming to
  the Cloud"	['Ang Li', 'Wei Du', 'Qinghua Li']	2018-10-02 03:11:55+00:00	http://arxiv.org/abs/1810.01048v1	"The increasing massive data generated by various sources has given birth to
big data analytics. Solving large-scale nonlinear programming problems (NLPs)
is one important big data analytics task that has applications in many domains
such as transport and logistics. However, NLPs are usually too computationally
expensive for resource-constrained users. Fortunately, cloud computing provides
an alternative and economical service for resource-constrained users to
outsource their computation tasks to the cloud. However, one major concern with
outsourcing NLPs is the leakage of user's private information contained in NLP
formulations and results. Although much work has been done on
privacy-preserving outsourcing of computation tasks, little attention has been
paid to NLPs. In this paper, we for the first time investigate secure
outsourcing of general large-scale NLPs with nonlinear constraints. A secure
and efficient transformation scheme at the user side is proposed to protect
user's private information; at the cloud side, generalized reduced gradient
method is applied to effectively solve the transformed large-scale NLPs. The
proposed protocol is implemented on a cloud computing testbed. Experimental
evaluations demonstrate that significant time can be saved for users and the
proposed mechanism has the potential for practical use."	ArXiv
996	A Data-Centric Framework for Composable NLP Workflows	['Zhengzhong Liu', 'Guanxiong Ding', 'Avinash Bukkittu', 'Mansi Gupta', 'Pengzhi Gao', 'Atif Ahmed', 'Shikun Zhang', 'Xin Gao', 'Swapnil Singhavi', 'Linwei Li', 'Wei Wei', 'Zecong Hu', 'Haoran Shi', 'Haoying Zhang', 'Xiaodan Liang', 'Teruko Mitamura', 'Eric P. Xing', 'Zhiting Hu']	2021-03-02 16:19:44+00:00	http://arxiv.org/abs/2103.01834v4	"Empirical natural language processing (NLP) systems in application domains
(e.g., healthcare, finance, education) involve interoperation among multiple
components, ranging from data ingestion, human annotation, to text retrieval,
analysis, generation, and visualization. We establish a unified open-source
framework to support fast development of such sophisticated NLP workflows in a
composable manner. The framework introduces a uniform data representation to
encode heterogeneous results by a wide range of NLP tasks. It offers a large
repository of processors for NLP tasks, visualization, and annotation, which
can be easily assembled with full interoperability under the unified
representation. The highly extensible framework allows plugging in custom
processors from external off-the-shelf NLP and deep learning libraries. The
whole framework is delivered through two modularized yet integratable
open-source projects, namely Forte (for workflow infrastructure and NLP
function processors) and Stave (for user interaction, visualization, and
annotation)."	ArXiv
997	"Fine-Tuning Large Neural Language Models for Biomedical Natural Language
  Processing"	['Robert Tinn', 'Hao Cheng', 'Yu Gu', 'Naoto Usuyama', 'Xiaodong Liu', 'Tristan Naumann', 'Jianfeng Gao', 'Hoifung Poon']	2021-12-15 04:20:35+00:00	http://arxiv.org/abs/2112.07869v1	"Motivation: A perennial challenge for biomedical researchers and clinical
practitioners is to stay abreast with the rapid growth of publications and
medical notes. Natural language processing (NLP) has emerged as a promising
direction for taming information overload. In particular, large neural language
models facilitate transfer learning by pretraining on unlabeled text, as
exemplified by the successes of BERT models in various NLP applications.
However, fine-tuning such models for an end task remains challenging,
especially with small labeled datasets, which are common in biomedical NLP.
  Results: We conduct a systematic study on fine-tuning stability in biomedical
NLP. We show that finetuning performance may be sensitive to pretraining
settings, especially in low-resource domains. Large models have potential to
attain better performance, but increasing model size also exacerbates
finetuning instability. We thus conduct a comprehensive exploration of
techniques for addressing fine-tuning instability. We show that these
techniques can substantially improve fine-tuning performance for lowresource
biomedical NLP applications. Specifically, freezing lower layers is helpful for
standard BERT-BASE models, while layerwise decay is more effective for
BERT-LARGE and ELECTRA models. For low-resource text similarity tasks such as
BIOSSES, reinitializing the top layer is the optimal strategy. Overall,
domainspecific vocabulary and pretraining facilitate more robust models for
fine-tuning. Based on these findings, we establish new state of the art on a
wide range of biomedical NLP applications.
  Availability and implementation: To facilitate progress in biomedical NLP, we
release our state-of-the-art pretrained and fine-tuned models:
https://aka.ms/BLURB."	ArXiv
998	"Annotating the Tweebank Corpus on Named Entity Recognition and Building
  NLP Models for Social Media Analysis"	['Hang Jiang', 'Yining Hua', 'Doug Beeferman', 'Deb Roy']	2022-01-18 19:34:23+00:00	http://arxiv.org/abs/2201.07281v2	"Social media data such as Twitter messages (""tweets"") pose a particular
challenge to NLP systems because of their short, noisy, and colloquial nature.
Tasks such as Named Entity Recognition (NER) and syntactic parsing require
highly domain-matched training data for good performance. To date, there is no
complete training corpus for both NER and syntactic analysis (e.g., part of
speech tagging, dependency parsing) of tweets. While there are some publicly
available annotated NLP datasets of tweets, they are only designed for
individual tasks. In this study, we aim to create Tweebank-NER, an English NER
corpus based on Tweebank V2 (TB2), train state-of-the-art (SOTA) Tweet NLP
models on TB2, and release an NLP pipeline called Twitter-Stanza. We annotate
named entities in TB2 using Amazon Mechanical Turk and measure the quality of
our annotations. We train the Stanza pipeline on TB2 and compare with
alternative NLP frameworks (e.g., FLAIR, spaCy) and transformer-based models.
The Stanza tokenizer and lemmatizer achieve SOTA performance on TB2, while the
Stanza NER tagger, part-of-speech (POS) tagger, and dependency parser achieve
competitive performance against non-transformer models. The transformer-based
models establish a strong baseline in Tweebank-NER and achieve the new SOTA
performance in POS tagging and dependency parsing on TB2. We release the
dataset and make both the Stanza pipeline and BERTweet-based models available
""off-the-shelf"" for use in future Tweet NLP research. Our source code, data,
and pre-trained models are available at:
\url{https://github.com/social-machines/TweebankNLP}."	ArXiv
999	On the Explainability of Natural Language Processing Deep Models	['Julia El Zini', 'Mariette Awad']	2022-10-13 11:59:39+00:00	http://arxiv.org/abs/2210.06929v1	"While there has been a recent explosion of work on ExplainableAI ExAI on deep
models that operate on imagery and tabular data, textual datasets present new
challenges to the ExAI community. Such challenges can be attributed to the lack
of input structure in textual data, the use of word embeddings that add to the
opacity of the models and the difficulty of the visualization of the inner
workings of deep models when they are trained on textual data.
  Lately, methods have been developed to address the aforementioned challenges
and present satisfactory explanations on Natural Language Processing (NLP)
models. However, such methods are yet to be studied in a comprehensive
framework where common challenges are properly stated and rigorous evaluation
practices and metrics are proposed. Motivated to democratize ExAI methods in
the NLP field, we present in this work a survey that studies model-agnostic as
well as model-specific explainability methods on NLP models. Such methods can
either develop inherently interpretable NLP models or operate on pre-trained
models in a post-hoc manner. We make this distinction and we further decompose
the methods into three categories according to what they explain: (1) word
embeddings (input-level), (2) inner workings of NLP models (processing-level)
and (3) models' decisions (output-level). We also detail the different
evaluation approaches interpretability methods in the NLP field. Finally, we
present a case-study on the well-known neural machine translation in an
appendix and we propose promising future research directions for ExAI in the
NLP field."	ArXiv
1000	"Potrika: Raw and Balanced Newspaper Datasets in the Bangla Language with
  Eight Topics and Five Attributes"	['Istiak Ahmad', 'Fahad AlQurashi', 'Rashid Mehmood']	2022-10-17 19:37:42+00:00	http://arxiv.org/abs/2210.09389v1	"Knowledge is central to human and scientific developments. Natural Language
Processing (NLP) allows automated analysis and creation of knowledge. Data is a
crucial NLP and machine learning ingredient. The scarcity of open datasets is a
well-known problem in machine and deep learning research. This is very much the
case for textual NLP datasets in English and other major world languages. For
the Bangla language, the situation is even more challenging and the number of
large datasets for NLP research is practically nil. We hereby present Potrika,
a large single-label Bangla news article textual dataset curated for NLP
research from six popular online news portals in Bangladesh (Jugantor,
Jaijaidin, Ittefaq, Kaler Kontho, Inqilab, and Somoyer Alo) for the period
2014-2020. The articles are classified into eight distinct categories
(National, Sports, International, Entertainment, Economy, Education, Politics,
and Science \& Technology) providing five attributes (News Article, Category,
Headline, Publication Date, and Newspaper Source). The raw dataset contains
185.51 million words and 12.57 million sentences contained in 664,880 news
articles. Moreover, using NLP augmentation techniques, we create from the raw
(unbalanced) dataset another (balanced) dataset comprising 320,000 news
articles with 40,000 articles in each of the eight news categories. Potrika
contains both the datasets (raw and balanced) to suit a wide range of NLP
research. By far, to the best of our knowledge, Potrika is the largest and the
most extensive dataset for news classification."	ArXiv
1001	"Natural Language Processing with Deep Learning for Medical Adverse Event
  Detection from Free-Text Medical Narratives: A Case Study of Detecting Total
  Hip Replacement Dislocation"	['Alireza Borjali', 'Martin Magneli', 'David Shin', 'Henrik Malchau', 'Orhun K. Muratoglu', 'Kartik M. Varadarajan']	2020-04-17 16:25:36+00:00	http://arxiv.org/abs/2004.08333v2	"Accurate and timely detection of medical adverse events (AEs) from free-text
medical narratives is challenging. Natural language processing (NLP) with deep
learning has already shown great potential for analyzing free-text data, but
its application for medical AE detection has been limited. In this study we
proposed deep learning based NLP (DL-NLP) models for efficient and accurate hip
dislocation AE detection following total hip replacement from standard
(radiology notes) and non-standard (follow-up telephone notes) free-text
medical narratives. We benchmarked these proposed models with a wide variety of
traditional machine learning based NLP (ML-NLP) models, and also assessed the
accuracy of International Classification of Diseases (ICD) and Current
Procedural Terminology (CPT) codes in capturing these hip dislocation AEs in a
multi-center orthopaedic registry. All DL-NLP models out-performed all of the
ML-NLP models, with a convolutional neural network (CNN) model achieving the
best overall performance (Kappa = 0.97 for radiology notes, and Kappa = 1.00
for follow-up telephone notes). On the other hand, the ICD/CPT codes of the
patients who sustained a hip dislocation AE were only 75.24% accurate, showing
the potential of the proposed model to be used in largescale orthopaedic
registries for accurate and efficient hip dislocation AE detection to improve
the quality of care and patient outcome."	ArXiv
1002	"Meta-Embeddings for Natural Language Inference and Semantic Similarity
  tasks"	['Shree Charran R', 'Rahul Kumar Dubey']	2020-12-01 16:58:01+00:00	http://arxiv.org/abs/2012.00633v1	"Word Representations form the core component for almost all advanced Natural
Language Processing (NLP) applications such as text mining, question-answering,
and text summarization, etc. Over the last two decades, immense research is
conducted to come up with one single model to solve all major NLP tasks. The
major problem currently is that there are a plethora of choices for different
NLP tasks. Thus for NLP practitioners, the task of choosing the right model to
be used itself becomes a challenge. Thus combining multiple pre-trained word
embeddings and forming meta embeddings has become a viable approach to improve
tackle NLP tasks. Meta embedding learning is a process of producing a single
word embedding from a given set of pre-trained input word embeddings. In this
paper, we propose to use Meta Embedding derived from few State-of-the-Art
(SOTA) models to efficiently tackle mainstream NLP tasks like classification,
semantic relatedness, and text similarity. We have compared both ensemble and
dynamic variants to identify an efficient approach. The results obtained show
that even the best State-of-the-Art models can be bettered. Thus showing us
that meta-embeddings can be used for several NLP tasks by harnessing the power
of several individual representations."	ArXiv
1003	"A Primer on Contrastive Pretraining in Language Processing: Methods,
  Lessons Learned and Perspectives"	['Nils Rethmeier', 'Isabelle Augenstein']	2021-02-25 16:35:07+00:00	http://arxiv.org/abs/2102.12982v1	"Modern natural language processing (NLP) methods employ self-supervised
pretraining objectives such as masked language modeling to boost the
performance of various application tasks. These pretraining methods are
frequently extended with recurrence, adversarial or linguistic property
masking, and more recently with contrastive learning objectives. Contrastive
self-supervised training objectives enabled recent successes in image
representation pretraining by learning to contrast input-input pairs of
augmented images as either similar or dissimilar. However, in NLP, automated
creation of text input augmentations is still very challenging because a single
token can invert the meaning of a sentence. For this reason, some contrastive
NLP pretraining methods contrast over input-label pairs, rather than over
input-input pairs, using methods from Metric Learning and Energy Based Models.
In this survey, we summarize recent self-supervised and supervised contrastive
NLP pretraining methods and describe where they are used to improve language
modeling, few or zero-shot learning, pretraining data-efficiency and specific
NLP end-tasks. We introduce key contrastive learning concepts with lessons
learned from prior research and structure works by applications and cross-field
relations. Finally, we point to open challenges and future directions for
contrastive NLP to encourage bringing contrastive NLP pretraining closer to
recent successes in image representation pretraining."	ArXiv
1004	"The NLP Cookbook: Modern Recipes for Transformer based Deep Learning
  Architectures"	['Sushant Singh', 'Ausif Mahmood']	2021-03-23 22:38:20+00:00	http://arxiv.org/abs/2104.10640v3	"In recent years, Natural Language Processing (NLP) models have achieved
phenomenal success in linguistic and semantic tasks like text classification,
machine translation, cognitive dialogue systems, information retrieval via
Natural Language Understanding (NLU), and Natural Language Generation (NLG).
This feat is primarily attributed due to the seminal Transformer architecture,
leading to designs such as BERT, GPT (I, II, III), etc. Although these
large-size models have achieved unprecedented performances, they come at high
computational costs. Consequently, some of the recent NLP architectures have
utilized concepts of transfer learning, pruning, quantization, and knowledge
distillation to achieve moderate model sizes while keeping nearly similar
performances as achieved by their predecessors. Additionally, to mitigate the
data size challenge raised by language models from a knowledge extraction
perspective, Knowledge Retrievers have been built to extricate explicit data
documents from a large corpus of databases with greater efficiency and
accuracy. Recent research has also focused on superior inference by providing
efficient attention to longer input sequences. In this paper, we summarize and
examine the current state-of-the-art (SOTA) NLP models that have been employed
for numerous NLP tasks for optimal performance and efficiency. We provide a
detailed understanding and functioning of the different architectures, a
taxonomy of NLP designs, comparative evaluations, and future directions in NLP."	ArXiv
1005	Graph Neural Networks for Natural Language Processing: A Survey	['Lingfei Wu', 'Yu Chen', 'Kai Shen', 'Xiaojie Guo', 'Hanning Gao', 'Shucheng Li', 'Jian Pei', 'Bo Long']	2021-06-10 23:59:26+00:00	http://arxiv.org/abs/2106.06090v2	"Deep learning has become the dominant approach in coping with various tasks
in Natural LanguageProcessing (NLP). Although text inputs are typically
represented as a sequence of tokens, there isa rich variety of NLP problems
that can be best expressed with a graph structure. As a result, thereis a surge
of interests in developing new deep learning techniques on graphs for a large
numberof NLP tasks. In this survey, we present a comprehensive overview onGraph
Neural Networks(GNNs) for Natural Language Processing. We propose a new
taxonomy of GNNs for NLP, whichsystematically organizes existing research of
GNNs for NLP along three axes: graph construction,graph representation
learning, and graph based encoder-decoder models. We further introducea large
number of NLP applications that are exploiting the power of GNNs and summarize
thecorresponding benchmark datasets, evaluation metrics, and open-source codes.
Finally, we discussvarious outstanding challenges for making the full use of
GNNs for NLP as well as future researchdirections. To the best of our
knowledge, this is the first comprehensive overview of Graph NeuralNetworks for
Natural Language Processing."	ArXiv
1006	"How can NLP Help Revitalize Endangered Languages? A Case Study and
  Roadmap for the Cherokee Language"	['Shiyue Zhang', 'Ben Frey', 'Mohit Bansal']	2022-04-25 18:25:57+00:00	http://arxiv.org/abs/2204.11909v1	"More than 43% of the languages spoken in the world are endangered, and
language loss currently occurs at an accelerated rate because of globalization
and neocolonialism. Saving and revitalizing endangered languages has become
very important for maintaining the cultural diversity on our planet. In this
work, we focus on discussing how NLP can help revitalize endangered languages.
We first suggest three principles that may help NLP practitioners to foster
mutual understanding and collaboration with language communities, and we
discuss three ways in which NLP can potentially assist in language education.
We then take Cherokee, a severely-endangered Native American language, as a
case study. After reviewing the language's history, linguistic features, and
existing resources, we (in collaboration with Cherokee community members)
arrive at a few meaningful ways NLP practitioners can collaborate with
community partners. We suggest two approaches to enrich the Cherokee language's
resources with machine-in-the-loop processing, and discuss several NLP tools
that people from the Cherokee community have shown interest in. We hope that
our work serves not only to inform the NLP community about Cherokee, but also
to provide inspiration for future work on endangered languages in general. Our
code and data will be open-sourced at
https://github.com/ZhangShiyue/RevitalizeCherokee"	ArXiv
1007	"Square One Bias in NLP: Towards a Multi-Dimensional Exploration of the
  Research Manifold"	['Sebastian Ruder', 'Ivan Vulić', 'Anders Søgaard']	2022-06-20 13:04:23+00:00	http://arxiv.org/abs/2206.09755v1	"The prototypical NLP experiment trains a standard architecture on labeled
English data and optimizes for accuracy, without accounting for other
dimensions such as fairness, interpretability, or computational efficiency. We
show through a manual classification of recent NLP research papers that this is
indeed the case and refer to it as the square one experimental setup. We
observe that NLP research often goes beyond the square one setup, e.g, focusing
not only on accuracy, but also on fairness or interpretability, but typically
only along a single dimension. Most work targeting multilinguality, for
example, considers only accuracy; most work on fairness or interpretability
considers only English; and so on. We show this through manual classification
of recent NLP research papers and ACL Test-of-Time award recipients. Such
one-dimensionality of most research means we are only exploring a fraction of
the NLP research search space. We provide historical and recent examples of how
the square one bias has led researchers to draw false conclusions or make
unwise choices, point to promising yet unexplored directions on the research
manifold, and make practical recommendations to enable more multi-dimensional
research. We open-source the results of our annotations to enable further
analysis at https://github.com/google-research/url-nlp"	ArXiv
1008	"DeepHider: A Covert NLP Watermarking Framework Based on Multi-task
  Learning"	['Long Dai', 'Jiarong Mao', 'Xuefeng Fan', 'Xiaoyi Zhou']	2022-08-09 11:53:24+00:00	http://arxiv.org/abs/2208.04676v3	"Natural language processing (NLP) technology has shown great commercial value
in applications such as sentiment analysis. But NLP models are vulnerable to
the threat of pirated redistribution, damaging the economic interests of model
owners. Digital watermarking technology is an effective means to protect the
intellectual property rights of NLP model. The existing NLP model protection
mainly designs watermarking schemes by improving both security and robustness
purposes, however, the security and robustness of these schemes have the
following problems, respectively: (1) Watermarks are difficult to defend
against fraudulent declaration by adversary and are easily detected and blocked
from verification by human or anomaly detector during the verification process.
(2) The watermarking model cannot meet multiple robustness requirements at the
same time. To solve the above problems, this paper proposes a novel
watermarking framework for NLP model based on the over-parameterization of
depth model and the multi-task learning theory. Specifically, a covert trigger
set is established to realize the perception-free verification of the
watermarking model, and a novel auxiliary network is designed to improve the
robustness and security of the watermarking model. The proposed framework was
evaluated on two benchmark datasets and three mainstream NLP models, and the
results show that the framework can successfully validate model ownership with
100% validation accuracy and advanced robustness and security without
compromising the host model performance."	ArXiv
1009	"Ontology-Driven Self-Supervision for Adverse Childhood Experiences
  Identification Using Social Media Datasets"	['Jinge Wu', 'Rowena Smith', 'Honghan Wu']	2022-08-24 12:23:01+00:00	http://arxiv.org/abs/2208.11701v1	"Adverse Childhood Experiences (ACEs) are defined as a collection of highly
stressful, and potentially traumatic, events or circumstances that occur
throughout childhood and/or adolescence. They have been shown to be associated
with increased risks of mental health diseases or other abnormal behaviours in
later lives. However, the identification of ACEs from textual data with Natural
Language Processing (NLP) is challenging because (a) there are no NLP ready ACE
ontologies; (b) there are few resources available for machine learning,
necessitating the data annotation from clinical experts; (c) costly annotations
by domain experts and large number of documents for supporting large machine
learning models. In this paper, we present an ontology-driven self-supervised
approach (derive concept embeddings using an auto-encoder from baseline NLP
results) for producing a publicly available resource that would support
large-scale machine learning (e.g., training transformer based large language
models) on social media corpus. This resource as well as the proposed approach
are aimed to facilitate the community in training transferable NLP models for
effectively surfacing ACEs in low-resource scenarios like NLP on clinical notes
within Electronic Health Records. The resource including a list of ACE ontology
terms, ACE concept embeddings and the NLP annotated corpus is available at
https://github.com/knowlab/ACE-NLP."	ArXiv
1010	"Few-Shot Learning for Clinical Natural Language Processing Using Siamese
  Neural Networks"	['David Oniani', 'Sonish Sivarajkumar', 'Yanshan Wang']	2022-08-31 15:36:27+00:00	http://arxiv.org/abs/2208.14923v2	"Clinical Natural Language Processing (NLP) has become an emerging technology
in healthcare that leverages a large amount of free-text data in electronic
health records (EHRs) to improve patient care, support clinical decisions, and
facilitate clinical and translational science research. Recently, deep learning
has achieved state-of-the-art performance in many clinical NLP tasks. However,
training deep learning models usually requires large annotated datasets, which
are normally not publicly available and can be time-consuming to build in
clinical domains. Working with smaller annotated datasets is typical in
clinical NLP and therefore, ensuring that deep learning models perform well is
crucial for the models to be used in real-world applications. A widely adopted
approach is fine-tuning existing Pre-trained Language Models (PLMs), but these
attempts fall short when the training dataset contains only a few annotated
samples. Few-Shot Learning (FSL) has recently been investigated to tackle this
problem. Siamese Neural Network (SNN) has been widely utilized as an FSL
approach in computer vision, but has not been studied well in NLP. Furthermore,
the literature on its applications in clinical domains is scarce. In this
paper, we propose two SNN-based FSL approaches for clinical NLP, including
Pre-Trained SNN (PT-SNN) and SNN with Second-Order Embeddings (SOE-SNN). We
evaluated the proposed approaches on two clinical tasks, namely clinical text
classification and clinical named entity recognition. We tested three few-shot
settings including 4-shot, 8-shot, and 16-shot learning. Both clinical NLP
tasks were benchmarked using three PLMs, including BERT,BioBERT, and
BioClinicalBERT. The experimental results verified the effectiveness of the
proposed SNN-based FSL approaches in both NLP tasks."	ArXiv
1011	"The Elephant in the Room: Analyzing the Presence of Big Tech in Natural
  Language Processing Research"	['Mohamed Abdalla', 'Jan Philip Wahle', 'Terry Ruas', 'Aurélie Névéol', 'Fanny Ducel', 'Saif M. Mohammad', 'Karën Fort']	2023-05-04 12:57:18+00:00	http://arxiv.org/abs/2305.02797v4	"Recent advances in deep learning methods for natural language processing
(NLP) have created new business opportunities and made NLP research critical
for industry development. As one of the big players in the field of NLP,
together with governments and universities, it is important to track the
influence of industry on research. In this study, we seek to quantify and
characterize industry presence in the NLP community over time. Using a corpus
with comprehensive metadata of 78,187 NLP publications and 701 resumes of NLP
publication authors, we explore the industry presence in the field since the
early 90s. We find that industry presence among NLP authors has been steady
before a steep increase over the past five years (180% growth from 2017 to
2022). A few companies account for most of the publications and provide funding
to academic researchers through grants and internships. Our study shows that
the presence and impact of the industry on natural language processing research
are significant and fast-growing. This work calls for increased transparency of
industry influence in the field."	ArXiv
1012	"Examining risks of racial biases in NLP tools for child protective
  services"	['Anjalie Field', 'Amanda Coston', 'Nupoor Gandhi', 'Alexandra Chouldechova', 'Emily Putnam-Hornstein', 'David Steier', 'Yulia Tsvetkov']	2023-05-30 21:00:47+00:00	http://arxiv.org/abs/2305.19409v1	"Although much literature has established the presence of demographic bias in
natural language processing (NLP) models, most work relies on curated bias
metrics that may not be reflective of real-world applications. At the same
time, practitioners are increasingly using algorithmic tools in high-stakes
settings, with particular recent interest in NLP. In this work, we focus on one
such setting: child protective services (CPS). CPS workers often write copious
free-form text notes about families they are working with, and CPS agencies are
actively seeking to deploy NLP models to leverage these data. Given
well-established racial bias in this setting, we investigate possible ways
deployed NLP is liable to increase racial disparities. We specifically examine
word statistics within notes and algorithmic fairness in risk prediction,
coreference resolution, and named entity recognition (NER). We document
consistent algorithmic unfairness in NER models, possible algorithmic
unfairness in coreference resolution models, and little evidence of exacerbated
racial bias in risk prediction. While there is existing pronounced criticism of
risk prediction, our results expose previously undocumented risks of racial
bias in realistic information extraction systems, highlighting potential
concerns in deploying them, even though they may appear more benign. Our work
serves as a rare realistic examination of NLP algorithmic fairness in a
potential deployed setting and a timely investigation of a specific risk
associated with deploying NLP in CPS settings."	ArXiv
1013	Regulation and NLP (RegNLP): Taming Large Language Models	['Catalina Goanta', 'Nikolaos Aletras', 'Ilias Chalkidis', 'Sofia Ranchordas', 'Gerasimos Spanakis']	2023-10-09 09:22:40+00:00	http://arxiv.org/abs/2310.05553v1	"The scientific innovation in Natural Language Processing (NLP) and more
broadly in artificial intelligence (AI) is at its fastest pace to date. As
large language models (LLMs) unleash a new era of automation, important debates
emerge regarding the benefits and risks of their development, deployment and
use. Currently, these debates have been dominated by often polarized narratives
mainly led by the AI Safety and AI Ethics movements. This polarization, often
amplified by social media, is swaying political agendas on AI regulation and
governance and posing issues of regulatory capture. Capture occurs when the
regulator advances the interests of the industry it is supposed to regulate, or
of special interest groups rather than pursuing the general public interest.
Meanwhile in NLP research, attention has been increasingly paid to the
discussion of regulating risks and harms. This often happens without systematic
methodologies or sufficient rooting in the disciplines that inspire an extended
scope of NLP research, jeopardizing the scientific integrity of these
endeavors. Regulation studies are a rich source of knowledge on how to
systematically deal with risk and uncertainty, as well as with scientific
evidence, to evaluate and compare regulatory options. This resource has largely
remained untapped so far. In this paper, we argue how NLP research on these
topics can benefit from proximity to regulatory studies and adjacent fields. We
do so by discussing basic tenets of regulation, and risk and uncertainty, and
by highlighting the shortcomings of current NLP discussions dealing with risk
assessment. Finally, we advocate for the development of a new multidisciplinary
research space on regulation and NLP (RegNLP), focused on connecting scientific
knowledge to regulatory processes based on systematic methodologies."	ArXiv
1014	"Surveying the Landscape of Text Summarization with Deep Learning: A
  Comprehensive Review"	['Guanghua Wang', 'Weili Wu']	2023-10-13 21:24:37+00:00	http://arxiv.org/abs/2310.09411v1	"In recent years, deep learning has revolutionized natural language processing
(NLP) by enabling the development of models that can learn complex
representations of language data, leading to significant improvements in
performance across a wide range of NLP tasks. Deep learning models for NLP
typically use large amounts of data to train deep neural networks, allowing
them to learn the patterns and relationships in language data. This is in
contrast to traditional NLP approaches, which rely on hand-engineered features
and rules to perform NLP tasks. The ability of deep neural networks to learn
hierarchical representations of language data, handle variable-length input
sequences, and perform well on large datasets makes them well-suited for NLP
applications. Driven by the exponential growth of textual data and the
increasing demand for condensed, coherent, and informative summaries, text
summarization has been a critical research area in the field of NLP. Applying
deep learning to text summarization refers to the use of deep neural networks
to perform text summarization tasks. In this survey, we begin with a review of
fashionable text summarization tasks in recent years, including extractive,
abstractive, multi-document, and so on. Next, we discuss most deep
learning-based models and their experimental results on these tasks. The paper
also covers datasets and data representation for summarization tasks. Finally,
we delve into the opportunities and challenges associated with summarization
tasks and their corresponding methodologies, aiming to inspire future research
efforts to advance the field further. A goal of our survey is to explain how
these methods differ in their requirements as understanding them is essential
for choosing a technique suited for a specific setting."	ArXiv
1015	"An Introduction to Natural Language Processing Techniques and Framework
  for Clinical Implementation in Radiation Oncology"	['Reza Khanmohammadi', 'Mohammad M. Ghassemi', 'Kyle Verdecchia', 'Ahmed I. Ghanem', 'Luo Bing', 'Indrin J. Chetty', 'Hassan Bagher-Ebadian', 'Farzan Siddiqui', 'Mohamed Elshaikh', 'Benjamin Movsas', 'Kundan Thind']	2023-11-03 19:32:35+00:00	http://arxiv.org/abs/2311.02205v2	"Natural Language Processing (NLP) is a key technique for developing Medical
Artificial Intelligence (AI) systems that leverage Electronic Health Record
(EHR) data to build diagnostic and prognostic models. NLP enables the
conversion of unstructured clinical text into structured data that can be fed
into AI algorithms. The emergence of the transformer architecture and large
language models (LLMs) has led to remarkable advances in NLP for various
healthcare tasks, such as entity recognition, relation extraction, sentence
similarity, text summarization, and question answering. In this article, we
review the major technical innovations that underpin modern NLP models and
present state-of-the-art NLP applications that employ LLMs in radiation
oncology research. However, these LLMs are prone to many errors such as
hallucinations, biases, and ethical violations, which necessitate rigorous
evaluation and validation before clinical deployment. As such, we propose a
comprehensive framework for assessing the NLP models based on their purpose and
clinical fit, technical performance, bias and trust, legal and ethical
implications, and quality assurance, prior to implementation in clinical
radiation oncology. Our article aims to provide guidance and insights for
researchers and clinicians who are interested in developing and using NLP
models in clinical radiation oncology."	ArXiv
1016	"Practical Guidelines for the Selection and Evaluation of Natural
  Language Processing Techniques in Requirements Engineering"	['Mehrdad Sabetzadeh', 'Chetan Arora']	2024-01-03 02:24:35+00:00	http://arxiv.org/abs/2401.01508v3	"Natural Language Processing (NLP) is now a cornerstone of requirements
automation. One compelling factor behind the growing adoption of NLP in
Requirements Engineering (RE) is the prevalent use of natural language (NL) for
specifying requirements in industry. NLP techniques are commonly used for
automatically classifying requirements, extracting important information, e.g.,
domain models and glossary terms, and performing quality assurance tasks, such
as ambiguity handling and completeness checking. With so many different NLP
solution strategies available and the possibility of applying machine learning
alongside, it can be challenging to choose the right strategy for a specific RE
task and to evaluate the resulting solution in an empirically rigorous manner.
In this chapter, we present guidelines for the selection of NLP techniques as
well as for their evaluation in the context of RE. In particular, we discuss
how to choose among different strategies such as traditional NLP, feature-based
machine learning, and language-model-based methods. Our ultimate hope for this
chapter is to serve as a stepping stone, assisting newcomers to NLP4RE in
quickly initiating themselves into the NLP technologies most pertinent to the
RE field."	ArXiv
1017	"Natural Language Processing Methods for Symbolic Music Generation and
  Information Retrieval: a Survey"	['Dinh-Viet-Toan Le', 'Louis Bigo', 'Mikaela Keller', 'Dorien Herremans']	2024-02-27 12:48:01+00:00	http://arxiv.org/abs/2402.17467v1	"Several adaptations of Transformers models have been developed in various
domains since its breakthrough in Natural Language Processing (NLP). This trend
has spread into the field of Music Information Retrieval (MIR), including
studies processing music data. However, the practice of leveraging NLP tools
for symbolic music data is not novel in MIR. Music has been frequently compared
to language, as they share several similarities, including sequential
representations of text and music. These analogies are also reflected through
similar tasks in MIR and NLP. This survey reviews NLP methods applied to
symbolic music generation and information retrieval studies following two axes.
We first propose an overview of representations of symbolic music adapted from
natural language sequential representations. Such representations are designed
by considering the specificities of symbolic music. These representations are
then processed by models. Such models, possibly originally developed for text
and adapted for symbolic music, are trained on various tasks. We describe these
models, in particular deep learning models, through different prisms,
highlighting music-specialized mechanisms. We finally present a discussion
surrounding the effective use of NLP tools for symbolic music data. This
includes technical issues regarding NLP methods and fundamental differences
between text and music, which may open several doors for further research into
more effectively adapting NLP tools to symbolic MIR."	ArXiv
1018	"A Survey of Prompt Engineering Methods in Large Language Models for
  Different NLP Tasks"	['Shubham Vatsal', 'Harsh Dubey']	2024-07-17 20:23:19+00:00	http://arxiv.org/abs/2407.12994v2	"Large language models (LLMs) have shown remarkable performance on many
different Natural Language Processing (NLP) tasks. Prompt engineering plays a
key role in adding more to the already existing abilities of LLMs to achieve
significant performance gains on various NLP tasks. Prompt engineering requires
composing natural language instructions called prompts to elicit knowledge from
LLMs in a structured way. Unlike previous state-of-the-art (SoTA) models,
prompt engineering does not require extensive parameter re-training or
fine-tuning based on the given NLP task and thus solely operates on the
embedded knowledge of LLMs. Additionally, LLM enthusiasts can intelligently
extract LLMs' knowledge through a basic natural language conversational
exchange or prompt engineering, allowing more and more people even without deep
mathematical machine learning background to experiment with LLMs. With prompt
engineering gaining popularity in the last two years, researchers have come up
with numerous engineering techniques around designing prompts to improve
accuracy of information extraction from the LLMs. In this paper, we summarize
different prompting techniques and club them together based on different NLP
tasks that they have been used for. We further granularly highlight the
performance of these prompting strategies on various datasets belonging to that
NLP task, talk about the corresponding LLMs used, present a taxonomy diagram
and discuss the possible SoTA for specific datasets. In total, we read and
present a survey of 44 research papers which talk about 39 different prompting
methods on 29 different NLP tasks of which most of them have been published in
the last two years."	ArXiv
1019	"A Scoping Review of Publicly Available Language Tasks in Clinical
  Natural Language Processing"	['Yanjun Gao', 'Dmitriy Dligach', 'Leslie Christensen', 'Samuel Tesch', 'Ryan Laffin', 'Dongfang Xu', 'Timothy Miller', 'Ozlem Uzuner', 'Matthew M Churpek', 'Majid Afshar']	2021-12-07 22:49:58+00:00	http://arxiv.org/abs/2112.05780v1	"Objective: to provide a scoping review of papers on clinical natural language
processing (NLP) tasks that use publicly available electronic health record
data from a cohort of patients. Materials and Methods: We searched six
databases, including biomedical research and computer science literature
database. A round of title/abstract screening and full-text screening were
conducted by two reviewers. Our method followed the Preferred Reporting Items
for Systematic Reviews and Meta-Analysis (PRISMA) guidelines. Results: A total
of 35 papers with 47 clinical NLP tasks met inclusion criteria between 2007 and
2021. We categorized the tasks by the type of NLP problems, including name
entity recognition, summarization, and other NLP tasks. Some tasks were
introduced with a topic of clinical decision support applications, such as
substance abuse, phenotyping, cohort selection for clinical trial. We
summarized the tasks by publication and dataset information. Discussion: The
breadth of clinical NLP tasks keeps growing as the field of NLP evolves with
advancements in language systems. However, gaps exist in divergent interests
between general domain NLP community and clinical informatics community, and in
generalizability of the data sources. We also identified issues in data
selection and preparation including the lack of time-sensitive data, and
invalidity of problem size and evaluation. Conclusions: The existing clinical
NLP tasks cover a wide range of topics and the field will continue to grow and
attract more attention from both general domain NLP and clinical informatics
community. We encourage future work to incorporate multi-disciplinary
collaboration, reporting transparency, and standardization in data preparation."	ArXiv
1020	"Time to Embrace Natural Language Processing (NLP)-based Digital
  Pathology: Benchmarking NLP- and Convolutional Neural Network-based Deep
  Learning Pipelines"	['Min Cen', 'Xingyu Li', 'Bangwei Guo', 'Jitendra Jonnagaddala', 'Hong Zhang', 'Xu Steven Xu']	2023-02-21 02:42:03+00:00	http://arxiv.org/abs/2302.10406v1	"NLP-based computer vision models, particularly vision transformers, have been
shown to outperform CNN models in many imaging tasks. However, most digital
pathology artificial-intelligence models are based on CNN architectures,
probably owing to a lack of data regarding NLP models for pathology images. In
this study, we developed digital pathology pipelines to benchmark the five most
recently proposed NLP models (vision transformer (ViT), Swin Transformer,
MobileViT, CMT, and Sequencer2D) and four popular CNN models (ResNet18,
ResNet50, MobileNetV2, and EfficientNet) to predict biomarkers in colorectal
cancer (microsatellite instability, CpG island methylator phenotype, and BRAF
mutation). Hematoxylin and eosin-stained whole-slide images from Molecular and
Cellular Oncology and The Cancer Genome Atlas were used as training and
external validation datasets, respectively. Cross-study external validations
revealed that the NLP-based models significantly outperformed the CNN-based
models in biomarker prediction tasks, improving the overall prediction and
precision up to approximately 10% and 26%, respectively. Notably, compared with
existing models in the current literature using large training datasets, our
NLP models achieved state-of-the-art predictions for all three biomarkers using
a relatively small training dataset, suggesting that large training datasets
are not a prerequisite for NLP models or transformers, and NLP may be more
suitable for clinical studies in which small training datasets are commonly
collected. The superior performance of Sequencer2D suggests that further
research and innovation on both transformer and bidirectional long short-term
memory architectures are warranted in the field of digital pathology. NLP
models can replace classic CNN architectures and become the new workhorse
backbone in the field of digital pathology."	ArXiv
1021	"Heavy Quarkonium Production at Collider Energies: Factorization and
  Evolution"	['Zhong-Bo Kang', 'Yan-Qing Ma', 'Jian-Wei Qiu', 'George Sterman']	2014-01-05 18:28:58+00:00	http://arxiv.org/abs/1401.0923v2	"We present a factorization formalism for inclusive production of heavy
quarkonia of large transverse momentum, $p_T$ at collider energies, including
both leading power (LP) and next-to-leading power (NLP) behavior in $p_T$. We
demonstrate that both LP and NLP contributions can be factorized in terms of
perturbatively calculable short-distance partonic coefficient functions and
universal non-perturbative fragmentation functions, and derive the evolution
equations that are implied by the factorization. We identify projection
operators for all channels of the factorized LP and NLP infrared safe
short-distance partonic hard parts, and corresponding operator definitions of
fragmentation functions. For the NLP, we focus on the contributions involving
the production of a heavy quark pair, a necessary condition for producing a
heavy quarkonium. We evaluate the first non-trivial order of evolution kernels
for all relevant fragmentation functions, and discuss the role of NLP
contributions."	ArXiv
1022	Visualizing NLP annotations for Crowdsourcing	['Hanchuan Li', 'Haichen Shen', 'Shengliang Xu', 'Congle Zhang']	2015-08-25 06:34:00+00:00	http://arxiv.org/abs/1508.06044v1	"Visualizing NLP annotation is useful for the collection of training data for
the statistical NLP approaches. Existing toolkits either provide limited visual
aid, or introduce comprehensive operators to realize sophisticated linguistic
rules. Workers must be well trained to use them. Their audience thus can hardly
be scaled to large amounts of non-expert crowdsourced workers. In this paper,
we present CROWDANNO, a visualization toolkit to allow crowd-sourced workers to
annotate two general categories of NLP problems: clustering and parsing.
Workers can finish the tasks with simplified operators in an interactive
interface, and fix errors conveniently. User studies show our toolkit is very
friendly to NLP non-experts, and allow them to produce high quality labels for
several sophisticated problems. We release our source code and toolkit to spur
future research."	ArXiv
1023	Non-abelian factorisation for next-to-leading-power threshold logarithms	['D. Bonocore', 'E. Laenen', 'L. Magnea', 'L. Vernazza', 'C. D. White']	2016-10-21 16:23:31+00:00	http://arxiv.org/abs/1610.06842v2	"Soft and collinear radiation is responsible for large corrections to many
hadronic cross sections, near thresholds for the production of heavy final
states. There is much interest in extending our understanding of this radiation
to next-to-leading power (NLP) in the threshold expansion. In this paper, we
generalise a previously proposed all-order NLP factorisation formula to include
non-abelian corrections. We define a non-abelian radiative jet function,
organising collinear enhancements at NLP, and compute it for quark jets at one
loop. We discuss in detail the issue of double counting between soft and
collinear regions. Finally, we verify our prescription by reproducing all NLP
logarithms in Drell-Yan production up to NNLO, including those associated with
double real emission. Our results constitute an important step in the
development of a fully general resummation formalism for NLP threshold effects."	ArXiv
1024	Anaphora and Coreference Resolution: A Review	['Rhea Sukthanker', 'Soujanya Poria', 'Erik Cambria', 'Ramkumar Thirunavukarasu']	2018-05-30 06:49:15+00:00	http://arxiv.org/abs/1805.11824v1	"Entity resolution aims at resolving repeated references to an entity in a
document and forms a core component of natural language processing (NLP)
research. This field possesses immense potential to improve the performance of
other NLP fields like machine translation, sentiment analysis, paraphrase
detection, summarization, etc. The area of entity resolution in NLP has seen
proliferation of research in two separate sub-areas namely: anaphora resolution
and coreference resolution. Through this review article, we aim at clarifying
the scope of these two tasks in entity resolution. We also carry out a detailed
analysis of the datasets, evaluation metrics and research methods that have
been adopted to tackle this NLP problem. This survey is motivated with the aim
of providing the reader with a clear understanding of what constitutes this NLP
problem and the issues that require attention."	ArXiv
1025	"Implementing a Portable Clinical NLP System with a Common Data Model - a
  Lisp Perspective"	['Yuan Luo', 'Peter Szolovits']	2018-11-15 04:58:21+00:00	http://arxiv.org/abs/1811.06179v1	"This paper presents a Lisp architecture for a portable NLP system, termed
LAPNLP, for processing clinical notes. LAPNLP integrates multiple standard,
customized and in-house developed NLP tools. Our system facilitates portability
across different institutions and data systems by incorporating an enriched
Common Data Model (CDM) to standardize necessary data elements. It utilizes
UMLS to perform domain adaptation when integrating generic domain NLP tools. It
also features stand-off annotations that are specified by positional reference
to the original document. We built an interval tree based search engine to
efficiently query and retrieve the stand-off annotations by specifying
positional requirements. We also developed a utility to convert an inline
annotation format to stand-off annotations to enable the reuse of clinical text
datasets with inline annotations. We experimented with our system on several
NLP facilitated tasks including computational phenotyping for lymphoma patients
and semantic relation extraction for clinical notes. These experiments
showcased the broader applicability and utility of LAPNLP."	ArXiv
1026	Comparing BERT against traditional machine learning text classification	['Santiago González-Carvajal', 'Eduardo C. Garrido-Merchán']	2020-05-26 20:14:39+00:00	http://arxiv.org/abs/2005.13012v2	"The BERT model has arisen as a popular state-of-the-art machine learning
model in the recent years that is able to cope with multiple NLP tasks such as
supervised text classification without human supervision. Its flexibility to
cope with any type of corpus delivering great results has make this approach
very popular not only in academia but also in the industry. Although, there are
lots of different approaches that have been used throughout the years with
success. In this work, we first present BERT and include a little review on
classical NLP approaches. Then, we empirically test with a suite of experiments
dealing different scenarios the behaviour of BERT against the traditional
TF-IDF vocabulary fed to machine learning algorithms. Our purpose of this work
is to add empirical evidence to support or refuse the use of BERT as a default
on NLP tasks. Experiments show the superiority of BERT and its independence of
features of the NLP problem such as the language of the text adding empirical
evidence to use BERT as a default technique to be used in NLP problems."	ArXiv
1027	"Language (Technology) is Power: A Critical Survey of ""Bias"" in NLP"	['Su Lin Blodgett', 'Solon Barocas', 'Hal Daumé III', 'Hanna Wallach']	2020-05-28 14:32:08+00:00	http://arxiv.org/abs/2005.14050v2	"We survey 146 papers analyzing ""bias"" in NLP systems, finding that their
motivations are often vague, inconsistent, and lacking in normative reasoning,
despite the fact that analyzing ""bias"" is an inherently normative process. We
further find that these papers' proposed quantitative techniques for measuring
or mitigating ""bias"" are poorly matched to their motivations and do not engage
with the relevant literature outside of NLP. Based on these findings, we
describe the beginnings of a path forward by proposing three recommendations
that should guide work analyzing ""bias"" in NLP systems. These recommendations
rest on a greater recognition of the relationships between language and social
hierarchies, encouraging researchers and practitioners to articulate their
conceptualizations of ""bias""---i.e., what kinds of system behaviors are
harmful, in what ways, to whom, and why, as well as the normative reasoning
underlying these statements---and to center work around the lived experiences
of members of communities affected by NLP systems, while interrogating and
reimagining the power relations between technologists and such communities."	ArXiv
1028	NeuronBlocks: Building Your NLP DNN Models Like Playing Lego	['Ming Gong', 'Linjun Shou', 'Wutao Lin', 'Zhijie Sang', 'Quanjia Yan', 'Ze Yang', 'Feixiang Cheng', 'Daxin Jiang']	2019-04-21 03:11:24+00:00	http://arxiv.org/abs/1904.09535v3	"Deep Neural Networks (DNN) have been widely employed in industry to address
various Natural Language Processing (NLP) tasks. However, many engineers find
it a big overhead when they have to choose from multiple frameworks, compare
different types of models, and understand various optimization mechanisms. An
NLP toolkit for DNN models with both generality and flexibility can greatly
improve the productivity of engineers by saving their learning cost and guiding
them to find optimal solutions to their tasks. In this paper, we introduce
NeuronBlocks\footnote{Code: \url{https://github.com/Microsoft/NeuronBlocks}}
\footnote{Demo: \url{https://youtu.be/x6cOpVSZcdo}}, a toolkit encapsulating a
suite of neural network modules as building blocks to construct various DNN
models with complex architecture. This toolkit empowers engineers to build,
train, and test various NLP models through simple configuration of JSON files.
The experiments on several NLP datasets such as GLUE, WikiQA and CoNLL-2003
demonstrate the effectiveness of NeuronBlocks."	ArXiv
1029	Energy and Policy Considerations for Deep Learning in NLP	['Emma Strubell', 'Ananya Ganesh', 'Andrew McCallum']	2019-06-05 18:40:53+00:00	http://arxiv.org/abs/1906.02243v1	"Recent progress in hardware and methodology for training neural networks has
ushered in a new generation of large networks trained on abundant data. These
models have obtained notable gains in accuracy across many NLP tasks. However,
these accuracy improvements depend on the availability of exceptionally large
computational resources that necessitate similarly substantial energy
consumption. As a result these models are costly to train and develop, both
financially, due to the cost of hardware and electricity or cloud compute time,
and environmentally, due to the carbon footprint required to fuel modern tensor
processing hardware. In this paper we bring this issue to the attention of NLP
researchers by quantifying the approximate financial and environmental costs of
training a variety of recently successful neural network models for NLP. Based
on these findings, we propose actionable recommendations to reduce costs and
improve equity in NLP research and practice."	ArXiv
1030	Mitigating Gender Bias in Natural Language Processing: Literature Review	['Tony Sun', 'Andrew Gaut', 'Shirlyn Tang', 'Yuxin Huang', 'Mai ElSherief', 'Jieyu Zhao', 'Diba Mirza', 'Elizabeth Belding', 'Kai-Wei Chang', 'William Yang Wang']	2019-06-21 06:39:11+00:00	http://arxiv.org/abs/1906.08976v1	"As Natural Language Processing (NLP) and Machine Learning (ML) tools rise in
popularity, it becomes increasingly vital to recognize the role they play in
shaping societal biases and stereotypes. Although NLP models have shown success
in modeling various applications, they propagate and may even amplify gender
bias found in text corpora. While the study of bias in artificial intelligence
is not new, methods to mitigate gender bias in NLP are relatively nascent. In
this paper, we review contemporary studies on recognizing and mitigating gender
bias in NLP. We discuss gender bias based on four forms of representation bias
and analyze methods recognizing gender bias. Furthermore, we discuss the
advantages and drawbacks of existing gender debiasing methods. Finally, we
discuss future studies for recognizing and mitigating gender bias in NLP."	ArXiv
1031	"Predictive Biases in Natural Language Processing Models: A Conceptual
  Framework and Overview"	['Deven Shah', 'H. Andrew Schwartz', 'Dirk Hovy']	2019-11-09 23:53:19+00:00	http://arxiv.org/abs/1912.11078v2	"An increasing number of works in natural language processing have addressed
the effect of bias on the predicted outcomes, introducing mitigation techniques
that act on different parts of the standard NLP pipeline (data and models).
However, these works have been conducted in isolation, without a unifying
framework to organize efforts within the field. This leads to repetitive
approaches, and puts an undue focus on the effects of bias, rather than on
their origins. Research focused on bias symptoms rather than the underlying
origins could limit the development of effective countermeasures. In this
paper, we propose a unifying conceptualization: the predictive bias framework
for NLP. We summarize the NLP literature and propose a general mathematical
definition of predictive bias in NLP along with a conceptual framework,
differentiating four main origins of biases: label bias, selection bias, model
overamplification, and semantic bias. We discuss how past work has countered
each bias origin. Our framework serves to guide an introductory overview of
predictive bias in NLP, integrating existing work into a single structure and
opening avenues for future research."	ArXiv
1032	Countering Online Hate Speech: An NLP Perspective	['Mudit Chaudhary', 'Chandni Saxena', 'Helen Meng']	2021-09-07 08:48:13+00:00	http://arxiv.org/abs/2109.02941v1	"Online hate speech has caught everyone's attention from the news related to
the COVID-19 pandemic, US elections, and worldwide protests. Online toxicity -
an umbrella term for online hateful behavior, manifests itself in forms such as
online hate speech. Hate speech is a deliberate attack directed towards an
individual or a group motivated by the targeted entity's identity or opinions.
The rising mass communication through social media further exacerbates the
harmful consequences of online hate speech. While there has been significant
research on hate-speech identification using Natural Language Processing (NLP),
the work on utilizing NLP for prevention and intervention of online hate speech
lacks relatively. This paper presents a holistic conceptual framework on
hate-speech NLP countering methods along with a thorough survey on the current
progress of NLP for countering online hate speech. It classifies the countering
techniques based on their time of action, and identifies potential future
research areas on this topic."	ArXiv
1033	Multi-Task Learning in Natural Language Processing: An Overview	['Shijie Chen', 'Yu Zhang', 'Qiang Yang']	2021-09-19 14:51:51+00:00	http://arxiv.org/abs/2109.09138v2	"Deep learning approaches have achieved great success in the field of Natural
Language Processing (NLP). However, directly training deep neural models often
suffer from overfitting and data scarcity problems that are pervasive in NLP
tasks. In recent years, Multi-Task Learning (MTL), which can leverage useful
information of related tasks to achieve simultaneous performance improvement on
these tasks, has been used to handle these problems. In this paper, we give an
overview of the use of MTL in NLP tasks. We first review MTL architectures used
in NLP tasks and categorize them into four classes, including parallel
architecture, hierarchical architecture, modular architecture, and generative
adversarial architecture. Then we present optimization techniques on loss
construction, gradient regularization, data sampling, and task scheduling to
properly train a multi-task model. After presenting applications of MTL in a
variety of NLP tasks, we introduce some benchmark datasets. Finally, we make a
conclusion and discuss several possible research directions in this field."	ArXiv
1034	Paradigm Shift in Natural Language Processing	['Tianxiang Sun', 'Xiangyang Liu', 'Xipeng Qiu', 'Xuanjing Huang']	2021-09-26 11:55:23+00:00	http://arxiv.org/abs/2109.12575v2	"In the era of deep learning, modeling for most NLP tasks has converged to
several mainstream paradigms. For example, we usually adopt the sequence
labeling paradigm to solve a bundle of tasks such as POS-tagging, NER,
Chunking, and adopt the classification paradigm to solve tasks like sentiment
analysis. With the rapid progress of pre-trained language models, recent years
have observed a rising trend of Paradigm Shift, which is solving one NLP task
by reformulating it as another one. Paradigm shift has achieved great success
on many tasks, becoming a promising way to improve model performance. Moreover,
some of these paradigms have shown great potential to unify a large number of
NLP tasks, making it possible to build a single model to handle diverse tasks.
In this paper, we review such phenomenon of paradigm shifts in recent years,
highlighting several paradigms that have the potential to solve different NLP
tasks."	ArXiv
1035	"One size does not fit all: Investigating strategies for
  differentially-private learning across NLP tasks"	['Manuel Senge', 'Timour Igamberdiev', 'Ivan Habernal']	2021-12-15 14:31:32+00:00	http://arxiv.org/abs/2112.08159v3	"Preserving privacy in contemporary NLP models allows us to work with
sensitive data, but unfortunately comes at a price. We know that stricter
privacy guarantees in differentially-private stochastic gradient descent
(DP-SGD) generally degrade model performance. However, previous research on the
efficiency of DP-SGD in NLP is inconclusive or even counter-intuitive. In this
short paper, we provide an extensive analysis of different privacy preserving
strategies on seven downstream datasets in five different `typical' NLP tasks
with varying complexity using modern neural models based on BERT and
XtremeDistil architectures. We show that unlike standard non-private approaches
to solving NLP tasks, where bigger is usually better, privacy-preserving
strategies do not exhibit a winning pattern, and each task and privacy regime
requires a special treatment to achieve adequate performance."	ArXiv
1036	Measure and Improve Robustness in NLP Models: A Survey	['Xuezhi Wang', 'Haohan Wang', 'Diyi Yang']	2021-12-15 18:02:04+00:00	http://arxiv.org/abs/2112.08313v2	"As NLP models achieved state-of-the-art performances over benchmarks and
gained wide applications, it has been increasingly important to ensure the safe
deployment of these models in the real world, e.g., making sure the models are
robust against unseen or challenging scenarios. Despite robustness being an
increasingly studied topic, it has been separately explored in applications
like vision and NLP, with various definitions, evaluation and mitigation
strategies in multiple lines of research. In this paper, we aim to provide a
unifying survey of how to define, measure and improve robustness in NLP. We
first connect multiple definitions of robustness, then unify various lines of
work on identifying robustness failures and evaluating models' robustness.
Correspondingly, we present mitigation strategies that are data-driven,
model-driven, and inductive-prior-based, with a more systematic view of how to
effectively improve robustness in NLP models. Finally, we conclude by outlining
open challenges and future directions to motivate further research in this
area."	ArXiv
1037	"Robust Natural Language Processing: Recent Advances, Challenges, and
  Future Directions"	['Marwan Omar', 'Soohyeon Choi', 'DaeHun Nyang', 'David Mohaisen']	2022-01-03 17:17:11+00:00	http://arxiv.org/abs/2201.00768v1	"Recent natural language processing (NLP) techniques have accomplished high
performance on benchmark datasets, primarily due to the significant improvement
in the performance of deep learning. The advances in the research community
have led to great enhancements in state-of-the-art production systems for NLP
tasks, such as virtual assistants, speech recognition, and sentiment analysis.
However, such NLP systems still often fail when tested with adversarial
attacks. The initial lack of robustness exposed troubling gaps in current
models' language understanding capabilities, creating problems when NLP systems
are deployed in real life. In this paper, we present a structured overview of
NLP robustness research by summarizing the literature in a systemic way across
various dimensions. We then take a deep-dive into the various dimensions of
robustness, across techniques, metrics, embeddings, and benchmarks. Finally, we
argue that robustness should be multi-dimensional, provide insights into
current research, identify gaps in the literature to suggest directions worth
pursuing to address these gaps."	ArXiv
1038	Distillation-Resistant Watermarking for Model Protection in NLP	['Xuandong Zhao', 'Lei Li', 'Yu-Xiang Wang']	2022-10-07 04:14:35+00:00	http://arxiv.org/abs/2210.03312v2	"How can we protect the intellectual property of trained NLP models? Modern
NLP models are prone to stealing by querying and distilling from their publicly
exposed APIs. However, existing protection methods such as watermarking only
work for images but are not applicable to text. We propose
Distillation-Resistant Watermarking (DRW), a novel technique to protect NLP
models from being stolen via distillation. DRW protects a model by injecting
watermarks into the victim's prediction probability corresponding to a secret
key and is able to detect such a key by probing a suspect model. We prove that
a protected model still retains the original accuracy within a certain bound.
We evaluate DRW on a diverse set of NLP tasks including text classification,
part-of-speech tagging, and named entity recognition. Experiments show that DRW
protects the original model and detects stealing suspects at 100% mean average
precision for all four tasks while the prior method fails on two."	ArXiv
1039	"Dim-Krum: Backdoor-Resistant Federated Learning for NLP with
  Dimension-wise Krum-Based Aggregation"	['Zhiyuan Zhang', 'Qi Su', 'Xu Sun']	2022-10-13 10:43:42+00:00	http://arxiv.org/abs/2210.06894v1	"Despite the potential of federated learning, it is known to be vulnerable to
backdoor attacks. Many robust federated aggregation methods are proposed to
reduce the potential backdoor risk. However, they are mainly validated in the
CV field. In this paper, we find that NLP backdoors are hard to defend against
than CV, and we provide a theoretical analysis that the malicious update
detection error probabilities are determined by the relative backdoor
strengths. NLP attacks tend to have small relative backdoor strengths, which
may result in the failure of robust federated aggregation methods for NLP
attacks. Inspired by the theoretical results, we can choose some dimensions
with higher backdoor strengths to settle this issue. We propose a novel
federated aggregation algorithm, Dim-Krum, for NLP tasks, and experimental
results validate its effectiveness."	ArXiv
1040	"Missing Counter-Evidence Renders NLP Fact-Checking Unrealistic for
  Misinformation"	['Max Glockner', 'Yufang Hou', 'Iryna Gurevych']	2022-10-25 09:40:48+00:00	http://arxiv.org/abs/2210.13865v1	"Misinformation emerges in times of uncertainty when credible information is
limited. This is challenging for NLP-based fact-checking as it relies on
counter-evidence, which may not yet be available. Despite increasing interest
in automatic fact-checking, it is still unclear if automated approaches can
realistically refute harmful real-world misinformation. Here, we contrast and
compare NLP fact-checking with how professional fact-checkers combat
misinformation in the absence of counter-evidence. In our analysis, we show
that, by design, existing NLP task definitions for fact-checking cannot refute
misinformation as professional fact-checkers do for the majority of claims. We
then define two requirements that the evidence in datasets must fulfill for
realistic fact-checking: It must be (1) sufficient to refute the claim and (2)
not leaked from existing fact-checking articles. We survey existing
fact-checking datasets and find that all of them fail to satisfy both criteria.
Finally, we perform experiments to demonstrate that models trained on a
large-scale fact-checking dataset rely on leaked evidence, which makes them
unsuitable in real-world scenarios. Taken together, we show that current NLP
fact-checking cannot realistically combat real-world misinformation because it
depends on unrealistic assumptions about counter-evidence in the data."	ArXiv
1041	NLP and CALL: integration is working	['Georges Antoniadis', 'Sylviane Granger', 'Olivier Kraif', 'Claude Ponton', 'Virginie Zampa']	2013-02-20 05:47:44+00:00	http://arxiv.org/abs/1302.4814v1	"In the first part of this article, we explore the background of
computer-assisted learning from its beginnings in the early XIXth century and
the first teaching machines, founded on theories of learning, at the start of
the XXth century. With the arrival of the computer, it became possible to offer
language learners different types of language activities such as comprehension
tasks, simulations, etc. However, these have limits that cannot be overcome
without some contribution from the field of natural language processing (NLP).
In what follows, we examine the challenges faced and the issues raised by
integrating NLP into CALL. We hope to demonstrate that the key to success in
integrating NLP into CALL is to be found in multidisciplinary work between
computer experts, linguists, language teachers, didacticians and NLP
specialists."	ArXiv
1042	"Towards a Seamless Integration of Word Senses into Downstream NLP
  Applications"	['Mohammad Taher Pilehvar', 'Jose Camacho-Collados', 'Roberto Navigli', 'Nigel Collier']	2017-10-18 09:13:06+00:00	http://arxiv.org/abs/1710.06632v1	"Lexical ambiguity can impede NLP systems from accurate understanding of
semantics. Despite its potential benefits, the integration of sense-level
information into NLP systems has remained understudied. By incorporating a
novel disambiguation algorithm into a state-of-the-art classification model, we
create a pipeline to integrate sense-level information into downstream NLP
applications. We show that a simple disambiguation of the input text can lead
to consistent performance improvement on multiple topic categorization and
polarity detection datasets, particularly when the fine granularity of the
underlying sense inventory is reduced and the document is sufficiently large.
Our results also point to the need for sense representation research to focus
more on in vivo evaluations which target the performance in downstream NLP
applications rather than artificial benchmarks."	ArXiv
1043	Natural Language Processing, Sentiment Analysis and Clinical Analytics	['Adil Rajput']	2019-02-02 09:30:26+00:00	http://arxiv.org/abs/1902.00679v1	"Recent advances in Big Data has prompted health care practitioners to utilize
the data available on social media to discern sentiment and emotions
expression. Health Informatics and Clinical Analytics depend heavily on
information gathered from diverse sources. Traditionally, a healthcare
practitioner will ask a patient to fill out a questionnaire that will form the
basis of diagnosing the medical condition. However, medical practitioners have
access to many sources of data including the patients writings on various
media. Natural Language Processing (NLP) allows researchers to gather such data
and analyze it to glean the underlying meaning of such writings. The field of
sentiment analysis (applied to many other domains) depend heavily on techniques
utilized by NLP. This work will look into various prevalent theories underlying
the NLP field and how they can be leveraged to gather users sentiments on
social media. Such sentiments can be culled over a period of time thus
minimizing the errors introduced by data input and other stressors.
Furthermore, we look at some applications of sentiment analysis and application
of NLP to mental health. The reader will also learn about the NLTK toolkit that
implements various NLP theories and how they can make the data scavenging
process a lot easier."	ArXiv
1044	"On the Equivalence Between Abstract Dialectical Frameworks and Logic
  Programs"	['João Alcântara', 'Samy Sá', 'Juan Acosta-Guadarrama']	2019-07-22 19:54:20+00:00	http://arxiv.org/abs/1907.09548v1	"Abstract Dialectical Frameworks (ADFs) are argumentation frameworks where
each node is associated with an acceptance condition. This allows us to model
different types of dependencies as supports and attacks. Previous studies
provided a translation from Normal Logic Programs (NLPs) to ADFs and proved the
stable models semantics for a normal logic program has an equivalent semantics
to that of the corresponding ADF. However, these studies failed in identifying
a semantics for ADFs equivalent to a three-valued semantics (as partial stable
models and well-founded models) for NLPs. In this work, we focus on a fragment
of ADFs, called Attacking Dialectical Frameworks (ADF$^+$s), and provide a
translation from NLPs to ADF$^+$s robust enough to guarantee the equivalence
between partial stable models, well-founded models, regular models, stable
models semantics for NLPs and respectively complete models, grounded models,
preferred models, stable models for ADFs. In addition, we define a new
semantics for ADF$^+$s, called L-stable, and show it is equivalent to the
L-stable semantics for NLPs. This paper is under consideration for acceptance
in TPLP."	ArXiv
1045	"Considering Likelihood in NLP Classification Explanations with Occlusion
  and Language Modeling"	['David Harbecke', 'Christoph Alt']	2020-04-21 10:37:44+00:00	http://arxiv.org/abs/2004.09890v1	"Recently, state-of-the-art NLP models gained an increasing syntactic and
semantic understanding of language, and explanation methods are crucial to
understand their decisions. Occlusion is a well established method that
provides explanations on discrete language data, e.g. by removing a language
unit from an input and measuring the impact on a model's decision. We argue
that current occlusion-based methods often produce invalid or syntactically
incorrect language data, neglecting the improved abilities of recent NLP
models. Furthermore, gradient-based explanation methods disregard the discrete
distribution of data in NLP. Thus, we propose OLM: a novel explanation method
that combines occlusion and language models to sample valid and syntactically
correct replacements with high likelihood, given the context of the original
input. We lay out a theoretical foundation that alleviates these weaknesses of
other explanation methods in NLP and provide results that underline the
importance of considering data likelihood in occlusion-based explanation."	ArXiv
1046	NLP Service APIs and Models for Efficient Registration of New Clients	['Sahil Shah', 'Vihari Piratla', 'Soumen Chakrabarti', 'Sunita Sarawagi']	2020-10-04 09:47:40+00:00	http://arxiv.org/abs/2010.01526v1	"State-of-the-art NLP inference uses enormous neural architectures and models
trained for GPU-months, well beyond the reach of most consumers of NLP. This
has led to one-size-fits-all public API-based NLP service models by major AI
companies, serving large numbers of clients. Neither (hardware deficient)
clients nor (heavily subscribed) servers can afford traditional fine tuning.
Many clients own little or no labeled data. We initiate a study of adaptation
of centralized NLP services to clients, and present one practical and
lightweight approach. Each client uses an unsupervised, corpus-based sketch to
register to the service. The server uses an auxiliary network to map the sketch
to an abstract vector representation, which then informs the main labeling
network. When a new client registers with its sketch, it gets immediate
accuracy benefits. We demonstrate the success of the proposed architecture
using sentiment labeling, NER, and predictive language modeling"	ArXiv
1047	"Situated Data, Situated Systems: A Methodology to Engage with Power
  Relations in Natural Language Processing Research"	['Lucy Havens', 'Melissa Terras', 'Benjamin Bach', 'Beatrice Alex']	2020-11-11 17:04:55+00:00	http://arxiv.org/abs/2011.05911v1	"We propose a bias-aware methodology to engage with power relations in natural
language processing (NLP) research. NLP research rarely engages with bias in
social contexts, limiting its ability to mitigate bias. While researchers have
recommended actions, technical methods, and documentation practices, no
methodology exists to integrate critical reflections on bias with technical NLP
methods. In this paper, after an extensive and interdisciplinary literature
review, we contribute a bias-aware methodology for NLP research. We also
contribute a definition of biased text, a discussion of the implications of
biased NLP systems, and a case study demonstrating how we are executing the
bias-aware methodology in research on archival metadata descriptions."	ArXiv
1048	NLPStatTest: A Toolkit for Comparing NLP System Performance	['Haotian Zhu', 'Denise Mak', 'Jesse Gioannini', 'Fei Xia']	2020-11-26 10:59:23+00:00	http://arxiv.org/abs/2011.13231v1	"Statistical significance testing centered on p-values is commonly used to
compare NLP system performance, but p-values alone are insufficient because
statistical significance differs from practical significance. The latter can be
measured by estimating effect size. In this paper, we propose a three-stage
procedure for comparing NLP system performance and provide a toolkit,
NLPStatTest, that automates the process. Users can upload NLP system evaluation
scores and the toolkit will analyze these scores, run appropriate significance
tests, estimate effect size, and conduct power analysis to estimate Type II
error. The toolkit provides a convenient and systematic way to compare NLP
system performance that goes beyond statistical significance testing"	ArXiv
1049	Taxonomic survey of Hindi Language NLP systems	['Nikita P. Desai', 'Prof.', 'Vipul K. Dabhi']	2021-01-30 11:53:56+00:00	http://arxiv.org/abs/2102.00214v1	"Natural Language processing (NLP) represents the task of automatic handling
of natural human language by machines.There is large spectrum of possible
applications of NLP which help in automating tasks like translating text from
one language to other, retrieving and summarizing data from very huge
repositories, spam email filtering, identifying fake news in digital media,
find sentiment and feedback of people, find political opinions and views of
people on various government policies, provide effective medical assistance
based on past history records of patient etc. Hindi is the official language of
India with nearly 691 million users in India and 366 million in rest of world.
At present, a number of government and private sector projects and researchers
in India and abroad, are working towards developing NLP applications and
resources for Indian languages. This survey gives a report of the resources and
applications available for Hindi language NLP."	ArXiv
1050	"Automated essay scoring using efficient transformer-based language
  models"	['Christopher M Ormerod', 'Akanksha Malhotra', 'Amir Jafari']	2021-02-25 19:28:39+00:00	http://arxiv.org/abs/2102.13136v1	"Automated Essay Scoring (AES) is a cross-disciplinary effort involving
Education, Linguistics, and Natural Language Processing (NLP). The efficacy of
an NLP model in AES tests it ability to evaluate long-term dependencies and
extrapolate meaning even when text is poorly written. Large pretrained
transformer-based language models have dominated the current state-of-the-art
in many NLP tasks, however, the computational requirements of these models make
them expensive to deploy in practice. The goal of this paper is to challenge
the paradigm in NLP that bigger is better when it comes to AES. To do this, we
evaluate the performance of several fine-tuned pretrained NLP models with a
modest number of parameters on an AES dataset. By ensembling our models, we
achieve excellent results with fewer parameters than most pretrained
transformer-based models."	ArXiv
1051	"CrossFit: A Few-shot Learning Challenge for Cross-task Generalization in
  NLP"	['Qinyuan Ye', 'Bill Yuchen Lin', 'Xiang Ren']	2021-04-18 12:14:46+00:00	http://arxiv.org/abs/2104.08835v2	"Humans can learn a new language task efficiently with only few examples, by
leveraging their knowledge obtained when learning prior tasks. In this paper,
we explore whether and how such cross-task generalization ability can be
acquired, and further applied to build better few-shot learners across diverse
NLP tasks. We introduce CrossFit, a problem setup for studying cross-task
generalization ability, which standardizes seen/unseen task partitions, data
access during different learning stages, and the evaluation protocols. To
instantiate different seen/unseen task partitions in CrossFit and facilitate
in-depth analysis, we present the NLP Few-shot Gym, a repository of 160 diverse
few-shot NLP tasks created from open-access NLP datasets and converted to a
unified text-to-text format. Our analysis reveals that the few-shot learning
ability on unseen tasks can be improved via an upstream learning stage using a
set of seen tasks. We also observe that the selection of upstream learning
tasks can significantly influence few-shot performance on unseen tasks, asking
further analysis on task similarity and transferability."	ArXiv
1052	Switching Contexts: Transportability Measures for NLP	['Guy Marshall', 'Mokanarangan Thayaparan', 'Philip Osborne', 'Andre Freitas']	2021-05-03 13:15:24+00:00	http://arxiv.org/abs/2105.00823v1	"This paper explores the topic of transportability, as a sub-area of
generalisability. By proposing the utilisation of metrics based on
well-established statistics, we are able to estimate the change in performance
of NLP models in new contexts. Defining a new measure for transportability may
allow for better estimation of NLP system performance in new domains, and is
crucial when assessing the performance of NLP systems in new tasks and domains.
Through several instances of increasing complexity, we demonstrate how
lightweight domain similarity measures can be used as estimators for the
transportability in NLP applications. The proposed transportability measures
are evaluated in the context of Named Entity Recognition and Natural Language
Inference tasks."	ArXiv
1053	Grounding 'Grounding' in NLP	['Khyathi Raghavi Chandu', 'Yonatan Bisk', 'Alan W Black']	2021-06-04 00:40:59+00:00	http://arxiv.org/abs/2106.02192v1	"The NLP community has seen substantial recent interest in grounding to
facilitate interaction between language technologies and the world. However, as
a community, we use the term broadly to reference any linking of text to data
or non-textual modality. In contrast, Cognitive Science more formally defines
""grounding"" as the process of establishing what mutual information is required
for successful communication between two interlocutors -- a definition which
might implicitly capture the NLP usage but differs in intent and scope. We
investigate the gap between these definitions and seek answers to the following
questions: (1) What aspects of grounding are missing from NLP tasks? Here we
present the dimensions of coordination, purviews and constraints. (2) How is
the term ""grounding"" used in the current research? We study the trends in
datasets, domains, and tasks introduced in recent NLP conferences. And finally,
(3) How to advance our current definition to bridge the gap with Cognitive
Science? We present ways to both create new tasks or repurpose existing ones to
make advancements towards achieving a more complete sense of grounding."	ArXiv
1054	Android Security using NLP Techniques: A Review	['Sevil Sen', 'Burcu Can']	2021-07-07 08:33:00+00:00	http://arxiv.org/abs/2107.03072v1	"Android is among the most targeted platform by attackers. While attackers are
improving their techniques, traditional solutions based on static and dynamic
analysis have been also evolving. In addition to the application code, Android
applications have some metadata that could be useful for security analysis of
applications. Unlike traditional application distribution mechanisms, Android
applications are distributed centrally in mobile markets. Therefore, beside
application packages, such markets contain app information provided by app
developers and app users. The availability of such useful textual data together
with the advancement in Natural Language Processing (NLP) that is used to
process and understand textual data has encouraged researchers to investigate
the use of NLP techniques in Android security. Especially, security solutions
based on NLP have accelerated in the last 5 years and proven to be useful. This
study reviews these proposals and aim to explore possible research directions
for future studies by presenting state-of-the-art in this domain. We mainly
focus on NLP-based solutions under four categories: description-to-behaviour
fidelity, description generation, privacy and malware detection."	ArXiv
1055	"Benchmarking for Biomedical Natural Language Processing Tasks with a
  Domain Specific ALBERT"	['Usman Naseem', 'Adam G. Dunn', 'Matloob Khushi', 'Jinman Kim']	2021-07-09 11:47:13+00:00	http://arxiv.org/abs/2107.04374v1	"The availability of biomedical text data and advances in natural language
processing (NLP) have made new applications in biomedical NLP possible.
Language models trained or fine tuned using domain specific corpora can
outperform general models, but work to date in biomedical NLP has been limited
in terms of corpora and tasks. We present BioALBERT, a domain-specific
adaptation of A Lite Bidirectional Encoder Representations from Transformers
(ALBERT), trained on biomedical (PubMed and PubMed Central) and clinical
(MIMIC-III) corpora and fine tuned for 6 different tasks across 20 benchmark
datasets. Experiments show that BioALBERT outperforms the state of the art on
named entity recognition (+11.09% BLURB score improvement), relation extraction
(+0.80% BLURB score), sentence similarity (+1.05% BLURB score), document
classification (+0.62% F1-score), and question answering (+2.83% BLURB score).
It represents a new state of the art in 17 out of 20 benchmark datasets. By
making BioALBERT models and data available, our aim is to help the biomedical
NLP community avoid computational costs of training and establish a new set of
baselines for future efforts across a broad range of biomedical NLP tasks."	ArXiv
1056	"Tea: Program Repair Using Neural Network Based on Program Information
  Attention Matrix"	['Wenshuo Wang', 'Chen Wu', 'Liang Cheng', 'Yang Zhang']	2021-07-17 15:49:22+00:00	http://arxiv.org/abs/2107.08262v1	"The advance in machine learning (ML)-driven natural language process (NLP)
points a promising direction for automatic bug fixing for software programs, as
fixing a buggy program can be transformed to a translation task. While software
programs contain much richer information than one-dimensional natural language
documents, pioneering work on using ML-driven NLP techniques for automatic
program repair only considered a limited set of such information. We
hypothesize that more comprehensive information of software programs, if
appropriately utilized, can improve the effectiveness of ML-driven NLP
approaches in repairing software programs. As the first step towards proving
this hypothesis, we propose a unified representation to capture the syntax,
data flow, and control flow aspects of software programs, and devise a method
to use such a representation to guide the transformer model from NLP in better
understanding and fixing buggy programs. Our preliminary experiment confirms
that the more comprehensive information of software programs used, the better
ML-driven NLP techniques can perform in fixing bugs in these programs."	ArXiv
1057	Natural Language Processing with Commonsense Knowledge: A Survey	['Yubo Xie', 'Zonghui Liu', 'Zongyang Ma', 'Fanyuan Meng', 'Yan Xiao', 'Fahui Miao', 'Pearl Pu']	2021-08-10 13:25:29+00:00	http://arxiv.org/abs/2108.04674v2	"Commonsense knowledge is essential for advancing natural language processing
(NLP) by enabling models to engage in human-like reasoning, which requires a
deeper understanding of context and often involves making inferences based on
implicit external knowledge. This paper explores the integration of commonsense
knowledge into various NLP tasks. We begin by reviewing prominent commonsense
knowledge bases and then discuss the benchmarks used to evaluate the
commonsense reasoning capabilities of NLP models, particularly language models.
Furthermore, we highlight key methodologies for incorporating commonsense
knowledge and their applications across different NLP tasks. The paper also
examines the challenges and emerging trends in enhancing NLP systems with
commonsense reasoning. All literature referenced in this survey can be accessed
via our GitHub repository: https://github.com/yuboxie/awesome-commonsense."	ArXiv
1058	"Systematic Inequalities in Language Technology Performance across the
  World's Languages"	['Damián Blasi', 'Antonios Anastasopoulos', 'Graham Neubig']	2021-10-13 14:03:07+00:00	http://arxiv.org/abs/2110.06733v1	"Natural language processing (NLP) systems have become a central technology in
communication, education, medicine, artificial intelligence, and many other
domains of research and development. While the performance of NLP methods has
grown enormously over the last decade, this progress has been restricted to a
minuscule subset of the world's 6,500 languages. We introduce a framework for
estimating the global utility of language technologies as revealed in a
comprehensive snapshot of recent publications in NLP. Our analyses involve the
field at large, but also more in-depth studies on both user-facing technologies
(machine translation, language understanding, question answering,
text-to-speech synthesis) as well as more linguistic NLP tasks (dependency
parsing, morphological inflection). In the process, we (1) quantify disparities
in the current state of NLP research, (2) explore some of its associated
societal and academic factors, and (3) produce tailored recommendations for
evidence-based policy making aimed at promoting more global and equitable
language technologies."	ArXiv
1059	"Interpreting Deep Learning Models in Natural Language Processing: A
  Review"	['Xiaofei Sun', 'Diyi Yang', 'Xiaoya Li', 'Tianwei Zhang', 'Yuxian Meng', 'Han Qiu', 'Guoyin Wang', 'Eduard Hovy', 'Jiwei Li']	2021-10-20 10:17:04+00:00	http://arxiv.org/abs/2110.10470v2	"Neural network models have achieved state-of-the-art performances in a wide
range of natural language processing (NLP) tasks. However, a long-standing
criticism against neural network models is the lack of interpretability, which
not only reduces the reliability of neural NLP systems but also limits the
scope of their applications in areas where interpretability is essential (e.g.,
health care applications). In response, the increasing interest in interpreting
neural NLP models has spurred a diverse array of interpretation methods over
recent years. In this survey, we provide a comprehensive review of various
interpretation methods for neural models in NLP. We first stretch out a
high-level taxonomy for interpretation methods in NLP, i.e., training-based
approaches, test-based approaches, and hybrid approaches. Next, we describe
sub-categories in each category in detail, e.g., influence-function based
methods, KNN-based methods, attention-based models, saliency-based methods,
perturbation-based methods, etc. We point out deficiencies of current methods
and suggest some avenues for future research."	ArXiv
1060	AdaPrompt: Adaptive Model Training for Prompt-based NLP	['Yulong Chen', 'Yang Liu', 'Li Dong', 'Shuohang Wang', 'Chenguang Zhu', 'Michael Zeng', 'Yue Zhang']	2022-02-10 04:04:57+00:00	http://arxiv.org/abs/2202.04824v2	"Prompt-based learning, with its capability to tackle zero-shot and few-shot
NLP tasks, has gained much attention in community. The main idea is to bridge
the gap between NLP downstream tasks and language modeling (LM), by mapping
these tasks into natural language prompts, which are then filled by pre-trained
language models (PLMs). However, for prompt learning, there are still two
salient gaps between NLP tasks and pretraining. First, prompt information is
not necessarily sufficiently present during LM pretraining. Second,
task-specific data are not necessarily well represented during pretraining. We
address these two issues by proposing AdaPrompt, adaptively retrieving external
data for continual pretraining of PLMs by making use of both task and prompt
characteristics. In addition, we make use of knowledge in Natural Language
Inference models for deriving adaptive verbalizers. Experimental results on
five NLP benchmarks show that AdaPrompt can improve over standard PLMs in
few-shot settings. In addition, in zero-shot settings, our method outperforms
standard prompt-based methods by up to 26.35\% relative error reduction."	ArXiv
1061	A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models	['Da Yin', 'Li Dong', 'Hao Cheng', 'Xiaodong Liu', 'Kai-Wei Chang', 'Furu Wei', 'Jianfeng Gao']	2022-02-17 17:17:43+00:00	http://arxiv.org/abs/2202.08772v1	"With the increasing of model capacity brought by pre-trained language models,
there emerges boosting needs for more knowledgeable natural language processing
(NLP) models with advanced functionalities including providing and making
flexible use of encyclopedic and commonsense knowledge. The mere pre-trained
language models, however, lack the capacity of handling such
knowledge-intensive NLP tasks alone. To address this challenge, large numbers
of pre-trained language models augmented with external knowledge sources are
proposed and in rapid development. In this paper, we aim to summarize the
current progress of pre-trained language model-based knowledge-enhanced models
(PLMKEs) by dissecting their three vital elements: knowledge sources,
knowledge-intensive NLP tasks, and knowledge fusion methods. Finally, we
present the challenges of PLMKEs based on the discussion regarding the three
elements and attempt to provide NLP practitioners with potential directions for
further research."	ArXiv
1062	Challenges and Strategies in Cross-Cultural NLP	['Daniel Hershcovich', 'Stella Frank', 'Heather Lent', 'Miryam de Lhoneux', 'Mostafa Abdou', 'Stephanie Brandl', 'Emanuele Bugliarello', 'Laura Cabello Piqueras', 'Ilias Chalkidis', 'Ruixiang Cui', 'Constanza Fierro', 'Katerina Margatina', 'Phillip Rust', 'Anders Søgaard']	2022-03-18 15:36:57+00:00	http://arxiv.org/abs/2203.10020v1	"Various efforts in the Natural Language Processing (NLP) community have been
made to accommodate linguistic diversity and serve speakers of many different
languages. However, it is important to acknowledge that speakers and the
content they produce and require, vary not just by language, but also by
culture. Although language and culture are tightly linked, there are important
differences. Analogous to cross-lingual and multilingual NLP, cross-cultural
and multicultural NLP considers these differences in order to better serve
users of NLP systems. We propose a principled framework to frame these efforts,
and survey existing and potential strategies."	ArXiv
1063	Residue-Based Natural Language Adversarial Attack Detection	['Vyas Raina', 'Mark Gales']	2022-04-17 17:47:47+00:00	http://arxiv.org/abs/2204.10192v2	"Deep learning based systems are susceptible to adversarial attacks, where a
small, imperceptible change at the input alters the model prediction. However,
to date the majority of the approaches to detect these attacks have been
designed for image processing systems. Many popular image adversarial detection
approaches are able to identify adversarial examples from embedding feature
spaces, whilst in the NLP domain existing state of the art detection approaches
solely focus on input text features, without consideration of model embedding
spaces. This work examines what differences result when porting these image
designed strategies to Natural Language Processing (NLP) tasks - these
detectors are found to not port over well. This is expected as NLP systems have
a very different form of input: discrete and sequential in nature, rather than
the continuous and fixed size inputs for images. As an equivalent model-focused
NLP detection approach, this work proposes a simple sentence-embedding
""residue"" based detector to identify adversarial examples. On many tasks, it
out-performs ported image domain detectors and recent state of the art NLP
specific detectors."	ArXiv
1064	"Noise-like Pulses from an All-Normal-Dispersion Fiber Laser with
  Weakened Spectrum Filtering"	['Zhicheng Zhang', 'Sha Wang', 'Jun Wang']	2022-05-03 09:49:51+00:00	http://arxiv.org/abs/2205.01393v2	"Noise-like pulses (NLP) are extremely sought after in many fields. Here, we
experimentally and numerically investigated the generation of noise-like pulses
in an all-normal-dispersion fiber laser with weak spectrum filtering. With the
insertion of the grating as a tunable spectrum filter, the laser operates at a
stable dissipative soliton state with a 3.84 ps duration. Replacing the grating
with a mirror, NLPs with double-scale intensity autocorrelation trace is
ultimately attained. Numerical simulations are performed in detail and
demonstrated that with the absence of a spectrum filter, the stable state
cannot be established but form the random pulse cluster. The random pulse
cluster achieves dynamic stability with suitable feedback, and the NLP is
ultimately generated. The NLP here is directly evolved by the initial noise,
and no other states occur during its evolution. These explorations could deepen
the understanding of NLP and enrich the complex dynamics of the ANDi ultrafast
fiber laser."	ArXiv
1065	"Reproducibility Beyond the Research Community: Experience from NLP
  Beginners"	['Shane Storks', 'Keunwoo Peter Yu', 'Joyce Chai']	2022-05-04 16:54:00+00:00	http://arxiv.org/abs/2205.02182v2	"As NLP research attracts public attention and excitement, it becomes
increasingly important for it to be accessible to a broad audience. As the
research community works to democratize NLP, it remains unclear whether
beginners to the field can easily apply the latest developments. To understand
their needs, we conducted a study with 93 students in an introductory NLP
course, where students reproduced results of recent NLP papers. Surprisingly,
our results suggest that their technical skill (i.e., programming experience)
has limited impact on their effort spent completing the exercise. Instead, we
find accessibility efforts by research authors to be key to a successful
experience, including thorough documentation and easy access to required models
and datasets."	ArXiv
1066	Improving Downstream Task Performance by Treating Numbers as Entities	['Dhanasekar Sundararaman', 'Vivek Subramanian', 'Guoyin Wang', 'Liyan Xu', 'Lawrence Carin']	2022-05-07 05:22:43+00:00	http://arxiv.org/abs/2205.03559v2	"Numbers are essential components of text, like any other word tokens, from
which natural language processing (NLP) models are built and deployed. Though
numbers are typically not accounted for distinctly in most NLP tasks, there is
still an underlying amount of numeracy already exhibited by NLP models. In this
work, we attempt to tap this potential of state-of-the-art NLP models and
transfer their ability to boost performance in related tasks. Our proposed
classification of numbers into entities helps NLP models perform well on
several tasks, including a handcrafted Fill-In-The-Blank (FITB) task and on
question answering using joint embeddings, outperforming the BERT and RoBERTa
baseline classification."	ArXiv
1067	"TinyGenius: Intertwining Natural Language Processing with Microtask
  Crowdsourcing for Scholarly Knowledge Graph Creation"	['Allard Oelen', 'Markus Stocker', 'Sören Auer']	2022-05-09 18:19:51+00:00	http://arxiv.org/abs/2205.04504v1	"As the number of published scholarly articles grows steadily each year, new
methods are needed to organize scholarly knowledge so that it can be more
efficiently discovered and used. Natural Language Processing (NLP) techniques
are able to autonomously process scholarly articles at scale and to create
machine readable representations of the article content. However, autonomous
NLP methods are by far not sufficiently accurate to create a high-quality
knowledge graph. Yet quality is crucial for the graph to be useful in practice.
We present TinyGenius, a methodology to validate NLP-extracted scholarly
knowledge statements using microtasks performed with crowdsourcing. The
scholarly context in which the crowd workers operate has multiple challenges.
The explainability of the employed NLP methods is crucial to provide context in
order to support the decision process of crowd workers. We employed TinyGenius
to populate a paper-centric knowledge graph, using five distinct NLP methods.
In the end, the resulting knowledge graph serves as a digital library for
scholarly articles."	ArXiv
1068	White-box Testing of NLP models with Mask Neuron Coverage	['Arshdeep Sekhon', 'Yangfeng Ji', 'Matthew B. Dwyer', 'Yanjun Qi']	2022-05-10 17:07:23+00:00	http://arxiv.org/abs/2205.05050v1	"Recent literature has seen growing interest in using black-box strategies
like CheckList for testing the behavior of NLP models. Research on white-box
testing has developed a number of methods for evaluating how thoroughly the
internal behavior of deep models is tested, but they are not applicable to NLP
models. We propose a set of white-box testing methods that are customized for
transformer-based NLP models. These include Mask Neuron Coverage (MNCOVER) that
measures how thoroughly the attention layers in models are exercised during
testing. We show that MNCOVER can refine testing suites generated by CheckList
by substantially reduce them in size, for more than 60\% on average, while
retaining failing tests -- thereby concentrating the fault detection power of
the test suite. Further we show how MNCOVER can be used to guide CheckList
input generation, evaluate alternative NLP testing methods, and drive data
augmentation to improve accuracy."	ArXiv
1069	Differential Privacy in Natural Language Processing: The Story So Far	['Oleksandra Klymenko', 'Stephen Meisenbacher', 'Florian Matthes']	2022-08-17 08:15:44+00:00	http://arxiv.org/abs/2208.08140v1	"As the tide of Big Data continues to influence the landscape of Natural
Language Processing (NLP), the utilization of modern NLP methods has grounded
itself in this data, in order to tackle a variety of text-based tasks. These
methods without a doubt can include private or otherwise personally
identifiable information. As such, the question of privacy in NLP has gained
fervor in recent years, coinciding with the development of new
Privacy-Enhancing Technologies (PETs). Among these PETs, Differential Privacy
boasts several desirable qualities in the conversation surrounding data
privacy. Naturally, the question becomes whether Differential Privacy is
applicable in the largely unstructured realm of NLP. This topic has sparked
novel research, which is unified in one basic goal: how can one adapt
Differential Privacy to NLP methods? This paper aims to summarize the
vulnerabilities addressed by Differential Privacy, the current thinking, and
above all, the crucial next steps that must be considered."	ArXiv
1070	Re-contextualizing Fairness in NLP: The Case of India	['Shaily Bhatt', 'Sunipa Dev', 'Partha Talukdar', 'Shachi Dave', 'Vinodkumar Prabhakaran']	2022-09-25 13:56:13+00:00	http://arxiv.org/abs/2209.12226v5	"Recent research has revealed undesirable biases in NLP data and models.
However, these efforts focus on social disparities in West, and are not
directly portable to other geo-cultural contexts. In this paper, we focus on
NLP fair-ness in the context of India. We start with a brief account of the
prominent axes of social disparities in India. We build resources for fairness
evaluation in the Indian context and use them to demonstrate prediction biases
along some of the axes. We then delve deeper into social stereotypes for Region
andReligion, demonstrating its prevalence in corpora and models. Finally, we
outline a holistic research agenda to re-contextualize NLP fairness research
for the Indian context, ac-counting for Indian societal context, bridging
technological gaps in NLP capabilities and re-sources, and adapting to Indian
cultural values. While we focus on India, this framework can be generalized to
other geo-cultural contexts."	ArXiv
1071	FinTech for Social Good: A Research Agenda from NLP Perspective	['Chung-Chi Chen', 'Hiroya Takamura', 'Hsin-Hsi Chen']	2022-11-13 22:29:41+00:00	http://arxiv.org/abs/2211.06431v1	"Making our research results positively impact on society and environment is
one of the goals our community has been pursuing recently. Although financial
technology (FinTech) is one of the popular application fields, we notice that
there is no discussion on how NLP can help in FinTech for the social good. When
mentioning FinTech for social good, people are talking about financial
inclusion and green finance. However, the role of NLP in these directions only
gets limited discussions. To fill this gap, this paper shares our idea of how
we can use NLP in FinTech for social good. We hope readers can rethink the
relationship between finance and NLP based on our sharing, and further join us
in improving the financial literacy of individual investors and improving the
supports for impact investment."	ArXiv
1072	Multilingual Sequence-to-Sequence Models for Hebrew NLP	['Matan Eyal', 'Hila Noga', 'Roee Aharoni', 'Idan Szpektor', 'Reut Tsarfaty']	2022-12-19 18:10:23+00:00	http://arxiv.org/abs/2212.09682v1	"Recent work attributes progress in NLP to large language models (LMs) with
increased model size and large quantities of pretraining data. Despite this,
current state-of-the-art LMs for Hebrew are both under-parameterized and
under-trained compared to LMs in other languages. Additionally, previous work
on pretrained Hebrew LMs focused on encoder-only models. While the encoder-only
architecture is beneficial for classification tasks, it does not cater well for
sub-word prediction tasks, such as Named Entity Recognition, when considering
the morphologically rich nature of Hebrew. In this paper we argue that
sequence-to-sequence generative architectures are more suitable for LLMs in the
case of morphologically rich languages (MRLs) such as Hebrew. We demonstrate
that by casting tasks in the Hebrew NLP pipeline as text-to-text tasks, we can
leverage powerful multilingual, pretrained sequence-to-sequence models as mT5,
eliminating the need for a specialized, morpheme-based, separately fine-tuned
decoder. Using this approach, our experiments show substantial improvements
over previously published results on existing Hebrew NLP benchmarks. These
results suggest that multilingual sequence-to-sequence models present a
promising building block for NLP for MRLs."	ArXiv
1073	"Requirement Formalisation using Natural Language Processing and Machine
  Learning: A Systematic Review"	['Shekoufeh Kolahdouz-Rahimi', 'Kevin Lano', 'Chenghua Lin']	2023-03-18 17:36:21+00:00	http://arxiv.org/abs/2303.13365v1	"Improvement of software development methodologies attracts developers to
automatic Requirement Formalisation (RF) in the Requirement Engineering (RE)
field. The potential advantages by applying Natural Language Processing (NLP)
and Machine Learning (ML) in reducing the ambiguity and incompleteness of
requirement written in natural languages is reported in different studies. The
goal of this paper is to survey and classify existing work on NLP and ML for
RF, identifying challenges in this domain and providing promising future
research directions. To achieve this, we conducted a systematic literature
review to outline the current state-of-the-art of NLP and ML techniques in RF
by selecting 257 papers from common used libraries. The search result is
filtered by defining inclusion and exclusion criteria and 47 relevant studies
between 2012 and 2022 are selected. We found that heuristic NLP approaches are
the most common NLP techniques used for automatic RF, primary operating on
structured and semi-structured data. This study also revealed that Deep
Learning (DL) technique are not widely used, instead classical ML techniques
are predominant in the surveyed studies. More importantly, we identified the
difficulty of comparing the performance of different approaches due to the lack
of standard benchmark cases for RF."	ArXiv
1074	"Thorny Roses: Investigating the Dual Use Dilemma in Natural Language
  Processing"	['Lucie-Aimée Kaffee', 'Arnav Arora', 'Zeerak Talat', 'Isabelle Augenstein']	2023-04-17 14:37:43+00:00	http://arxiv.org/abs/2304.08315v3	"Dual use, the intentional, harmful reuse of technology and scientific
artefacts, is a problem yet to be well-defined within the context of Natural
Language Processing (NLP). However, as NLP technologies continue to advance and
become increasingly widespread in society, their inner workings have become
increasingly opaque. Therefore, understanding dual use concerns and potential
ways of limiting them is critical to minimising the potential harms of research
and development. In this paper, we conduct a survey of NLP researchers and
practitioners to understand the depth and their perspective of the problem as
well as to assess existing available support. Based on the results of our
survey, we offer a definition of dual use that is tailored to the needs of the
NLP community. The survey revealed that a majority of researchers are concerned
about the potential dual use of their research but only take limited action
toward it. In light of the survey results, we discuss the current state and
potential means for mitigating dual use in NLP and propose a checklist that can
be integrated into existing conference ethics-frameworks, e.g., the ACL ethics
checklist."	ArXiv
1075	NLP Reproducibility For All: Understanding Experiences of Beginners	['Shane Storks', 'Keunwoo Peter Yu', 'Ziqiao Ma', 'Joyce Chai']	2023-05-26 02:08:54+00:00	http://arxiv.org/abs/2305.16579v3	"As natural language processing (NLP) has recently seen an unprecedented level
of excitement, and more people are eager to enter the field, it is unclear
whether current research reproducibility efforts are sufficient for this group
of beginners to apply the latest developments. To understand their needs, we
conducted a study with 93 students in an introductory NLP course, where
students reproduced the results of recent NLP papers. Surprisingly, we find
that their programming skill and comprehension of research papers have a
limited impact on their effort spent completing the exercise. Instead, we find
accessibility efforts by research authors to be the key to success, including
complete documentation, better coding practice, and easier access to data
files. Going forward, we recommend that NLP researchers pay close attention to
these simple aspects of open-sourcing their work, and use insights from
beginners' feedback to provide actionable ideas on how to better support them."	ArXiv
1076	"Uncertainty in Natural Language Processing: Sources, Quantification, and
  Applications"	['Mengting Hu', 'Zhen Zhang', 'Shiwan Zhao', 'Minlie Huang', 'Bingzhe Wu']	2023-06-05 06:46:53+00:00	http://arxiv.org/abs/2306.04459v1	"As a main field of artificial intelligence, natural language processing (NLP)
has achieved remarkable success via deep neural networks. Plenty of NLP tasks
have been addressed in a unified manner, with various tasks being associated
with each other through sharing the same paradigm. However, neural networks are
black boxes and rely on probability computation. Making mistakes is inevitable.
Therefore, estimating the reliability and trustworthiness (in other words,
uncertainty) of neural networks becomes a key research direction, which plays a
crucial role in reducing models' risks and making better decisions. Therefore,
in this survey, we provide a comprehensive review of uncertainty-relevant works
in the NLP field. Considering the data and paradigms characteristics, we first
categorize the sources of uncertainty in natural language into three types,
including input, system, and output. Then, we systemically review uncertainty
quantification approaches and the main applications. Finally, we discuss the
challenges of uncertainty estimation in NLP and discuss potential future
directions, taking into account recent trends in the field. Though there have
been a few surveys about uncertainty estimation, our work is the first to
review uncertainty from the NLP perspective."	ArXiv
1077	Expanding Scope: Adapting English Adversarial Attacks to Chinese	['Hanyu Liu', 'Chengyuan Cai', 'Yanjun Qi']	2023-06-08 02:07:49+00:00	http://arxiv.org/abs/2306.04874v1	"Recent studies have revealed that NLP predictive models are vulnerable to
adversarial attacks. Most existing studies focused on designing attacks to
evaluate the robustness of NLP models in the English language alone. Literature
has seen an increasing need for NLP solutions for other languages. We,
therefore, ask one natural question: whether state-of-the-art (SOTA) attack
methods generalize to other languages. This paper investigates how to adapt
SOTA adversarial attack algorithms in English to the Chinese language. Our
experiments show that attack methods previously applied to English NLP can
generate high-quality adversarial examples in Chinese when combined with proper
text segmentation and linguistic constraints. In addition, we demonstrate that
the generated adversarial examples can achieve high fluency and semantic
consistency by focusing on the Chinese language's morphology and phonology,
which in turn can be used to improve the adversarial robustness of Chinese NLP
models."	ArXiv
1078	Sample Attackability in Natural Language Adversarial Attacks	['Vyas Raina', 'Mark Gales']	2023-06-21 06:20:51+00:00	http://arxiv.org/abs/2306.12043v1	"Adversarial attack research in natural language processing (NLP) has made
significant progress in designing powerful attack methods and defence
approaches. However, few efforts have sought to identify which source samples
are the most attackable or robust, i.e. can we determine for an unseen target
model, which samples are the most vulnerable to an adversarial attack. This
work formally extends the definition of sample attackability/robustness for NLP
attacks. Experiments on two popular NLP datasets, four state of the art models
and four different NLP adversarial attack methods, demonstrate that sample
uncertainty is insufficient for describing characteristics of attackable/robust
samples and hence a deep learning based detector can perform much better at
identifying the most attackable and robust samples for an unseen target model.
Nevertheless, further analysis finds that there is little agreement in which
samples are considered the most attackable/robust across different NLP attack
methods, explaining a lack of portability of attackability detection methods
across attack methods."	ArXiv
1079	"Multi-Site Clinical Federated Learning using Recursive and Attentive
  Models and NVFlare"	['Won Joon Yun', 'Samuel Kim', 'Joongheon Kim']	2023-06-28 17:00:32+00:00	http://arxiv.org/abs/2306.16367v1	"The prodigious growth of digital health data has precipitated a mounting
interest in harnessing machine learning methodologies, such as natural language
processing (NLP), to scrutinize medical records, clinical notes, and other
text-based health information. Although NLP techniques have exhibited
substantial potential in augmenting patient care and informing clinical
decision-making, data privacy and adherence to regulations persist as critical
concerns. Federated learning (FL) emerges as a viable solution, empowering
multiple organizations to train machine learning models collaboratively without
disseminating raw data. This paper proffers a pragmatic approach to medical NLP
by amalgamating FL, NLP models, and the NVFlare framework, developed by NVIDIA.
We introduce two exemplary NLP models, the Long-Short Term Memory (LSTM)-based
model and Bidirectional Encoder Representations from Transformers (BERT), which
have demonstrated exceptional performance in comprehending context and
semantics within medical data. This paper encompasses the development of an
integrated framework that addresses data privacy and regulatory compliance
challenges while maintaining elevated accuracy and performance, incorporating
BERT pretraining, and comprehensively substantiating the efficacy of the
proposed approach."	ArXiv
1080	"Classical Out-of-Distribution Detection Methods Benchmark in Text
  Classification Tasks"	['Mateusz Baran', 'Joanna Baran', 'Mateusz Wójcik', 'Maciej Zięba', 'Adam Gonczarek']	2023-07-13 18:06:12+00:00	http://arxiv.org/abs/2307.07002v1	"State-of-the-art models can perform well in controlled environments, but they
often struggle when presented with out-of-distribution (OOD) examples, making
OOD detection a critical component of NLP systems. In this paper, we focus on
highlighting the limitations of existing approaches to OOD detection in NLP.
Specifically, we evaluated eight OOD detection methods that are easily
integrable into existing NLP systems and require no additional OOD data or
model modifications. One of our contributions is providing a well-structured
research environment that allows for full reproducibility of the results.
Additionally, our analysis shows that existing OOD detection methods for NLP
tasks are not yet sufficiently sensitive to capture all samples characterized
by various types of distributional shifts. Particularly challenging testing
scenarios arise in cases of background shift and randomly shuffled word order
within in domain texts. This highlights the need for future work to develop
more effective OOD detection approaches for the NLP problems, and our work
provides a well-defined foundation for further research in this area."	ArXiv
1081	"Lexicon and Rule-based Word Lemmatization Approach for the Somali
  Language"	['Shafie Abdi Mohamed', 'Muhidin Abdullahi Mohamed']	2023-08-03 14:31:57+00:00	http://arxiv.org/abs/2308.01785v1	"Lemmatization is a Natural Language Processing (NLP) technique used to
normalize text by changing morphological derivations of words to their root
forms. It is used as a core pre-processing step in many NLP tasks including
text indexing, information retrieval, and machine learning for NLP, among
others. This paper pioneers the development of text lemmatization for the
Somali language, a low-resource language with very limited or no prior
effective adoption of NLP methods and datasets. We especially develop a lexicon
and rule-based lemmatizer for Somali text, which is a starting point for a
full-fledged Somali lemmatization system for various NLP tasks. With
consideration of the language morphological rules, we have developed an initial
lexicon of 1247 root words and 7173 derivationally related terms enriched with
rules for lemmatizing words not present in the lexicon. We have tested the
algorithm on 120 documents of various lengths including news articles, social
media posts, and text messages. Our initial results demonstrate that the
algorithm achieves an accuracy of 57\% for relatively long documents (e.g. full
news articles), 60.57\% for news article extracts, and high accuracy of 95.87\%
for short texts such as social media messages."	ArXiv
1082	"Human-centered NLP Fact-checking: Co-Designing with Fact-checkers using
  Matchmaking for AI"	['Houjiang Liu', 'Anubrata Das', 'Alexander Boltz', 'Didi Zhou', 'Daisy Pinaroc', 'Matthew Lease', 'Min Kyung Lee']	2023-08-14 15:31:32+00:00	http://arxiv.org/abs/2308.07213v3	"While many Natural Language Processing (NLP) techniques have been proposed
for fact-checking, both academic research and fact-checking organizations
report limited adoption of such NLP work due to poor alignment with
fact-checker practices, values, and needs. To address this, we investigate a
co-design method, Matchmaking for AI, to enable fact-checkers, designers, and
NLP researchers to collaboratively identify what fact-checker needs should be
addressed by technology, and to brainstorm ideas for potential solutions.
Co-design sessions we conducted with 22 professional fact-checkers yielded a
set of 11 design ideas that offer a ""north star"", integrating fact-checker
criteria into novel NLP design concepts. These concepts range from pre-bunking
misinformation, efficient and personalized monitoring misinformation,
proactively reducing fact-checker potential biases, and collaborative writing
fact-check reports. Our work provides new insights into both human-centered
fact-checking research and practice and AI co-design research."	ArXiv
1083	"What Learned Representations and Influence Functions Can Tell Us About
  Adversarial Examples"	['Shakila Mahjabin Tonni', 'Mark Dras']	2023-09-19 20:28:24+00:00	http://arxiv.org/abs/2309.10916v3	"Adversarial examples, deliberately crafted using small perturbations to fool
deep neural networks, were first studied in image processing and more recently
in NLP. While approaches to detecting adversarial examples in NLP have largely
relied on search over input perturbations, image processing has seen a range of
techniques that aim to characterise adversarial subspaces over the learned
representations.
  In this paper, we adapt two such approaches to NLP, one based on nearest
neighbors and influence functions and one on Mahalanobis distances. The former
in particular produces a state-of-the-art detector when compared against
several strong baselines; moreover, the novel use of influence functions
provides insight into how the nature of adversarial example subspaces in NLP
relate to those in image processing, and also how they differ depending on the
kind of NLP task."	ArXiv
1084	NLPBench: Evaluating Large Language Models on Solving NLP Problems	['Linxin Song', 'Jieyu Zhang', 'Lechao Cheng', 'Pengyuan Zhou', 'Tianyi Zhou', 'Irene Li']	2023-09-27 13:02:06+00:00	http://arxiv.org/abs/2309.15630v4	"Recent developments in large language models (LLMs) have shown promise in
enhancing the capabilities of natural language processing (NLP). Despite these
successes, there remains a dearth of research dedicated to the NLP
problem-solving abilities of LLMs. To fill the gap in this area, we present a
unique benchmarking dataset, NLPBench, comprising 378 college-level NLP
questions spanning various NLP topics sourced from Yale University's prior
final exams. NLPBench includes questions with context, in which multiple
sub-questions share the same public information, and diverse question types,
including multiple choice, short answer, and math. Our evaluation, centered on
LLMs such as GPT-3.5/4, PaLM-2, and LLAMA-2, incorporates advanced prompting
strategies like the chain-of-thought (CoT) and tree-of-thought (ToT). Our study
reveals that the effectiveness of the advanced prompting strategies can be
inconsistent, occasionally damaging LLM performance, especially in smaller
models like the LLAMA-2 (13b). Furthermore, our manual assessment illuminated
specific shortcomings in LLMs' scientific problem-solving skills, with
weaknesses in logical decomposition and reasoning notably affecting results."	ArXiv
1085	Hierarchical Evaluation Framework: Best Practices for Human Evaluation	['Iva Bojic', 'Jessica Chen', 'Si Yuan Chang', 'Qi Chwen Ong', 'Shafiq Joty', 'Josip Car']	2023-10-03 09:46:02+00:00	http://arxiv.org/abs/2310.01917v2	"Human evaluation plays a crucial role in Natural Language Processing (NLP) as
it assesses the quality and relevance of developed systems, thereby
facilitating their enhancement. However, the absence of widely accepted human
evaluation metrics in NLP hampers fair comparisons among different systems and
the establishment of universal assessment standards. Through an extensive
analysis of existing literature on human evaluation metrics, we identified
several gaps in NLP evaluation methodologies. These gaps served as motivation
for developing our own hierarchical evaluation framework. The proposed
framework offers notable advantages, particularly in providing a more
comprehensive representation of the NLP system's performance. We applied this
framework to evaluate the developed Machine Reading Comprehension system, which
was utilized within a human-AI symbiosis model. The results highlighted the
associations between the quality of inputs and outputs, underscoring the
necessity to evaluate both components rather than solely focusing on outputs.
In future work, we will investigate the potential time-saving benefits of our
proposed framework for evaluators assessing NLP systems."	ArXiv
1086	PerturbScore: Connecting Discrete and Continuous Perturbations in NLP	['Linyang Li', 'Ke Ren', 'Yunfan Shao', 'Pengyu Wang', 'Xipeng Qiu']	2023-10-13 06:50:15+00:00	http://arxiv.org/abs/2310.08889v1	"With the rapid development of neural network applications in NLP, model
robustness problem is gaining more attention. Different from computer vision,
the discrete nature of texts makes it more challenging to explore robustness in
NLP. Therefore, in this paper, we aim to connect discrete perturbations with
continuous perturbations, therefore we can use such connections as a bridge to
help understand discrete perturbations in NLP models. Specifically, we first
explore how to connect and measure the correlation between discrete
perturbations and continuous perturbations. Then we design a regression task as
a PerturbScore to learn the correlation automatically. Through experimental
results, we find that we can build a connection between discrete and continuous
perturbations and use the proposed PerturbScore to learn such correlation,
surpassing previous methods used in discrete perturbation measuring. Further,
the proposed PerturbScore can be well generalized to different datasets,
perturbation methods, indicating that we can use it as a powerful tool to study
model robustness in NLP."	ArXiv
1087	"Finite-context Indexing of Restricted Output Space for NLP Models Facing
  Noisy Input"	['Minh Nguyen', 'Nancy F. Chen']	2023-10-21 20:28:26+00:00	http://arxiv.org/abs/2310.14110v1	"NLP models excel on tasks with clean inputs, but are less accurate with noisy
inputs. In particular, character-level noise such as human-written typos and
adversarially-engineered realistic-looking misspellings often appears in text
and can easily trip up NLP models. Prior solutions to address character-level
noise often alter the content of the inputs (low fidelity), thus inadvertently
lowering model accuracy on clean inputs. We proposed FiRo, an approach to boost
NLP model performance on noisy inputs without sacrificing performance on clean
inputs. FiRo sanitizes the input text while preserving its fidelity by
inferring the noise-free form for each token in the input. FiRo uses
finite-context aggregation to obtain contextual embeddings which is then used
to find the noise-free form within a restricted output space. The output space
is restricted to a small cluster of probable candidates in order to predict the
noise-free tokens more accurately. Although the clusters are small, FiRo's
effective vocabulary (union of all clusters) can be scaled up to better
preserve the input content. Experimental results show NLP models that use FiRo
outperforming baselines on six classification tasks and one sequence labeling
task at various degrees of noise."	ArXiv
1088	CRoW: Benchmarking Commonsense Reasoning in Real-World Tasks	['Mete Ismayilzada', 'Debjit Paul', 'Syrielle Montariol', 'Mor Geva', 'Antoine Bosselut']	2023-10-23 18:00:23+00:00	http://arxiv.org/abs/2310.15239v1	"Recent efforts in natural language processing (NLP) commonsense reasoning
research have yielded a considerable number of new datasets and benchmarks.
However, most of these datasets formulate commonsense reasoning challenges in
artificial scenarios that are not reflective of the tasks which real-world NLP
systems are designed to solve. In this work, we present CRoW, a
manually-curated, multi-task benchmark that evaluates the ability of models to
apply commonsense reasoning in the context of six real-world NLP tasks. CRoW is
constructed using a multi-stage data collection pipeline that rewrites examples
from existing datasets using commonsense-violating perturbations. We use CRoW
to study how NLP systems perform across different dimensions of commonsense
knowledge, such as physical, temporal, and social reasoning. We find a
significant performance gap when NLP systems are evaluated on CRoW compared to
humans, showcasing that commonsense reasoning is far from being solved in
real-world task settings. We make our dataset and leaderboard available to the
research community at https://github.com/mismayil/crow."	ArXiv
1089	mahaNLP: A Marathi Natural Language Processing Library	['Vidula Magdum', 'Omkar Dhekane', 'Sharayu Hiwarkhedkar', 'Saloni Mittal', 'Raviraj Joshi']	2023-11-05 06:59:59+00:00	http://arxiv.org/abs/2311.02579v1	"We present mahaNLP, an open-source natural language processing (NLP) library
specifically built for the Marathi language. It aims to enhance the support for
the low-resource Indian language Marathi in the field of NLP. It is an
easy-to-use, extensible, and modular toolkit for Marathi text analysis built on
state-of-the-art MahaBERT-based transformer models. Our work holds significant
importance as other existing Indic NLP libraries provide basic Marathi
processing support and rely on older models with restricted performance. Our
toolkit stands out by offering a comprehensive array of NLP tasks, encompassing
both fundamental preprocessing tasks and advanced NLP tasks like sentiment
analysis, NER, hate speech detection, and sentence completion. This paper
focuses on an overview of the mahaNLP framework, its features, and its usage.
This work is a part of the L3Cube MahaNLP initiative, more information about it
can be found at https://github.com/l3cube-pune/MarathiNLP ."	ArXiv
1090	"Collaboration or Corporate Capture? Quantifying NLP's Reliance on
  Industry Artifacts and Contributions"	['Will Aitken', 'Mohamed Abdalla', 'Karen Rudie', 'Catherine Stinson']	2023-12-06 21:12:22+00:00	http://arxiv.org/abs/2312.03912v2	"Impressive performance of pre-trained models has garnered public attention
and made news headlines in recent years. Almost always, these models are
produced by or in collaboration with industry. Using them is critical for
competing on natural language processing (NLP) benchmarks and correspondingly
to stay relevant in NLP research. We surveyed 100 papers published at EMNLP
2022 to determine the degree to which researchers rely on industry models,
other artifacts, and contributions to publish in prestigious NLP venues and
found that the ratio of their citation is at least three times greater than
what would be expected. Our work serves as a scaffold to enable future
researchers to more accurately address whether: 1) Collaboration with industry
is still collaboration in the absence of an alternative or 2) if NLP inquiry
has been captured by the motivations and research direction of private
corporations."	ArXiv
1091	"Safety Alignment in NLP Tasks: Weakly Aligned Summarization as an
  In-Context Attack"	['Yu Fu', 'Yufei Li', 'Wen Xiao', 'Cong Liu', 'Yue Dong']	2023-12-12 01:39:29+00:00	http://arxiv.org/abs/2312.06924v2	"Recent developments in balancing the usefulness and safety of Large Language
Models (LLMs) have raised a critical question: Are mainstream NLP tasks
adequately aligned with safety consideration? Our study, focusing on
safety-sensitive documents obtained through adversarial attacks, reveals
significant disparities in the safety alignment of various NLP tasks. For
instance, LLMs can effectively summarize malicious long documents but often
refuse to translate them. This discrepancy highlights a previously unidentified
vulnerability: attacks exploiting tasks with weaker safety alignment, like
summarization, can potentially compromise the integrity of tasks traditionally
deemed more robust, such as translation and question-answering (QA). Moreover,
the concurrent use of multiple NLP tasks with lesser safety alignment increases
the risk of LLMs inadvertently processing harmful content. We demonstrate these
vulnerabilities in various safety-aligned LLMs, particularly Llama2 models,
Gemini and GPT-4, indicating an urgent need for strengthening safety alignments
across a broad spectrum of NLP tasks."	ArXiv
1092	Indexing Portuguese NLP Resources with PT-Pump-Up	['Rúben Almeida', 'Ricardo Campos', 'Alípio Jorge', 'Sérgio Nunes']	2024-01-27 12:33:07+00:00	http://arxiv.org/abs/2401.15400v1	"The recent advances in natural language processing (NLP) are linked to
training processes that require vast amounts of corpora. Access to this data is
commonly not a trivial process due to resource dispersion and the need to
maintain these infrastructures online and up-to-date. New developments in NLP
are often compromised due to the scarcity of data or lack of a shared
repository that works as an entry point to the community. This is especially
true in low and mid-resource languages, such as Portuguese, which lack data and
proper resource management infrastructures. In this work, we propose
PT-Pump-Up, a set of tools that aim to reduce resource dispersion and improve
the accessibility to Portuguese NLP resources. Our proposal is divided into
four software components: a) a web platform to list the available resources; b)
a client-side Python package to simplify the loading of Portuguese NLP
resources; c) an administrative Python package to manage the platform and d) a
public GitHub repository to foster future collaboration and contributions. All
four components are accessible using: https://linktr.ee/pt_pump_up"	ArXiv
1093	"Advancing NLP Models with Strategic Text Augmentation: A Comprehensive
  Study of Augmentation Methods and Curriculum Strategies"	['Himmet Toprak Kesgin', 'Mehmet Fatih Amasyali']	2024-02-14 12:41:09+00:00	http://arxiv.org/abs/2402.09141v1	"This study conducts a thorough evaluation of text augmentation techniques
across a variety of datasets and natural language processing (NLP) tasks to
address the lack of reliable, generalized evidence for these methods. It
examines the effectiveness of these techniques in augmenting training sets to
improve performance in tasks such as topic classification, sentiment analysis,
and offensive language detection. The research emphasizes not only the
augmentation methods, but also the strategic order in which real and augmented
instances are introduced during training. A major contribution is the
development and evaluation of Modified Cyclical Curriculum Learning (MCCL) for
augmented datasets, which represents a novel approach in the field. Results
show that specific augmentation methods, especially when integrated with MCCL,
significantly outperform traditional training approaches in NLP model
performance. These results underscore the need for careful selection of
augmentation techniques and sequencing strategies to optimize the balance
between speed and quality improvement in various NLP tasks. The study concludes
that the use of augmentation methods, especially in conjunction with MCCL,
leads to improved results in various classification tasks, providing a
foundation for future advances in text augmentation strategies in NLP."	ArXiv
1094	Classist Tools: Social Class Correlates with Performance in NLP	['Amanda Cercas Curry', 'Giuseppe Attanasio', 'Zeerak Talat', 'Dirk Hovy']	2024-03-07 12:27:08+00:00	http://arxiv.org/abs/2403.04445v1	"Since the foundational work of William Labov on the social stratification of
language (Labov, 1964), linguistics has made concentrated efforts to explore
the links between sociodemographic characteristics and language production and
perception. But while there is strong evidence for socio-demographic
characteristics in language, they are infrequently used in Natural Language
Processing (NLP). Age and gender are somewhat well represented, but Labov's
original target, socioeconomic status, is noticeably absent. And yet it
matters. We show empirically that NLP disadvantages less-privileged
socioeconomic groups. We annotate a corpus of 95K utterances from movies with
social class, ethnicity and geographical language variety and measure the
performance of NLP systems on three tasks: language modelling, automatic speech
recognition, and grammar error correction. We find significant performance
disparities that can be attributed to socioeconomic status as well as ethnicity
and geographical differences. With NLP technologies becoming ever more
ubiquitous and quotidian, they must accommodate all language varieties to avoid
disadvantaging already marginalised groups. We argue for the inclusion of
socioeconomic class in future language technologies."	ArXiv
1095	NLP Progress in Indigenous Latin American Languages	['Atnafu Lambebo Tonja', 'Fazlourrahman Balouchzahi', 'Sabur Butt', 'Olga Kolesnikova', 'Hector Ceballos', 'Alexander Gelbukh', 'Thamar Solorio']	2024-04-08 10:04:55+00:00	http://arxiv.org/abs/2404.05365v2	"The paper focuses on the marginalization of indigenous language communities
in the face of rapid technological advancements. We highlight the cultural
richness of these languages and the risk they face of being overlooked in the
realm of Natural Language Processing (NLP). We aim to bridge the gap between
these communities and researchers, emphasizing the need for inclusive
technological advancements that respect indigenous community perspectives. We
show the NLP progress of indigenous Latin American languages and the survey
that covers the status of indigenous languages in Latin America, their
representation in NLP, and the challenges and innovations required for their
preservation and development. The paper contributes to the current literature
in understanding the need and progress of NLP for indigenous communities of
Latin America, specifically low-resource and indigenous communities in general."	ArXiv
1096	An Audit on the Perspectives and Challenges of Hallucinations in NLP	['Pranav Narayanan Venkit', 'Tatiana Chakravorti', 'Vipul Gupta', 'Heidi Biggs', 'Mukund Srinath', 'Koustava Goswami', 'Sarah Rajtmajer', 'Shomir Wilson']	2024-04-11 03:51:29+00:00	http://arxiv.org/abs/2404.07461v2	"We audit how hallucination in large language models (LLMs) is characterized
in peer-reviewed literature, using a critical examination of 103 publications
across NLP research. Through the examination of the literature, we identify a
lack of agreement with the term `hallucination' in the field of NLP.
Additionally, to compliment our audit, we conduct a survey with 171
practitioners from the field of NLP and AI to capture varying perspectives on
hallucination. Our analysis calls for the necessity of explicit definitions and
frameworks outlining hallucination within NLP, highlighting potential
challenges, and our survey inputs provide a thematic understanding of the
influence and ramifications of hallucination in society."	ArXiv
1097	Revealing Trends in Datasets from the 2022 ACL and EMNLP Conferences	['Jesse Atuhurra', 'Hidetaka Kamigaito']	2024-03-31 15:13:15+00:00	http://arxiv.org/abs/2404.08666v2	"Natural language processing (NLP) has grown significantly since the advent of
the Transformer architecture. Transformers have given birth to pre-trained
large language models (PLMs). There has been tremendous improvement in the
performance of NLP systems across several tasks. NLP systems are on par or, in
some cases, better than humans at accomplishing specific tasks. However, it
remains the norm that \emph{better quality datasets at the time of pretraining
enable PLMs to achieve better performance, regardless of the task.} The need to
have quality datasets has prompted NLP researchers to continue creating new
datasets to satisfy particular needs. For example, the two top NLP conferences,
ACL and EMNLP, accepted ninety-two papers in 2022, introducing new datasets.
This work aims to uncover the trends and insights mined within these datasets.
Moreover, we provide valuable suggestions to researchers interested in curating
datasets in the future."	ArXiv
1098	"Enhancing Organizational Performance: Harnessing AI and NLP for User
  Feedback Analysis in Product Development"	['Tian Tian', 'Liu Ze hui', 'Huang Zichen', 'Yubing Tang']	2024-05-07 22:07:07+00:00	http://arxiv.org/abs/2405.04692v1	"This paper explores the application of AI and NLP techniques for user
feedback analysis in the context of heavy machine crane products. By leveraging
AI and NLP, organizations can gain insights into customer perceptions, improve
product development, enhance satisfaction and loyalty, inform decision-making,
and gain a competitive advantage. The paper highlights the impact of user
feedback analysis on organizational performance and emphasizes the reasons for
using AI and NLP, including scalability, objectivity, improved accuracy,
increased insights, and time savings. The methodology involves data collection,
cleaning, text and rating analysis, interpretation, and feedback
implementation. Results include sentiment analysis, word cloud visualizations,
and radar charts comparing product attributes. These findings provide valuable
information for understanding customer sentiment, identifying improvement
areas, and making data-driven decisions to enhance the customer experience. In
conclusion, promising AI and NLP techniques in user feedback analysis offer
organizations a powerful tool to understand customers, improve product
development, increase satisfaction, and drive business success"	ArXiv
1099	A Survey on Transformers in NLP with Focus on Efficiency	['Wazib Ansar', 'Saptarsi Goswami', 'Amlan Chakrabarti']	2024-05-15 10:32:41+00:00	http://arxiv.org/abs/2406.16893v1	"The advent of transformers with attention mechanisms and associated
pre-trained models have revolutionized the field of Natural Language Processing
(NLP). However, such models are resource-intensive due to highly complex
architecture. This limits their application to resource-constrained
environments. While choosing an appropriate NLP model, a major trade-off exists
over choosing accuracy over efficiency and vice versa. This paper presents a
commentary on the evolution of NLP and its applications with emphasis on their
accuracy as-well-as efficiency. Following this, a survey of research
contributions towards enhancing the efficiency of transformer-based models at
various stages of model development along with hardware considerations has been
conducted. The goal of this survey is to determine how current NLP techniques
contribute towards a sustainable society and to establish a foundation for
future research."	ArXiv
1100	"On Behalf of the Stakeholders: Trends in NLP Model Interpretability in
  the Era of LLMs"	['Nitay Calderon', 'Roi Reichart']	2024-07-27 08:00:27+00:00	http://arxiv.org/abs/2407.19200v1	"Recent advancements in NLP systems, particularly with the introduction of
LLMs, have led to widespread adoption of these systems by a broad spectrum of
users across various domains, impacting decision-making, the job market,
society, and scientific research. This surge in usage has led to an explosion
in NLP model interpretability and analysis research, accompanied by numerous
technical surveys. Yet, these surveys often overlook the needs and perspectives
of explanation stakeholders. In this paper, we address three fundamental
questions: Why do we need interpretability, what are we interpreting, and how?
By exploring these questions, we examine existing interpretability paradigms,
their properties, and their relevance to different stakeholders. We further
explore the practical implications of these paradigms by analyzing trends from
the past decade across multiple research fields. To this end, we retrieved
thousands of papers and employed an LLM to characterize them. Our analysis
reveals significant disparities between NLP developers and non-developer users,
as well as between research fields, underscoring the diverse needs of
stakeholders. For example, explanations of internal model components are rarely
used outside the NLP field. We hope this paper informs the future design,
development, and application of methods that align with the objectives and
requirements of various stakeholders."	ArXiv
1101	"LogogramNLP: Comparing Visual and Textual Representations of Ancient
  Logographic Writing Systems for NLP"	['Danlu Chen', 'Freda Shi', 'Aditi Agarwal', 'Jacobo Myerston', 'Taylor Berg-Kirkpatrick']	2024-08-08 17:58:06+00:00	http://arxiv.org/abs/2408.04628v1	"Standard natural language processing (NLP) pipelines operate on symbolic
representations of language, which typically consist of sequences of discrete
tokens. However, creating an analogous representation for ancient logographic
writing systems is an extremely labor intensive process that requires expert
knowledge. At present, a large portion of logographic data persists in a purely
visual form due to the absence of transcription -- this issue poses a
bottleneck for researchers seeking to apply NLP toolkits to study ancient
logographic languages: most of the relevant data are images of writing.
  This paper investigates whether direct processing of visual representations
of language offers a potential solution. We introduce LogogramNLP, the first
benchmark enabling NLP analysis of ancient logographic languages, featuring
both transcribed and visual datasets for four writing systems along with
annotations for tasks like classification, translation, and parsing. Our
experiments compare systems that employ recent visual and text encoding
strategies as backbones. The results demonstrate that visual representations
outperform textual representations for some investigated tasks, suggesting that
visual processing pipelines may unlock a large amount of cultural heritage data
of logographic languages for NLP-based analyses."	ArXiv
1102	A Quantum-Inspired Analysis of Human Disambiguation Processes	['Daphne Wang']	2024-08-14 09:21:23+00:00	http://arxiv.org/abs/2408.07402v1	"Formal languages are essential for computer programming and are constructed
to be easily processed by computers. In contrast, natural languages are much
more challenging and instigated the field of Natural Language Processing (NLP).
One major obstacle is the ubiquity of ambiguities. Recent advances in NLP have
led to the development of large language models, which can resolve ambiguities
with high accuracy. At the same time, quantum computers have gained much
attention in recent years as they can solve some computational problems faster
than classical computers. This new computing paradigm has reached the fields of
machine learning and NLP, where hybrid classical-quantum learning algorithms
have emerged. However, more research is needed to identify which NLP tasks
could benefit from a genuine quantum advantage. In this thesis, we applied
formalisms arising from foundational quantum mechanics, such as contextuality
and causality, to study ambiguities arising from linguistics. By doing so, we
also reproduced psycholinguistic results relating to the human disambiguation
process. These results were subsequently used to predict human behaviour and
outperformed current NLP methods."	ArXiv
1103	"NLP-Powered Repository and Search Engine for Academic Papers: A Case
  Study on Cyber Risk Literature with CyLit"	['Linfeng Zhang', 'Changyue Hu', 'Zhiyu Quan']	2024-09-10 05:41:40+00:00	http://arxiv.org/abs/2409.06226v1	"As the body of academic literature continues to grow, researchers face
increasing difficulties in effectively searching for relevant resources.
Existing databases and search engines often fall short of providing a
comprehensive and contextually relevant collection of academic literature. To
address this issue, we propose a novel framework that leverages Natural
Language Processing (NLP) techniques. This framework automates the retrieval,
summarization, and clustering of academic literature within a specific research
domain. To demonstrate the effectiveness of our approach, we introduce CyLit,
an NLP-powered repository specifically designed for the cyber risk literature.
CyLit empowers researchers by providing access to context-specific resources
and enabling the tracking of trends in the dynamic and rapidly evolving field
of cyber risk. Through the automatic processing of large volumes of data, our
NLP-powered solution significantly enhances the efficiency and specificity of
academic literature searches. We compare the literature categorization results
of CyLit to those presented in survey papers or generated by ChatGPT,
highlighting the distinctive insights this tool provides into cyber risk
research literature. Using NLP techniques, we aim to revolutionize the way
researchers discover, analyze, and utilize academic resources, ultimately
fostering advancements in various domains of knowledge."	ArXiv
1104	"A Systematic Review of NLP for Dementia- Tasks, Datasets and
  Opportunities"	['Lotem Peled-Cohen', 'Roi Reichart']	2024-09-29 15:30:59+00:00	http://arxiv.org/abs/2409.19737v1	"The close link between cognitive decline and language has fostered
long-standing collaboration between the NLP and medical communities in dementia
research. To examine this, we reviewed over 200 papers applying NLP to dementia
related efforts, drawing from medical, technological, and NLP-focused
literature. We identify key research areas, including dementia detection,
linguistic biomarker extraction, caregiver support, and patient assistance,
showing that half of all papers focus solely on dementia detection using
clinical data. However, many directions remain unexplored: artificially
degraded language models, synthetic data, digital twins, and more. We highlight
gaps and opportunities around trust, scientific rigor, applicability, and
cross-community collaboration, and showcase the diverse datasets encountered
throughout our review: recorded, written, structured, spontaneous, synthetic,
clinical, social media based, and more. This review aims to inspire more
creative approaches to dementia research within the medical and NLP
communities."	ArXiv
1105	"A survey of neural-network-based methods utilising comparable data for
  finding translation equivalents"	['Michaela Denisová', 'Pavel Rychlý']	2024-10-19 16:10:41+00:00	http://arxiv.org/abs/2410.15144v1	"The importance of inducing bilingual dictionary components in many natural
language processing (NLP) applications is indisputable. However, the dictionary
compilation process requires extensive work and combines two disciplines, NLP
and lexicography, while the former often omits the latter. In this paper, we
present the most common approaches from NLP that endeavour to automatically
induce one of the essential dictionary components, translation equivalents and
focus on the neural-network-based methods using comparable data. We analyse
them from a lexicographic perspective since their viewpoints are crucial for
improving the described methods. Moreover, we identify the methods that
integrate these viewpoints and can be further exploited in various applications
that require them. This survey encourages a connection between the NLP and
lexicography fields as the NLP field can benefit from lexicographic insights,
and it serves as a helping and inspiring material for further research in the
context of neural-network-based methods utilising comparable data."	ArXiv
1106	"IPM-LSTM: A Learning-Based Interior Point Method for Solving Nonlinear
  Programs"	['Xi Gao', 'Jinxin Xiong', 'Akang Wang', 'Qihong Duan', 'Jiang Xue', 'Qingjiang Shi']	2024-10-21 07:47:59+00:00	http://arxiv.org/abs/2410.15731v1	"Solving constrained nonlinear programs (NLPs) is of great importance in
various domains such as power systems, robotics, and wireless communication
networks. One widely used approach for addressing NLPs is the interior point
method (IPM). The most computationally expensive procedure in IPMs is to solve
systems of linear equations via matrix factorization. Recently, machine
learning techniques have been adopted to expedite classic optimization
algorithms. In this work, we propose using Long Short-Term Memory (LSTM) neural
networks to approximate the solution of linear systems and integrate this
approximating step into an IPM. The resulting approximate NLP solution is then
utilized to warm-start an interior point solver. Experiments on various types
of NLPs, including Quadratic Programs and Quadratically Constrained Quadratic
Programs, show that our approach can significantly accelerate NLP solving,
reducing iterations by up to 60% and solution time by up to 70% compared to the
default solver."	ArXiv
1107	Extracting Biological Pathway Models From NLP Event Representations	['Michael Spranger', 'Sucheendra K. Palaniappan', 'Samik Ghosh']	2016-08-12 11:58:00+00:00	http://arxiv.org/abs/1608.03764v1	"This paper describes an an open-source software system for the automatic
conversion of NLP event representations to system biology structured data
interchange formats such as SBML and BioPAX. It is part of a larger effort to
make results of the NLP community available for system biology pathway
modelers."	ArXiv
1108	Domain reduction techniques for global NLP and MINLP optimization	['Yash Puranik', 'Nikolaos V. Sahinidis']	2017-06-26 21:22:57+00:00	http://arxiv.org/abs/1706.08601v1	"Optimization solvers routinely utilize presolve techniques, including model
simplification, reformulation and domain reduction techniques. Domain reduction
techniques are especially important in speeding up convergence to the global
optimum for challenging nonconvex nonlinear programming (NLP) and mixed-integer
nonlinear programming (MINLP) optimization problems. In this work, we survey
the various techniques used for domain reduction of NLP and MINLP optimization
problems. We also present a computational analysis of the impact of these
techniques on the performance of various widely available global solvers on a
collection of 1740 test problems."	ArXiv
1109	"Code-switching patterns can be an effective route to improve performance
  of downstream NLP applications: A case study of humour, sarcasm and hate
  speech detection"	['Srijan Bansal', 'Vishal Garimella', 'Ayush Suhane', 'Jasabanta Patro', 'Animesh Mukherjee']	2020-05-05 15:48:34+00:00	http://arxiv.org/abs/2005.02295v1	"In this paper we demonstrate how code-switching patterns can be utilised to
improve various downstream NLP applications. In particular, we encode different
switching features to improve humour, sarcasm and hate speech detection tasks.
We believe that this simple linguistic observation can also be potentially
helpful in improving other similar NLP applications."	ArXiv
1110	"When does MAML Work the Best? An Empirical Study on Model-Agnostic
  Meta-Learning in NLP Applications"	['Zequn Liu', 'Ruiyi Zhang', 'Yiping Song', 'Wei Ju', 'Ming Zhang']	2020-05-24 09:29:36+00:00	http://arxiv.org/abs/2005.11700v2	"Model-Agnostic Meta-Learning (MAML), a model-agnostic meta-learning method,
is successfully employed in NLP applications including few-shot text
classification and multi-domain low-resource language generation. Many
impacting factors, including data quantity, similarity among tasks, and the
balance between general language model and task-specific adaptation, can affect
the performance of MAML in NLP, but few works have thoroughly studied them. In
this paper, we conduct an empirical study to investigate these impacting
factors and conclude when MAML works the best based on the experimental
results."	ArXiv
1111	"PPD-IPM: Outer primal, inner primal-dual interior-point method for
  nonlinear programming"	['Martin Neuenhofen']	2018-03-05 18:48:52+00:00	http://arxiv.org/abs/1803.01829v1	"In this paper we present a novel numerical method for computing local
minimizers of twice smooth differentiable non-linear programming (NLP)
problems.
  So far all algorithms for NLP are based on either of the following three
principles: successive quadratic programming (SQP), active sets (AS), or
interior-point methods (IPM). Each of them has drawbacks. These are in order:
iteration complexity, feasibility management in the sub-program, and utility of
initial guesses. Our novel approach attempts to overcome these drawbacks.
  We provide: a mathematical description of the method; proof of global
convergence; proof of second order local convergence; an implementation in
\textsc{Matlab}; experimental results for large sparse NLPs from direct
transcription of path-constrained optimal control problems."	ArXiv
1112	Gradual Fine-Tuning for Low-Resource Domain Adaptation	['Haoran Xu', 'Seth Ebner', 'Mahsa Yarmohammadi', 'Aaron Steven White', 'Benjamin Van Durme', 'Kenton Murray']	2021-03-03 06:24:54+00:00	http://arxiv.org/abs/2103.02205v2	"Fine-tuning is known to improve NLP models by adapting an initial model
trained on more plentiful but less domain-salient examples to data in a target
domain. Such domain adaptation is typically done using one stage of
fine-tuning. We demonstrate that gradually fine-tuning in a multi-stage process
can yield substantial further gains and can be applied without modifying the
model or learning objective."	ArXiv
1113	LightTag: Text Annotation Platform	['Tal Perry']	2021-09-06 09:41:48+00:00	http://arxiv.org/abs/2109.02320v1	"Text annotation tools assume that their user's goal is to create a labeled
corpus. However, users view annotation as a necessary evil on the way to
deliver business value through NLP. Thus an annotation tool should optimize for
the throughput of the global NLP process, not only the productivity of
individual annotators. LightTag is a text annotation tool designed and built on
that principle. This paper shares our design rationale, data modeling choices,
and user interface decisions then illustrates how those choices serve the full
NLP lifecycle."	ArXiv
1114	"Just What do You Think You're Doing, Dave?' A Checklist for Responsible
  Data Use in NLP"	['Anna Rogers', 'Tim Baldwin', 'Kobi Leins']	2021-09-14 11:36:42+00:00	http://arxiv.org/abs/2109.06598v1	"A key part of the NLP ethics movement is responsible use of data, but exactly
what that means or how it can be best achieved remain unclear. This position
paper discusses the core legal and ethical principles for collection and
sharing of textual data, and the tensions between them. We propose a potential
checklist for responsible data (re-)use that could both standardise the peer
review of conference submissions, as well as enable a more in-depth view of
published research across the community. Our proposal aims to contribute to the
development of a consistent standard for data (re-)use, embraced across NLP
conferences."	ArXiv
1115	Evaluating Debiasing Techniques for Intersectional Biases	['Shivashankar Subramanian', 'Xudong Han', 'Timothy Baldwin', 'Trevor Cohn', 'Lea Frermann']	2021-09-21 22:01:28+00:00	http://arxiv.org/abs/2109.10441v1	"Bias is pervasive in NLP models, motivating the development of automatic
debiasing techniques. Evaluation of NLP debiasing methods has largely been
limited to binary attributes in isolation, e.g., debiasing with respect to
binary gender or race, however many corpora involve multiple such attributes,
possibly with higher cardinality. In this paper we argue that a truly fair
model must consider `gerrymandering' groups which comprise not only single
attributes, but also intersectional groups. We evaluate a form of
bias-constrained model which is new to NLP, as well an extension of the
iterative nullspace projection technique which can handle multiple protected
attributes."	ArXiv
1116	"Identifying beneficial task relations for multi-task learning in deep
  neural networks"	['Joachim Bingel', 'Anders Søgaard']	2017-02-27 14:37:21+00:00	http://arxiv.org/abs/1702.08303v1	"Multi-task learning (MTL) in deep neural networks for NLP has recently
received increasing interest due to some compelling benefits, including its
potential to efficiently regularize models and to reduce the need for labeled
data. While it has brought significant improvements in a number of NLP tasks,
mixed results have been reported, and little is known about the conditions
under which MTL leads to gains in NLP. This paper sheds light on the specific
task relations that can lead to gains from MTL models over single-task setups."	ArXiv
1117	HUBERT Untangles BERT to Improve Transfer across NLP Tasks	['Mehrad Moradshahi', 'Hamid Palangi', 'Monica S. Lam', 'Paul Smolensky', 'Jianfeng Gao']	2019-10-25 06:25:25+00:00	http://arxiv.org/abs/1910.12647v2	"We introduce HUBERT which combines the structured-representational power of
Tensor-Product Representations (TPRs) and BERT, a pre-trained bidirectional
Transformer language model. We show that there is shared structure between
different NLP datasets that HUBERT, but not BERT, is able to learn and
leverage. We validate the effectiveness of our model on the GLUE benchmark and
HANS dataset. Our experiment results show that untangling data-specific
semantics from general language structure is key for better transfer among NLP
tasks."	ArXiv
1118	A Workflow Manager for Complex NLP and Content Curation Pipelines	['Julián Moreno-Schneider', 'Peter Bourgonje', 'Florian Kintzel', 'Georg Rehm']	2020-04-16 21:23:28+00:00	http://arxiv.org/abs/2004.14130v1	"We present a workflow manager for the flexible creation and customisation of
NLP processing pipelines. The workflow manager addresses challenges in
interoperability across various different NLP tasks and hardware-based resource
usage. Based on the four key principles of generality, flexibility, scalability
and efficiency, we present the first version of the workflow manager by
providing details on its custom definition language, explaining the
communication components and the general system architecture and setup. We
currently implement the system, which is grounded and motivated by real-world
industry use cases in several innovation and transfer projects."	ArXiv
1119	Formal Language Theory Meets Modern NLP	['William Merrill']	2021-02-19 18:51:10+00:00	http://arxiv.org/abs/2102.10094v3	"NLP is deeply intertwined with the formal study of language, both
conceptually and historically. Arguably, this connection goes all the way back
to Chomsky's Syntactic Structures in 1957. It also still holds true today, with
a strand of recent works building formal analysis of modern neural networks
methods in terms of formal languages. In this document, I aim to explain
background about formal languages as they relate to this recent work. I will by
necessity ignore large parts of the rich history of this field, instead
focusing on concepts connecting to modern deep learning-based NLP."	ArXiv
1120	Summarization, Simplification, and Generation: The Case of Patents	['Silvia Casola', 'Alberto Lavelli']	2021-04-30 09:28:29+00:00	http://arxiv.org/abs/2104.14860v2	"We survey Natural Language Processing (NLP) approaches to summarizing,
simplifying, and generating patents' text. While solving these tasks has
important practical applications - given patents' centrality in the R&D process
- patents' idiosyncrasies open peculiar challenges to the current NLP state of
the art. This survey aims at a) describing patents' characteristics and the
questions they raise to the current NLP systems, b) critically presenting
previous work and its evolution, and c) drawing attention to directions of
research in which further work is needed. To the best of our knowledge, this is
the first survey of generative approaches in the patent domain."	ArXiv
1121	Architectures of Meaning, A Systematic Corpus Analysis of NLP Systems	['Oskar Wysocki', 'Malina Florea', 'Donal Landers', 'Andre Freitas']	2021-07-16 21:10:43+00:00	http://arxiv.org/abs/2107.08124v1	"This paper proposes a novel statistical corpus analysis framework targeted
towards the interpretation of Natural Language Processing (NLP) architectural
patterns at scale. The proposed approach combines saturation-based lexicon
construction, statistical corpus analysis methods and graph collocations to
induce a synthesis representation of NLP architectural patterns from corpora.
The framework is validated in the full corpus of Semeval tasks and demonstrated
coherent architectural patterns which can be used to answer architectural
questions on a data-driven fashion, providing a systematic mechanism to
interpret a largely dynamic and exponentially growing field."	ArXiv
1122	"A Survey on Model Compression and Acceleration for Pretrained Language
  Models"	['Canwen Xu', 'Julian McAuley']	2022-02-15 00:18:47+00:00	http://arxiv.org/abs/2202.07105v2	"Despite achieving state-of-the-art performance on many NLP tasks, the high
energy cost and long inference delay prevent Transformer-based pretrained
language models (PLMs) from seeing broader adoption including for edge and
mobile computing. Efficient NLP research aims to comprehensively consider
computation, time and carbon emission for the entire life-cycle of NLP,
including data preparation, model training and inference. In this survey, we
focus on the inference stage and review the current state of model compression
and acceleration for pretrained language models, including benchmarks, metrics
and methodology."	ArXiv
1123	A Survey on Bias and Fairness in Natural Language Processing	['Rajas Bansal']	2022-03-06 18:12:30+00:00	http://arxiv.org/abs/2204.09591v1	"As NLP models become more integrated with the everyday lives of people, it
becomes important to examine the social effect that the usage of these systems
has. While these models understand language and have increased accuracy on
difficult downstream tasks, there is evidence that these models amplify gender,
racial and cultural stereotypes and lead to a vicious cycle in many settings.
In this survey, we analyze the origins of biases, the definitions of fairness,
and how different subfields of NLP mitigate bias. We finally discuss how future
studies can work towards eradicating pernicious biases from NLP algorithms."	ArXiv
1124	"Location-based Twitter Filtering for the Creation of Low-Resource
  Language Datasets in Indonesian Local Languages"	['Mukhlis Amien', 'Chong Feng', 'Heyan Huang']	2022-06-15 01:53:43+00:00	http://arxiv.org/abs/2206.07238v1	"Twitter contains an abundance of linguistic data from the real world. We
examine Twitter for user-generated content in low-resource languages such as
local Indonesian. For NLP to work in Indonesian, it must consider local
dialects, geographic context, and regional culture influence Indonesian
languages. This paper identifies the problems we faced when constructing a
Local Indonesian NLP dataset. Furthermore, we are developing a framework for
creating, collecting, and classifying Local Indonesian datasets for NLP. Using
twitter's geolocation tool for automatic annotating."	ArXiv
1125	"Improving Clinical Efficiency and Reducing Medical Errors through
  NLP-enabled diagnosis of Health Conditions from Transcription Reports"	['Krish Maniar', 'Shafin Haque', 'Kabir Ramzan']	2022-06-27 06:37:15+00:00	http://arxiv.org/abs/2206.13516v1	"Misdiagnosis rates are one of the leading causes of medical errors in
hospitals, affecting over 12 million adults across the US. To address the high
rate of misdiagnosis, this study utilizes 4 NLP-based algorithms to determine
the appropriate health condition based on an unstructured transcription report.
From the Logistic Regression, Random Forest, LSTM, and CNNLSTM models, the
CNN-LSTM model performed the best with an accuracy of 97.89%. We packaged this
model into a authenticated web platform for accessible assistance to
clinicians. Overall, by standardizing health care diagnosis and structuring
transcription reports, our NLP platform drastically improves the clinical
efficiency and accuracy of hospitals worldwide."	ArXiv
1126	"Multilingual Persuasion Detection: Video Games as an Invaluable Data
  Source for NLP"	['Teemu Pöyhönen', 'Mika Hämäläinen', 'Khalid Alnajjar']	2022-07-10 12:38:02+00:00	http://arxiv.org/abs/2207.04453v1	"Role-playing games (RPGs) have a considerable amount of text in video game
dialogues. Quite often this text is semi-annotated by the game developers. In
this paper, we extract a multilingual dataset of persuasive dialogue from
several RPGs. We show the viability of this data in building a persuasion
detection system using a natural language processing (NLP) model called BERT.
We believe that video games have a lot of unused potential as a datasource for
a variety of NLP tasks. The code and data described in this paper are available
on Zenodo."	ArXiv
1127	NLP Inspired Training Mechanics For Modeling Transient Dynamics	['Lalit Ghule', 'Rishikesh Ranade', 'Jay Pathak']	2022-11-04 19:06:40+00:00	http://arxiv.org/abs/2211.02716v1	"In recent years, Machine learning (ML) techniques developed for Natural
Language Processing (NLP) have permeated into developing better computer vision
algorithms. In this work, we use such NLP-inspired techniques to improve the
accuracy, robustness and generalizability of ML models for simulating transient
dynamics. We introduce teacher forcing and curriculum learning based training
mechanics to model vortical flows and show an enhancement in accuracy for ML
models, such as FNO and UNet by more than 50%."	ArXiv
1128	"The Role of Interactive Visualization in Explaining (Large) NLP Models:
  from Data to Inference"	['Richard Brath', 'Daniel Keim', 'Johannes Knittel', 'Shimei Pan', 'Pia Sommerauer', 'Hendrik Strobelt']	2023-01-11 15:46:52+00:00	http://arxiv.org/abs/2301.04528v1	"With a constant increase of learned parameters, modern neural language models
become increasingly more powerful. Yet, explaining these complex model's
behavior remains a widely unsolved problem. In this paper, we discuss the role
interactive visualization can play in explaining NLP models (XNLP). We motivate
the use of visualization in relation to target users and common NLP pipelines.
We also present several use cases to provide concrete examples on XNLP with
visualization. Finally, we point out an extensive list of research
opportunities in this field."	ArXiv
1129	Linguistic ambiguity analysis in ChatGPT	['Miguel Ortega-Martín', 'Óscar García-Sierra', 'Alfonso Ardoiz', 'Jorge Álvarez', 'Juan Carlos Armenteros', 'Adrián Alonso']	2023-02-13 15:03:07+00:00	http://arxiv.org/abs/2302.06426v2	"Linguistic ambiguity is and has always been one of the main challenges in
Natural Language Processing (NLP) systems. Modern Transformer architectures
like BERT, T5 or more recently InstructGPT have achieved some impressive
improvements in many NLP fields, but there is still plenty of work to do.
Motivated by the uproar caused by ChatGPT, in this paper we provide an
introduction to linguistic ambiguity, its varieties and their relevance in
modern NLP, and perform an extensive empiric analysis. ChatGPT strengths and
weaknesses are revealed, as well as strategies to get the most of this model."	ArXiv
1130	"Who should I Collaborate with? A Comparative Study of Academia and
  Industry Research Collaboration in NLP"	['Hussain Sadiq Abuwala', 'Bohan Zhang', 'Mushi Wang']	2023-07-21 01:26:29+00:00	http://arxiv.org/abs/2308.04524v1	"The goal of our research was to investigate the effects of collaboration
between academia and industry on Natural Language Processing (NLP). To do this,
we created a pipeline to extract affiliations and citations from NLP papers and
divided them into three categories: academia, industry, and hybrid
(collaborations between academia and industry). Our empirical analysis found
that there is a trend towards an increase in industry and academia-industry
collaboration publications and that these types of publications tend to have a
higher impact compared to those produced solely within academia."	ArXiv
1131	The Ghanaian NLP Landscape: A First Look	['Sheriff Issaka', 'Zhaoyi Zhang', 'Mihir Heda', 'Keyi Wang', 'Yinka Ajibola', 'Ryan DeMar', 'Xuefeng Du']	2024-05-10 21:39:09+00:00	http://arxiv.org/abs/2405.06818v1	"Despite comprising one-third of global languages, African languages are
critically underrepresented in Artificial Intelligence (AI), threatening
linguistic diversity and cultural heritage. Ghanaian languages, in particular,
face an alarming decline, with documented extinction and several at risk. This
study pioneers a comprehensive survey of Natural Language Processing (NLP)
research focused on Ghanaian languages, identifying methodologies, datasets,
and techniques employed. Additionally, we create a detailed roadmap outlining
challenges, best practices, and future directions, aiming to improve
accessibility for researchers. This work serves as a foundational resource for
Ghanaian NLP research and underscores the critical need for integrating global
linguistic diversity into AI development."	ArXiv
1132	Revisiting the Exit from Nuclear Energy in Germany with NLP	['Sebastian Haunss', 'André Blessing']	2024-08-25 11:13:29+00:00	http://arxiv.org/abs/2408.13810v1	"Annotation of political discourse is resource-intensive, but recent
developments in NLP promise to automate complex annotation tasks. Fine-tuned
transformer-based models outperform human annotators in some annotation tasks,
but they require large manually annotated training datasets. In our
contribution, we explore to which degree a manually annotated dataset can be
automatically replicated with today's NLP methods, using unsupervised machine
learning and zero- and few-shot learning."	ArXiv
1133	"What is the social benefit of hate speech detection research? A
  Systematic Review"	['Sidney Gig-Jan Wong']	2024-09-26 01:57:27+00:00	http://arxiv.org/abs/2409.17467v1	"While NLP research into hate speech detection has grown exponentially in the
last three decades, there has been minimal uptake or engagement from policy
makers and non-profit organisations. We argue the absence of ethical frameworks
have contributed to this rift between current practice and best practice. By
adopting appropriate ethical frameworks, NLP researchers may enable the social
impact potential of hate speech research. This position paper is informed by
reviewing forty-eight hate speech detection systems associated with
thirty-seven publications from different venues."	ArXiv
1134	"Evaluating Deduplication Techniques for Economic Research Paper Titles
  with a Focus on Semantic Similarity using NLP and LLMs"	['Doohee You', 'Samuel Fraiberger']	2024-10-02 00:43:10+00:00	http://arxiv.org/abs/2410.01141v2	"This study investigates efficient deduplication techniques for a large NLP
dataset of economic research paper titles. We explore various pairing methods
alongside established distance measures (Levenshtein distance, cosine
similarity) and a sBERT model for semantic evaluation. Our findings suggest a
potentially low prevalence of duplicates based on the observed semantic
similarity across different methods. Further exploration with a human-annotated
ground truth set is completed for a more conclusive assessment. The result
supports findings from the NLP, LLM based distance metrics."	ArXiv
1135	"Enhancing Assamese NLP Capabilities: Introducing a Centralized Dataset
  Repository"	['S. Tamang', 'D. J. Bora']	2024-10-15 05:26:57+00:00	http://arxiv.org/abs/2410.11291v2	"This paper introduces a centralized, open-source dataset repository designed
to advance NLP and NMT for Assamese, a low-resource language. The repository,
available at GitHub, supports various tasks like sentiment analysis, named
entity recognition, and machine translation by providing both pre-training and
fine-tuning corpora. We review existing datasets, highlighting the need for
standardized resources in Assamese NLP, and discuss potential applications in
AI-driven research, such as LLMs, OCR, and chatbots. While promising,
challenges like data scarcity and linguistic diversity remain. The repository
aims to foster collaboration and innovation, promoting Assamese language
research in the digital age."	ArXiv
1136	"Accelerating and Evaluation of Syntactic Parsing in Natural Language
  Question Answering Systems"	['Zhe Chen', 'Dunwei Wen']	2009-03-01 20:39:52+00:00	http://arxiv.org/abs/0903.0174v2	"With the development of Natural Language Processing (NLP), more and more
systems want to adopt NLP in User Interface Module to process user input, in
order to communicate with user in a natural way. However, this raises a speed
problem. That is, if NLP module can not process sentences in durable time
delay, users will never use the system. As a result, systems which are strict
with processing time, such as dialogue systems, web search systems, automatic
customer service systems, especially real-time systems, have to abandon NLP
module in order to get a faster system response. This paper aims to solve the
speed problem. In this paper, at first, the construction of a syntactic parser
which is based on corpus machine learning and statistics model is introduced,
and then a speed problem analysis is performed on the parser and its
algorithms. Based on the analysis, two accelerating methods, Compressed POS Set
and Syntactic Patterns Pruning, are proposed, which can effectively improve the
time efficiency of parsing in NLP module. To evaluate different parameters in
the accelerating algorithms, two new factors, PT and RT, are introduced and
explained in detail. Experiments are also completed to prove and test these
methods, which will surely contribute to the application of NLP."	ArXiv
1137	"Evaluating the Portability of an NLP System for Processing
  Echocardiograms: A Retrospective, Multi-site Observational Study"	['Prakash Adekkanattu', 'Guoqian Jiang', 'Yuan Luo', 'Paul R. Kingsbury', 'Zhenxing Xu', 'Luke V. Rasmussen', 'Jennifer A. Pacheco', 'Richard C. Kiefer', 'Daniel J. Stone', 'Pascal S. Brandt', 'Liang Yao', 'Yizhen Zhong', 'Yu Deng', 'Fei Wang', 'Jessica S. Ancker', 'Thomas R. Campion', 'Jyotishman Pathak']	2019-04-02 02:01:28+00:00	http://arxiv.org/abs/1905.01961v1	"While natural language processing (NLP) of unstructured clinical narratives
holds the potential for patient care and clinical research, portability of NLP
approaches across multiple sites remains a major challenge. This study
investigated the portability of an NLP system developed initially at the
Department of Veterans Affairs (VA) to extract 27 key cardiac concepts from
free-text or semi-structured echocardiograms from three academic medical
centers: Weill Cornell Medicine, Mayo Clinic and Northwestern Medicine. While
the NLP system showed high precision and recall measurements for four target
concepts (aortic valve regurgitation, left atrium size at end systole, mitral
valve regurgitation, tricuspid valve regurgitation) across all sites, we found
moderate or poor results for the remaining concepts and the NLP system
performance varied between individual sites."	ArXiv
1138	PowerNorm: Rethinking Batch Normalization in Transformers	['Sheng Shen', 'Zhewei Yao', 'Amir Gholami', 'Michael W. Mahoney', 'Kurt Keutzer']	2020-03-17 17:50:26+00:00	http://arxiv.org/abs/2003.07845v2	"The standard normalization method for neural network (NN) models used in
Natural Language Processing (NLP) is layer normalization (LN). This is
different than batch normalization (BN), which is widely-adopted in Computer
Vision. The preferred use of LN in NLP is principally due to the empirical
observation that a (naive/vanilla) use of BN leads to significant performance
degradation for NLP tasks; however, a thorough understanding of the underlying
reasons for this is not always evident. In this paper, we perform a systematic
study of NLP transformer models to understand why BN has a poor performance, as
compared to LN. We find that the statistics of NLP data across the batch
dimension exhibit large fluctuations throughout training. This results in
instability, if BN is naively implemented. To address this, we propose Power
Normalization (PN), a novel normalization scheme that resolves this issue by
(i) relaxing zero-mean normalization in BN, (ii) incorporating a running
quadratic mean instead of per batch statistics to stabilize fluctuations, and
(iii) using an approximate backpropagation for incorporating the running
statistics in the forward pass. We show theoretically, under mild assumptions,
that PN leads to a smaller Lipschitz constant for the loss, compared with BN.
Furthermore, we prove that the approximate backpropagation scheme leads to
bounded gradients. We extensively test PN for transformers on a range of NLP
tasks, and we show that it significantly outperforms both LN and BN. In
particular, PN outperforms LN by 0.4/0.6 BLEU on IWSLT14/WMT14 and 5.6/3.0 PPL
on PTB/WikiText-103. We make our code publicly available at
\url{https://github.com/sIncerass/powernorm}."	ArXiv
1139	OkwuGbé: End-to-End Speech Recognition for Fon and Igbo	['Bonaventure F. P. Dossou', 'Chris C. Emezue']	2021-03-13 18:02:44+00:00	http://arxiv.org/abs/2103.07762v2	"Language is inherent and compulsory for human communication. Whether
expressed in a written or spoken way, it ensures understanding between people
of the same and different regions. With the growing awareness and effort to
include more low-resourced languages in NLP research, African languages have
recently been a major subject of research in machine translation, and other
text-based areas of NLP. However, there is still very little comparable
research in speech recognition for African languages. Interestingly, some of
the unique properties of African languages affecting NLP, like their
diacritical and tonal complexities, have a major root in their speech,
suggesting that careful speech interpretation could provide more intuition on
how to deal with the linguistic complexities of African languages for
text-based NLP. OkwuGb\'e is a step towards building speech recognition systems
for African low-resourced languages. Using Fon and Igbo as our case study, we
conduct a comprehensive linguistic analysis of each language and describe the
creation of end-to-end, deep neural network-based speech recognition models for
both languages. We present a state-of-art ASR model for Fon, as well as
benchmark ASR model results for Igbo. Our linguistic analyses (for Fon and
Igbo) provide valuable insights and guidance into the creation of speech
recognition models for other African low-resourced languages, as well as guide
future NLP research for Fon and Igbo. The Fon and Igbo models source code have
been made publicly available."	ArXiv
1140	NLP for Ghanaian Languages	['Paul Azunre', 'Salomey Osei', 'Salomey Addo', 'Lawrence Asamoah Adu-Gyamfi', 'Stephen Moore', 'Bernard Adabankah', 'Bernard Opoku', 'Clara Asare-Nyarko', 'Samuel Nyarko', 'Cynthia Amoaba', 'Esther Dansoa Appiah', 'Felix Akwerh', 'Richard Nii Lante Lawson', 'Joel Budu', 'Emmanuel Debrah', 'Nana Boateng', 'Wisdom Ofori', 'Edwin Buabeng-Munkoh', 'Franklin Adjei', 'Isaac Kojo Essel Ampomah', 'Joseph Otoo', 'Reindorf Borkor', 'Standylove Birago Mensah', 'Lucien Mensah', 'Mark Amoako Marcel', 'Anokye Acheampong Amponsah', 'James Ben Hayfron-Acquah']	2021-03-29 10:16:52+00:00	http://arxiv.org/abs/2103.15475v2	"NLP Ghana is an open-source non-profit organization aiming to advance the
development and adoption of state-of-the-art NLP techniques and digital
language tools to Ghanaian languages and problems. In this paper, we first
present the motivation and necessity for the efforts of the organization; by
introducing some popular Ghanaian languages while presenting the state of NLP
in Ghana. We then present the NLP Ghana organization and outline its aims,
scope of work, some of the methods employed and contributions made thus far in
the NLP community in Ghana."	ArXiv
1141	"Probing new physics with long-lived charged particles produced by
  atmospheric and astrophysical neutrinos"	"[""Shin'ichiro Ando"", 'John F. Beacom', 'Stefano Profumo', 'David Rainwater']"	2007-11-19 20:04:33+00:00	http://arxiv.org/abs/0711.2908v2	"As suggested by some extensions of the Standard Model of particle physics,
dark matter may be a super-weakly interacting lightest stable particle, while
the next-to-lightest particle (NLP) is charged and meta-stable. One could test
such a possibility with neutrino telescopes, by detecting the charged NLPs
produced in high-energy neutrino collisions with Earth matter. We study the
production of charged NLPs by both atmospheric and astrophysical neutrinos;
only the latter, which is largely uncertain and has not been detected yet, was
the focus of previous studies. We compute the resulting fluxes of the charged
NLPs, compare those of different origins, and analyze the dependence on the
underlying particle physics setup. We point out that even if the astrophysical
neutrino flux is very small, atmospheric neutrinos, especially those from the
prompt decay of charmed mesons, may provide a detectable flux of NLP pairs at
neutrino telescopes such as IceCube. We also comment on the flux of charged
NLPs expected from proton-nucleon collisions, and show that, for theoretically
motivated and phenomenologically viable models, it is typically sub-dominant
and below detectable rates."	ArXiv
1142	"SqueezeBERT: What can computer vision teach NLP about efficient neural
  networks?"	['Forrest N. Iandola', 'Albert E. Shaw', 'Ravi Krishna', 'Kurt W. Keutzer']	2020-06-19 18:40:29+00:00	http://arxiv.org/abs/2006.11316v1	"Humans read and write hundreds of billions of messages every day. Further,
due to the availability of large datasets, large computing systems, and better
neural network models, natural language processing (NLP) technology has made
significant strides in understanding, proofreading, and organizing these
messages. Thus, there is a significant opportunity to deploy NLP in myriad
applications to help web users, social networks, and businesses. In particular,
we consider smartphones and other mobile devices as crucial platforms for
deploying NLP models at scale. However, today's highly-accurate NLP neural
network models such as BERT and RoBERTa are extremely computationally
expensive, with BERT-base taking 1.7 seconds to classify a text snippet on a
Pixel 3 smartphone. In this work, we observe that methods such as grouped
convolutions have yielded significant speedups for computer vision networks,
but many of these techniques have not been adopted by NLP neural network
designers. We demonstrate how to replace several operations in self-attention
layers with grouped convolutions, and we use this technique in a novel network
architecture called SqueezeBERT, which runs 4.3x faster than BERT-base on the
Pixel 3 while achieving competitive accuracy on the GLUE test set. The
SqueezeBERT code will be released."	ArXiv
1143	"Universal Natural Language Processing with Limited Annotations: Try
  Few-shot Textual Entailment as a Start"	['Wenpeng Yin', 'Nazneen Fatema Rajani', 'Dragomir Radev', 'Richard Socher', 'Caiming Xiong']	2020-10-06 09:50:25+00:00	http://arxiv.org/abs/2010.02584v1	"A standard way to address different NLP problems is by first constructing a
problem-specific dataset, then building a model to fit this dataset. To build
the ultimate artificial intelligence, we desire a single machine that can
handle diverse new problems, for which task-specific annotations are limited.
We bring up textual entailment as a unified solver for such NLP problems.
However, current research of textual entailment has not spilled much ink on the
following questions: (i) How well does a pretrained textual entailment system
generalize across domains with only a handful of domain-specific examples? and
(ii) When is it worth transforming an NLP task into textual entailment? We
argue that the transforming is unnecessary if we can obtain rich annotations
for this task. Textual entailment really matters particularly when the target
NLP task has insufficient annotations.
  Universal NLP can be probably achieved through different routines. In this
work, we introduce Universal Few-shot textual Entailment (UFO-Entail). We
demonstrate that this framework enables a pretrained entailment model to work
well on new entailment domains in a few-shot setting, and show its
effectiveness as a unified solver for several downstream NLP tasks such as
question answering and coreference resolution when the end-task annotations are
limited. Code: https://github.com/salesforce/UniversalFewShotNLP"	ArXiv
1144	A Survey of Data Augmentation Approaches for NLP	['Steven Y. Feng', 'Varun Gangal', 'Jason Wei', 'Sarath Chandar', 'Soroush Vosoughi', 'Teruko Mitamura', 'Eduard Hovy']	2021-05-07 06:03:45+00:00	http://arxiv.org/abs/2105.03075v5	"Data augmentation has recently seen increased interest in NLP due to more
work in low-resource domains, new tasks, and the popularity of large-scale
neural networks that require large amounts of training data. Despite this
recent upsurge, this area is still relatively underexplored, perhaps due to the
challenges posed by the discrete nature of language data. In this paper, we
present a comprehensive and unifying survey of data augmentation for NLP by
summarizing the literature in a structured manner. We first introduce and
motivate data augmentation for NLP, and then discuss major methodologically
representative approaches. Next, we highlight techniques that are used for
popular NLP applications and tasks. We conclude by outlining current challenges
and directions for future research. Overall, our paper aims to clarify the
landscape of existing literature in data augmentation for NLP and motivate
additional work in this area. We also present a GitHub repository with a paper
list that will be continuously updated at
https://github.com/styfeng/DataAug4NLP"	ArXiv
1145	"A Review of Bangla Natural Language Processing Tasks and the Utility of
  Transformer Models"	['Firoj Alam', 'Arid Hasan', 'Tanvirul Alam', 'Akib Khan', 'Janntatul Tajrin', 'Naira Khan', 'Shammur Absar Chowdhury']	2021-07-08 13:49:46+00:00	http://arxiv.org/abs/2107.03844v3	"Bangla -- ranked as the 6th most widely spoken language across the world
(https://www.ethnologue.com/guides/ethnologue200), with 230 million native
speakers -- is still considered as a low-resource language in the natural
language processing (NLP) community. With three decades of research, Bangla NLP
(BNLP) is still lagging behind mainly due to the scarcity of resources and the
challenges that come with it. There is sparse work in different areas of BNLP;
however, a thorough survey reporting previous work and recent advances is yet
to be done. In this study, we first provide a review of Bangla NLP tasks,
resources, and tools available to the research community; we benchmark datasets
collected from various platforms for nine NLP tasks using current
state-of-the-art algorithms (i.e., transformer-based models). We provide
comparative results for the studied NLP tasks by comparing monolingual vs.
multilingual models of varying sizes. We report our results using both
individual and consolidated datasets and provide data splits for future
research. We reviewed a total of 108 papers and conducted 175 sets of
experiments. Our results show promising performance using transformer-based
models while highlighting the trade-off with computational costs. We hope that
such a comprehensive survey will motivate the community to build on and further
advance the research on Bangla NLP."	ArXiv
1146	A Survey of Adversarial Defences and Robustness in NLP	['Shreya Goyal', 'Sumanth Doddapaneni', 'Mitesh M. Khapra', 'Balaraman Ravindran']	2022-03-12 11:37:17+00:00	http://arxiv.org/abs/2203.06414v4	"In the past few years, it has become increasingly evident that deep neural
networks are not resilient enough to withstand adversarial perturbations in
input data, leaving them vulnerable to attack. Various authors have proposed
strong adversarial attacks for computer vision and Natural Language Processing
(NLP) tasks. As a response, many defense mechanisms have also been proposed to
prevent these networks from failing. The significance of defending neural
networks against adversarial attacks lies in ensuring that the model's
predictions remain unchanged even if the input data is perturbed. Several
methods for adversarial defense in NLP have been proposed, catering to
different NLP tasks such as text classification, named entity recognition, and
natural language inference. Some of these methods not only defend neural
networks against adversarial attacks but also act as a regularization mechanism
during training, saving the model from overfitting. This survey aims to review
the various methods proposed for adversarial defenses in NLP over the past few
years by introducing a novel taxonomy. The survey also highlights the fragility
of advanced deep neural networks in NLP and the challenges involved in
defending them."	ArXiv
1147	"How to keep text private? A systematic review of deep learning methods
  for privacy-preserving natural language processing"	['Samuel Sousa', 'Roman Kern']	2022-05-20 11:29:44+00:00	http://arxiv.org/abs/2205.10095v1	"Deep learning (DL) models for natural language processing (NLP) tasks often
handle private data, demanding protection against breaches and disclosures.
Data protection laws, such as the European Union's General Data Protection
Regulation (GDPR), thereby enforce the need for privacy. Although many
privacy-preserving NLP methods have been proposed in recent years, no
categories to organize them have been introduced yet, making it hard to follow
the progress of the literature. To close this gap, this article systematically
reviews over sixty DL methods for privacy-preserving NLP published between 2016
and 2020, covering theoretical foundations, privacy-enhancing technologies, and
analysis of their suitability for real-world scenarios. First, we introduce a
novel taxonomy for classifying the existing methods into three categories: data
safeguarding methods, trusted methods, and verification methods. Second, we
present an extensive summary of privacy threats, datasets for applications, and
metrics for privacy evaluation. Third, throughout the review, we describe
privacy issues in the NLP pipeline in a holistic view. Further, we discuss open
challenges in privacy-preserving NLP regarding data traceability, computation
overhead, dataset size, the prevalence of human biases in embeddings, and the
privacy-utility tradeoff. Finally, this review presents future research
directions to guide successive research and development of privacy-preserving
NLP models."	ArXiv
1148	"TextGrad: Advancing Robustness Evaluation in NLP by Gradient-Driven
  Optimization"	['Bairu Hou', 'Jinghan Jia', 'Yihua Zhang', 'Guanhua Zhang', 'Yang Zhang', 'Sijia Liu', 'Shiyu Chang']	2022-12-19 05:55:58+00:00	http://arxiv.org/abs/2212.09254v1	"Robustness evaluation against adversarial examples has become increasingly
important to unveil the trustworthiness of the prevailing deep models in
natural language processing (NLP). However, in contrast to the computer vision
domain where the first-order projected gradient descent (PGD) is used as the
benchmark approach to generate adversarial examples for robustness evaluation,
there lacks a principled first-order gradient-based robustness evaluation
framework in NLP. The emerging optimization challenges lie in 1) the discrete
nature of textual inputs together with the strong coupling between the
perturbation location and the actual content, and 2) the additional constraint
that the perturbed text should be fluent and achieve a low perplexity under a
language model. These challenges make the development of PGD-like NLP attacks
difficult. To bridge the gap, we propose TextGrad, a new attack generator using
gradient-driven optimization, supporting high-accuracy and high-quality
assessment of adversarial robustness in NLP. Specifically, we address the
aforementioned challenges in a unified optimization framework. And we develop
an effective convex relaxation method to co-optimize the continuously-relaxed
site selection and perturbation variables and leverage an effective sampling
method to establish an accurate mapping from the continuous optimization
variables to the discrete textual perturbations. Moreover, as a first-order
attack generation method, TextGrad can be baked into adversarial training to
further improve the robustness of NLP models. Extensive experiments are
provided to demonstrate the effectiveness of TextGrad not only in attack
generation for robustness evaluation but also in adversarial defense."	ArXiv
1149	"A Review of the Trends and Challenges in Adopting Natural Language
  Processing Methods for Education Feedback Analysis"	['Thanveer Shaik', 'Xiaohui Tao', 'Yan Li', 'Christopher Dann', 'Jacquie Mcdonald', 'Petrea Redmond', 'Linda Galligan']	2023-01-20 23:38:58+00:00	http://arxiv.org/abs/2301.08826v1	"Artificial Intelligence (AI) is a fast-growing area of study that stretching
its presence to many business and research domains. Machine learning, deep
learning, and natural language processing (NLP) are subsets of AI to tackle
different areas of data processing and modelling. This review article presents
an overview of AI impact on education outlining with current opportunities. In
the education domain, student feedback data is crucial to uncover the merits
and demerits of existing services provided to students. AI can assist in
identifying the areas of improvement in educational infrastructure, learning
management systems, teaching practices and study environment. NLP techniques
play a vital role in analyzing student feedback in textual format. This
research focuses on existing NLP methodologies and applications that could be
adapted to educational domain applications like sentiment annotations, entity
annotations, text summarization, and topic modelling. Trends and challenges in
adopting NLP in education were reviewed and explored. Contextbased challenges
in NLP like sarcasm, domain-specific language, ambiguity, and aspect-based
sentiment analysis are explained with existing methodologies to overcome them.
Research community approaches to extract the semantic meaning of emoticons and
special characters in feedback which conveys user opinion and challenges in
adopting NLP in education are explored."	ArXiv
1150	"Coupling Artificial Neurons in BERT and Biological Neurons in the Human
  Brain"	['Xu Liu', 'Mengyue Zhou', 'Gaosheng Shi', 'Yu Du', 'Lin Zhao', 'Zihao Wu', 'David Liu', 'Tianming Liu', 'Xintao Hu']	2023-03-27 01:41:48+00:00	http://arxiv.org/abs/2303.14871v1	"Linking computational natural language processing (NLP) models and neural
responses to language in the human brain on the one hand facilitates the effort
towards disentangling the neural representations underpinning language
perception, on the other hand provides neurolinguistics evidence to evaluate
and improve NLP models. Mappings of an NLP model's representations of and the
brain activities evoked by linguistic input are typically deployed to reveal
this symbiosis. However, two critical problems limit its advancement: 1) The
model's representations (artificial neurons, ANs) rely on layer-level
embeddings and thus lack fine-granularity; 2) The brain activities (biological
neurons, BNs) are limited to neural recordings of isolated cortical unit (i.e.,
voxel/region) and thus lack integrations and interactions among brain
functions. To address those problems, in this study, we 1) define ANs with
fine-granularity in transformer-based NLP models (BERT in this study) and
measure their temporal activations to input text sequences; 2) define BNs as
functional brain networks (FBNs) extracted from functional magnetic resonance
imaging (fMRI) data to capture functional interactions in the brain; 3) couple
ANs and BNs by maximizing the synchronization of their temporal activations.
Our experimental results demonstrate 1) The activations of ANs and BNs are
significantly synchronized; 2) the ANs carry meaningful linguistic/semantic
information and anchor to their BN signatures; 3) the anchored BNs are
interpretable in a neurolinguistic context. Overall, our study introduces a
novel, general, and effective framework to link transformer-based NLP models
and neural activities in response to language and may provide novel insights
for future studies such as brain-inspired evaluation and development of NLP
models."	ArXiv
1151	"Has It All Been Solved? Open NLP Research Questions Not Solved by Large
  Language Models"	['Oana Ignat', 'Zhijing Jin', 'Artem Abzaliev', 'Laura Biester', 'Santiago Castro', 'Naihao Deng', 'Xinyi Gao', 'Aylin Gunal', 'Jacky He', 'Ashkan Kazemi', 'Muhammad Khalifa', 'Namho Koh', 'Andrew Lee', 'Siyang Liu', 'Do June Min', 'Shinka Mori', 'Joan Nwatu', 'Veronica Perez-Rosas', 'Siqi Shen', 'Zekun Wang', 'Winston Wu', 'Rada Mihalcea']	2023-05-21 19:06:30+00:00	http://arxiv.org/abs/2305.12544v2	"Recent progress in large language models (LLMs) has enabled the deployment of
many generative NLP applications. At the same time, it has also led to a
misleading public discourse that ``it's all been solved.'' Not surprisingly,
this has, in turn, made many NLP researchers -- especially those at the
beginning of their careers -- worry about what NLP research area they should
focus on. Has it all been solved, or what remaining questions can we work on
regardless of LLMs? To address this question, this paper compiles NLP research
directions rich for exploration. We identify fourteen different research areas
encompassing 45 research directions that require new research and are not
directly solvable by LLMs. While we identify many research areas, many others
exist; we do not cover areas currently addressed by LLMs, but where LLMs lag
behind in performance or those focused on LLM development. We welcome
suggestions for other research directions to include:
https://bit.ly/nlp-era-llm"	ArXiv
1152	"On Bias and Fairness in NLP: Investigating the Impact of Bias and
  Debiasing in Language Models on the Fairness of Toxicity Detection"	['Fatma Elsafoury', 'Stamos Katsigiannis']	2023-05-22 08:44:00+00:00	http://arxiv.org/abs/2305.12829v3	"Language models are the new state-of-the-art natural language processing
(NLP) models and they are being increasingly used in many NLP tasks. Even
though there is evidence that language models are biased, the impact of that
bias on the fairness of downstream NLP tasks is still understudied.
Furthermore, despite that numerous debiasing methods have been proposed in the
literature, the impact of bias removal methods on the fairness of NLP tasks is
also understudied. In this work, we investigate three different sources of bias
in NLP models, i.e. representation bias, selection bias and overamplification
bias, and examine how they impact the fairness of the downstream task of
toxicity detection. Moreover, we investigate the impact of removing these
biases using different bias removal techniques on the fairness of toxicity
detection. Results show strong evidence that downstream sources of bias,
especially overamplification bias, are the most impactful types of bias on the
fairness of the task of toxicity detection. We also found strong evidence that
removing overamplification bias by fine-tuning the language models on a dataset
with balanced contextual representations and ratios of positive examples
between different identity groups can improve the fairness of the task of
toxicity detection. Finally, we build on our findings and introduce a list of
guidelines to ensure the fairness of the task of toxicity detection."	ArXiv
1153	NLP-Based Techniques for Cyber Threat Intelligence	['Marco Arazzi', 'Dincy R. Arikkat', 'Serena Nicolazzo', 'Antonino Nocera', 'Rafidha Rehiman K. A.', 'Vinod P.', 'Mauro Conti']	2023-11-15 09:23:33+00:00	http://arxiv.org/abs/2311.08807v1	"In the digital era, threat actors employ sophisticated techniques for which,
often, digital traces in the form of textual data are available. Cyber Threat
Intelligence~(CTI) is related to all the solutions inherent to data collection,
processing, and analysis useful to understand a threat actor's targets and
attack behavior. Currently, CTI is assuming an always more crucial role in
identifying and mitigating threats and enabling proactive defense strategies.
In this context, NLP, an artificial intelligence branch, has emerged as a
powerful tool for enhancing threat intelligence capabilities. This survey paper
provides a comprehensive overview of NLP-based techniques applied in the
context of threat intelligence. It begins by describing the foundational
definitions and principles of CTI as a major tool for safeguarding digital
assets. It then undertakes a thorough examination of NLP-based techniques for
CTI data crawling from Web sources, CTI data analysis, Relation Extraction from
cybersecurity data, CTI sharing and collaboration, and security threats of CTI.
Finally, the challenges and limitations of NLP in threat intelligence are
exhaustively examined, including data quality issues and ethical
considerations. This survey draws a complete framework and serves as a valuable
resource for security professionals and researchers seeking to understand the
state-of-the-art NLP-based threat intelligence techniques and their potential
impact on cybersecurity."	ArXiv
1154	"Solving the Right Problem is Key for Translational NLP: A Case Study in
  UMLS Vocabulary Insertion"	['Bernal Jimenez Gutierrez', 'Yuqing Mao', 'Vinh Nguyen', 'Kin Wah Fung', 'Yu Su', 'Olivier Bodenreider']	2023-11-25 19:35:53+00:00	http://arxiv.org/abs/2311.15106v1	"As the immense opportunities enabled by large language models become more
apparent, NLP systems will be increasingly expected to excel in real-world
settings. However, in many instances, powerful models alone will not yield
translational NLP solutions, especially if the formulated problem is not well
aligned with the real-world task. In this work, we study the case of UMLS
vocabulary insertion, an important real-world task in which hundreds of
thousands of new terms, referred to as atoms, are added to the UMLS, one of the
most comprehensive open-source biomedical knowledge bases. Previous work aimed
to develop an automated NLP system to make this time-consuming, costly, and
error-prone task more efficient. Nevertheless, practical progress in this
direction has been difficult to achieve due to a problem formulation and
evaluation gap between research output and the real-world task. In order to
address this gap, we introduce a new formulation for UMLS vocabulary insertion
which mirrors the real-world task, datasets which faithfully represent it and
several strong baselines we developed through re-purposing existing solutions.
Additionally, we propose an effective rule-enhanced biomedical language model
which enables important new model behavior, outperforms all strong baselines
and provides measurable qualitative improvements to editors who carry out the
UVI task. We hope this case study provides insight into the considerable
importance of problem formulation for the success of translational NLP
solutions."	ArXiv
1155	"NLP for Maternal Healthcare: Perspectives and Guiding Principles in the
  Age of LLMs"	['Maria Antoniak', 'Aakanksha Naik', 'Carla S. Alvarado', 'Lucy Lu Wang', 'Irene Y. Chen']	2023-12-19 02:35:13+00:00	http://arxiv.org/abs/2312.11803v2	"Ethical frameworks for the use of natural language processing (NLP) are
urgently needed to shape how large language models (LLMs) and similar tools are
used for healthcare applications. Healthcare faces existing challenges
including the balance of power in clinician-patient relationships, systemic
health disparities, historical injustices, and economic constraints. Drawing
directly from the voices of those most affected, and focusing on a case study
of a specific healthcare setting, we propose a set of guiding principles for
the use of NLP in maternal healthcare. We led an interactive session centered
on an LLM-based chatbot demonstration during a full-day workshop with 39
participants, and additionally surveyed 30 healthcare workers and 30 birthing
people about their values, needs, and perceptions of NLP tools in the context
of maternal health. We conducted quantitative and qualitative analyses of the
survey results and interactive discussions to consolidate our findings into a
set of guiding principles. We propose nine principles for ethical use of NLP
for maternal healthcare, grouped into three themes: (i) recognizing contextual
significance (ii) holistic measurements, and (iii) who/what is valued. For each
principle, we describe its underlying rationale and provide practical advice.
This set of principles can provide a methodological pattern for other
researchers and serve as a resource to practitioners working on maternal health
and other healthcare fields to emphasize the importance of technical nuance,
historical context, and inclusive design when developing NLP technologies for
clinical use."	ArXiv
1156	Natural Language Processing for Dialects of a Language: A Survey	['Aditya Joshi', 'Raj Dabre', 'Diptesh Kanojia', 'Zhuang Li', 'Haolan Zhan', 'Gholamreza Haffari', 'Doris Dippold']	2024-01-11 03:04:38+00:00	http://arxiv.org/abs/2401.05632v4	"State-of-the-art natural language processing (NLP) models are trained on
massive training corpora, and report a superlative performance on evaluation
datasets. This survey delves into an important attribute of these datasets: the
dialect of a language. Motivated by the performance degradation of NLP models
for dialectal datasets and its implications for the equity of language
technologies, we survey past research in NLP for dialects in terms of datasets,
and approaches. We describe a wide range of NLP tasks in terms of two
categories: natural language understanding (NLU) (for tasks such as dialect
classification, sentiment analysis, parsing, and NLU benchmarks) and natural
language generation (NLG) (for summarisation, machine translation, and dialogue
systems). The survey is also broad in its coverage of languages which include
English, Arabic, German, among others. We observe that past work in NLP
concerning dialects goes deeper than mere dialect classification, and extends
to several NLU and NLG tasks. For these tasks, we describe classical machine
learning using statistical models, along with the recent deep learning-based
approaches based on pre-trained language models. We expect that this survey
will be useful to NLP researchers interested in building equitable language
technologies by rethinking LLM benchmarks and model architectures."	ArXiv
1157	Emotion Analysis in NLP: Trends, Gaps and Roadmap for Future Directions	['Flor Miriam Plaza-del-Arco', 'Alba Curry', 'Amanda Cercas Curry', 'Dirk Hovy']	2024-03-02 14:38:03+00:00	http://arxiv.org/abs/2403.01222v2	"Emotions are a central aspect of communication. Consequently, emotion
analysis (EA) is a rapidly growing field in natural language processing (NLP).
However, there is no consensus on scope, direction, or methods. In this paper,
we conduct a thorough review of 154 relevant NLP publications from the last
decade. Based on this review, we address four different questions: (1) How are
EA tasks defined in NLP? (2) What are the most prominent emotion frameworks and
which emotions are modeled? (3) Is the subjectivity of emotions considered in
terms of demographics and cultural factors? and (4) What are the primary NLP
applications for EA? We take stock of trends in EA and tasks, emotion
frameworks used, existing datasets, methods, and applications. We then discuss
four lacunae: (1) the absence of demographic and cultural aspects does not
account for the variation in how emotions are perceived, but instead assumes
they are universally experienced in the same manner; (2) the poor fit of
emotion categories from the two main emotion theories to the task; (3) the lack
of standardized EA terminology hinders gap identification, comparison, and
future goals; and (4) the absence of interdisciplinary research isolates EA
from insights in other fields. Our work will enable more focused research into
EA and a more holistic approach to modeling emotions in NLP."	ArXiv
1158	Natural Language Processing for Requirements Traceability	['Jin L. C. Guo', 'Jan-Philipp Steghöfer', 'Andreas Vogelsang', 'Jane Cleland-Huang']	2024-05-17 15:17:00+00:00	http://arxiv.org/abs/2405.10845v1	"Traceability, the ability to trace relevant software artifacts to support
reasoning about the quality of the software and its development process, plays
a crucial role in requirements and software engineering, particularly for
safety-critical systems. In this chapter, we provide a comprehensive overview
of the representative tasks in requirement traceability for which natural
language processing (NLP) and related techniques have made considerable
progress in the past decade. We first present the definition of traceability in
the context of requirements and the overall engineering process, as well as
other important concepts related to traceability tasks. Then, we discuss two
tasks in detail, including trace link recovery and trace link maintenance. We
also introduce two other related tasks concerning when trace links are used in
practical contexts. For each task, we explain the characteristics of the task,
how it can be approached through NLP techniques, and how to design and conduct
the experiment to demonstrate the performance of the NLP techniques. We further
discuss practical considerations on how to effectively apply NLP techniques and
assess their effectiveness regarding the data set collection, the metrics
selection, and the role of humans when evaluating the NLP approaches. Overall,
this chapter prepares the readers with the fundamental knowledge of designing
automated traceability solutions enabled by NLP in practice."	ArXiv
1159	"SYNTHEVAL: Hybrid Behavioral Testing of NLP Models with Synthetic
  CheckLists"	['Raoyuan Zhao', 'Abdullatif Köksal', 'Yihong Liu', 'Leonie Weissweiler', 'Anna Korhonen', 'Hinrich Schütze']	2024-08-30 17:41:30+00:00	http://arxiv.org/abs/2408.17437v2	"Traditional benchmarking in NLP typically involves using static held-out test
sets. However, this approach often results in an overestimation of performance
and lacks the ability to offer comprehensive, interpretable, and dynamic
assessments of NLP models. Recently, works like DynaBench (Kiela et al., 2021)
and CheckList (Ribeiro et al., 2020) have addressed these limitations through
behavioral testing of NLP models with test types generated by a multistep
human-annotated pipeline. Unfortunately, manually creating a variety of test
types requires much human labor, often at prohibitive cost. In this work, we
propose SYNTHEVAL, a hybrid behavioral testing framework that leverages large
language models (LLMs) to generate a wide range of test types for a
comprehensive evaluation of NLP models. SYNTHEVAL first generates sentences via
LLMs using controlled generation, and then identifies challenging examples by
comparing the predictions made by LLMs with task-specific NLP models. In the
last stage, human experts investigate the challenging examples, manually design
templates, and identify the types of failures the taskspecific models
consistently exhibit. We apply SYNTHEVAL to two classification tasks, sentiment
analysis and toxic language detection, and show that our framework is effective
in identifying weaknesses of strong models on these tasks. We share our code in
https://github.com/Loreley99/SynthEval_CheckList."	ArXiv
1160	"Advancing Fairness in Natural Language Processing: From Traditional
  Methods to Explainability"	['Fanny Jourdan']	2024-10-16 12:38:58+00:00	http://arxiv.org/abs/2410.12511v1	"The burgeoning field of Natural Language Processing (NLP) stands at a
critical juncture where the integration of fairness within its frameworks has
become an imperative. This PhD thesis addresses the need for equity and
transparency in NLP systems, recognizing that fairness in NLP is not merely a
technical challenge but a moral and ethical necessity, requiring a rigorous
examination of how these technologies interact with and impact diverse human
populations. Through this lens, this thesis undertakes a thorough investigation
into the development of equitable NLP methodologies and the evaluation of
biases that prevail in current systems.
  First, it introduces an innovative algorithm to mitigate biases in
multi-class classifiers, tailored for high-risk NLP applications, surpassing
traditional methods in both bias mitigation and prediction accuracy. Then, an
analysis of the Bios dataset reveals the impact of dataset size on
discriminatory biases and the limitations of standard fairness metrics. This
awareness has led to explorations in the field of explainable AI, aiming for a
more complete understanding of biases where traditional metrics are limited.
Consequently, the thesis presents COCKATIEL, a model-agnostic explainability
method that identifies and ranks concepts in Transformer models, outperforming
previous approaches in sentiment analysis tasks. Finally, the thesis
contributes to bridging the gap between fairness and explainability by
introducing TaCo, a novel method to neutralize bias in Transformer model
embeddings.
  In conclusion, this thesis constitutes a significant interdisciplinary
endeavor that intertwines explicability and fairness to challenge and reshape
current NLP paradigms. The methodologies and critiques presented contribute to
the ongoing discourse on fairness in machine learning, offering actionable
solutions for more equitable and responsible AI systems."	ArXiv
1161	"The ""Whiteboard"" Architecture: a way to integrate heterogeneous
  components of NLP systems"	['Christian Boitet', 'Mark Seligman']	1994-11-04 13:16:25+00:00	http://arxiv.org/abs/cmp-lg/9411010v1	"We present a new software architecture for NLP systems made of heterogeneous
components, and demonstrate an architectural prototype we have built at ATR in
the context of Speech Translation."	ArXiv
1162	Deep Learning applied to NLP	['Marc Moreno Lopez', 'Jugal Kalita']	2017-03-09 01:04:07+00:00	http://arxiv.org/abs/1703.03091v1	"Convolutional Neural Network (CNNs) are typically associated with Computer
Vision. CNNs are responsible for major breakthroughs in Image Classification
and are the core of most Computer Vision systems today. More recently CNNs have
been applied to problems in Natural Language Processing and gotten some
interesting results. In this paper, we will try to explain the basics of CNNs,
its different variations and how they have been applied to NLP."	ArXiv
1163	A Biomedical Information Extraction Primer for NLP Researchers	['Surag Nair']	2017-05-10 10:00:00+00:00	http://arxiv.org/abs/1705.05437v1	"Biomedical Information Extraction is an exciting field at the crossroads of
Natural Language Processing, Biology and Medicine. It encompasses a variety of
different tasks that require application of state-of-the-art NLP techniques,
such as NER and Relation Extraction. This paper provides an overview of the
problems in the field and discusses some of the techniques used for solving
them."	ArXiv
1164	What is wrong with style transfer for texts?	['Alexey Tikhonov', 'Ivan P. Yamshchikov']	2018-08-13 11:50:03+00:00	http://arxiv.org/abs/1808.04365v1	"A number of recent machine learning papers work with an automated style
transfer for texts and, counter to intuition, demonstrate that there is no
consensus formulation of this NLP task. Different researchers propose different
algorithms, datasets and target metrics to address it. This short opinion paper
aims to discuss possible formalization of this NLP task in anticipation of a
further growing interest to it."	ArXiv
1165	Distributed NLP	['Galip Aydin', 'Ibrahim Riza Hallac']	2018-02-10 15:08:56+00:00	http://arxiv.org/abs/1802.03606v1	"In this paper we present the performance of parallel text processing with Map
Reduce on a cloud platform. Scientific papers in Turkish language are processed
using Zemberek NLP library. Experiments were run on a Hadoop cluster and
compared with the single machines performance."	ArXiv
1166	NLP-assisted software testing: A systematic mapping of the literature	['Vahid Garousi', 'Sara Bauer', 'Michael Felderer']	2018-06-02 20:00:44+00:00	http://arxiv.org/abs/1806.00696v3	"Context: To reduce manual effort of extracting test cases from
natural-language requirements, many approaches based on Natural Language
Processing (NLP) have been proposed in the literature. Given the large amount
of approaches in this area, and since many practitioners are eager to utilize
such techniques, it is important to synthesize and provide an overview of the
state-of-the-art in this area. Objective: Our objective is to summarize the
state-of-the-art in NLP-assisted software testing which could benefit
practitioners to potentially utilize those NLP-based techniques. Moreover, this
can benefit researchers in providing an overview of the research landscape.
Method: To address the above need, we conducted a survey in the form of a
systematic literature mapping (classification). After compiling an initial pool
of 95 papers, we conducted a systematic voting, and our final pool included 67
technical papers. Results: This review paper provides an overview of the
contribution types presented in the papers, types of NLP approaches used to
assist software testing, types of required input requirements, and a review of
tool support in this area. Some key results we have detected are: (1) only four
of the 38 tools (11%) presented in the papers are available for download; (2) a
larger ratio of the papers (30 of 67) provided a shallow exposure to the NLP
aspects (almost no details). Conclusion: This paper would benefit both
practitioners and researchers by serving as an ""index"" to the body of knowledge
in this area. The results could help practitioners utilizing the existing
NLP-based techniques; this in turn reduces the cost of test-case design and
decreases the amount of human resources spent on test activities. After sharing
this review with some of our industrial collaborators, initial insights show
that this review can indeed be useful and beneficial to practitioners."	ArXiv
1167	Deep Learning Models for Automatic Summarization	['Pirmin Lemberger']	2020-05-25 09:12:37+00:00	http://arxiv.org/abs/2005.11988v1	"Text summarization is an NLP task which aims to convert a textual document
into a shorter one while keeping as much meaning as possible. This pedagogical
article reviews a number of recent Deep Learning architectures that have helped
to advance research in this field. We will discuss in particular applications
of pointer networks, hierarchical Transformers and Reinforcement Learning. We
assume basic knowledge of Seq2Seq architecture and Transformer networks within
NLP."	ArXiv
1168	The Cost of Training NLP Models: A Concise Overview	['Or Sharir', 'Barak Peleg', 'Yoav Shoham']	2020-04-19 16:28:35+00:00	http://arxiv.org/abs/2004.08900v1	"We review the cost of training large-scale language models, and the drivers
of these costs. The intended audience includes engineers and scientists
budgeting their model-training experiments, as well as non-practitioners trying
to make sense of the economics of modern-day Natural Language Processing (NLP)."	ArXiv
1169	"An Open Natural Language Processing Development Framework for EHR-based
  Clinical Research: A case demonstration using the National COVID Cohort
  Collaborative (N3C)"	['Sijia Liu', 'Andrew Wen', 'Liwei Wang', 'Huan He', 'Sunyang Fu', 'Robert Miller', 'Andrew Williams', 'Daniel Harris', 'Ramakanth Kavuluru', 'Mei Liu', 'Noor Abu-el-rub', 'Dalton Schutte', 'Rui Zhang', 'Masoud Rouhizadeh', 'John D. Osborne', 'Yongqun He', 'Umit Topaloglu', 'Stephanie S Hong', 'Joel H Saltz', 'Thomas Schaffter', 'Emily Pfaff', 'Christopher G. Chute', 'Tim Duong', 'Melissa A. Haendel', 'Rafael Fuentes', 'Peter Szolovits', 'Hua Xu', 'Hongfang Liu', 'National COVID Cohort Collaborative', 'Natural Language Processing', 'Subgroup', 'National COVID Cohort Collaborative']	2021-10-20 21:09:41+00:00	http://arxiv.org/abs/2110.10780v3	"While we pay attention to the latest advances in clinical natural language
processing (NLP), we can notice some resistance in the clinical and
translational research community to adopt NLP models due to limited
transparency, interpretability, and usability. In this study, we proposed an
open natural language processing development framework. We evaluated it through
the implementation of NLP algorithms for the National COVID Cohort
Collaborative (N3C). Based on the interests in information extraction from
COVID-19 related clinical notes, our work includes 1) an open data annotation
process using COVID-19 signs and symptoms as the use case, 2) a
community-driven ruleset composing platform, and 3) a synthetic text data
generation workflow to generate texts for information extraction tasks without
involving human subjects. The corpora were derived from texts from three
different institutions (Mayo Clinic, University of Kentucky, University of
Minnesota). The gold standard annotations were tested with a single
institution's (Mayo) ruleset. This resulted in performances of 0.876, 0.706,
and 0.694 in F-scores for Mayo, Minnesota, and Kentucky test datasets,
respectively. The study as a consortium effort of the N3C NLP subgroup
demonstrates the feasibility of creating a federated NLP algorithm development
and benchmarking platform to enhance multi-institution clinical NLP study and
adoption. Although we use COVID-19 as a use case in this effort, our framework
is general enough to be applied to other domains of interest in clinical NLP."	ArXiv
1170	"KnowDA: All-in-One Knowledge Mixture Model for Data Augmentation in
  Low-Resource NLP"	['Yufei Wang', 'Jiayi Zheng', 'Can Xu', 'Xiubo Geng', 'Tao Shen', 'Chongyang Tao', 'Daxin Jiang']	2022-06-21 11:34:02+00:00	http://arxiv.org/abs/2206.10265v2	"This paper focuses on the data augmentation for low-resource NLP tasks where
the training set is limited. The existing solutions either leverage
task-independent heuristic rules (e.g., Synonym Replacement) or fine-tune
general-purpose pre-trained language models (e.g., GPT2) using the limited
training instances to produce new synthetic data. Consequently, they have
trivial task-specific knowledge and are limited to yielding low-quality
synthetic data. To combat this issue, we propose Knowledge Mixture Data
Augmentation Model (KnowDA) which is an Seq2Seq language model pre-trained on a
mixture of diverse NLP tasks under a novel framework of Knowledge Mixture
Training (KoMT). The goal of KoMT is to condense diverse NLP task-specific
knowledge into the single KnowDA model (i.e., all-in-one) such that KnowDA
could utilize these knowledge to quickly grasp the inherent synthesis law of
the target task through limited training instances. Specifically, KoMT
reformulates input examples from various heterogeneous NLP tasks into a unified
text-to-text format, and employs denoising training objectives in different
granularity to learn to reconstruct partial or complete samples. To the best of
our knowledge, we are the first attempt to apply 100+ NLP multi-task training
for data augmentation. Extensive experiments show that i) the synthetic data
produced by KnowDA successfully improves performance of the strong pre-trained
language models (i.e., Bert, ALBert and Deberta) by a large margin on the
low-resource NLP benchmark FewGLUE, CoNLL'03 and WikiAnn; ii) KnowDA
successfully transfers the task knowledge to NLP tasks whose types are seen and
unseen in KoMT."	ArXiv
1171	"Associations Between Natural Language Processing (NLP) Enriched Social
  Determinants of Health and Suicide Death among US Veterans"	['Avijit Mitra', 'Richeek Pradhan', 'Rachel D Melamed', 'Kun Chen', 'David C Hoaglin', 'Katherine L Tucker', 'Joel I Reisman', 'Zhichao Yang', 'Weisong Liu', 'Jack Tsai', 'Hong Yu']	2022-12-11 17:15:02+00:00	http://arxiv.org/abs/2212.05546v3	"Importance: Social determinants of health (SDOH) are known to be associated
with increased risk of suicidal behaviors, but few studies utilized SDOH from
unstructured electronic health record (EHR) notes.
  Objective: To investigate associations between suicide and recent SDOH,
identified using structured and unstructured data.
  Design: Nested case-control study.
  Setting: EHR data from the US Veterans Health Administration (VHA).
  Participants: 6,122,785 Veterans who received care in the US VHA between
October 1, 2010, and September 30, 2015.
  Exposures: Occurrence of SDOH over a maximum span of two years compared with
no occurrence of SDOH.
  Main Outcomes and Measures: Cases of suicide deaths were matched with 4
controls on birth year, cohort entry date, sex, and duration of follow-up. We
developed an NLP system to extract SDOH from unstructured notes. Structured
data, NLP on unstructured data, and combining them yielded six, eight and nine
SDOH respectively. Adjusted odds ratios (aORs) and 95% confidence intervals
(CIs) were estimated using conditional logistic regression.
  Results: In our cohort, 8,821 Veterans committed suicide during 23,725,382
person-years of follow-up (incidence rate 37.18/100,000 person-years). Our
cohort was mostly male (92.23%) and white (76.99%). Across the five common SDOH
as covariates, NLP-extracted SDOH, on average, covered 80.03% of all SDOH
occurrences. All SDOH, measured by structured data and NLP, were significantly
associated with increased risk of suicide. The SDOH with the largest effects
was legal problems (aOR=2.66, 95% CI=.46-2.89), followed by violence (aOR=2.12,
95% CI=1.98-2.27). NLP-extracted and structured SDOH were also associated with
suicide.
  Conclusions and Relevance: NLP-extracted SDOH were always significantly
associated with increased risk of suicide among Veterans, suggesting the
potential of NLP in public health studies."	ArXiv
1172	What Can Natural Language Processing Do for Peer Review?	['Ilia Kuznetsov', 'Osama Mohammed Afzal', 'Koen Dercksen', 'Nils Dycke', 'Alexander Goldberg', 'Tom Hope', 'Dirk Hovy', 'Jonathan K. Kummerfeld', 'Anne Lauscher', 'Kevin Leyton-Brown', 'Sheng Lu', 'Mausam', 'Margot Mieskes', 'Aurélie Névéol', 'Danish Pruthi', 'Lizhen Qu', 'Roy Schwartz', 'Noah A. Smith', 'Thamar Solorio', 'Jingyan Wang', 'Xiaodan Zhu', 'Anna Rogers', 'Nihar B. Shah', 'Iryna Gurevych']	2024-05-10 16:06:43+00:00	http://arxiv.org/abs/2405.06563v1	"The number of scientific articles produced every year is growing rapidly.
Providing quality control over them is crucial for scientists and, ultimately,
for the public good. In modern science, this process is largely delegated to
peer review -- a distributed procedure in which each submission is evaluated by
several independent experts in the field. Peer review is widely used, yet it is
hard, time-consuming, and prone to error. Since the artifacts involved in peer
review -- manuscripts, reviews, discussions -- are largely text-based, Natural
Language Processing has great potential to improve reviewing. As the emergence
of large language models (LLMs) has enabled NLP assistance for many new tasks,
the discussion on machine-assisted peer review is picking up the pace. Yet,
where exactly is help needed, where can NLP help, and where should it stand
aside? The goal of our paper is to provide a foundation for the future efforts
in NLP for peer-reviewing assistance. We discuss peer review as a general
process, exemplified by reviewing at AI conferences. We detail each step of the
process from manuscript submission to camera-ready revision, and discuss the
associated challenges and opportunities for NLP assistance, illustrated by
existing work. We then turn to the big challenges in NLP for peer review as a
whole, including data acquisition and licensing, operationalization and
experimentation, and ethical issues. To help consolidate community efforts, we
create a companion repository that aggregates key datasets pertaining to peer
review. Finally, we issue a detailed call for action for the scientific
community, NLP and AI researchers, policymakers, and funding bodies to help
bring the research in NLP for peer review forward. We hope that our work will
help set the agenda for research in machine-assisted scientific quality control
in the age of AI, within the NLP community and beyond."	ArXiv
1173	New Methods, Current Trends and Software Infrastructure for NLP	['Hamish Cunningham', 'Yorick Wilks', 'Robert J. Gaizauskas']	1996-07-23 15:31:44+00:00	http://arxiv.org/abs/cmp-lg/9607025v1	"The increasing use of `new methods' in NLP, which the NeMLaP conference
series exemplifies, occurs in the context of a wider shift in the nature and
concerns of the discipline. This paper begins with a short review of this
context and significant trends in the field. The review motivates and leads to
a set of requirements for support software of general utility for NLP research
and development workers. A freely-available system designed to meet these
requirements is described (called GATE - a General Architecture for Text
Engineering). Information Extraction (IE), in the sense defined by the Message
Understanding Conferences (ARPA \cite{Arp95}), is an NLP application in which
many of the new methods have found a home (Hobbs \cite{Hob93}; Jacobs ed.
\cite{Jac92}). An IE system based on GATE is also available for research
purposes, and this is described. Lastly we review related work."	ArXiv
1174	Software Infrastructure for Natural Language Processing	['Hamish Cunningham', 'Kevin Humphreys', 'Robert Gaizauskas', 'Yorick Wilks']	1997-02-10 21:07:20+00:00	http://arxiv.org/abs/cmp-lg/9702005v1	"We classify and review current approaches to software infrastructure for
research, development and delivery of NLP systems. The task is motivated by a
discussion of current trends in the field of NLP and Language Engineering. We
describe a system called GATE (a General Architecture for Text Engineering)
that provides a software infrastructure on top of which heterogeneous NLP
processing modules may be evaluated and refined individually, or may be
combined into larger application systems. GATE aims to support both researchers
and developers working on component technologies (e.g. parsing, tagging,
morphological analysis) and those working on developing end-user applications
(e.g. information extraction, text summarisation, document generation, machine
translation, and second language learning). GATE promotes reuse of component
technology, permits specialisation and collaboration in large-scale projects,
and allows for the comparison and evaluation of alternative technologies. The
first release of GATE is now available - see
http://www.dcs.shef.ac.uk/research/groups/nlp/gate/"	ArXiv
1175	Fast Statistical Parsing of Noun Phrases for Document Indexing	['Chengxiang Zhai']	1997-02-12 16:30:14+00:00	http://arxiv.org/abs/cmp-lg/9702009v1	"Information Retrieval (IR) is an important application area of Natural
Language Processing (NLP) where one encounters the genuine challenge of
processing large quantities of unrestricted natural language text. While much
effort has been made to apply NLP techniques to IR, very few NLP techniques
have been evaluated on a document collection larger than several megabytes.
Many NLP techniques are simply not efficient enough, and not robust enough, to
handle a large amount of text. This paper proposes a new probabilistic model
for noun phrase parsing, and reports on the application of such a parsing
technique to enhance document indexing. The effectiveness of using syntactic
phrases provided by the parser to supplement single words for indexing is
evaluated with a 250 megabytes document collection. The experiment's results
show that supplementing single words with syntactic phrases for indexing
consistently and significantly improves retrieval performance."	ArXiv
1176	"NLP-SIR: A Natural Language Approach for Spreadsheet Information
  Retrieval"	['Derek Flood', 'Kevin Mc Daid', 'Fergal Mc Caffery']	2009-08-08 21:23:52+00:00	http://arxiv.org/abs/0908.1193v1	"Spreadsheets are a ubiquitous software tool, used for a wide variety of tasks
such as financial modelling, statistical analysis and inventory management.
Extracting meaningful information from such data can be a difficult task,
especially for novice users unfamiliar with the advanced data processing
features of many spreadsheet applications. We believe that through the use of
Natural Language Processing (NLP) techniques this task can be made considerably
easier. This paper introduces NLP-SIR, a Natural language interface for
spreadsheet information retrieval. The results of a recent evaluation which
compared NLP-SIR with existing Information retrieval tools are also outlined.
This evaluation has shown that NLP-SIR is a more effective method of
spreadsheet information retrieval."	ArXiv
1177	"Complete Complementary Results Report of the MARF's NLP Approach to the
  DEFT 2010 Competition"	['Serguei A. Mokhov']	2010-06-18 19:54:29+00:00	http://arxiv.org/abs/1006.3787v7	"This companion paper complements the main DEFT'10 article describing the MARF
approach (arXiv:0905.1235) to the DEFT'10 NLP challenge (described at
http://www.groupes.polymtl.ca/taln2010/deft.php in French). This paper is aimed
to present the complete result sets of all the conducted experiments and their
settings in the resulting tables highlighting the approach and the best
results, but also showing the worse and the worst and their subsequent
analysis. This particular work focuses on application of the MARF's classical
and NLP pipelines to identification tasks within various francophone corpora to
identify decades when certain articles were published for the first track
(Piste 1) and place of origin of a publication (Piste 2), such as the journal
and location (France vs. Quebec). This is the sixth iteration of the release of
the results."	ArXiv
1178	NILE: Fast Natural Language Processing for Electronic Health Records	['Sheng Yu', 'Tianrun Cai', 'Tianxi Cai']	2013-11-23 22:39:52+00:00	http://arxiv.org/abs/1311.6063v5	"Objective: Narrative text in Electronic health records (EHR) contain rich
information for medical and data science studies. This paper introduces the
design and performance of Narrative Information Linear Extraction (NILE), a
natural language processing (NLP) package for EHR analysis that we share with
the medical informatics community. Methods: NILE uses a modified prefix-tree
search algorithm for named entity recognition, which can detect prefix and
suffix sharing. The semantic analyses are implemented as rule-based finite
state machines. Analyses include negation, location, modification, family
history, and ignoring. Result: The processing speed of NILE is hundreds to
thousands times faster than existing NLP software for medical text. The
accuracy of presence analysis of NILE is on par with the best performing models
on the 2010 i2b2/VA NLP challenge data. Conclusion: The speed, accuracy, and
being able to operate via API make NILE a valuable addition to the NLP software
for medical informatics and data science."	ArXiv
1179	Building an Evaluation Scale using Item Response Theory	['John P. Lalor', 'Hao Wu', 'Hong Yu']	2016-05-28 13:19:15+00:00	http://arxiv.org/abs/1605.08889v2	"Evaluation of NLP methods requires testing against a previously vetted
gold-standard test set and reporting standard metrics
(accuracy/precision/recall/F1). The current assumption is that all items in a
given test set are equal with regards to difficulty and discriminating power.
We propose Item Response Theory (IRT) from psychometrics as an alternative
means for gold-standard test-set generation and NLP system evaluation. IRT is
able to describe characteristics of individual items - their difficulty and
discriminating power - and can account for these characteristics in its
estimation of human intelligence or ability for an NLP task. In this paper, we
demonstrate IRT by generating a gold-standard test set for Recognizing Textual
Entailment. By collecting a large number of human responses and fitting our IRT
model, we show that our IRT model compares NLP systems with the performance in
a human population and is able to provide more insight into system performance
than standard evaluation metrics. We show that a high accuracy score does not
always imply a high IRT score, which depends on the item characteristics and
the response pattern."	ArXiv
1180	Computing Word Classes Using Spectral Clustering	['Effi Levi', 'Saggy Herman', 'Ari Rappoport']	2018-08-16 08:11:24+00:00	http://arxiv.org/abs/1808.05374v1	"Clustering a lexicon of words is a well-studied problem in natural language
processing (NLP). Word clusters are used to deal with sparse data in
statistical language processing, as well as features for solving various NLP
tasks (text categorization, question answering, named entity recognition and
others).
  Spectral clustering is a widely used technique in the field of image
processing and speech recognition. However, it has scarcely been explored in
the context of NLP; specifically, the method used in this (Meila and Shi, 2001)
has never been used to cluster a general word lexicon.
  We apply spectral clustering to a lexicon of words, evaluating the resulting
clusters by using them as features for solving two classical NLP tasks:
semantic role labeling and dependency parsing. We compare performance with
Brown clustering, a widely-used technique for word clustering, as well as with
other clustering methods. We show that spectral clusters produce similar
results to Brown clusters, and outperform other clustering methods. In
addition, we quantify the overlap between spectral and Brown clusters, showing
that each model captures some information which is uncaptured by the other."	ArXiv
1181	"Fast UAV Trajectory Optimization using Bilevel Optimization with
  Analytical Gradients"	['Weidong Sun', 'Gao Tang', 'Kris Hauser']	2018-11-27 00:18:18+00:00	http://arxiv.org/abs/1811.10753v2	"We present an efficient optimization framework that solves trajectory
optimization problems by decoupling state variables from timing variables,
thereby decomposing a challenging nonlinear programming (NLP) problem into two
easier subproblems. With timing fixed, the state variables can be optimized
efficiently using convex optimization, and the timing variables can be
optimized in a separate NLP, which forms a bilevel optimization problem. The
challenge of obtaining the gradient of the timing variables is solved by
sensitivity analysis of parametric NLPs. The exact analytic gradient is
computed from the dual solution as a by-product, whereas existing
finite-difference techniques require additional optimization. The bilevel
optimization framework efficiently optimizes both timing and state variables
which is demonstrated on generating trajectories for an unmanned aerial
vehicle. Numerical experiments demonstrate that bilevel optimization converges
significantly more reliably than a standard NLP solver, and analytical
gradients outperform finite differences in terms of computation speed and
accuracy. Physical experiments demonstrate its real-time applicability for
reactive target tracking tasks."	ArXiv
1182	Natural Language Processing Advancements By Deep Learning: A Survey	['Amirsina Torfi', 'Rouzbeh A. Shirvani', 'Yaser Keneshloo', 'Nader Tavaf', 'Edward A. Fox']	2020-03-02 21:32:05+00:00	http://arxiv.org/abs/2003.01200v4	"Natural Language Processing (NLP) helps empower intelligent machines by
enhancing a better understanding of the human language for linguistic-based
human-computer communication. Recent developments in computational power and
the advent of large amounts of linguistic data have heightened the need and
demand for automating semantic analysis using data-driven approaches. The
utilization of data-driven strategies is pervasive now due to the significant
improvements demonstrated through the usage of deep learning methods in areas
such as Computer Vision, Automatic Speech Recognition, and in particular, NLP.
This survey categorizes and addresses the different aspects and applications of
NLP that have benefited from deep learning. It covers core NLP tasks and
applications and describes how deep learning methods and models advance these
areas. We further analyze and compare different approaches and state-of-the-art
models."	ArXiv
1183	Predicting Performance for Natural Language Processing Tasks	['Mengzhou Xia', 'Antonios Anastasopoulos', 'Ruochen Xu', 'Yiming Yang', 'Graham Neubig']	2020-05-02 16:02:18+00:00	http://arxiv.org/abs/2005.00870v1	"Given the complexity of combinations of tasks, languages, and domains in
natural language processing (NLP) research, it is computationally prohibitive
to exhaustively test newly proposed models on each possible experimental
setting. In this work, we attempt to explore the possibility of gaining
plausible judgments of how well an NLP model can perform under an experimental
setting, without actually training or testing the model. To do so, we build
regression models to predict the evaluation score of an NLP experiment given
the experimental settings as input. Experimenting on 9 different NLP tasks, we
find that our predictors can produce meaningful predictions over unseen
languages and different modeling architectures, outperforming reasonable
baselines as well as human experts. Going further, we outline how our predictor
can be used to find a small subset of representative experiments that should be
run in order to obtain plausible predictions for all other experimental
settings."	ArXiv
1184	Beyond Accuracy: Behavioral Testing of NLP models with CheckList	['Marco Tulio Ribeiro', 'Tongshuang Wu', 'Carlos Guestrin', 'Sameer Singh']	2020-05-08 15:48:31+00:00	http://arxiv.org/abs/2005.04118v1	"Although measuring held-out accuracy has been the primary approach to
evaluate generalization, it often overestimates the performance of NLP models,
while alternative approaches for evaluating models either focus on individual
tasks or on specific behaviors. Inspired by principles of behavioral testing in
software engineering, we introduce CheckList, a task-agnostic methodology for
testing NLP models. CheckList includes a matrix of general linguistic
capabilities and test types that facilitate comprehensive test ideation, as
well as a software tool to generate a large and diverse number of test cases
quickly. We illustrate the utility of CheckList with tests for three tasks,
identifying critical failures in both commercial and state-of-art models. In a
user study, a team responsible for a commercial sentiment analysis model found
new and actionable bugs in an extensively tested model. In another user study,
NLP practitioners with CheckList created twice as many tests, and found almost
three times as many bugs as users without it."	ArXiv
1185	"Replicability Analysis for Natural Language Processing: Testing
  Significance with Multiple Datasets"	['Rotem Dror', 'Gili Baumer', 'Marina Bogomolov', 'Roi Reichart']	2017-09-27 13:31:41+00:00	http://arxiv.org/abs/1709.09500v1	"With the ever-growing amounts of textual data from a large variety of
languages, domains, and genres, it has become standard to evaluate NLP
algorithms on multiple datasets in order to ensure consistent performance
across heterogeneous setups. However, such multiple comparisons pose
significant challenges to traditional statistical analysis methods in NLP and
can lead to erroneous conclusions. In this paper, we propose a Replicability
Analysis framework for a statistically sound analysis of multiple comparisons
between algorithms for NLP tasks. We discuss the theoretical advantages of this
framework over the current, statistically unjustified, practice in the NLP
literature, and demonstrate its empirical value across four applications:
multi-domain dependency parsing, multilingual POS tagging, cross-domain
sentiment classification and word similarity prediction."	ArXiv
1186	Advancing NLP with Cognitive Language Processing Signals	['Nora Hollenstein', 'Maria Barrett', 'Marius Troendle', 'Francesco Bigiolli', 'Nicolas Langer', 'Ce Zhang']	2019-04-04 17:38:16+00:00	http://arxiv.org/abs/1904.02682v1	"When we read, our brain processes language and generates cognitive processing
data such as gaze patterns and brain activity. These signals can be recorded
while reading. Cognitive language processing data such as eye-tracking features
have shown improvements on single NLP tasks. We analyze whether using such
human features can show consistent improvement across tasks and data sources.
We present an extensive investigation of the benefits and limitations of using
cognitive processing data for NLP. Specifically, we use gaze and EEG features
to augment models of named entity recognition, relation classification, and
sentiment analysis. These methods significantly outperform the baselines and
show the potential and current limitations of employing human language
processing data for NLP."	ArXiv
1187	Alternative Weighting Schemes for ELMo Embeddings	['Nils Reimers', 'Iryna Gurevych']	2019-04-05 09:24:36+00:00	http://arxiv.org/abs/1904.02954v1	"ELMo embeddings (Peters et. al, 2018) had a huge impact on the NLP community
and may recent publications use these embeddings to boost the performance for
downstream NLP tasks. However, integration of ELMo embeddings in existent NLP
architectures is not straightforward. In contrast to traditional word
embeddings, like GloVe or word2vec embeddings, the bi-directional language
model of ELMo produces three 1024 dimensional vectors per token in a sentence.
Peters et al. proposed to learn a task-specific weighting of these three
vectors for downstream tasks. However, this proposed weighting scheme is not
feasible for certain tasks, and, as we will show, it does not necessarily yield
optimal performance. We evaluate different methods that combine the three
vectors from the language model in order to achieve the best possible
performance in downstream NLP tasks. We notice that the third layer of the
published language model often decreases the performance. By learning a
weighted average of only the first two layers, we are able to improve the
performance for many datasets. Due to the reduced complexity of the language
model, we have a training speed-up of 19-44% for the downstream task."	ArXiv
1188	"Empirical Evaluation of Multi-task Learning in Deep Neural Networks for
  Natural Language Processing"	['Jianquan Li', 'Xiaokang Liu', 'Wenpeng Yin', 'Min Yang', 'Liqun Ma', 'Yaohong Jin']	2019-08-16 03:16:40+00:00	http://arxiv.org/abs/1908.07820v2	"Multi-Task Learning (MTL) aims at boosting the overall performance of each
individual task by leveraging useful information contained in multiple related
tasks. It has shown great success in natural language processing (NLP).
Currently, a number of MLT architectures and learning mechanisms have been
proposed for various NLP tasks. However, there is no systematic exploration and
comparison of different MLT architectures and learning mechanisms for their
strong performance in-depth. In this paper, we conduct a thorough examination
of typical MTL methods on a broad range of representative NLP tasks. Our
primary goal is to understand the merits and demerits of existing MTL methods
in NLP tasks, thus devising new hybrid architectures intended to combine their
strengths."	ArXiv
1189	"TX-Ray: Quantifying and Explaining Model-Knowledge Transfer in
  (Un-)Supervised NLP"	['Nils Rethmeier', 'Vageesh Kumar Saxena', 'Isabelle Augenstein']	2019-12-02 18:21:31+00:00	http://arxiv.org/abs/1912.00982v3	"While state-of-the-art NLP explainability (XAI) methods focus on explaining
per-sample decisions in supervised end or probing tasks, this is insufficient
to explain and quantify model knowledge transfer during (un-)supervised
training. Thus, for TX-Ray, we modify the established computer vision
explainability principle of 'visualizing preferred inputs of neurons' to make
it usable transfer analysis and NLP. This allows one to analyze, track and
quantify how self- or supervised NLP models first build knowledge abstractions
in pretraining (1), and then transfer these abstractions to a new domain (2),
or adapt them during supervised fine-tuning (3). TX-Ray expresses neurons as
feature preference distributions to quantify fine-grained knowledge transfer or
adaptation and guide human analysis. We find that, similar to Lottery Ticket
based pruning, TX-Ray based pruning can improve test set generalization and
that it can reveal how early stages of self-supervision automatically learn
linguistic abstractions like parts-of-speech."	ArXiv
1190	Substructure Substitution: Structured Data Augmentation for NLP	['Haoyue Shi', 'Karen Livescu', 'Kevin Gimpel']	2021-01-02 09:54:24+00:00	http://arxiv.org/abs/2101.00411v1	"We study a family of data augmentation methods, substructure substitution
(SUB2), for natural language processing (NLP) tasks. SUB2 generates new
examples by substituting substructures (e.g., subtrees or subsequences) with
ones with the same label, which can be applied to many structured NLP tasks
such as part-of-speech tagging and parsing. For more general tasks (e.g., text
classification) which do not have explicitly annotated substructures, we
present variations of SUB2 based on constituency parse trees, introducing
structure-aware data augmentation methods to general NLP tasks. For most cases,
training with the augmented dataset by SUB2 achieves better performance than
training with the original training set. Further experiments show that SUB2 has
more consistent performance than other investigated augmentation methods,
across different tasks and sizes of the seed dataset."	ArXiv
1191	Representing Numbers in NLP: a Survey and a Vision	['Avijit Thawani', 'Jay Pujara', 'Pedro A. Szekely', 'Filip Ilievski']	2021-03-24 12:28:22+00:00	http://arxiv.org/abs/2103.13136v1	"NLP systems rarely give special consideration to numbers found in text. This
starkly contrasts with the consensus in neuroscience that, in the brain,
numbers are represented differently from words. We arrange recent NLP work on
numeracy into a comprehensive taxonomy of tasks and methods. We break down the
subjective notion of numeracy into 7 subtasks, arranged along two dimensions:
granularity (exact vs approximate) and units (abstract vs grounded). We analyze
the myriad representational choices made by 18 previously published number
encoders and decoders. We synthesize best practices for representing numbers in
text and articulate a vision for holistic numeracy in NLP, comprised of design
trade-offs and a unified evaluation."	ArXiv
1192	"Small-Bench NLP: Benchmark for small single GPU trained models in
  Natural Language Processing"	['Kamal Raj Kanakarajan', 'Bhuvana Kundumani', 'Malaikannan Sankarasubbu']	2021-09-22 17:18:55+00:00	http://arxiv.org/abs/2109.10847v2	"Recent progress in the Natural Language Processing domain has given us
several State-of-the-Art (SOTA) pretrained models which can be finetuned for
specific tasks. These large models with billions of parameters trained on
numerous GPUs/TPUs over weeks are leading in the benchmark leaderboards. In
this paper, we discuss the need for a benchmark for cost and time effective
smaller models trained on a single GPU. This will enable researchers with
resource constraints experiment with novel and innovative ideas on
tokenization, pretraining tasks, architecture, fine tuning methods etc. We set
up Small-Bench NLP, a benchmark for small efficient neural language models
trained on a single GPU. Small-Bench NLP benchmark comprises of eight NLP tasks
on the publicly available GLUE datasets and a leaderboard to track the progress
of the community. Our ELECTRA-DeBERTa (15M parameters) small model architecture
achieves an average score of 81.53 which is comparable to that of BERT-Base's
82.20 (110M parameters). Our models, code and leaderboard are available at
https://github.com/smallbenchnlp"	ArXiv
1193	Dataset Geography: Mapping Language Data to Language Users	['Fahim Faisal', 'Yinkai Wang', 'Antonios Anastasopoulos']	2021-12-07 05:13:50+00:00	http://arxiv.org/abs/2112.03497v2	"As language technologies become more ubiquitous, there are increasing efforts
towards expanding the language diversity and coverage of natural language
processing (NLP) systems. Arguably, the most important factor influencing the
quality of modern NLP systems is data availability. In this work, we study the
geographical representativeness of NLP datasets, aiming to quantify if and by
how much do NLP datasets match the expected needs of the language speakers. In
doing so, we use entity recognition and linking systems, also making important
observations about their cross-lingual consistency and giving suggestions for
more robust evaluation. Last, we explore some geographical and economic factors
that may explain the observed dataset distributions. Code and data are
available here: https://github.com/ffaisal93/dataset_geography. Additional
visualizations are available here: https://nlp.cs.gmu.edu/project/datasetmaps/."	ArXiv
1194	Predicting Fine-Tuning Performance with Probing	['Zining Zhu', 'Soroosh Shahtalebi', 'Frank Rudzicz']	2022-10-13 20:58:14+00:00	http://arxiv.org/abs/2210.07352v1	"Large NLP models have recently shown impressive performance in language
understanding tasks, typically evaluated by their fine-tuned performance.
Alternatively, probing has received increasing attention as being a lightweight
method for interpreting the intrinsic mechanisms of large NLP models. In
probing, post-hoc classifiers are trained on ""out-of-domain"" datasets that
diagnose specific abilities. While probing the language models has led to
insightful findings, they appear disjointed from the development of models.
This paper explores the utility of probing deep NLP models to extract a proxy
signal widely used in model development -- the fine-tuning performance. We find
that it is possible to use the accuracies of only three probing tests to
predict the fine-tuning performance with errors $40\%$ - $80\%$ smaller than
baselines. We further discuss possible avenues where probing can empower the
development of deep NLP models."	ArXiv
1195	"Expose Backdoors on the Way: A Feature-Based Efficient Defense against
  Textual Backdoor Attacks"	['Sishuo Chen', 'Wenkai Yang', 'Zhiyuan Zhang', 'Xiaohan Bi', 'Xu Sun']	2022-10-14 15:44:28+00:00	http://arxiv.org/abs/2210.07907v1	"Natural language processing (NLP) models are known to be vulnerable to
backdoor attacks, which poses a newly arisen threat to NLP models. Prior online
backdoor defense methods for NLP models only focus on the anomalies at either
the input or output level, still suffering from fragility to adaptive attacks
and high computational cost. In this work, we take the first step to
investigate the unconcealment of textual poisoned samples at the
intermediate-feature level and propose a feature-based efficient online defense
method. Through extensive experiments on existing attacking methods, we find
that the poisoned samples are far away from clean samples in the intermediate
feature space of a poisoned NLP model. Motivated by this observation, we devise
a distance-based anomaly score (DAN) to distinguish poisoned samples from clean
samples at the feature level. Experiments on sentiment analysis and offense
detection tasks demonstrate the superiority of DAN, as it substantially
surpasses existing online defense methods in terms of defending performance and
enjoys lower inference costs. Moreover, we show that DAN is also resistant to
adaptive attacks based on feature-level regularization. Our code is available
at https://github.com/lancopku/DAN."	ArXiv
1196	"Some Languages are More Equal than Others: Probing Deeper into the
  Linguistic Disparity in the NLP World"	['Surangika Ranathunga', 'Nisansa de Silva']	2022-10-16 12:50:30+00:00	http://arxiv.org/abs/2210.08523v2	"Linguistic disparity in the NLP world is a problem that has been widely
acknowledged recently. However, different facets of this problem, or the
reasons behind this disparity are seldom discussed within the NLP community.
This paper provides a comprehensive analysis of the disparity that exists
within the languages of the world. We show that simply categorising languages
considering data availability may not be always correct. Using an existing
language categorisation based on speaker population and vitality, we analyse
the distribution of language data resources, amount of NLP/CL research,
inclusion in multilingual web-based platforms and the inclusion in pre-trained
multilingual models. We show that many languages do not get covered in these
resources or platforms, and even within the languages belonging to the same
language group, there is wide disparity. We analyse the impact of family,
geographical location, GDP and the speaker population of languages and provide
possible reasons for this disparity, along with some suggestions to overcome
the same."	ArXiv
1197	Natural Language Processing - A Survey	['Kevin Mote']	2012-09-25 21:05:08+00:00	http://arxiv.org/abs/1209.6238v1	"The utility and power of Natural Language Processing (NLP) seems destined to
change our technological society in profound and fundamental ways. However
there are, to date, few accessible descriptions of the science of NLP that have
been written for a popular audience, or even for an audience of intelligent,
but uninitiated scientists. This paper aims to provide just such an overview.
In short, the objective of this article is to describe the purpose, procedures
and practical applications of NLP in a clear, balanced, and readable way. We
will examine the most recent literature describing the methods and processes of
NLP, analyze some of the challenges that researchers are faced with, and
briefly survey some of the current and future applications of this science to
IT research in general."	ArXiv
1198	"Reverse Transfer Learning: Can Word Embeddings Trained for Different NLP
  Tasks Improve Neural Language Models?"	['Lyan Verwimp', 'Jerome R. Bellegarda']	2019-09-09 20:01:51+00:00	http://arxiv.org/abs/1909.04130v1	"Natural language processing (NLP) tasks tend to suffer from a paucity of
suitably annotated training data, hence the recent success of transfer learning
across a wide variety of them. The typical recipe involves: (i) training a
deep, possibly bidirectional, neural network with an objective related to
language modeling, for which training data is plentiful; and (ii) using the
trained network to derive contextual representations that are far richer than
standard linear word embeddings such as word2vec, and thus result in important
gains. In this work, we wonder whether the opposite perspective is also true:
can contextual representations trained for different NLP tasks improve language
modeling itself? Since language models (LMs) are predominantly locally
optimized, other NLP tasks may help them make better predictions based on the
entire semantic fabric of a document. We test the performance of several types
of pre-trained embeddings in neural LMs, and we investigate whether it is
possible to make the LM more aware of global semantic information through
embeddings pre-trained with a domain classification model. Initial experiments
suggest that as long as the proper objective criterion is used during training,
pre-trained embeddings are likely to be beneficial for neural language
modeling."	ArXiv
1199	Perturbation Sensitivity Analysis to Detect Unintended Model Biases	['Vinodkumar Prabhakaran', 'Ben Hutchinson', 'Margaret Mitchell']	2019-10-09 19:25:21+00:00	http://arxiv.org/abs/1910.04210v1	"Data-driven statistical Natural Language Processing (NLP) techniques leverage
large amounts of language data to build models that can understand language.
However, most language data reflect the public discourse at the time the data
was produced, and hence NLP models are susceptible to learning incidental
associations around named referents at a particular point in time, in addition
to general linguistic meaning. An NLP system designed to model notions such as
sentiment and toxicity should ideally produce scores that are independent of
the identity of such entities mentioned in text and their social associations.
For example, in a general purpose sentiment analysis system, a phrase such as I
hate Katy Perry should be interpreted as having the same sentiment as I hate
Taylor Swift. Based on this idea, we propose a generic evaluation framework,
Perturbation Sensitivity Analysis, which detects unintended model biases
related to named entities, and requires no new annotations or corpora. We
demonstrate the utility of this analysis by employing it on two different NLP
models --- a sentiment model and a toxicity model --- applied on online
comments in English language from four different genres."	ArXiv
1200	"Not All Claims are Created Equal: Choosing the Right Statistical
  Approach to Assess Hypotheses"	['Erfan Sadeqi Azer', 'Daniel Khashabi', 'Ashish Sabharwal', 'Dan Roth']	2019-11-10 04:41:31+00:00	http://arxiv.org/abs/1911.03850v3	"Empirical research in Natural Language Processing (NLP) has adopted a narrow
set of principles for assessing hypotheses, relying mainly on p-value
computation, which suffers from several known issues. While alternative
proposals have been well-debated and adopted in other fields, they remain
rarely discussed or used within the NLP community. We address this gap by
contrasting various hypothesis assessment techniques, especially those not
commonly used in the field (such as evaluations based on Bayesian inference).
Since these statistical techniques differ in the hypotheses they can support,
we argue that practitioners should first decide their target hypothesis before
choosing an assessment method. This is crucial because common fallacies,
misconceptions, and misinterpretation surrounding hypothesis assessment methods
often stem from a discrepancy between what one would like to claim versus what
the method used actually assesses. Our survey reveals that these issues are
omnipresent in the NLP research community. As a step forward, we provide best
practices and guidelines tailored to NLP research, as well as an easy-to-use
package called 'HyBayes' for Bayesian assessment of hypotheses, complementing
existing tools."	ArXiv
1201	"Natural language processing for achieving sustainable development: the
  case of neural labelling to enhance community profiling"	['Costanza Conforti', 'Stephanie Hirmer', 'David Morgan', 'Marco Basaldella', 'Yau Ben Or']	2020-04-27 16:51:21+00:00	http://arxiv.org/abs/2004.12935v2	"In recent years, there has been an increasing interest in the application of
Artificial Intelligence - and especially Machine Learning - to the field of
Sustainable Development (SD). However, until now, NLP has not been applied in
this context. In this research paper, we show the high potential of NLP
applications to enhance the sustainability of projects. In particular, we focus
on the case of community profiling in developing countries, where, in contrast
to the developed world, a notable data gap exists. In this context, NLP could
help to address the cost and time barrier of structuring qualitative data that
prohibits its widespread use and associated benefits. We propose the new task
of Automatic UPV classification, which is an extreme multi-class multi-label
classification problem. We release Stories2Insights, an expert-annotated
dataset, provide a detailed corpus analysis, and implement a number of strong
neural baselines to address the task. Experimental results show that the
problem is challenging, and leave plenty of room for future research at the
intersection of NLP and SD."	ArXiv
1202	Towards an evolutionary-based approach for natural language processing	['Luca Manzoni', 'Domagoj Jakobovic', 'Luca Mariot', 'Stjepan Picek', 'Mauro Castelli']	2020-04-23 18:44:12+00:00	http://arxiv.org/abs/2004.13832v1	"Tasks related to Natural Language Processing (NLP) have recently been the
focus of a large research endeavor by the machine learning community. The
increased interest in this area is mainly due to the success of deep learning
methods. Genetic Programming (GP), however, was not under the spotlight with
respect to NLP tasks. Here, we propose a first proof-of-concept that combines
GP with the well established NLP tool word2vec for the next word prediction
task. The main idea is that, once words have been moved into a vector space,
traditional GP operators can successfully work on vectors, thus producing
meaningful words as the output. To assess the suitability of this approach, we
perform an experimental evaluation on a set of existing newspaper headlines.
Individuals resulting from this (pre-)training phase can be employed as the
initial population in other NLP tasks, like sentence generation, which will be
the focus of future investigations, possibly employing adversarial
co-evolutionary approaches."	ArXiv
1203	GREEK-BERT: The Greeks visiting Sesame Street	['John Koutsikakis', 'Ilias Chalkidis', 'Prodromos Malakasiotis', 'Ion Androutsopoulos']	2020-08-27 09:36:14+00:00	http://arxiv.org/abs/2008.12014v2	"Transformer-based language models, such as BERT and its variants, have
achieved state-of-the-art performance in several downstream natural language
processing (NLP) tasks on generic benchmark datasets (e.g., GLUE, SQUAD, RACE).
However, these models have mostly been applied to the resource-rich English
language. In this paper, we present GREEK-BERT, a monolingual BERT-based
language model for modern Greek. We evaluate its performance in three NLP
tasks, i.e., part-of-speech tagging, named entity recognition, and natural
language inference, obtaining state-of-the-art performance. Interestingly, in
two of the benchmarks GREEK-BERT outperforms two multilingual Transformer-based
models (M-BERT, XLM-R), as well as shallower neural baselines operating on
pre-trained word embeddings, by a large margin (5%-10%). Most importantly, we
make both GREEK-BERT and our training code publicly available, along with code
illustrating how GREEK-BERT can be fine-tuned for downstream NLP tasks. We
expect these resources to boost NLP research and applications for modern Greek."	ArXiv
1204	Case Study: Deontological Ethics in NLP	['Shrimai Prabhumoye', 'Brendon Boldt', 'Ruslan Salakhutdinov', 'Alan W Black']	2020-10-09 16:04:51+00:00	http://arxiv.org/abs/2010.04658v2	"Recent work in natural language processing (NLP) has focused on ethical
challenges such as understanding and mitigating bias in data and algorithms;
identifying objectionable content like hate speech, stereotypes and offensive
language; and building frameworks for better system design and data handling
practices. However, there has been little discussion about the ethical
foundations that underlie these efforts. In this work, we study one ethical
theory, namely deontological ethics, from the perspective of NLP. In
particular, we focus on the generalization principle and the respect for
autonomy through informed consent. We provide four case studies to demonstrate
how these principles can be used with NLP systems. We also recommend directions
to avoid the ethical issues in these systems."	ArXiv
1205	On the diminishing return of labeling clinical reports	['Jean-Baptiste Lamare', 'Tobi Olatunji', 'Li Yao']	2020-10-27 19:51:04+00:00	http://arxiv.org/abs/2010.14587v1	"Ample evidence suggests that better machine learning models may be steadily
obtained by training on increasingly larger datasets on natural language
processing (NLP) problems from non-medical domains. Whether the same holds true
for medical NLP has by far not been thoroughly investigated. This work shows
that this is indeed not always the case. We reveal the somehow
counter-intuitive observation that performant medical NLP models may be
obtained with small amount of labeled data, quite the opposite to the common
belief, most likely due to the domain specificity of the problem. We show
quantitatively the effect of training data size on a fixed test set composed of
two of the largest public chest x-ray radiology report datasets on the task of
abnormality classification. The trained models not only make use of the
training data efficiently, but also outperform the current state-of-the-art
rule-based systems by a significant margin."	ArXiv
1206	"A Comprehensive Survey on Word Representation Models: From Classical to
  State-Of-The-Art Word Representation Language Models"	['Usman Naseem', 'Imran Razzak', 'Shah Khalid Khan', 'Mukesh Prasad']	2020-10-28 15:15:13+00:00	http://arxiv.org/abs/2010.15036v1	"Word representation has always been an important research area in the history
of natural language processing (NLP). Understanding such complex text data is
imperative, given that it is rich in information and can be used widely across
various applications. In this survey, we explore different word representation
models and its power of expression, from the classical to modern-day
state-of-the-art word representation language models (LMS). We describe a
variety of text representation methods, and model designs have blossomed in the
context of NLP, including SOTA LMs. These models can transform large volumes of
text into effective vector representations capturing the same semantic
information. Further, such representations can be utilized by various machine
learning (ML) algorithms for a variety of NLP related tasks. In the end, this
survey briefly discusses the commonly used ML and DL based classifiers,
evaluation metrics and the applications of these word embeddings in different
NLP tasks."	ArXiv
1207	"Offline Reinforcement Learning from Human Feedback in Real-World
  Sequence-to-Sequence Tasks"	['Julia Kreutzer', 'Stefan Riezler', 'Carolin Lawrence']	2020-11-04 19:30:46+00:00	http://arxiv.org/abs/2011.02511v3	"Large volumes of interaction logs can be collected from NLP systems that are
deployed in the real world. How can this wealth of information be leveraged?
Using such interaction logs in an offline reinforcement learning (RL) setting
is a promising approach. However, due to the nature of NLP tasks and the
constraints of production systems, a series of challenges arise. We present a
concise overview of these challenges and discuss possible solutions."	ArXiv
1208	"NLPGym -- A toolkit for evaluating RL agents on Natural Language
  Processing Tasks"	['Rajkumar Ramamurthy', 'Rafet Sifa', 'Christian Bauckhage']	2020-11-16 20:58:35+00:00	http://arxiv.org/abs/2011.08272v1	"Reinforcement learning (RL) has recently shown impressive performance in
complex game AI and robotics tasks. To a large extent, this is thanks to the
availability of simulated environments such as OpenAI Gym, Atari Learning
Environment, or Malmo which allow agents to learn complex tasks through
interaction with virtual environments. While RL is also increasingly applied to
natural language processing (NLP), there are no simulated textual environments
available for researchers to apply and consistently benchmark RL on NLP tasks.
With the work reported here, we therefore release NLPGym, an open-source Python
toolkit that provides interactive textual environments for standard NLP tasks
such as sequence tagging, multi-label classification, and question answering.
We also present experimental results for 6 tasks using different RL algorithms
which serve as baselines for further research. The toolkit is published at
https://github.com/rajcscw/nlp-gym"	ArXiv
1209	QUACKIE: A NLP Classification Task With Ground Truth Explanations	['Yves Rychener', 'Xavier Renard', 'Djamé Seddah', 'Pascal Frossard', 'Marcin Detyniecki']	2020-12-24 10:43:20+00:00	http://arxiv.org/abs/2012.13190v2	"NLP Interpretability aims to increase trust in model predictions. This makes
evaluating interpretability approaches a pressing issue. There are multiple
datasets for evaluating NLP Interpretability, but their dependence on human
provided ground truths raises questions about their unbiasedness. In this work,
we take a different approach and formulate a specific classification task by
diverting question-answering datasets. For this custom classification task, the
interpretability ground-truth arises directly from the definition of the
classification problem. We use this method to propose a benchmark and lay the
groundwork for future research in NLP interpretability by evaluating a wide
range of current state of the art methods."	ArXiv
1210	"TransRegex: Multi-modal Regular Expression Synthesis by
  Generate-and-Repair"	['Yeting Li', 'Shuaimin Li', 'Zhiwu Xu', 'Jialun Cao', 'Zixuan Chen', 'Yun Hu', 'Haiming Chen', 'Shing-Chi Cheung']	2020-12-31 07:36:42+00:00	http://arxiv.org/abs/2012.15489v2	"Since regular expressions (abbrev. regexes) are difficult to understand and
compose, automatically generating regexes has been an important research
problem. This paper introduces TransRegex, for automatically constructing
regexes from both natural language descriptions and examples. To the best of
our knowledge, TransRegex is the first to treat the NLP-and-example-based regex
synthesis problem as the problem of NLP-based synthesis with regex repair. For
this purpose, we present novel algorithms for both NLP-based synthesis and
regex repair. We evaluate TransRegex with ten relevant state-of-the-art tools
on three publicly available datasets. The evaluation results demonstrate that
the accuracy of our TransRegex is 17.4%, 35.8% and 38.9% higher than that of
NLP-based approaches on the three datasets, respectively. Furthermore,
TransRegex can achieve higher accuracy than the state-of-the-art multi-modal
techniques with 10% to 30% higher accuracy on all three datasets. The
evaluation results also indicate TransRegex utilizing natural language and
examples in a more effective way."	ArXiv
1211	"How to Write a Bias Statement: Recommendations for Submissions to the
  Workshop on Gender Bias in NLP"	['Christian Hardmeier', 'Marta R. Costa-jussà', 'Kellie Webster', 'Will Radford', 'Su Lin Blodgett']	2021-04-07 10:00:11+00:00	http://arxiv.org/abs/2104.03026v1	"At the Workshop on Gender Bias in NLP (GeBNLP), we'd like to encourage
authors to give explicit consideration to the wider aspects of bias and its
social implications. For the 2020 edition of the workshop, we therefore
requested that all authors include an explicit bias statement in their work to
clarify how their work relates to the social context in which NLP systems are
used.
  The programme committee of the workshops included a number of reviewers with
a background in the humanities and social sciences, in addition to NLP experts
doing the bulk of the reviewing. Each paper was assigned one of those
reviewers, and they were asked to pay specific attention to the provided bias
statements in their reviews. This initiative was well received by the authors
who submitted papers to the workshop, several of whom said they received useful
suggestions and literature hints from the bias reviewers. We are therefore
planning to keep this feature of the review process in future editions of the
workshop."	ArXiv
1212	A survey on extremism analysis using Natural Language Processing	['Javier Torregrosa', 'Gema Bello-Orgaz', 'Eugenio Martinez-Camara', 'Javier Del Ser', 'David Camacho']	2021-03-28 11:05:43+00:00	http://arxiv.org/abs/2104.04069v2	"Extremism research has grown as an open problem for several countries during
recent years, especially due to the apparition of movements such as jihadism.
This and other extremist groups have taken advantage of different approaches,
such as the use of Social Media, to spread their ideology, promote their acts
and recruit followers. Natural Language Processing (NLP) represents a way of
detecting this type of content, and several authors make use of it to describe
and discriminate the discourse held by this groups, with the final objective of
detecting and preventing its spread. This survey aims to review the
contributions of NLP to the field of extremism research, providing the reader
with a comprehensive picture of the state of the art of this research area. The
content includes a description and comparison of the frequently used NLP
techniques, how they were applied, the insights they provided, the most
frequently used NLP software tools and the availability of datasets and data
sources for research. Finally, research questions are approached and answered
with highlights from the review, while future trends, challenges and directions
derived from these highlights are suggested."	ArXiv
1213	skweak: Weak Supervision Made Easy for NLP	['Pierre Lison', 'Jeremy Barnes', 'Aliaksandr Hubin']	2021-04-19 23:26:51+00:00	http://arxiv.org/abs/2104.09683v1	"We present skweak, a versatile, Python-based software toolkit enabling NLP
developers to apply weak supervision to a wide range of NLP tasks. Weak
supervision is an emerging machine learning paradigm based on a simple idea:
instead of labelling data points by hand, we use labelling functions derived
from domain knowledge to automatically obtain annotations for a given dataset.
The resulting labels are then aggregated with a generative model that estimates
the accuracy (and possible confusions) of each labelling function. The skweak
toolkit makes it easy to implement a large spectrum of labelling functions
(such as heuristics, gazetteers, neural models or linguistic constraints) on
text data, apply them on a corpus, and aggregate their results in a fully
unsupervised fashion. skweak is especially designed to facilitate the use of
weak supervision for NLP tasks such as text classification and sequence
labelling. We illustrate the use of skweak for NER and sentiment analysis.
skweak is released under an open-source license and is available at:
https://github.com/NorskRegnesentral/skweak"	ArXiv
1214	On the Ethical Limits of Natural Language Processing on Legal Text	['Dimitrios Tsarapatsanis', 'Nikolaos Aletras']	2021-05-06 15:22:24+00:00	http://arxiv.org/abs/2105.02751v3	"Natural language processing (NLP) methods for analyzing legal text offer
legal scholars and practitioners a range of tools allowing to empirically
analyze law on a large scale. However, researchers seem to struggle when it
comes to identifying ethical limits to using NLP systems for acquiring genuine
insights both about the law and the systems' predictive capacity. In this paper
we set out a number of ways in which to think systematically about such issues.
We place emphasis on three crucial normative parameters which have, to the best
of our knowledge, been underestimated by current debates: (a) the importance of
academic freedom, (b) the existence of a wide diversity of legal and ethical
norms domestically but even more so internationally and (c) the threat of
moralism in research related to computational law. For each of these three
parameters we provide specific recommendations for the legal NLP community. Our
discussion is structured around the study of a real-life scenario that has
prompted recent debate in the legal NLP research community."	ArXiv
1215	How transfer learning impacts linguistic knowledge in deep NLP models?	['Nadir Durrani', 'Hassan Sajjad', 'Fahim Dalvi']	2021-05-31 17:43:57+00:00	http://arxiv.org/abs/2105.15179v1	"Transfer learning from pre-trained neural language models towards downstream
tasks has been a predominant theme in NLP recently. Several researchers have
shown that deep NLP models learn non-trivial amount of linguistic knowledge,
captured at different layers of the model. We investigate how fine-tuning
towards downstream NLP tasks impacts the learned linguistic knowledge. We carry
out a study across popular pre-trained models BERT, RoBERTa and XLNet using
layer and neuron-level diagnostic classifiers. We found that for some GLUE
tasks, the network relies on the core linguistic information and preserve it
deeper in the network, while for others it forgets. Linguistic information is
distributed in the pre-trained language models but becomes localized to the
lower layers post fine-tuning, reserving higher layers for the task specific
knowledge. The pattern varies across architectures, with BERT retaining
linguistic information relatively deeper in the network compared to RoBERTa and
XLNet, where it is predominantly delegated to the lower layers."	ArXiv
1216	"Use of Formal Ethical Reviews in NLP Literature: Historical Trends and
  Current Practices"	['Sebastin Santy', 'Anku Rani', 'Monojit Choudhury']	2021-06-02 12:12:59+00:00	http://arxiv.org/abs/2106.01105v1	"Ethical aspects of research in language technologies have received much
attention recently. It is a standard practice to get a study involving human
subjects reviewed and approved by a professional ethics committee/board of the
institution. How commonly do we see mention of ethical approvals in NLP
research? What types of research or aspects of studies are usually subject to
such reviews? With the rising concerns and discourse around the ethics of NLP,
do we also observe a rise in formal ethical reviews of NLP studies? And, if so,
would this imply that there is a heightened awareness of ethical issues that
was previously lacking? We aim to address these questions by conducting a
detailed quantitative and qualitative analysis of the ACL Anthology, as well as
comparing the trends in our field to those of other related disciplines, such
as cognitive science, machine learning, data mining, and systems."	ArXiv
1217	"DocNLI: A Large-scale Dataset for Document-level Natural Language
  Inference"	['Wenpeng Yin', 'Dragomir Radev', 'Caiming Xiong']	2021-06-17 13:02:26+00:00	http://arxiv.org/abs/2106.09449v1	"Natural language inference (NLI) is formulated as a unified framework for
solving various NLP problems such as relation extraction, question answering,
summarization, etc. It has been studied intensively in the past few years
thanks to the availability of large-scale labeled datasets. However, most
existing studies focus on merely sentence-level inference, which limits the
scope of NLI's application in downstream NLP problems. This work presents
DocNLI -- a newly-constructed large-scale dataset for document-level NLI.
DocNLI is transformed from a broad range of NLP problems and covers multiple
genres of text. The premises always stay in the document granularity, whereas
the hypotheses vary in length from single sentences to passages with hundreds
of words. Additionally, DocNLI has pretty limited artifacts which unfortunately
widely exist in some popular sentence-level NLI datasets. Our experiments
demonstrate that, even without fine-tuning, a model pretrained on DocNLI shows
promising performance on popular sentence-level benchmarks, and generalizes
well to out-of-domain NLP tasks that rely on inference at document granularity.
Task-specific fine-tuning can bring further improvements. Data, code, and
pretrained models can be found at https://github.com/salesforce/DocNLI."	ArXiv
1218	TweeNLP: A Twitter Exploration Portal for Natural Language Processing	['Viraj Shah', 'Shruti Singh', 'Mayank Singh']	2021-06-19 15:11:22+00:00	http://arxiv.org/abs/2106.10512v1	"We present TweeNLP, a one-stop portal that organizes Twitter's natural
language processing (NLP) data and builds a visualization and exploration
platform. It curates 19,395 tweets (as of April 2021) from various NLP
conferences and general NLP discussions. It supports multiple features such as
TweetExplorer to explore tweets by topics, visualize insights from Twitter
activity throughout the organization cycle of conferences, discover popular
research papers and researchers. It also builds a timeline of conference and
workshop submission deadlines. We envision TweeNLP to function as a collective
memory unit for the NLP community by integrating the tweets pertaining to
research papers with the NLPExplorer scientific literature search engine. The
current system is hosted at http://nlpexplorer.org/twitter/CFP ."	ArXiv
1219	Another source of mesh dependence in topology optimization	['Miguel A. Salazar de Troya', 'Geoffrey M. Oxberry', 'Cosmin G. Petra', 'Daniel A Tortorelli']	2021-06-22 23:17:28+00:00	http://arxiv.org/abs/2106.12098v2	"The topology optimization community has regularly employed nonlinear
programming (NLP) algorithms from the operations research community. However,
these algorithms are implemented in the real vector space $\mathbb{R}^n$
instead of the proper function space where the design variable resides. In this
article, we show how the volume fraction variable discretization on non-uniform
meshes affects the convergence of $\mathbb{R}^n$ based NLP algorithms. We do so
by first summarizing the functional analysis tools necessary to understand why
convergence is affected by the mesh. Namely, the distinction between derivative
definitions and the role of the mesh-dependent inner product within the NLP
algorithm. These tools are then used to make the Globally Convergent Method of
Moving Asymptotes (GCMMA), a popular NLP algorithm in the topology optimization
community, converge in a mesh independent fashion when starting from the same
initial design. We then benchmark our algorithms with three common problems in
topology optimization."	ArXiv
1220	Sexism in the Judiciary	['Noa Baker Gillis']	2021-06-29 05:38:53+00:00	http://arxiv.org/abs/2106.15103v1	"We analyze 6.7 million case law documents to determine the presence of gender
bias within our judicial system. We find that current bias detectino methods in
NLP are insufficient to determine gender bias in our case law database and
propose an alternative approach. We show that existing algorithms' inconsistent
results are consequences of prior research's definition of biases themselves.
Bias detection algorithms rely on groups of words to represent bias (e.g.,
'salary,' 'job,' and 'boss' to represent employment as a potentially biased
theme against women in text). However, the methods to build these groups of
words have several weaknesses, primarily that the word lists are based on the
researchers' own intuitions. We suggest two new methods of automating the
creation of word lists to represent biases. We find that our methods outperform
current NLP bias detection methods. Our research improves the capabilities of
NLP technology to detect bias and highlights gender biases present in
influential case law. In order test our NLP bias detection method's
performance, we regress our results of bias in case law against U.S census data
of women's participation in the workforce in the last 100 years."	ArXiv
1221	"Interviewer-Candidate Role Play: Towards Developing Real-World NLP
  Systems"	['Neeraj Varshney', 'Swaroop Mishra', 'Chitta Baral']	2021-07-01 09:08:43+00:00	http://arxiv.org/abs/2107.00315v1	"Standard NLP tasks do not incorporate several common real-world scenarios
such as seeking clarifications about the question, taking advantage of clues,
abstaining in order to avoid incorrect answers, etc. This difference in task
formulation hinders the adoption of NLP systems in real-world settings. In this
work, we take a step towards bridging this gap and present a multi-stage task
that simulates a typical human-human questioner-responder interaction such as
an interview. Specifically, the system is provided with question
simplifications, knowledge statements, examples, etc. at various stages to
improve its prediction when it is not sufficiently confident. We instantiate
the proposed task in Natural Language Inference setting where a system is
evaluated on both in-domain and out-of-domain (OOD) inputs. We conduct
comprehensive experiments and find that the multi-stage formulation of our task
leads to OOD generalization performance improvement up to 2.29% in Stage 1,
1.91% in Stage 2, 54.88% in Stage 3, and 72.02% in Stage 4 over the standard
unguided prediction. However, our task leaves a significant challenge for NLP
researchers to further improve OOD performance at each stage."	ArXiv
1222	DaCy: A Unified Framework for Danish NLP	['Kenneth Enevoldsen', 'Lasse Hansen', 'Kristoffer Nielbo']	2021-07-12 10:14:31+00:00	http://arxiv.org/abs/2107.05295v1	"Danish natural language processing (NLP) has in recent years obtained
considerable improvements with the addition of multiple new datasets and
models. However, at present, there is no coherent framework for applying
state-of-the-art models for Danish. We present DaCy: a unified framework for
Danish NLP built on SpaCy. DaCy uses efficient multitask models which obtain
state-of-the-art performance on named entity recognition, part-of-speech
tagging, and dependency parsing. DaCy contains tools for easy integration of
existing models such as for polarity, emotion, or subjectivity detection. In
addition, we conduct a series of tests for biases and robustness of Danish NLP
pipelines through augmentation of the test set of DaNE. DaCy large compares
favorably and is especially robust to long input lengths and spelling
variations and errors. All models except DaCy large display significant biases
related to ethnicity while only Polyglot shows a significant gender bias. We
argue that for languages with limited benchmark sets, data augmentation can be
particularly useful for obtaining more realistic and fine-grained performance
estimates. We provide a series of augmenters as a first step towards a more
thorough evaluation of language models for low and medium resource languages
and encourage further development."	ArXiv
1223	Generating Gender Augmented Data for NLP	['Nishtha Jain', 'Maja Popovic', 'Declan Groves', 'Eva Vanmassenhove']	2021-07-13 11:13:21+00:00	http://arxiv.org/abs/2107.05987v1	"Gender bias is a frequent occurrence in NLP-based applications, especially
pronounced in gender-inflected languages. Bias can appear through associations
of certain adjectives and animate nouns with the natural gender of referents,
but also due to unbalanced grammatical gender frequencies of inflected words.
This type of bias becomes more evident in generating conversational utterances
where gender is not specified within the sentence, because most current NLP
applications still work on a sentence-level context. As a step towards more
inclusive NLP, this paper proposes an automatic and generalisable rewriting
approach for short conversational sentences. The rewriting method can be
applied to sentences that, without extra-sentential context, have multiple
equivalent alternatives in terms of gender. The method can be applied both for
creating gender balanced outputs as well as for creating gender balanced
training data. The proposed approach is based on a neural machine translation
(NMT) system trained to 'translate' from one gender alternative to another.
Both the automatic and manual analysis of the approach show promising results
for automatic generation of gender alternatives for conversational sentences in
Spanish."	ArXiv
1224	FLEX: Unifying Evaluation for Few-Shot NLP	['Jonathan Bragg', 'Arman Cohan', 'Kyle Lo', 'Iz Beltagy']	2021-07-15 07:37:06+00:00	http://arxiv.org/abs/2107.07170v2	"Few-shot NLP research is highly active, yet conducted in disjoint research
threads with evaluation suites that lack challenging-yet-realistic testing
setups and fail to employ careful experimental design. Consequently, the
community does not know which techniques perform best or even if they
outperform simple baselines. In response, we formulate the FLEX Principles, a
set of requirements and best practices for unified, rigorous, valid, and
cost-sensitive few-shot NLP evaluation. These principles include Sample Size
Design, a novel approach to benchmark design that optimizes statistical
accuracy and precision while keeping evaluation costs manageable. Following the
principles, we release the FLEX benchmark, which includes four few-shot
transfer settings, zero-shot evaluation, and a public leaderboard that covers
diverse NLP tasks. In addition, we present UniFew, a prompt-based model for
few-shot learning that unifies pretraining and finetuning prompt formats,
eschewing complex machinery of recent prompt-based approaches in adapting
downstream task formats to language model pretraining objectives. We
demonstrate that despite simplicity, UniFew achieves results competitive with
both popular meta-learning and prompt-based approaches."	ArXiv
1225	"Dispatch of Virtual Inertia and Damping: Numerical Method with SDP and
  ADMM"	['Tong Han', 'David J. Hill']	2021-07-25 09:25:45+00:00	http://arxiv.org/abs/2107.11764v1	"Power grids are evolving toward 100% renewable energy interfaced by
inverters. Virtual inertia and damping provided by inverters are essential to
synchronism and frequency stability of future power grids. This paper
numerically addresses the problem of dispatch of virtual inertia and damping
(DID) among inverters in the transmission network. The DID problem is first
formulated as a nonlinear program (NLP) by the Radua collocation method which
is flexible to handle various types of disturbances and bounds constraints.
Since the NLP of DID is highly non-convex, semi-definite programming (SDP)
relaxation for the NLP is further derived to tackle the non-convexity, followed
by its sparsity being exploited hierarchically based on chordality of graphs to
seek enhancement of computational efficiency. Considering high dimension and
inexactness of the SDP relaxation, a feasibility-embedded distributed approach
is finally proposed under the framework of alternating direction method of
multipliers (ADMM), which achieves parallel computing and solution feasibility
regarding the original NLP. Numerical simulations carried out for five test
power systems demonstrate the proposed method and necessity of DID."	ArXiv
1226	"Evaluating the Robustness of Neural Language Models to Input
  Perturbations"	['Milad Moradi', 'Matthias Samwald']	2021-08-27 12:31:17+00:00	http://arxiv.org/abs/2108.12237v1	"High-performance neural language models have obtained state-of-the-art
results on a wide range of Natural Language Processing (NLP) tasks. However,
results for common benchmark datasets often do not reflect model reliability
and robustness when applied to noisy, real-world data. In this study, we design
and implement various types of character-level and word-level perturbation
methods to simulate realistic scenarios in which input texts may be slightly
noisy or different from the data distribution on which NLP systems were
trained. Conducting comprehensive experiments on different NLP tasks, we
investigate the ability of high-performance language models such as BERT,
XLNet, RoBERTa, and ELMo in handling different types of input perturbations.
The results suggest that language models are sensitive to input perturbations
and their performance can decrease even when small changes are introduced. We
highlight that models need to be further improved and that current benchmarks
are not reflecting model robustness well. We argue that evaluations on
perturbed inputs should routinely complement widely-used benchmarks in order to
yield a more realistic understanding of NLP systems robustness."	ArXiv
1227	LaoPLM: Pre-trained Language Models for Lao	['Nankai Lin', 'Yingwen Fu', 'Chuwei Chen', 'Ziyu Yang', 'Shengyi Jiang']	2021-10-12 11:13:07+00:00	http://arxiv.org/abs/2110.05896v3	"Trained on the large corpus, pre-trained language models (PLMs) can capture
different levels of concepts in context and hence generate universal language
representations. They can benefit multiple downstream natural language
processing (NLP) tasks. Although PTMs have been widely used in most NLP
applications, especially for high-resource languages such as English, it is
under-represented in Lao NLP research. Previous work on Lao has been hampered
by the lack of annotated datasets and the sparsity of language resources. In
this work, we construct a text classification dataset to alleviate the
resource-scare situation of the Lao language. We additionally present the first
transformer-based PTMs for Lao with four versions: BERT-small, BERT-base,
ELECTRA-small and ELECTRA-base, and evaluate it over two downstream tasks:
part-of-speech tagging and text classification. Experiments demonstrate the
effectiveness of our Lao models. We will release our models and datasets to the
community, hoping to facilitate the future development of Lao NLP applications."	ArXiv
1228	Natural Language Processing in-and-for Design Research	['L Siddharth', 'Lucienne T. M. Blessing', 'Jianxi Luo']	2021-11-27 06:32:54+00:00	http://arxiv.org/abs/2111.13827v3	"We review the scholarly contributions that utilise Natural Language
Processing (NLP) techniques to support the design process. Using a heuristic
approach, we gathered 223 articles that are published in 32 journals within the
period 1991-present. We present state-of-the-art NLP in-and-for design research
by reviewing these articles according to the type of natural language text
sources: internal reports, design concepts, discourse transcripts, technical
publications, consumer opinions, and others. Upon summarizing and identifying
the gaps in these contributions, we utilise an existing design innovation
framework to identify the applications that are currently being supported by
NLP. We then propose a few methodological and theoretical directions for future
NLP in-and-for design research."	ArXiv
1229	Mukayese: Turkish NLP Strikes Back	['Ali Safaya', 'Emirhan Kurtuluş', 'Arda Göktoğan', 'Deniz Yuret']	2022-03-02 16:18:44+00:00	http://arxiv.org/abs/2203.01215v2	"Having sufficient resources for language X lifts it from the under-resourced
languages class, but not necessarily from the under-researched class. In this
paper, we address the problem of the absence of organized benchmarks in the
Turkish language. We demonstrate that languages such as Turkish are left behind
the state-of-the-art in NLP applications. As a solution, we present Mukayese, a
set of NLP benchmarks for the Turkish language that contains several NLP tasks.
We work on one or more datasets for each benchmark and present two or more
baselines. Moreover, we present four new benchmarking datasets in Turkish for
language modeling, sentence segmentation, and spell checking. All datasets and
baselines are available under: https://github.com/alisafaya/mukayese"	ArXiv
1230	On the Evaluation of NLP-based Models for Software Engineering	['Maliheh Izadi', 'Matin Nili Ahmadabadi']	2022-03-31 16:42:19+00:00	http://arxiv.org/abs/2203.17166v1	"NLP-based models have been increasingly incorporated to address SE problems.
These models are either employed in the SE domain with little to no change, or
they are greatly tailored to source code and its unique characteristics. Many
of these approaches are considered to be outperforming or complementing
existing solutions. However, an important question arises here: ""Are these
models evaluated fairly and consistently in the SE community?"". To answer this
question, we reviewed how NLP-based models for SE problems are being evaluated
by researchers. The findings indicate that currently there is no consistent and
widely-accepted protocol for the evaluation of these models. While different
aspects of the same task are being assessed in different studies, metrics are
defined based on custom choices, rather than a system, and finally, answers are
collected and interpreted case by case. Consequently, there is a dire need to
provide a methodological way of evaluating NLP-based models to have a
consistent assessment and preserve the possibility of fair and efficient
comparison."	ArXiv
1231	"Forecasting Cryptocurrency Returns from Sentiment Signals: An Analysis
  of BERT Classifiers and Weak Supervision"	['Duygu Ider', 'Stefan Lessmann']	2022-04-06 07:45:05+00:00	http://arxiv.org/abs/2204.05781v3	"Anticipating price developments in financial markets is a topic of continued
interest in forecasting. Funneled by advancements in deep learning and natural
language processing (NLP) together with the availability of vast amounts of
textual data in form of news articles, social media postings, etc., an
increasing number of studies incorporate text-based predictors in forecasting
models. We contribute to this literature by introducing weak learning, a
recently proposed NLP approach to address the problem that text data is
unlabeled. Without a dependent variable, it is not possible to finetune
pretrained NLP models on a custom corpus. We confirm that finetuning using weak
labels enhances the predictive value of text-based features and raises forecast
accuracy in the context of predicting cryptocurrency returns. More
fundamentally, the modeling paradigm we present, weak labeling domain-specific
text and finetuning pretrained NLP models, is universally applicable in
(financial) forecasting and unlocks new ways to leverage text data."	ArXiv
1232	"Towards Process-Oriented, Modular, and Versatile Question Generation
  that Meets Educational Needs"	['Xu Wang', 'Simin Fan', 'Jessica Houghton', 'Lu Wang']	2022-04-30 22:24:39+00:00	http://arxiv.org/abs/2205.00355v1	"NLP-powered automatic question generation (QG) techniques carry great
pedagogical potential of saving educators' time and benefiting student
learning. Yet, QG systems have not been widely adopted in classrooms to date.
In this work, we aim to pinpoint key impediments and investigate how to improve
the usability of automatic QG techniques for educational purposes by
understanding how instructors construct questions and identifying touch points
to enhance the underlying NLP models. We perform an in-depth need finding study
with 11 instructors across 7 different universities, and summarize their
thought processes and needs when creating questions. While instructors show
great interests in using NLP systems to support question design, none of them
has used such tools in practice. They resort to multiple sources of
information, ranging from domain knowledge to students' misconceptions, all of
which missing from today's QG systems. We argue that building effective
human-NLP collaborative QG systems that emphasize instructor control and
explainability is imperative for real-world adoption. We call for QG systems to
provide process-oriented support, use modular design, and handle diverse
sources of input."	ArXiv
1233	"Beyond Static Models and Test Sets: Benchmarking the Potential of
  Pre-trained Models Across Tasks and Languages"	['Kabir Ahuja', 'Sandipan Dandapat', 'Sunayana Sitaram', 'Monojit Choudhury']	2022-05-12 20:42:48+00:00	http://arxiv.org/abs/2205.06356v2	"Although recent Massively Multilingual Language Models (MMLMs) like mBERT and
XLMR support around 100 languages, most existing multilingual NLP benchmarks
provide evaluation data in only a handful of these languages with little
linguistic diversity. We argue that this makes the existing practices in
multilingual evaluation unreliable and does not provide a full picture of the
performance of MMLMs across the linguistic landscape. We propose that the
recent work done in Performance Prediction for NLP tasks can serve as a
potential solution in fixing benchmarking in Multilingual NLP by utilizing
features related to data and language typology to estimate the performance of
an MMLM on different languages. We compare performance prediction with
translating test data with a case study on four different multilingual
datasets, and observe that these methods can provide reliable estimates of the
performance that are often on-par with the translation based approaches,
without the need for any additional translation as well as evaluation costs."	ArXiv
1234	"Order-sensitive Shapley Values for Evaluating Conceptual Soundness of
  NLP Models"	['Kaiji Lu', 'Anupam Datta']	2022-06-01 02:30:12+00:00	http://arxiv.org/abs/2206.00192v1	"Previous works show that deep NLP models are not always conceptually sound:
they do not always learn the correct linguistic concepts. Specifically, they
can be insensitive to word order. In order to systematically evaluate models
for their conceptual soundness with respect to word order, we introduce a new
explanation method for sequential data: Order-sensitive Shapley Values (OSV).
We conduct an extensive empirical evaluation to validate the method and surface
how well various deep NLP models learn word order. Using synthetic data, we
first show that OSV is more faithful in explaining model behavior than
gradient-based methods. Second, applying to the HANS dataset, we discover that
the BERT-based NLI model uses only the word occurrences without word orders.
Although simple data augmentation improves accuracy on HANS, OSV shows that the
augmented model does not fundamentally improve the model's learning of order.
Third, we discover that not all sentiment analysis models learn negation
properly: some fail to capture the correct syntax of the negation construct.
Finally, we show that pretrained language models such as BERT may rely on the
absolute positions of subject words to learn long-range Subject-Verb Agreement.
With each NLP task, we also demonstrate how OSV can be leveraged to generate
adversarial examples."	ArXiv
1235	"PerD: Perturbation Sensitivity-based Neural Trojan Detection Framework
  on NLP Applications"	['Diego Garcia-soto', 'Huili Chen', 'Farinaz Koushanfar']	2022-08-08 22:50:03+00:00	http://arxiv.org/abs/2208.04943v1	"Deep Neural Networks (DNNs) have been shown to be susceptible to Trojan
attacks. Neural Trojan is a type of targeted poisoning attack that embeds the
backdoor into the victim and is activated by the trigger in the input space.
The increasing deployment of DNNs in critical systems and the surge of
outsourcing DNN training (which makes Trojan attack easier) makes the detection
of Trojan attacks necessary. While Neural Trojan detection has been studied in
the image domain, there is a lack of solutions in the NLP domain. In this
paper, we propose a model-level Trojan detection framework by analyzing the
deviation of the model output when we introduce a specially crafted
perturbation to the input. Particularly, we extract the model's responses to
perturbed inputs as the `signature' of the model and train a meta-classifier to
determine if a model is Trojaned based on its signature. We demonstrate the
effectiveness of our proposed method on both a dataset of NLP models we create
and a public dataset of Trojaned NLP models from TrojAI. Furthermore, we
propose a lightweight variant of our detection method that reduces the
detection time while preserving the detection rates."	ArXiv
1236	Multi-task Active Learning for Pre-trained Transformer-based Models	['Guy Rotman', 'Roi Reichart']	2022-08-10 14:54:13+00:00	http://arxiv.org/abs/2208.05379v2	"Multi-task learning, in which several tasks are jointly learned by a single
model, allows NLP models to share information from multiple annotations and may
facilitate better predictions when the tasks are inter-related. This technique,
however, requires annotating the same text with multiple annotation schemes
which may be costly and laborious. Active learning (AL) has been demonstrated
to optimize annotation processes by iteratively selecting unlabeled examples
whose annotation is most valuable for the NLP model. Yet, multi-task active
learning (MT-AL) has not been applied to state-of-the-art pre-trained
Transformer-based NLP models. This paper aims to close this gap. We explore
various multi-task selection criteria in three realistic multi-task scenarios,
reflecting different relations between the participating tasks, and demonstrate
the effectiveness of multi-task compared to single-task selection. Our results
suggest that MT-AL can be effectively used in order to minimize annotation
efforts for multi-task NLP models."	ArXiv
1237	"Automated Utterance Labeling of Conversations Using Natural Language
  Processing"	['Maria Laricheva', 'Chiyu Zhang', 'Yan Liu', 'Guanyu Chen', 'Terence Tracey', 'Richard Young', 'Giuseppe Carenini']	2022-08-12 23:03:45+00:00	http://arxiv.org/abs/2208.06525v1	"Conversational data is essential in psychology because it can help
researchers understand individuals cognitive processes, emotions, and
behaviors. Utterance labelling is a common strategy for analyzing this type of
data. The development of NLP algorithms allows researchers to automate this
task. However, psychological conversational data present some challenges to NLP
researchers, including multilabel classification, a large number of classes,
and limited available data. This study explored how automated labels generated
by NLP methods are comparable to human labels in the context of conversations
on adulthood transition. We proposed strategies to handle three common
challenges raised in psychological studies. Our findings showed that the deep
learning method with domain adaptation (RoBERTa-CON) outperformed all other
machine learning methods; and the hierarchical labelling system that we
proposed was shown to help researchers strategically analyze conversational
data. Our Python code and NLP model are available at
https://github.com/mlaricheva/automated_labeling."	ArXiv
1238	MockingBERT: A Method for Retroactively Adding Resilience to NLP Models	['Jan Jezabek', 'Akash Singh']	2022-08-21 16:02:01+00:00	http://arxiv.org/abs/2208.09915v1	"Protecting NLP models against misspellings whether accidental or adversarial
has been the object of research interest for the past few years. Existing
remediations have typically either compromised accuracy or required full model
re-training with each new class of attacks. We propose a novel method of
retroactively adding resilience to misspellings to transformer-based NLP
models. This robustness can be achieved without the need for re-training of the
original NLP model and with only a minimal loss of language understanding
performance on inputs without misspellings. Additionally we propose a new
efficient approximate method of generating adversarial misspellings, which
significantly reduces the cost needed to evaluate a model's resilience to
adversarial attacks."	ArXiv
1239	"Adverse Childhood Experiences Identification from Clinical Notes with
  Ontologies and NLP"	['Jinge Wu', 'Rowena Smith', 'Honghan Wu']	2022-08-24 12:17:32+00:00	http://arxiv.org/abs/2208.11466v1	"Adverse Childhood Experiences (ACEs) are defined as a collection of highly
stressful, and potentially traumatic, events or circumstances that occur
throughout childhood and/or adolescence. They have been shown to be associated
with increased risks of mental health diseases or other abnormal behaviours in
later lives. However, the identification of ACEs from free-text Electronic
Health Records (EHRs) with Natural Language Processing (NLP) is challenging
because (a) there is no NLP ready ACE ontologies; (b) there are limited cases
available for machine learning, necessitating the data annotation from clinical
experts. We are currently developing a tool that would use NLP techniques to
assist us in surfacing ACEs from clinical notes. This will enable us further
research in identifying evidence of the relationship between ACEs and the
subsequent developments of mental illness (e.g., addictions) in large-scale and
longitudinal free-text EHRs, which has previously not been possible."	ArXiv
1240	"Annotated Dataset Creation through General Purpose Language Models for
  non-English Medical NLP"	['Johann Frei', 'Frank Kramer']	2022-08-30 18:42:55+00:00	http://arxiv.org/abs/2208.14493v1	"Obtaining text datasets with semantic annotations is an effortful process,
yet crucial for supervised training in natural language processsing (NLP). In
general, developing and applying new NLP pipelines in domain-specific contexts
for tasks often requires custom designed datasets to address NLP tasks in
supervised machine learning fashion. When operating in non-English languages
for medical data processing, this exposes several minor and major,
interconnected problems such as lack of task-matching datasets as well as
task-specific pre-trained models. In our work we suggest to leverage pretrained
language models for training data acquisition in order to retrieve sufficiently
large datasets for training smaller and more efficient models for use-case
specific tasks. To demonstrate the effectiveness of your approach, we create a
custom dataset which we use to train a medical NER model for German texts,
GPTNERMED, yet our method remains language-independent in principle. Our
obtained dataset as well as our pre-trained models are publicly available at:
https://github.com/frankkramer-lab/GPTNERMED"	ArXiv
1241	CSL: A Large-scale Chinese Scientific Literature Dataset	['Yudong Li', 'Yuqing Zhang', 'Zhe Zhao', 'Linlin Shen', 'Weijie Liu', 'Weiquan Mao', 'Hui Zhang']	2022-09-12 06:10:47+00:00	http://arxiv.org/abs/2209.05034v1	"Scientific literature serves as a high-quality corpus, supporting a lot of
Natural Language Processing (NLP) research. However, existing datasets are
centered around the English language, which restricts the development of
Chinese scientific NLP. In this work, we present CSL, a large-scale Chinese
Scientific Literature dataset, which contains the titles, abstracts, keywords
and academic fields of 396k papers. To our knowledge, CSL is the first
scientific document dataset in Chinese. The CSL can serve as a Chinese corpus.
Also, this semi-structured data is a natural annotation that can constitute
many supervised NLP tasks. Based on CSL, we present a benchmark to evaluate the
performance of models across scientific domain tasks, i.e., summarization,
keyword generation and text classification. We analyze the behavior of existing
text-to-text models on the evaluation tasks and reveal the challenges for
Chinese scientific NLP tasks, which provides a valuable reference for future
research. Data and code are available at https://github.com/ydli-ai/CSL"	ArXiv
1242	Towards Faithful Model Explanation in NLP: A Survey	['Qing Lyu', 'Marianna Apidianaki', 'Chris Callison-Burch']	2022-09-22 21:40:51+00:00	http://arxiv.org/abs/2209.11326v4	"End-to-end neural Natural Language Processing (NLP) models are notoriously
difficult to understand. This has given rise to numerous efforts towards model
explainability in recent years. One desideratum of model explanation is
faithfulness, i.e. an explanation should accurately represent the reasoning
process behind the model's prediction. In this survey, we review over 110 model
explanation methods in NLP through the lens of faithfulness. We first discuss
the definition and evaluation of faithfulness, as well as its significance for
explainability. We then introduce recent advances in faithful explanation,
grouping existing approaches into five categories: similarity-based methods,
analysis of model-internal structures, backpropagation-based methods,
counterfactual intervention, and self-explanatory models. For each category, we
synthesize its representative studies, strengths, and weaknesses. Finally, we
summarize their common virtues and remaining challenges, and reflect on future
work directions towards faithful explainability in NLP."	ArXiv
1243	"User or Labor: An Interaction Framework for Human-Machine Relationships
  in NLP"	['Ruyuan Wan', 'Naome Etori', 'Karla Badillo-Urquiola', 'Dongyeop Kang']	2022-11-03 01:57:57+00:00	http://arxiv.org/abs/2211.01553v1	"The bridging research between Human-Computer Interaction and Natural Language
Processing is developing quickly these years. However, there is still a lack of
formative guidelines to understand the human-machine interaction in the NLP
loop. When researchers crossing the two fields talk about humans, they may
imply a user or labor. Regarding a human as a user, the human is in control,
and the machine is used as a tool to achieve the human's goals. Considering a
human as a laborer, the machine is in control, and the human is used as a
resource to achieve the machine's goals. Through a systematic literature review
and thematic analysis, we present an interaction framework for understanding
human-machine relationships in NLP. In the framework, we propose four types of
human-machine interactions: Human-Teacher and Machine-Learner, Machine-Leading,
Human-Leading, and Human-Machine Collaborators. Our analysis shows that the
type of interaction is not fixed but can change across tasks as the
relationship between the human and the machine develops. We also discuss the
implications of this framework for the future of NLP and human-machine
relationships."	ArXiv
1244	An Inclusive Notion of Text	['Ilia Kuznetsov', 'Iryna Gurevych']	2022-11-10 14:26:43+00:00	http://arxiv.org/abs/2211.05604v2	"Natural language processing (NLP) researchers develop models of grammar,
meaning and communication based on written text. Due to task and data
differences, what is considered text can vary substantially across studies. A
conceptual framework for systematically capturing these differences is lacking.
We argue that clarity on the notion of text is crucial for reproducible and
generalizable NLP. Towards that goal, we propose common terminology to discuss
the production and transformation of textual data, and introduce a two-tier
taxonomy of linguistic and non-linguistic elements that are available in
textual sources and can be used in NLP modeling. We apply this taxonomy to
survey existing work that extends the notion of text beyond the conservative
language-centered view. We outline key desiderata and challenges of the
emerging inclusive approach to text in NLP, and suggest community-level
reporting as a crucial next step to consolidate the discussion."	ArXiv
1245	NLPeer: A Unified Resource for the Computational Study of Peer Review	['Nils Dycke', 'Ilia Kuznetsov', 'Iryna Gurevych']	2022-11-12 12:29:38+00:00	http://arxiv.org/abs/2211.06651v2	"Peer review constitutes a core component of scholarly publishing; yet it
demands substantial expertise and training, and is susceptible to errors and
biases. Various applications of NLP for peer reviewing assistance aim to
support reviewers in this complex process, but the lack of clearly licensed
datasets and multi-domain corpora prevent the systematic study of NLP for peer
review. To remedy this, we introduce NLPeer -- the first ethically sourced
multidomain corpus of more than 5k papers and 11k review reports from five
different venues. In addition to the new datasets of paper drafts, camera-ready
versions and peer reviews from the NLP community, we establish a unified data
representation and augment previous peer review datasets to include parsed and
structured paper representations, rich metadata and versioning information. We
complement our resource with implementations and analysis of three reviewing
assistance tasks, including a novel guided skimming task. Our work paves the
path towards systematic, multi-faceted, evidence-based study of peer review in
NLP and beyond. The data and code are publicly available."	ArXiv
1246	"GLUE-X: Evaluating Natural Language Understanding Models from an
  Out-of-distribution Generalization Perspective"	['Linyi Yang', 'Shuibai Zhang', 'Libo Qin', 'Yafu Li', 'Yidong Wang', 'Hanmeng Liu', 'Jindong Wang', 'Xing Xie', 'Yue Zhang']	2022-11-15 11:53:55+00:00	http://arxiv.org/abs/2211.08073v4	"Pre-trained language models (PLMs) are known to improve the generalization
performance of natural language understanding models by leveraging large
amounts of data during the pre-training phase. However, the out-of-distribution
(OOD) generalization problem remains a challenge in many NLP tasks, limiting
the real-world deployment of these methods. This paper presents the first
attempt at creating a unified benchmark named GLUE-X for evaluating OOD
robustness in NLP models, highlighting the importance of OOD robustness and
providing insights on how to measure the robustness of a model and how to
improve it. The benchmark includes 13 publicly available datasets for OOD
testing, and evaluations are conducted on 8 classic NLP tasks over 21 popularly
used PLMs, including GPT-3 and GPT-3.5. Our findings confirm the need for
improved OOD accuracy in NLP tasks, as significant performance degradation was
observed in all settings compared to in-distribution (ID) accuracy."	ArXiv
1247	"Testing the effectiveness of saliency-based explainability in NLP using
  randomized survey-based experiments"	['Adel Rahimi', 'Shaurya Jain']	2022-11-25 08:49:01+00:00	http://arxiv.org/abs/2211.15351v1	"As the applications of Natural Language Processing (NLP) in sensitive areas
like Political Profiling, Review of Essays in Education, etc. proliferate,
there is a great need for increasing transparency in NLP models to build trust
with stakeholders and identify biases. A lot of work in Explainable AI has
aimed to devise explanation methods that give humans insights into the workings
and predictions of NLP models. While these methods distill predictions from
complex models like Neural Networks into consumable explanations, how humans
understand these explanations is still widely unexplored. Innate human
tendencies and biases can handicap the understanding of these explanations in
humans, and can also lead to them misjudging models and predictions as a
result. We designed a randomized survey-based experiment to understand the
effectiveness of saliency-based Post-hoc explainability methods in Natural
Language Processing. The result of the experiment showed that humans have a
tendency to accept explanations with a less critical view."	ArXiv
1248	A Major Obstacle for NLP Research: Let's Talk about Time Allocation!	['Katharina Kann', 'Shiran Dudy', 'Arya D. McCarthy']	2022-11-30 10:00:12+00:00	http://arxiv.org/abs/2211.16858v1	"The field of natural language processing (NLP) has grown over the last few
years: conferences have become larger, we have published an incredible amount
of papers, and state-of-the-art research has been implemented in a large
variety of customer-facing products. However, this paper argues that we have
been less successful than we should have been and reflects on where and how the
field fails to tap its full potential. Specifically, we demonstrate that, in
recent years, subpar time allocation has been a major obstacle for NLP
research. We outline multiple concrete problems together with their negative
consequences and, importantly, suggest remedies to improve the status quo. We
hope that this paper will be a starting point for discussions around which
common practices are -- or are not -- beneficial for NLP research."	ArXiv
1249	"Collaborating Heterogeneous Natural Language Processing Tasks via
  Federated Learning"	['Chenhe Dong', 'Yuexiang Xie', 'Bolin Ding', 'Ying Shen', 'Yaliang Li']	2022-12-12 09:27:50+00:00	http://arxiv.org/abs/2212.05789v1	"The increasing privacy concerns on personal private text data promote the
development of federated learning (FL) in recent years. However, the existing
studies on applying FL in NLP are not suitable to coordinate participants with
heterogeneous or private learning objectives. In this study, we further broaden
the application scope of FL in NLP by proposing an Assign-Then-Contrast
(denoted as ATC) framework, which enables clients with heterogeneous NLP tasks
to construct an FL course and learn useful knowledge from each other.
Specifically, the clients are suggested to first perform local training with
the unified tasks assigned by the server rather than using their own learning
objectives, which is called the Assign training stage. After that, in the
Contrast training stage, clients train with different local learning objectives
and exchange knowledge with other clients who contribute consistent and useful
model updates. We conduct extensive experiments on six widely-used datasets
covering both Natural Language Understanding (NLU) and Natural Language
Generation (NLG) tasks, and the proposed ATC framework achieves significant
improvements compared with various baseline methods. The source code is
available at
\url{https://github.com/alibaba/FederatedScope/tree/master/federatedscope/nlp/hetero_tasks}."	ArXiv
1250	Is ChatGPT a General-Purpose Natural Language Processing Task Solver?	['Chengwei Qin', 'Aston Zhang', 'Zhuosheng Zhang', 'Jiaao Chen', 'Michihiro Yasunaga', 'Diyi Yang']	2023-02-08 09:44:51+00:00	http://arxiv.org/abs/2302.06476v3	"Spurred by advancements in scale, large language models (LLMs) have
demonstrated the ability to perform a variety of natural language processing
(NLP) tasks zero-shot -- i.e., without adaptation on downstream data. Recently,
the debut of ChatGPT has drawn a great deal of attention from the natural
language processing (NLP) community due to the fact that it can generate
high-quality responses to human input and self-correct previous mistakes based
on subsequent conversations. However, it is not yet known whether ChatGPT can
serve as a generalist model that can perform many NLP tasks zero-shot. In this
work, we empirically analyze the zero-shot learning ability of ChatGPT by
evaluating it on 20 popular NLP datasets covering 7 representative task
categories. With extensive empirical studies, we demonstrate both the
effectiveness and limitations of the current version of ChatGPT. We find that
ChatGPT performs well on many tasks favoring reasoning capabilities (e.g.,
arithmetic reasoning) while it still faces challenges when solving specific
tasks such as sequence tagging. We additionally provide in-depth analysis
through qualitative case studies."	ArXiv
1251	A Two-Sided Discussion of Preregistration of NLP Research	['Anders Søgaard', 'Daniel Hershcovich', 'Miryam de Lhoneux']	2023-02-20 16:48:34+00:00	http://arxiv.org/abs/2302.10086v1	"Van Miltenburg et al. (2021) suggest NLP research should adopt
preregistration to prevent fishing expeditions and to promote publication of
negative results. At face value, this is a very reasonable suggestion,
seemingly solving many methodological problems with NLP research. We discuss
pros and cons -- some old, some new: a) Preregistration is challenged by the
practice of retrieving hypotheses after the results are known; b)
preregistration may bias NLP toward confirmatory research; c) preregistration
must allow for reclassification of research as exploratory; d) preregistration
may increase publication bias; e) preregistration may increase flag-planting;
f) preregistration may increase p-hacking; and finally, g) preregistration may
make us less risk tolerant. We cast our discussion as a dialogue, presenting
both sides of the debate."	ArXiv
1252	Natural Language Processing in the Legal Domain	['Daniel Martin Katz', 'Dirk Hartung', 'Lauritz Gerlach', 'Abhik Jana', 'Michael J. Bommarito II']	2023-02-23 14:02:47+00:00	http://arxiv.org/abs/2302.12039v1	"In this paper, we summarize the current state of the field of NLP & Law with
a specific focus on recent technical and substantive developments. To support
our analysis, we construct and analyze a nearly complete corpus of more than
six hundred NLP & Law related papers published over the past decade. Our
analysis highlights several major trends. Namely, we document an increasing
number of papers written, tasks undertaken, and languages covered over the
course of the past decade. We observe an increase in the sophistication of the
methods which researchers deployed in this applied context. Slowly but surely,
Legal NLP is beginning to match not only the methodological sophistication of
general NLP but also the professional standards of data availability and code
reproducibility observed within the broader scientific community. We believe
all of these trends bode well for the future of the field, but many questions
in both the academic and commercial sphere still remain open."	ArXiv
1253	"HugNLP: A Unified and Comprehensive Library for Natural Language
  Processing"	['Jianing Wang', 'Nuo Chen', 'Qiushi Sun', 'Wenkang Huang', 'Chengyu Wang', 'Ming Gao']	2023-02-28 03:38:26+00:00	http://arxiv.org/abs/2302.14286v1	"In this paper, we introduce HugNLP, a unified and comprehensive library for
natural language processing (NLP) with the prevalent backend of HuggingFace
Transformers, which is designed for NLP researchers to easily utilize
off-the-shelf algorithms and develop novel methods with user-defined models and
tasks in real-world scenarios. HugNLP consists of a hierarchical structure
including models, processors and applications that unifies the learning process
of pre-trained language models (PLMs) on different NLP tasks. Additionally, we
present some featured NLP applications to show the effectiveness of HugNLP,
such as knowledge-enhanced PLMs, universal information extraction, low-resource
mining, and code understanding and generation, etc. The source code will be
released on GitHub (https://github.com/wjn1996/HugNLP)."	ArXiv
1254	"NLP Workbench: Efficient and Extensible Integration of State-of-the-art
  Text Mining Tools"	['Peiran Yao', 'Matej Kosmajac', 'Abeer Waheed', 'Kostyantyn Guzhva', 'Natalie Hervieux', 'Denilson Barbosa']	2023-03-02 16:59:31+00:00	http://arxiv.org/abs/2303.01410v1	"NLP Workbench is a web-based platform for text mining that allows non-expert
users to obtain semantic understanding of large-scale corpora using
state-of-the-art text mining models. The platform is built upon latest
pre-trained models and open source systems from academia that provide semantic
analysis functionalities, including but not limited to entity linking,
sentiment analysis, semantic parsing, and relation extraction. Its extensible
design enables researchers and developers to smoothly replace an existing model
or integrate a new one. To improve efficiency, we employ a microservice
architecture that facilitates allocation of acceleration hardware and
parallelization of computation. This paper presents the architecture of NLP
Workbench and discusses the challenges we faced in designing it. We also
discuss diverse use cases of NLP Workbench and the benefits of using it over
other approaches. The platform is under active development, with its source
code released under the MIT license. A website and a short video demonstrating
our platform are also available."	ArXiv
1255	"Natural Language Processing in Ethiopian Languages: Current State,
  Challenges, and Opportunities"	['Atnafu Lambebo Tonja', 'Tadesse Destaw Belay', 'Israel Abebe Azime', 'Abinew Ali Ayele', 'Moges Ahmed Mehamed', 'Olga Kolesnikova', 'Seid Muhie Yimam']	2023-03-25 09:04:29+00:00	http://arxiv.org/abs/2303.14406v1	"This survey delves into the current state of natural language processing
(NLP) for four Ethiopian languages: Amharic, Afaan Oromo, Tigrinya, and
Wolaytta. Through this paper, we identify key challenges and opportunities for
NLP research in Ethiopia. Furthermore, we provide a centralized repository on
GitHub that contains publicly available resources for various NLP tasks in
these languages. This repository can be updated periodically with contributions
from other researchers. Our objective is to identify research gaps and
disseminate the information to NLP researchers interested in Ethiopian
languages and encourage future research in this domain."	ArXiv
1256	Natural Language Reasoning, A Survey	['Fei Yu', 'Hongbo Zhang', 'Prayag Tiwari', 'Benyou Wang']	2023-03-26 13:44:18+00:00	http://arxiv.org/abs/2303.14725v2	"This survey paper proposes a clearer view of natural language reasoning in
the field of Natural Language Processing (NLP), both conceptually and
practically. Conceptually, we provide a distinct definition for natural
language reasoning in NLP, based on both philosophy and NLP scenarios, discuss
what types of tasks require reasoning, and introduce a taxonomy of reasoning.
Practically, we conduct a comprehensive literature review on natural language
reasoning in NLP, mainly covering classical logical reasoning, natural language
inference, multi-hop question answering, and commonsense reasoning. The paper
also identifies and views backward reasoning, a powerful paradigm for
multi-step reasoning, and introduces defeasible reasoning as one of the most
important future directions in natural language reasoning research. We focus on
single-modality unstructured natural language text, excluding neuro-symbolic
techniques and mathematical reasoning."	ArXiv
1257	"Application of Transformers based methods in Electronic Medical Records:
  A Systematic Literature Review"	['Vitor Alcantara Batista', 'Alexandre Gonçalves Evsukoff']	2023-04-05 22:19:42+00:00	http://arxiv.org/abs/2304.02768v1	"The combined growth of available data and their unstructured nature has
received increased interest in natural language processing (NLP) techniques to
make value of these data assets since this format is not suitable for
statistical analysis. This work presents a systematic literature review of
state-of-the-art advances using transformer-based methods on electronic medical
records (EMRs) in different NLP tasks. To the best of our knowledge, this work
is unique in providing a comprehensive review of research on transformer-based
methods for NLP applied to the EMR field. In the initial query, 99 articles
were selected from three public databases and filtered into 65 articles for
detailed analysis. The papers were analyzed with respect to the business
problem, NLP task, models and techniques, availability of datasets,
reproducibility of modeling, language, and exchange format. The paper presents
some limitations of current research and some recommendations for further
research."	ArXiv
1258	"Radar de Parité: An NLP system to measure gender representation in
  French news stories"	['Valentin-Gabriel Soumah', 'Prashanth Rao', 'Philipp Eibl', 'Maite Taboada']	2023-04-19 21:33:59+00:00	http://arxiv.org/abs/2304.09982v1	"We present the Radar de Parit\'e, an automated Natural Language Processing
(NLP) system that measures the proportion of women and men quoted daily in six
Canadian French-language media outlets. We outline the system's architecture
and detail the challenges we overcame to address French-specific issues, in
particular regarding coreference resolution, a new contribution to the NLP
literature on French. We also showcase statistics covering over one year's
worth of data (282,512 news articles). Our results highlight the
underrepresentation of women in news stories, while also illustrating the
application of modern NLP methods to measure gender representation and address
societal issues."	ArXiv
1259	A Group-Specific Approach to NLP for Hate Speech Detection	['Karina Halevy']	2023-04-21 19:08:49+00:00	http://arxiv.org/abs/2304.11223v1	"Automatic hate speech detection is an important yet complex task, requiring
knowledge of common sense, stereotypes of protected groups, and histories of
discrimination, each of which may constantly evolve. In this paper, we propose
a group-specific approach to NLP for online hate speech detection. The approach
consists of creating and infusing historical and linguistic knowledge about a
particular protected group into hate speech detection models, analyzing
historical data about discrimination against a protected group to better
predict spikes in hate speech against that group, and critically evaluating
hate speech detection models through lenses of intersectionality and ethics. We
demonstrate this approach through a case study on NLP for detection of
antisemitic hate speech. The case study synthesizes the current
English-language literature on NLP for antisemitism detection, introduces a
novel knowledge graph of antisemitic history and language from the 20th century
to the present, infuses information from the knowledge graph into a set of
tweets over Logistic Regression and uncased DistilBERT baselines, and suggests
that incorporating context from the knowledge graph can help models pick up
subtle stereotypes."	ArXiv
1260	"Randomized Smoothing with Masked Inference for Adversarially Robust Text
  Classifications"	['Han Cheol Moon', 'Shafiq Joty', 'Ruochen Zhao', 'Megh Thakkar', 'Xu Chi']	2023-05-11 01:50:16+00:00	http://arxiv.org/abs/2305.06522v1	"Large-scale pre-trained language models have shown outstanding performance in
a variety of NLP tasks. However, they are also known to be significantly
brittle against specifically crafted adversarial examples, leading to
increasing interest in probing the adversarial robustness of NLP systems. We
introduce RSMI, a novel two-stage framework that combines randomized smoothing
(RS) with masked inference (MI) to improve the adversarial robustness of NLP
systems. RS transforms a classifier into a smoothed classifier to obtain robust
representations, whereas MI forces a model to exploit the surrounding context
of a masked token in an input sequence. RSMI improves adversarial robustness by
2 to 3 times over existing state-of-the-art methods on benchmark datasets. We
also perform in-depth qualitative analysis to validate the effectiveness of the
different stages of RSMI and probe the impact of its components through
extensive ablations. By empirically proving the stability of RSMI, we put it
forward as a practical method to robustly train large-scale NLP models. Our
code and datasets are available at https://github.com/Han8931/rsmi_nlp"	ArXiv
1261	"A Diachronic Analysis of Paradigm Shifts in NLP Research: When, How, and
  Why?"	['Aniket Pramanick', 'Yufang Hou', 'Saif M. Mohammad', 'Iryna Gurevych']	2023-05-22 11:08:00+00:00	http://arxiv.org/abs/2305.12920v3	"Understanding the fundamental concepts and trends in a scientific field is
crucial for keeping abreast of its continuous advancement. In this study, we
propose a systematic framework for analyzing the evolution of research topics
in a scientific field using causal discovery and inference techniques. We
define three variables to encompass diverse facets of the evolution of research
topics within NLP and utilize a causal discovery algorithm to unveil the causal
connections among these variables using observational data. Subsequently, we
leverage this structure to measure the intensity of these relationships. By
conducting extensive experiments on the ACL Anthology corpus, we demonstrate
that our framework effectively uncovers evolutionary trends and the underlying
causes for a wide range of NLP research topics. Specifically, we show that
tasks and methods are primary drivers of research in NLP, with datasets
following, while metrics have minimal impact."	ArXiv
1262	WYWEB: A NLP Evaluation Benchmark For Classical Chinese	['Bo Zhou', 'Qianglong Chen', 'Tianyu Wang', 'Xiaomi Zhong', 'Yin Zhang']	2023-05-23 15:15:11+00:00	http://arxiv.org/abs/2305.14150v1	"To fully evaluate the overall performance of different NLP models in a given
domain, many evaluation benchmarks are proposed, such as GLUE, SuperGLUE and
CLUE. The fi eld of natural language understanding has traditionally focused on
benchmarks for various tasks in languages such as Chinese, English, and
multilingua, however, there has been a lack of attention given to the area of
classical Chinese, also known as ""wen yan wen"", which has a rich history
spanning thousands of years and holds signifi cant cultural and academic value.
For the prosperity of the NLP community, in this paper, we introduce the WYWEB
evaluation benchmark, which consists of nine NLP tasks in classical Chinese,
implementing sentence classifi cation, sequence labeling, reading
comprehension, and machine translation. We evaluate the existing pre-trained
language models, which are all struggling with this benchmark. We also
introduce a number of supplementary datasets and additional tools to help
facilitate further progress on classical Chinese NLU. The github repository is
https://github.com/baudzhou/WYWEB."	ArXiv
1263	"GENTLE: A Genre-Diverse Multilayer Challenge Set for English NLP and
  Linguistic Evaluation"	['Tatsuya Aoyama', 'Shabnam Behzad', 'Luke Gessler', 'Lauren Levine', 'Jessica Lin', 'Yang Janet Liu', 'Siyao Peng', 'Yilun Zhu', 'Amir Zeldes']	2023-06-03 00:20:15+00:00	http://arxiv.org/abs/2306.01966v2	"We present GENTLE, a new mixed-genre English challenge corpus totaling 17K
tokens and consisting of 8 unusual text types for out-of domain evaluation:
dictionary entries, esports commentaries, legal documents, medical notes,
poetry, mathematical proofs, syllabuses, and threat letters. GENTLE is manually
annotated for a variety of popular NLP tasks, including syntactic dependency
parsing, entity recognition, coreference resolution, and discourse parsing. We
evaluate state-of-the-art NLP systems on GENTLE and find severe degradation for
at least some genres in their performance on all tasks, which indicates
GENTLE's utility as an evaluation dataset for NLP systems."	ArXiv
1264	Operationalising Representation in Natural Language Processing	['Jacqueline Harding']	2023-06-14 01:34:16+00:00	http://arxiv.org/abs/2306.08193v2	"Despite its centrality in the philosophy of cognitive science, there has been
little prior philosophical work engaging with the notion of representation in
contemporary NLP practice. This paper attempts to fill that lacuna: drawing on
ideas from cognitive science, I introduce a framework for evaluating the
representational claims made about components of neural NLP models, proposing
three criteria with which to evaluate whether a component of a model represents
a property and operationalising these criteria using probing classifiers, a
popular analysis technique in NLP (and deep learning more broadly).
  The project of operationalising a philosophically-informed notion of
representation should be of interest to both philosophers of science and NLP
practitioners. It affords philosophers a novel testing-ground for claims about
the nature of representation, and helps NLPers organise the large literature on
probing experiments, suggesting novel avenues for empirical research."	ArXiv
1265	Exploring the Landscape of Natural Language Processing Research	['Tim Schopf', 'Karim Arabi', 'Florian Matthes']	2023-07-20 07:33:30+00:00	http://arxiv.org/abs/2307.10652v5	"As an efficient approach to understand, generate, and process natural
language texts, research in natural language processing (NLP) has exhibited a
rapid spread and wide adoption in recent years. Given the increasing research
work in this area, several NLP-related approaches have been surveyed in the
research community. However, a comprehensive study that categorizes established
topics, identifies trends, and outlines areas for future research remains
absent. Contributing to closing this gap, we have systematically classified and
analyzed research papers in the ACL Anthology. As a result, we present a
structured overview of the research landscape, provide a taxonomy of fields of
study in NLP, analyze recent developments in NLP, summarize our findings, and
highlight directions for future work."	ArXiv
1266	"Next-to-leading power resummed rapidity distributions near threshold for
  Drell-Yan and diphoton production"	['Robin van Bijleveld', 'Eric Laenen', 'Leonardo Vernazza', 'Guoxing Wang']	2023-08-01 02:00:20+00:00	http://arxiv.org/abs/2308.00230v1	"We consider Drell-Yan production and QCD-induced diphoton production and
compute their rapidity distributions up to next-to-leading power (NLP) in the
threshold variable. We give results for rapidity distributions of the Drell-Yan
process up to NNLO accuracy and show that a factorised structure occurs for the
leading logarithms (LL) at NLP, generalising the result at leading power. For
diphoton production, we generalise methods based on kinematical shifts to find
the NLO cross section up to NLP for rapidity distributions. From the results
for these two processes, we derive resummed cross sections at NLP LL accuracy
that are double differential in the threshold variable and the rapidity
variable, which generalise results for single differential resummed cross
sections."	ArXiv
1267	"To Build Our Future, We Must Know Our Past: Contextualizing Paradigm
  Shifts in Natural Language Processing"	['Sireesh Gururaja', 'Amanda Bertsch', 'Clara Na', 'David Gray Widder', 'Emma Strubell']	2023-10-11 17:59:36+00:00	http://arxiv.org/abs/2310.07715v1	"NLP is in a period of disruptive change that is impacting our methodologies,
funding sources, and public perception. In this work, we seek to understand how
to shape our future by better understanding our past. We study factors that
shape NLP as a field, including culture, incentives, and infrastructure by
conducting long-form interviews with 26 NLP researchers of varying seniority,
research area, institution, and social identity. Our interviewees identify
cyclical patterns in the field, as well as new shifts without historical
parallel, including changes in benchmark culture and software infrastructure.
We complement this discussion with quantitative analysis of citation,
authorship, and language use in the ACL Anthology over time. We conclude by
discussing shared visions, concerns, and hopes for the future of NLP. We hope
that this study of our field's past and present can prompt informed discussion
of our community's implicit norms and more deliberate action to consciously
shape the future."	ArXiv
1268	Values, Ethics, Morals? On the Use of Moral Concepts in NLP Research	['Karina Vida', 'Judith Simon', 'Anne Lauscher']	2023-10-21 06:04:10+00:00	http://arxiv.org/abs/2310.13915v1	"With language technology increasingly affecting individuals' lives, many
recent works have investigated the ethical aspects of NLP. Among other topics,
researchers focused on the notion of morality, investigating, for example,
which moral judgements language models make. However, there has been little to
no discussion of the terminology and the theories underpinning those efforts
and their implications. This lack is highly problematic, as it hides the works'
underlying assumptions and hinders a thorough and targeted scientific debate of
morality in NLP. In this work, we address this research gap by (a) providing an
overview of some important ethical concepts stemming from philosophy and (b)
systematically surveying the existing literature on moral NLP w.r.t. their
philosophical foundation, terminology, and data basis. For instance, we analyse
what ethical theory an approach is based on, how this decision is justified,
and what implications it entails. Our findings surveying 92 papers show that,
for instance, most papers neither provide a clear definition of the terms they
use nor adhere to definitions from philosophy. Finally, (c) we give three
recommendations for future research in the field. We hope our work will lead to
a more informed, careful, and sound discussion of morality in language
technology."	ArXiv
1269	"Natural Language Processing for Drug Discovery Knowledge Graphs:
  promises and pitfalls"	['J. Charles G. Jeynes', 'Tim James', 'Matthew Corney']	2023-10-24 07:35:24+00:00	http://arxiv.org/abs/2310.15572v1	"Building and analysing knowledge graphs (KGs) to aid drug discovery is a
topical area of research. A salient feature of KGs is their ability to combine
many heterogeneous data sources in a format that facilitates discovering
connections. The utility of KGs has been exemplified in areas such as drug
repurposing, with insights made through manual exploration and modelling of the
data. In this article, we discuss promises and pitfalls of using natural
language processing (NLP) to mine unstructured text typically from scientific
literature as a data source for KGs. This draws on our experience of initially
parsing structured data sources such as ChEMBL as the basis for data within a
KG, and then enriching or expanding upon them using NLP. The fundamental
promise of NLP for KGs is the automated extraction of data from millions of
documents a task practically impossible to do via human curation alone.
However, there are many potential pitfalls in NLP-KG pipelines such as
incorrect named entity recognition and ontology linking all of which could
ultimately lead to erroneous inferences and conclusions."	ArXiv
1270	"A Review of Reinforcement Learning for Natural Language Processing, and
  Applications in Healthcare"	['Ying Liu', 'Haozhu Wang', 'Huixue Zhou', 'Mingchen Li', 'Yu Hou', 'Sicheng Zhou', 'Fang Wang', 'Rama Hoetzlein', 'Rui Zhang']	2023-10-23 20:26:15+00:00	http://arxiv.org/abs/2310.18354v1	"Reinforcement learning (RL) has emerged as a powerful approach for tackling
complex medical decision-making problems such as treatment planning,
personalized medicine, and optimizing the scheduling of surgeries and
appointments. It has gained significant attention in the field of Natural
Language Processing (NLP) due to its ability to learn optimal strategies for
tasks such as dialogue systems, machine translation, and question-answering.
This paper presents a review of the RL techniques in NLP, highlighting key
advancements, challenges, and applications in healthcare. The review begins by
visualizing a roadmap of machine learning and its applications in healthcare.
And then it explores the integration of RL with NLP tasks. We examined dialogue
systems where RL enables the learning of conversational strategies, RL-based
machine translation models, question-answering systems, text summarization, and
information extraction. Additionally, ethical considerations and biases in
RL-NLP systems are addressed."	ArXiv
1271	Defining a New NLP Playground	['Sha Li', 'Chi Han', 'Pengfei Yu', 'Carl Edwards', 'Manling Li', 'Xingyao Wang', 'Yi R. Fung', 'Charles Yu', 'Joel R. Tetreault', 'Eduard H. Hovy', 'Heng Ji']	2023-10-31 17:02:33+00:00	http://arxiv.org/abs/2310.20633v1	"The recent explosion of performance of large language models (LLMs) has
changed the field of Natural Language Processing (NLP) more abruptly and
seismically than any other shift in the field's 80-year history. This has
resulted in concerns that the field will become homogenized and
resource-intensive. The new status quo has put many academic researchers,
especially PhD students, at a disadvantage. This paper aims to define a new NLP
playground by proposing 20+ PhD-dissertation-worthy research directions,
covering theoretical analysis, new and challenging problems, learning
paradigms, and interdisciplinary applications."	ArXiv
1272	"Incorporating Worker Perspectives into MTurk Annotation Practices for
  NLP"	['Olivia Huang', 'Eve Fleisig', 'Dan Klein']	2023-11-06 00:06:11+00:00	http://arxiv.org/abs/2311.02802v2	"Current practices regarding data collection for natural language processing
on Amazon Mechanical Turk (MTurk) often rely on a combination of studies on
data quality and heuristics shared among NLP researchers. However, without
considering the perspectives of MTurk workers, these approaches are susceptible
to issues regarding workers' rights and poor response quality. We conducted a
critical literature review and a survey of MTurk workers aimed at addressing
open questions regarding best practices for fair payment, worker privacy, data
quality, and considering worker incentives. We found that worker preferences
are often at odds with received wisdom among NLP researchers. Surveyed workers
preferred reliable, reasonable payments over uncertain, very high payments;
reported frequently lying on demographic questions; and expressed frustration
at having work rejected with no explanation. We also found that workers view
some quality control methods, such as requiring minimum response times or
Master's qualifications, as biased and largely ineffective. Based on the survey
results, we provide recommendations on how future NLP studies may better
account for MTurk workers' experiences in order to respect workers' rights and
improve data quality."	ArXiv
1273	Principles from Clinical Research for NLP Model Generalization	['Aparna Elangovan', 'Jiayuan He', 'Yuan Li', 'Karin Verspoor']	2023-11-07 02:17:25+00:00	http://arxiv.org/abs/2311.03663v3	"The NLP community typically relies on performance of a model on a held-out
test set to assess generalization. Performance drops observed in datasets
outside of official test sets are generally attributed to ""out-of-distribution""
effects. Here, we explore the foundations of generalizability and study the
factors that affect it, articulating lessons from clinical studies. In clinical
research, generalizability is an act of reasoning that depends on (a) internal
validity of experiments to ensure controlled measurement of cause and effect,
and (b) external validity or transportability of the results to the wider
population. We demonstrate how learning spurious correlations, such as the
distance between entities in relation extraction tasks, can affect a model's
internal validity and in turn adversely impact generalization. We, therefore,
present the need to ensure internal validity when building machine learning
models in NLP. Our recommendations also apply to generative large language
models, as they are known to be sensitive to even minor semantic preserving
alterations. We also propose adapting the idea of matching in randomized
controlled trials and observational studies to NLP evaluation to measure
causation."	ArXiv
1274	Energy and Carbon Considerations of Fine-Tuning BERT	['Xiaorong Wang', 'Clara Na', 'Emma Strubell', 'Sorelle Friedler', 'Sasha Luccioni']	2023-11-17 01:27:01+00:00	http://arxiv.org/abs/2311.10267v2	"Despite the popularity of the `pre-train then fine-tune' paradigm in the NLP
community, existing work quantifying energy costs and associated carbon
emissions has largely focused on language model pre-training. Although a single
pre-training run draws substantially more energy than fine-tuning, fine-tuning
is performed more frequently by many more individual actors, and thus must be
accounted for when considering the energy and carbon footprint of NLP. In order
to better characterize the role of fine-tuning in the landscape of energy and
carbon emissions in NLP, we perform a careful empirical study of the
computational costs of fine-tuning across tasks, datasets, hardware
infrastructure and measurement modalities. Our experimental results allow us to
place fine-tuning energy and carbon costs into perspective with respect to
pre-training and inference, and outline recommendations to NLP researchers and
practitioners who wish to improve their fine-tuning energy efficiency."	ArXiv
1275	"Combining EEG and NLP Features for Predicting Students' Lecture
  Comprehension using Ensemble Classification"	['Phantharach Natnithikarat', 'Theerawit Wilaiprasitporn', 'Supavit Kongwudhikunakorn']	2023-11-18 14:35:26+00:00	http://arxiv.org/abs/2311.11088v1	"Electroencephalography (EEG) and Natural Language Processing (NLP) can be
applied for education to measure students' comprehension in classroom lectures;
currently, the two measures have been used separately. In this work, we propose
a classification framework for predicting students' lecture comprehension in
two tasks: (i) students' confusion after listening to the simulated lecture and
(ii) the correctness of students' responses to the post-lecture assessment. The
proposed framework includes EEG and NLP feature extraction, processing, and
classification. EEG and NLP features are extracted to construct integrated
features obtained from recorded EEG signals and sentence-level syntactic
analysis, which provide information about specific biomarkers and sentence
structures. An ensemble stacking classification method -- a combination of
multiple individual models that produces an enhanced predictive model -- is
studied to learn from the features to make predictions accurately. Furthermore,
we also utilized subjective confusion ratings as another integrated feature to
enhance classification performance. By doing so, experiment results show that
this framework performs better than the baselines, which achieved F1 up to 0.65
for predicting confusion and 0.78 for predicting correctness, highlighting that
utilizing this has helped improve the classification performance."	ArXiv
1276	Exploring Prompting Large Language Models as Explainable Metrics	['Ghazaleh Mahmoudi']	2023-11-20 06:06:22+00:00	http://arxiv.org/abs/2311.11552v1	"This paper describes the IUST NLP Lab submission to the Prompting Large
Language Models as Explainable Metrics Shared Task at the Eval4NLP 2023
Workshop on Evaluation & Comparison of NLP Systems. We have proposed a
zero-shot prompt-based strategy for explainable evaluation of the summarization
task using Large Language Models (LLMs). The conducted experiments demonstrate
the promising potential of LLMs as evaluation metrics in Natural Language
Processing (NLP), particularly in the field of summarization. Both few-shot and
zero-shot approaches are employed in these experiments. The performance of our
best provided prompts achieved a Kendall correlation of 0.477 with human
evaluations in the text summarization task on the test data. Code and results
are publicly available on GitHub."	ArXiv
1277	"Deep Learning and NLP in Cryptocurrency Forecasting: Integrating
  Financial, Blockchain, and Social Media Data"	['Vincent Gurgul', 'Stefan Lessmann', 'Wolfgang Karl Härdle']	2023-11-23 16:14:44+00:00	http://arxiv.org/abs/2311.14759v2	"We introduce novel approaches to cryptocurrency price forecasting, leveraging
Machine Learning (ML) and Natural Language Processing (NLP) techniques, with a
focus on Bitcoin and Ethereum. By analysing news and social media content,
primarily from Twitter and Reddit, we assess the impact of public sentiment on
cryptocurrency markets. A distinctive feature of our methodology is the
application of the BART MNLI zero-shot classification model to detect bullish
and bearish trends, significantly advancing beyond traditional sentiment
analysis. Additionally, we systematically compare a range of pre-trained and
fine-tuned deep learning NLP models against conventional dictionary-based
sentiment analysis methods. Another key contribution of our work is the
adoption of local extrema alongside daily price movements as predictive
targets, reducing trading frequency and portfolio volatility. Our findings
demonstrate that integrating textual data into cryptocurrency price forecasting
not only improves forecasting accuracy but also consistently enhances the
profitability and Sharpe ratio across various validation scenarios,
particularly when applying deep learning NLP techniques. The entire codebase of
our experiments is made available via an online repository:
https://anonymous.4open.science/r/crypto-forecasting-public"	ArXiv
1278	Factorization and resummation at next-to-leading-power	['Leonardo Vernazza']	2023-12-09 11:53:07+00:00	http://arxiv.org/abs/2312.05553v2	"We discuss recent progress concerning the resummation of large logarithms at
next-to-leading power (NLP) in scattering processes such as Drell-Yan and deep
inelastic scattering near threshold, and thrust in the two-jet limit. We start
by reviewing the approach based on soft-collinear effective field theory and
show that the standard factorization into short distance coefficients,
collinear and soft functions at NLP leads in general to the appearance of
endpoint divergences, which prevent the naive application of resummation
techniques based on the renormalization group. Taking thrust as a case study,
we then show that these singularities are indeed an artifact of the effective
theory, and discuss how they can be removed to recover a finite factorization
theorem and achieve resummation at NLP, at LL accuracy. Last, we discuss recent
work concerning the calculation of all collinear and soft functions necessary
to reproduce Drell-Yan near threshold up to NNLO in perturbation theory. This
calculation provides useful data to extend resummation at NLP beyond LL
accuracy."	ArXiv
1279	Large Human Language Models: A Need and the Challenges	['Nikita Soni', 'H. Andrew Schwartz', 'João Sedoc', 'Niranjan Balasubramanian']	2023-11-09 00:27:28+00:00	http://arxiv.org/abs/2312.07751v3	"As research in human-centered NLP advances, there is a growing recognition of
the importance of incorporating human and social factors into NLP models. At
the same time, our NLP systems have become heavily reliant on LLMs, most of
which do not model authors. To build NLP systems that can truly understand
human language, we must better integrate human contexts into LLMs. This brings
to the fore a range of design considerations and challenges in terms of what
human aspects to capture, how to represent them, and what modeling strategies
to pursue. To address these, we advocate for three positions toward creating
large human language models (LHLMs) using concepts from psychological and
behavioral sciences: First, LM training should include the human context.
Second, LHLMs should recognize that people are more than their group(s). Third,
LHLMs should be able to account for the dynamic and temporally-dependent nature
of the human context. We refer to relevant advances and present open challenges
that need to be addressed and their possible solutions in realizing these
goals."	ArXiv
1280	Is there really a Citation Age Bias in NLP?	['Hoa Nguyen', 'Steffen Eger']	2024-01-07 17:12:08+00:00	http://arxiv.org/abs/2401.03545v1	"Citations are a key ingredient of scientific research to relate a paper to
others published in the community. Recently, it has been noted that there is a
citation age bias in the Natural Language Processing (NLP) community, one of
the currently fastest growing AI subfields, in that the mean age of the
bibliography of NLP papers has become ever younger in the last few years,
leading to `citation amnesia' in which older knowledge is increasingly
forgotten. In this work, we put such claims into perspective by analyzing the
bibliography of $\sim$300k papers across 15 different scientific fields
submitted to the popular preprint server Arxiv in the time period from 2013 to
2022. We find that all AI subfields (in particular: cs.AI, cs.CL, cs.CV, cs.LG)
have similar trends of citation amnesia, in which the age of the bibliography
has roughly halved in the last 10 years (from above 12 in 2013 to below 7 in
2022), on average. Rather than diagnosing this as a citation age bias in the
NLP community, we believe this pattern is an artefact of the dynamics of these
research fields, in which new knowledge is produced in ever shorter time
intervals."	ArXiv
1281	We Need to Talk About Classification Evaluation Metrics in NLP	['Peter Vickers', 'Loïc Barrault', 'Emilio Monti', 'Nikolaos Aletras']	2024-01-08 11:40:48+00:00	http://arxiv.org/abs/2401.03831v1	"In Natural Language Processing (NLP) classification tasks such as topic
categorisation and sentiment analysis, model generalizability is generally
measured with standard metrics such as Accuracy, F-Measure, or AUC-ROC. The
diversity of metrics, and the arbitrariness of their application suggest that
there is no agreement within NLP on a single best metric to use. This lack
suggests there has not been sufficient examination of the underlying heuristics
which each metric encodes. To address this we compare several standard
classification metrics with more 'exotic' metrics and demonstrate that a
random-guess normalised Informedness metric is a parsimonious baseline for task
performance. To show how important the choice of metric is, we perform
extensive experiments on a wide range of NLP tasks including a synthetic
scenario, natural language understanding, question answering and machine
translation. Across these tasks we use a superset of metrics to rank models and
find that Informedness best captures the ideal model characteristics. Finally,
we release a Python implementation of Informedness following the SciKitLearn
classifier format."	ArXiv
1282	"""It's how you do things that matters"": Attending to Process to Better
  Serve Indigenous Communities with Language Technologies"	['Ned Cooper', 'Courtney Heldreth', 'Ben Hutchinson']	2024-02-04 23:23:51+00:00	http://arxiv.org/abs/2402.02639v2	"Indigenous languages are historically under-served by Natural Language
Processing (NLP) technologies, but this is changing for some languages with the
recent scaling of large multilingual models and an increased focus by the NLP
community on endangered languages. This position paper explores ethical
considerations in building NLP technologies for Indigenous languages, based on
the premise that such projects should primarily serve Indigenous communities.
We report on interviews with 17 researchers working in or with Aboriginal
and/or Torres Strait Islander communities on language technology projects in
Australia. Drawing on insights from the interviews, we recommend practices for
NLP researchers to increase attention to the process of engagements with
Indigenous communities, rather than focusing only on decontextualised
artefacts."	ArXiv
1283	"What is ""Typological Diversity"" in NLP?"	['Esther Ploeger', 'Wessel Poelman', 'Miryam de Lhoneux', 'Johannes Bjerva']	2024-02-06 18:29:39+00:00	http://arxiv.org/abs/2402.04222v4	"The NLP research community has devoted increased attention to languages
beyond English, resulting in considerable improvements for multilingual NLP.
However, these improvements only apply to a small subset of the world's
languages. Aiming to extend this, an increasing number of papers aspires to
enhance generalizable multilingual performance across languages. To this end,
linguistic typology is commonly used to motivate language selection, on the
basis that a broad typological sample ought to imply generalization across a
broad range of languages. These selections are often described as being
'typologically diverse'. In this work, we systematically investigate NLP
research that includes claims regarding 'typological diversity'. We find there
are no set definitions or criteria for such claims. We introduce metrics to
approximate the diversity of language selection along several axes and find
that the results vary considerably across papers. Crucially, we show that
skewed language selection can lead to overestimated multilingual performance.
We recommend future work to include an operationalization of 'typological
diversity' that empirically justifies the diversity of language samples."	ArXiv
1284	"Deep Learning Approaches for Improving Question Answering Systems in
  Hepatocellular Carcinoma Research"	['Shuning Huo', 'Yafei Xiang', 'Hanyi Yu', 'Mengran Zhu', 'Yulu Gong']	2024-02-25 09:32:17+00:00	http://arxiv.org/abs/2402.16038v1	"In recent years, advancements in natural language processing (NLP) have been
fueled by deep learning techniques, particularly through the utilization of
powerful computing resources like GPUs and TPUs. Models such as BERT and GPT-3,
trained on vast amounts of data, have revolutionized language understanding and
generation. These pre-trained models serve as robust bases for various tasks
including semantic understanding, intelligent writing, and reasoning, paving
the way for a more generalized form of artificial intelligence. NLP, as a vital
application of AI, aims to bridge the gap between humans and computers through
natural language interaction. This paper delves into the current landscape and
future prospects of large-scale model-based NLP, focusing on the
question-answering systems within this domain. Practical cases and developments
in artificial intelligence-driven question-answering systems are analyzed to
foster further exploration and research in the realm of large-scale NLP."	ArXiv
1285	VNLP: Turkish NLP Package	['Meliksah Turker', 'Mehmet Erdi Ari', 'Aydin Han']	2024-03-02 20:46:56+00:00	http://arxiv.org/abs/2403.01309v1	"In this work, we present VNLP: the first dedicated, complete, open-source,
well-documented, lightweight, production-ready, state-of-the-art Natural
Language Processing (NLP) package for the Turkish language. It contains a wide
variety of tools, ranging from the simplest tasks, such as sentence splitting
and text normalization, to the more advanced ones, such as text and token
classification models. Its token classification models are based on ""Context
Model"", a novel architecture that is both an encoder and an auto-regressive
model. NLP tasks solved by VNLP models include but are not limited to Sentiment
Analysis, Named Entity Recognition, Morphological Analysis \& Disambiguation
and Part-of-Speech Tagging. Moreover, it comes with pre-trained word embeddings
and corresponding SentencePiece Unigram tokenizers. VNLP has an open-source
GitHub repository, ReadtheDocs documentation, PyPi package for convenient
installation, Python and command-line API and a demo page to test all the
functionality. Consequently, our main contribution is a complete, compact,
easy-to-install and easy-to-use NLP package for Turkish."	ArXiv
1286	Impoverished Language Technology: The Lack of (Social) Class in NLP	['Amanda Cercas Curry', 'Zeerak Talat', 'Dirk Hovy']	2024-03-06 17:35:27+00:00	http://arxiv.org/abs/2403.03874v1	"Since Labov's (1964) foundational work on the social stratification of
language, linguistics has dedicated concerted efforts towards understanding the
relationships between socio-demographic factors and language production and
perception. Despite the large body of evidence identifying significant
relationships between socio-demographic factors and language production,
relatively few of these factors have been investigated in the context of NLP
technology. While age and gender are well covered, Labov's initial target,
socio-economic class, is largely absent. We survey the existing Natural
Language Processing (NLP) literature and find that only 20 papers even mention
socio-economic status. However, the majority of those papers do not engage with
class beyond collecting information of annotator-demographics. Given this
research lacuna, we provide a definition of class that can be operationalised
by NLP researchers, and argue for including socio-economic class in future
language technologies."	ArXiv
1287	Natural Language Processing in Patents: A Survey	['Lekang Jiang', 'Stephan Goetz']	2024-03-06 23:17:16+00:00	http://arxiv.org/abs/2403.04105v2	"Patents, encapsulating crucial technical and legal information, present a
rich domain for natural language processing (NLP) applications. As NLP
technologies evolve, large language models (LLMs) have demonstrated outstanding
capabilities in general text processing and generation tasks. However, the
application of LLMs in the patent domain remains under-explored and
under-developed due to the complexity of patent processing. Understanding the
unique characteristics of patent documents and related research in the patent
domain becomes essential for researchers to apply these tools effectively.
Therefore, this paper aims to equip NLP researchers with the essential
knowledge to navigate this complex domain efficiently. We introduce the
relevant fundamental aspects of patents to provide solid background
information, particularly for readers unfamiliar with the patent system. In
addition, we systematically break down the structural and linguistic
characteristics unique to patents and map out how NLP can be leveraged for
patent analysis and generation. Moreover, we demonstrate the spectrum of
text-based patent-related tasks, including nine patent analysis and four patent
generation tasks."	ArXiv
1288	A Taxonomy of Ambiguity Types for NLP	['Margaret Y. Li', 'Alisa Liu', 'Zhaofeng Wu', 'Noah A. Smith']	2024-03-21 01:47:22+00:00	http://arxiv.org/abs/2403.14072v1	"Ambiguity is an critical component of language that allows for more effective
communication between speakers, but is often ignored in NLP. Recent work
suggests that NLP systems may struggle to grasp certain elements of human
language understanding because they may not handle ambiguities at the level
that humans naturally do in communication. Additionally, different types of
ambiguity may serve different purposes and require different approaches for
resolution, and we aim to investigate how language models' abilities vary
across types. We propose a taxonomy of ambiguity types as seen in English to
facilitate NLP analysis. Our taxonomy can help make meaningful splits in
language ambiguity data, allowing for more fine-grained assessments of both
datasets and model performance."	ArXiv
1289	Targeted Visualization of the Backbone of Encoder LLMs	['Isaac Roberts', 'Alexander Schulz', 'Luca Hermes', 'Barbara Hammer']	2024-03-26 12:51:02+00:00	http://arxiv.org/abs/2403.18872v1	"Attention based Large Language Models (LLMs) are the state-of-the-art in
natural language processing (NLP). The two most common architectures are
encoders such as BERT, and decoders like the GPT models. Despite the success of
encoder models, on which we focus in this work, they also bear several risks,
including issues with bias or their susceptibility for adversarial attacks,
signifying the necessity for explainable AI to detect such issues. While there
does exist various local explainability methods focusing on the prediction of
single inputs, global methods based on dimensionality reduction for
classification inspection, which have emerged in other domains and that go
further than just using t-SNE in the embedding space, are not widely spread in
NLP.
  To reduce this gap, we investigate the application of DeepView, a method for
visualizing a part of the decision function together with a data set in two
dimensions, to the NLP domain. While in previous work, DeepView has been used
to inspect deep image classification models, we demonstrate how to apply it to
BERT-based NLP classifiers and investigate its usability in this domain,
including settings with adversarially perturbed input samples and pre-trained,
fine-tuned, and multi-task models."	ArXiv
1290	NLP for Counterspeech against Hate: A Survey and How-To Guide	['Helena Bonaldi', 'Yi-Ling Chung', 'Gavin Abercrombie', 'Marco Guerini']	2024-03-29 10:32:44+00:00	http://arxiv.org/abs/2403.20103v1	"In recent years, counterspeech has emerged as one of the most promising
strategies to fight online hate. These non-escalatory responses tackle online
abuse while preserving the freedom of speech of the users, and can have a
tangible impact in reducing online and offline violence. Recently, there has
been growing interest from the Natural Language Processing (NLP) community in
addressing the challenges of analysing, collecting, classifying, and
automatically generating counterspeech, to reduce the huge burden of manually
producing it. In particular, researchers have taken different directions in
addressing these challenges, thus providing a variety of related tasks and
resources. In this paper, we provide a guide for doing research on
counterspeech, by describing - with detailed examples - the steps to undertake,
and providing best practices that can be learnt from the NLP studies on this
topic. Finally, we discuss open challenges and future directions of
counterspeech research in NLP."	ArXiv
1291	BERTopic-Driven Stock Market Predictions: Unraveling Sentiment Insights	['Enmin Zhu', 'Jerome Yen']	2024-04-02 15:50:10+00:00	http://arxiv.org/abs/2404.02053v2	"This paper explores the intersection of Natural Language Processing (NLP) and
financial analysis, focusing on the impact of sentiment analysis in stock price
prediction. We employ BERTopic, an advanced NLP technique, to analyze the
sentiment of topics derived from stock market comments. Our methodology
integrates this sentiment analysis with various deep learning models, renowned
for their effectiveness in time series and stock prediction tasks. Through
comprehensive experiments, we demonstrate that incorporating topic sentiment
notably enhances the performance of these models. The results indicate that
topics in stock market comments provide implicit, valuable insights into stock
market volatility and price trends. This study contributes to the field by
showcasing the potential of NLP in enriching financial analysis and opens up
avenues for further research into real-time sentiment analysis and the
exploration of emotional and contextual aspects of market sentiment. The
integration of advanced NLP techniques like BERTopic with traditional financial
analysis methods marks a step forward in developing more sophisticated tools
for understanding and predicting market behaviors."	ArXiv
1292	"Modeling the Sacred: Considerations when Using Religious Texts in
  Natural Language Processing"	['Ben Hutchinson']	2024-04-23 04:47:22+00:00	http://arxiv.org/abs/2404.14740v2	"This position paper concerns the use of religious texts in Natural Language
Processing (NLP), which is of special interest to the Ethics of NLP. Religious
texts are expressions of culturally important values, and machine learned
models have a propensity to reproduce cultural values encoded in their training
data. Furthermore, translations of religious texts are frequently used by NLP
researchers when language data is scarce. This repurposes the translations from
their original uses and motivations, which often involve attracting new
followers. This paper argues that NLP's use of such texts raises considerations
that go beyond model biases, including data provenance, cultural contexts, and
their use in proselytism. We argue for more consideration of researcher
positionality, and of the perspectives of marginalized linguistic and religious
communities."	ArXiv
1293	"Towards A Structured Overview of Use Cases for Natural Language
  Processing in the Legal Domain: A German Perspective"	['Juraj Vladika', 'Stephen Meisenbacher', 'Martina Preis', 'Alexandra Klymenko', 'Florian Matthes']	2024-04-29 14:56:47+00:00	http://arxiv.org/abs/2404.18759v2	"In recent years, the field of Legal Tech has risen in prevalence, as the
Natural Language Processing (NLP) and legal disciplines have combined forces to
digitalize legal processes. Amidst the steady flow of research solutions
stemming from the NLP domain, the study of use cases has fallen behind, leading
to a number of innovative technical methods without a place in practice. In
this work, we aim to build a structured overview of Legal Tech use cases,
grounded in NLP literature, but also supplemented by voices from legal practice
in Germany. Based upon a Systematic Literature Review, we identify seven
categories of NLP technologies for the legal domain, which are then studied in
juxtaposition to 22 legal use cases. In the investigation of these use cases,
we identify 15 ethical, legal, and social aspects (ELSA), shedding light on the
potential concerns of digitally transforming the legal domain."	ArXiv
1294	Adversarial Attacks and Defense for Conversation Entailment Task	['Zhenning Yang', 'Ryan Krawec', 'Liang-Yuan Wu']	2024-05-01 02:49:18+00:00	http://arxiv.org/abs/2405.00289v2	"As the deployment of NLP systems in critical applications grows, ensuring the
robustness of large language models (LLMs) against adversarial attacks becomes
increasingly important. Large language models excel in various NLP tasks but
remain vulnerable to low-cost adversarial attacks. Focusing on the domain of
conversation entailment, where multi-turn dialogues serve as premises to verify
hypotheses, we fine-tune a transformer model to accurately discern the
truthfulness of these hypotheses. Adversaries manipulate hypotheses through
synonym swapping, aiming to deceive the model into making incorrect
predictions. To counteract these attacks, we implemented innovative fine-tuning
techniques and introduced an embedding perturbation loss method to
significantly bolster the model's robustness. Our findings not only emphasize
the importance of defending against adversarial attacks in NLP but also
highlight the real-world implications, suggesting that enhancing model
robustness is critical for reliable NLP applications."	ArXiv
1295	The Call for Socially Aware Language Technologies	['Diyi Yang', 'Dirk Hovy', 'David Jurgens', 'Barbara Plank']	2024-05-03 18:12:39+00:00	http://arxiv.org/abs/2405.02411v1	"Language technologies have made enormous progress, especially with the
introduction of large language models (LLMs). On traditional tasks such as
machine translation and sentiment analysis, these models perform at near-human
level. These advances can, however, exacerbate a variety of issues that models
have traditionally struggled with, such as bias, evaluation, and risks. In this
position paper, we argue that many of these issues share a common core: a lack
of awareness of the factors, context, and implications of the social
environment in which NLP operates, which we call social awareness. While NLP is
getting better at solving the formal linguistic aspects, limited progress has
been made in adding the social awareness required for language applications to
work in all situations for all users. Integrating social awareness into NLP
models will make applications more natural, helpful, and safe, and will open up
new possibilities. Thus we argue that substantial challenges remain for NLP to
develop social awareness and that we are just at the beginning of a new era for
the field."	ArXiv
1296	"OMP-Engineer: Bridging Syntax Analysis and In-Context Learning for
  Efficient Automated OpenMP Parallelization"	['Weidong Wang', 'Haoran Zhu']	2024-05-06 07:26:32+00:00	http://arxiv.org/abs/2405.03215v1	"In advancing parallel programming, particularly with OpenMP, the shift
towards NLP-based methods marks a significant innovation beyond traditional S2S
tools like Autopar and Cetus. These NLP approaches train on extensive datasets
of examples to efficiently generate optimized parallel code, streamlining the
development process. This method's strength lies in its ability to swiftly
produce parallelized code that runs efficiently. However, this reliance on NLP
models, without direct code analysis, can introduce inaccuracies, as these
models might not fully grasp the nuanced semantics of the code they
parallelize. We build OMP-Engineer, which balances the efficiency and
scalability of NLP models with the accuracy and reliability of traditional
methods, aiming to enhance the performance of automating parallelization while
navigating its inherent challenges."	ArXiv
1297	"Revitalising Stagecraft: NLP-Driven Sentiment Analysis for Traditional
  Theater Revival"	['Saikat Samanta', 'Saptarshi Karmakar', 'Satayajay Behuria', 'Shibam Dutta', 'Soujit Das', 'Soumik Saha']	2024-05-09 14:50:42+00:00	http://arxiv.org/abs/2405.05813v1	"This paper explores the application of FilmFrenzy, a python based ticket
booking web application, in the revival of traditional Indian theatres.
Additionally, this research paper explores how NLP can be implemented to
improve user experience. Through clarifying audience views and pinpointing
opportunities for development, FilmFrenzy aims to promote involvement and
rejuvenation in India's conventional theatre scene. The platform seeks to
maintain the relevance and vitality of conventional theatres by bridging the
gap between audiences and them through the incorporation of contemporary
technologies, especially NLP. This research envisions a future in which
technology plays a crucial part in maintaining India's rich theatrical
traditions, thereby contributing to the preservation and development of
cultural heritage. With sentiment analysis and natural language processing
(NLP) as essential instruments for improving stagecraft, the research envisions
a period when traditional theatre will still be vibrant."	ArXiv
1298	Evaluating Saliency Explanations in NLP by Crowdsourcing	['Xiaotian Lu', 'Jiyi Li', 'Zhen Wan', 'Xiaofeng Lin', 'Koh Takeuchi', 'Hisashi Kashima']	2024-05-17 13:27:45+00:00	http://arxiv.org/abs/2405.10767v1	"Deep learning models have performed well on many NLP tasks. However, their
internal mechanisms are typically difficult for humans to understand. The
development of methods to explain models has become a key issue in the
reliability of deep learning models in many important applications. Various
saliency explanation methods, which give each feature of input a score
proportional to the contribution of output, have been proposed to determine the
part of the input which a model values most. Despite a considerable body of
work on the evaluation of saliency methods, whether the results of various
evaluation metrics agree with human cognition remains an open question. In this
study, we propose a new human-based method to evaluate saliency methods in NLP
by crowdsourcing. We recruited 800 crowd workers and empirically evaluated
seven saliency methods on two datasets with the proposed method. We analyzed
the performance of saliency methods, compared our results with existing
automated evaluation methods, and identified notable differences between NLP
and computer vision (CV) fields when using saliency methods. The instance-level
data of our crowdsourced experiments and the code to reproduce the explanations
are available at https://github.com/xtlu/lreccoling_evaluation."	ArXiv
1299	"Sensitivity Analysis for Piecewise-Affine Approximations of Nonlinear
  Programs with Polytopic Constraints"	['Leila Gharavi', 'Changrui Liu', 'Bart De Schutter', 'Simone Baldi']	2024-05-30 18:00:11+00:00	http://arxiv.org/abs/2405.20387v1	"Nonlinear Programs (NLPs) are prevalent in optimization-based control of
nonlinear systems. Solving general NLPs is computationally expensive,
necessitating the development of fast hardware or tractable suboptimal
approximations. This paper investigates the sensitivity of the solutions of
NLPs with polytopic constraints when the nonlinear continuous objective
function is approximated by a PieceWise-Affine (PWA) counterpart. By leveraging
perturbation analysis using a convex modulus, we derive guaranteed bounds on
the distance between the optimal solution of the original
polytopically-constrained NLP and that of its approximated formulation. Our
approach aids in determining criteria for achieving desired solution bounds.
Two case studies on the Eggholder function and nonlinear model predictive
control of an inverted pendulum demonstrate the theoretical results."	ArXiv
1300	"Towards Supporting Legal Argumentation with NLP: Is More Data Really All
  You Need?"	['T. Y. S. S Santosh', 'Kevin D. Ashley', 'Katie Atkinson', 'Matthias Grabmair']	2024-06-16 15:15:44+00:00	http://arxiv.org/abs/2406.10974v3	"Modeling legal reasoning and argumentation justifying decisions in cases has
always been central to AI & Law, yet contemporary developments in legal NLP
have increasingly focused on statistically classifying legal conclusions from
text. While conceptually simpler, these approaches often fall short in
providing usable justifications connecting to appropriate legal concepts. This
paper reviews both traditional symbolic works in AI & Law and recent advances
in legal NLP, and distills possibilities of integrating expert-informed
knowledge to strike a balance between scalability and explanation in symbolic
vs. data-driven approaches. We identify open challenges and discuss the
potential of modern NLP models and methods that integrate"	ArXiv
1301	"Understanding ""Democratization"" in NLP and ML Research"	['Arjun Subramonian', 'Vagrant Gautam', 'Dietrich Klakow', 'Zeerak Talat']	2024-06-17 14:47:06+00:00	http://arxiv.org/abs/2406.11598v2	"Recent improvements in natural language processing (NLP) and machine learning
(ML) and increased mainstream adoption have led to researchers frequently
discussing the ""democratization"" of artificial intelligence. In this paper, we
seek to clarify how democratization is understood in NLP and ML publications,
through large-scale mixed-methods analyses of papers using the keyword
""democra*"" published in NLP and adjacent venues. We find that democratization
is most frequently used to convey (ease of) access to or use of technologies,
without meaningfully engaging with theories of democratization, while research
using other invocations of ""democra*"" tends to be grounded in theories of
deliberation and debate. Based on our findings, we call for researchers to
enrich their use of the term democratization with appropriate theory, towards
democratic technologies beyond superficial access."	ArXiv
1302	"Sports Intelligence: Assessing the Sports Understanding Capabilities of
  Language Models through Question Answering from Text to Video"	['Zhengbang Yang', 'Haotian Xia', 'Jingxi Li', 'Zezhi Chen', 'Zhuangdi Zhu', 'Weining Shen']	2024-06-21 05:57:50+00:00	http://arxiv.org/abs/2406.14877v1	"Understanding sports is crucial for the advancement of Natural Language
Processing (NLP) due to its intricate and dynamic nature. Reasoning over
complex sports scenarios has posed significant challenges to current NLP
technologies which require advanced cognitive capabilities. Toward addressing
the limitations of existing benchmarks on sports understanding in the NLP
field, we extensively evaluated mainstream large language models for various
sports tasks. Our evaluation spans from simple queries on basic rules and
historical facts to complex, context-specific reasoning, leveraging strategies
from zero-shot to few-shot learning, and chain-of-thought techniques. In
addition to unimodal analysis, we further assessed the sports reasoning
capabilities of mainstream video language models to bridge the gap in
multimodal sports understanding benchmarking. Our findings highlighted the
critical challenges of sports understanding for NLP. We proposed a new
benchmark based on a comprehensive overview of existing sports datasets and
provided extensive error analysis which we hope can help identify future
research priorities in this field."	ArXiv
1303	"NLP Sampling: Combining MCMC and NLP Methods for Diverse Constrained
  Sampling"	['Marc Toussaint', 'Cornelius V. Braun', 'Joaquim Ortiz-Haro']	2024-07-03 11:55:06+00:00	http://arxiv.org/abs/2407.03035v1	"Generating diverse samples under hard constraints is a core challenge in many
areas. With this work we aim to provide an integrative view and framework to
combine methods from the fields of MCMC, constrained optimization, as well as
robotics, and gain insights in their strengths from empirical evaluations. We
propose NLP Sampling as a general problem formulation, propose a family of
restarting two-phase methods as a framework to integrated methods from across
the fields, and evaluate them on analytical and robotic manipulation planning
problems. Complementary to this, we provide several conceptual discussions,
e.g. on the role of Lagrange parameters, global sampling, and the idea of a
Diffused NLP and a corresponding model-based denoising sampler."	ArXiv
1304	"TokenVerse: Towards Unifying Speech and NLP Tasks via Transducer-based
  ASR"	['Shashi Kumar', 'Srikanth Madikeri', 'Juan Zuluaga-Gomez', 'Iuliia Thorbecke', 'Esaú Villatoro-Tello', 'Sergio Burdisso', 'Petr Motlicek', 'Karthik Pandia', 'Aravind Ganapathiraju']	2024-07-05 11:54:38+00:00	http://arxiv.org/abs/2407.04444v2	"In traditional conversational intelligence from speech, a cascaded pipeline
is used, involving tasks such as voice activity detection, diarization,
transcription, and subsequent processing with different NLP models for tasks
like semantic endpointing and named entity recognition (NER). Our paper
introduces TokenVerse, a single Transducer-based model designed to handle
multiple tasks. This is achieved by integrating task-specific tokens into the
reference text during ASR model training, streamlining the inference and
eliminating the need for separate NLP models. In addition to ASR, we conduct
experiments on 3 different tasks: speaker change detection, endpointing, and
NER. Our experiments on a public and a private dataset show that the proposed
method improves ASR by up to 7.7% in relative WER while outperforming the
cascaded pipeline approach in individual task performance. Our code is publicly
available: https://github.com/idiap/tokenverse-unifying-speech-nlp"	ArXiv
1305	AraFinNLP 2024: The First Arabic Financial NLP Shared Task	['Sanad Malaysha', 'Mo El-Haj', 'Saad Ezzini', 'Mohammed Khalilia', 'Mustafa Jarrar', 'Sultan Almujaiwel', 'Ismail Berrada', 'Houda Bouamor']	2024-07-13 09:28:44+00:00	http://arxiv.org/abs/2407.09818v1	"The expanding financial markets of the Arab world require sophisticated
Arabic NLP tools. To address this need within the banking domain, the Arabic
Financial NLP (AraFinNLP) shared task proposes two subtasks: (i) Multi-dialect
Intent Detection and (ii) Cross-dialect Translation and Intent Preservation.
This shared task uses the updated ArBanking77 dataset, which includes about 39k
parallel queries in MSA and four dialects. Each query is labeled with one or
more of a common 77 intents in the banking domain. These resources aim to
foster the development of robust financial Arabic NLP, particularly in the
areas of machine translation and banking chat-bots. A total of 45 unique teams
registered for this shared task, with 11 of them actively participated in the
test phase. Specifically, 11 teams participated in Subtask 1, while only 1 team
participated in Subtask 2. The winning team of Subtask 1 achieved F1 score of
0.8773, and the only team submitted in Subtask 2 achieved a 1.667 BLEU score."	ArXiv
1306	Improving Academic Skills Assessment with NLP and Ensemble Learning	['Xinyi Huang', 'Yingyi Wu', 'Danyang Zhang', 'Jiacheng Hu', 'Yujian Long']	2024-09-23 23:43:43+00:00	http://arxiv.org/abs/2409.19013v3	"This study addresses the critical challenges of assessing foundational
academic skills by leveraging advancements in natural language processing
(NLP). Traditional assessment methods often struggle to provide timely and
comprehensive feedback on key cognitive and linguistic aspects, such as
coherence, syntax, and analytical reasoning. Our approach integrates multiple
state-of-the-art NLP models, including BERT, RoBERTa, BART, DeBERTa, and T5,
within an ensemble learning framework. These models are combined through
stacking techniques using LightGBM and Ridge regression to enhance predictive
accuracy. The methodology involves detailed data preprocessing, feature
extraction, and pseudo-label learning to optimize model performance. By
incorporating sophisticated NLP techniques and ensemble learning, this study
significantly improves the accuracy and efficiency of assessments, offering a
robust solution that surpasses traditional methods and opens new avenues for
educational technology research focused on enhancing core academic
competencies."	ArXiv
1307	"Transforming Scholarly Landscapes: Influence of Large Language Models on
  Academic Fields beyond Computer Science"	['Aniket Pramanick', 'Yufang Hou', 'Saif M. Mohammad', 'Iryna Gurevych']	2024-09-29 01:32:35+00:00	http://arxiv.org/abs/2409.19508v1	"Large Language Models (LLMs) have ushered in a transformative era in Natural
Language Processing (NLP), reshaping research and extending NLP's influence to
other fields of study. However, there is little to no work examining the degree
to which LLMs influence other research fields. This work empirically and
systematically examines the influence and use of LLMs in fields beyond NLP. We
curate $106$ LLMs and analyze $\sim$$148k$ papers citing LLMs to quantify their
influence and reveal trends in their usage patterns. Our analysis reveals not
only the increasing prevalence of LLMs in non-CS fields but also the
disparities in their usage, with some fields utilizing them more frequently
than others since 2018, notably Linguistics and Engineering together accounting
for $\sim$$45\%$ of LLM citations. Our findings further indicate that most of
these fields predominantly employ task-agnostic LLMs, proficient in zero or
few-shot learning without requiring further fine-tuning, to address their
domain-specific problems. This study sheds light on the cross-disciplinary
impact of NLP through LLMs, providing a better understanding of the
opportunities and challenges."	ArXiv
1308	"Building a Multivariate Time Series Benchmarking Datasets Inspired by
  Natural Language Processing (NLP)"	['Mohammad Asif Ibna Mustafa', 'Ferdinand Heinrich']	2024-10-14 16:25:54+00:00	http://arxiv.org/abs/2410.10687v1	"Time series analysis has become increasingly important in various domains,
and developing effective models relies heavily on high-quality benchmark
datasets. Inspired by the success of Natural Language Processing (NLP)
benchmark datasets in advancing pre-trained models, we propose a new approach
to create a comprehensive benchmark dataset for time series analysis. This
paper explores the methodologies used in NLP benchmark dataset creation and
adapts them to the unique challenges of time series data. We discuss the
process of curating diverse, representative, and challenging time series
datasets, highlighting the importance of domain relevance and data complexity.
Additionally, we investigate multi-task learning strategies that leverage the
benchmark dataset to enhance the performance of time series models. This
research contributes to the broader goal of advancing the state-of-the-art in
time series modeling by adopting successful strategies from the NLP domain."	ArXiv
1309	Advancing NLP Security by Leveraging LLMs as Adversarial Engines	['Sudarshan Srinivasan', 'Maria Mahbub', 'Amir Sadovnik']	2024-10-23 18:32:03+00:00	http://arxiv.org/abs/2410.18215v1	"This position paper proposes a novel approach to advancing NLP security by
leveraging Large Language Models (LLMs) as engines for generating diverse
adversarial attacks. Building upon recent work demonstrating LLMs'
effectiveness in creating word-level adversarial examples, we argue for
expanding this concept to encompass a broader range of attack types, including
adversarial patches, universal perturbations, and targeted attacks. We posit
that LLMs' sophisticated language understanding and generation capabilities can
produce more effective, semantically coherent, and human-like adversarial
examples across various domains and classifier architectures. This paradigm
shift in adversarial NLP has far-reaching implications, potentially enhancing
model robustness, uncovering new vulnerabilities, and driving innovation in
defense mechanisms. By exploring this new frontier, we aim to contribute to the
development of more secure, reliable, and trustworthy NLP systems for critical
applications."	ArXiv
1310	Human-Centric NLP or AI-Centric Illusion?: A Critical Investigation	['Piyapath T Spencer']	2024-12-14 19:16:53+00:00	http://arxiv.org/abs/2412.10939v1	"Human-Centric NLP often claims to prioritise human needs and values, yet many
implementations reveal an underlying AI-centric focus. Through an analysis of
case studies in language modelling, behavioural testing, and multi-modal
alignment, this study identifies a significant gap between the ideas of
human-centricity and actual practices. Key issues include misalignment with
human-centred design principles, the reduction of human factors to mere
benchmarks, and insufficient consideration of real-world impacts. The
discussion explores whether Human-Centric NLP embodies true human-centred
design, emphasising the need for interdisciplinary collaboration and ethical
considerations. The paper advocates for a redefinition of Human-Centric NLP,
urging a broader focus on real-world utility and societal implications to
ensure that language technologies genuinely serve and empower users."	ArXiv
1311	"A Thorough Investigation into the Application of Deep CNN for Enhancing
  Natural Language Processing Capabilities"	['Chang Weng', 'Scott Rood', 'Mehdi Ali Ramezani', 'Amir Aslani', 'Reza Zarrab', 'Wang Zwuo', 'Sanjeev Salimans', 'Tim Satheesh']	2024-12-20 13:53:41+00:00	http://arxiv.org/abs/2412.15900v1	"Natural Language Processing (NLP) is widely used in fields like machine
translation and sentiment analysis. However, traditional NLP models struggle
with accuracy and efficiency. This paper introduces Deep Convolutional Neural
Networks (DCNN) into NLP to address these issues. By integrating DCNN, machine
learning (ML) algorithms, and generative adversarial networks (GAN), the study
improves language understanding, reduces ambiguity, and enhances task
performance. The high-performance NLP model shows a 10% improvement in
segmentation accuracy and a 4% increase in recall rate compared to traditional
models. This integrated approach excels in tasks such as word segmentation,
part-of-speech tagging, machine translation, and text classification, offering
better recognition accuracy and processing efficiency."	ArXiv
1312	"Comparative Performance of Advanced NLP Models and LLMs in Multilingual
  Geo-Entity Detection"	['Kalin Kopanov']	2024-12-29 09:47:14+00:00	http://arxiv.org/abs/2412.20414v1	"The integration of advanced Natural Language Processing (NLP) methodologies
and Large Language Models (LLMs) has significantly enhanced the extraction and
analysis of geospatial data from multilingual texts, impacting sectors such as
national and international security. This paper presents a comprehensive
evaluation of leading NLP models -- SpaCy, XLM-RoBERTa, mLUKE, GeoLM -- and
LLMs, specifically OpenAI's GPT 3.5 and GPT 4, within the context of
multilingual geo-entity detection. Utilizing datasets from Telegram channels in
English, Russian, and Arabic, we examine the performance of these models
through metrics such as accuracy, precision, recall, and F1 scores, to assess
their effectiveness in accurately identifying geospatial references. The
analysis exposes each model's distinct advantages and challenges, underscoring
the complexities involved in achieving precise geo-entity identification across
varied linguistic landscapes. The conclusions drawn from this experiment aim to
direct the enhancement and creation of more advanced and inclusive NLP tools,
thus advancing the field of geospatial analysis and its application to global
security."	ArXiv
1313	"A frame semantic overview of NLP-based information extraction for
  cancer-related EHR notes"	['Surabhi Datta', 'Elmer V Bernstam', 'Kirk Roberts']	2019-04-02 20:27:42+00:00	http://arxiv.org/abs/1904.01655v1	"Objective: There is a lot of information about cancer in Electronic Health
Record (EHR) notes that can be useful for biomedical research provided natural
language processing (NLP) methods are available to extract and structure this
information. In this paper, we present a scoping review of existing clinical
NLP literature for cancer. Methods: We identified studies describing an NLP
method to extract specific cancer-related information from EHR sources from
PubMed, Google Scholar, ACL Anthology, and existing reviews. Two exclusion
criteria were used in this study. We excluded articles where the extraction
techniques used were too broad to be represented as frames and also where very
low-level extraction methods were used. 79 articles were included in the final
review. We organized this information according to frame semantic principles to
help identify common areas of overlap and potential gaps. Results: Frames were
created from the reviewed articles pertaining to cancer information such as
cancer diagnosis, tumor description, cancer procedure, breast cancer diagnosis,
prostate cancer diagnosis and pain in prostate cancer patients. These frames
included both a definition as well as specific frame elements (i.e. extractable
attributes). We found that cancer diagnosis was the most common frame among the
reviewed papers (36 out of 79), with recent work focusing on extracting
information related to treatment and breast cancer diagnosis. Conclusion: The
list of common frames described in this paper identifies important
cancer-related information extracted by existing NLP techniques and serves as a
useful resource for future researchers requiring cancer information extracted
from EHR notes. We also argue, due to the heavy duplication of cancer NLP
systems, that a general purpose resource of annotated cancer frames and
corresponding NLP tools would be valuable."	ArXiv
1314	A Panoramic Survey of Natural Language Processing in the Arab World	['Kareem Darwish', 'Nizar Habash', 'Mourad Abbas', 'Hend Al-Khalifa', 'Huseein T. Al-Natsheh', 'Samhaa R. El-Beltagy', 'Houda Bouamor', 'Karim Bouzoubaa', 'Violetta Cavalli-Sforza', 'Wassim El-Hajj', 'Mustafa Jarrar', 'Hamdy Mubarak']	2020-11-25 10:45:38+00:00	http://arxiv.org/abs/2011.12631v3	"The term natural language refers to any system of symbolic communication
(spoken, signed or written) without intentional human planning and design. This
distinguishes natural languages such as Arabic and Japanese from artificially
constructed languages such as Esperanto or Python. Natural language processing
(NLP) is the sub-field of artificial intelligence (AI) focused on modeling
natural languages to build applications such as speech recognition and
synthesis, machine translation, optical character recognition (OCR), sentiment
analysis (SA), question answering, dialogue systems, etc. NLP is a highly
interdisciplinary field with connections to computer science, linguistics,
cognitive science, psychology, mathematics and others. Some of the earliest AI
applications were in NLP (e.g., machine translation); and the last decade
(2010-2020) in particular has witnessed an incredible increase in quality,
matched with a rise in public awareness, use, and expectations of what may have
seemed like science fiction in the past. NLP researchers pride themselves on
developing language independent models and tools that can be applied to all
human languages, e.g. machine translation systems can be built for a variety of
languages using the same basic mechanisms and models. However, the reality is
that some languages do get more attention (e.g., English and Chinese) than
others (e.g., Hindi and Swahili). Arabic, the primary language of the Arab
world and the religious language of millions of non-Arab Muslims is somewhere
in the middle of this continuum. Though Arabic NLP has many challenges, it has
seen many successes and developments. Next we discuss Arabic's main challenges
as a necessary background, and we present a brief history of Arabic NLP. We
then survey a number of its research areas, and close with a critical
discussion of the future of Arabic NLP."	ArXiv
1315	Transient Chaos in BERT	['Katsuma Inoue', 'Soh Ohara', 'Yasuo Kuniyoshi', 'Kohei Nakajima']	2021-06-06 17:02:29+00:00	http://arxiv.org/abs/2106.03181v2	"Language is an outcome of our complex and dynamic human-interactions and the
technique of natural language processing (NLP) is hence built on human
linguistic activities. Bidirectional Encoder Representations from Transformers
(BERT) has recently gained its popularity by establishing the state-of-the-art
scores in several NLP benchmarks. A Lite BERT (ALBERT) is literally
characterized as a lightweight version of BERT, in which the number of BERT
parameters is reduced by repeatedly applying the same neural network called
Transformer's encoder layer. By pre-training the parameters with a massive
amount of natural language data, ALBERT can convert input sentences into
versatile high-dimensional vectors potentially capable of solving multiple NLP
tasks. In that sense, ALBERT can be regarded as a well-designed
high-dimensional dynamical system whose operator is the Transformer's encoder,
and essential structures of human language are thus expected to be encapsulated
in its dynamics. In this study, we investigated the embedded properties of
ALBERT to reveal how NLP tasks are effectively solved by exploiting its
dynamics. We thereby aimed to explore the nature of human language from the
dynamical expressions of the NLP model. Our short-term analysis clarified that
the pre-trained model stably yields trajectories with higher dimensionality,
which would enhance the expressive capacity required for NLP tasks. Also, our
long-term analysis revealed that ALBERT intrinsically shows transient chaos, a
typical nonlinear phenomenon showing chaotic dynamics only in its transient,
and the pre-trained ALBERT model tends to produce the chaotic trajectory for a
significantly longer time period compared to a randomly-initialized one. Our
results imply that local chaoticity would contribute to improving NLP
performance, uncovering a novel aspect in the role of chaotic dynamics in human
language behaviors."	ArXiv
1316	"Robust Learning for Text Classification with Multi-source Noise
  Simulation and Hard Example Mining"	['Guowei Xu', 'Wenbiao Ding', 'Weiping Fu', 'Zhongqin Wu', 'Zitao Liu']	2021-07-15 04:39:22+00:00	http://arxiv.org/abs/2107.07113v1	"Many real-world applications involve the use of Optical Character Recognition
(OCR) engines to transform handwritten images into transcripts on which
downstream Natural Language Processing (NLP) models are applied. In this
process, OCR engines may introduce errors and inputs to downstream NLP models
become noisy. Despite that pre-trained models achieve state-of-the-art
performance in many NLP benchmarks, we prove that they are not robust to noisy
texts generated by real OCR engines. This greatly limits the application of NLP
models in real-world scenarios. In order to improve model performance on noisy
OCR transcripts, it is natural to train the NLP model on labelled noisy texts.
However, in most cases there are only labelled clean texts. Since there is no
handwritten pictures corresponding to the text, it is impossible to directly
use the recognition model to obtain noisy labelled data. Human resources can be
employed to copy texts and take pictures, but it is extremely expensive
considering the size of data for model training. Consequently, we are
interested in making NLP models intrinsically robust to OCR errors in a low
resource manner. We propose a novel robust training framework which 1) employs
simple but effective methods to directly simulate natural OCR noises from clean
texts and 2) iteratively mines the hard examples from a large number of
simulated samples for optimal performance. 3) To make our model learn
noise-invariant representations, a stability loss is employed. Experiments on
three real-world datasets show that the proposed framework boosts the
robustness of pre-trained models by a large margin. We believe that this work
can greatly promote the application of NLP models in actual scenarios, although
the algorithm we use is simple and straightforward. We make our codes and three
datasets publicly
available\footnote{https://github.com/tal-ai/Robust-learning-MSSHEM}."	ArXiv
1317	"mmPose-NLP: A Natural Language Processing Approach to Precise Skeletal
  Pose Estimation using mmWave Radars"	['Arindam Sengupta', 'Siyang Cao']	2021-07-21 19:45:17+00:00	http://arxiv.org/abs/2107.10327v1	"In this paper we presented mmPose-NLP, a novel Natural Language Processing
(NLP) inspired Sequence-to-Sequence (Seq2Seq) skeletal key-point estimator
using millimeter-wave (mmWave) radar data. To the best of the author's
knowledge, this is the first method to precisely estimate upto 25 skeletal
key-points using mmWave radar data alone. Skeletal pose estimation is critical
in several applications ranging from autonomous vehicles, traffic monitoring,
patient monitoring, gait analysis, to defense security forensics, and aid both
preventative and actionable decision making. The use of mmWave radars for this
task, over traditionally employed optical sensors, provide several advantages,
primarily its operational robustness to scene lighting and adverse weather
conditions, where optical sensor performance degrade significantly. The mmWave
radar point-cloud (PCL) data is first voxelized (analogous to tokenization in
NLP) and $N$ frames of the voxelized radar data (analogous to a text paragraph
in NLP) is subjected to the proposed mmPose-NLP architecture, where the voxel
indices of the 25 skeletal key-points (analogous to keyword extraction in NLP)
are predicted. The voxel indices are converted back to real world 3-D
coordinates using the voxel dictionary used during the tokenization process.
Mean Absolute Error (MAE) metrics were used to measure the accuracy of the
proposed system against the ground truth, with the proposed mmPose-NLP offering
<3 cm localization errors in the depth, horizontal and vertical axes. The
effect of the number of input frames vs performance/accuracy was also studied
for N = {1,2,..,10}. A comprehensive methodology, results, discussions and
limitations are presented in this paper. All the source codes and results are
made available on GitHub for furthering research and development in this
critical yet emerging domain of skeletal key-point estimation using mmWave
radars."	ArXiv
1318	"Multi-Task Text Classification using Graph Convolutional Networks for
  Large-Scale Low Resource Language"	['Mounika Marreddy', 'Subba Reddy Oota', 'Lakshmi Sireesha Vakada', 'Venkata Charan Chinni', 'Radhika Mamidi']	2022-05-02 20:44:12+00:00	http://arxiv.org/abs/2205.01204v1	"Graph Convolutional Networks (GCN) have achieved state-of-art results on
single text classification tasks like sentiment analysis, emotion detection,
etc. However, the performance is achieved by testing and reporting on
resource-rich languages like English. Applying GCN for multi-task text
classification is an unexplored area. Moreover, training a GCN or adopting an
English GCN for Indian languages is often limited by data availability, rich
morphological variation, syntax, and semantic differences. In this paper, we
study the use of GCN for the Telugu language in single and multi-task settings
for four natural language processing (NLP) tasks, viz. sentiment analysis (SA),
emotion identification (EI), hate-speech (HS), and sarcasm detection (SAR). In
order to evaluate the performance of GCN with one of the Indian languages,
Telugu, we analyze the GCN based models with extensive experiments on four
downstream tasks. In addition, we created an annotated Telugu dataset, TEL-NLP,
for the four NLP tasks. Further, we propose a supervised graph reconstruction
method, Multi-Task Text GCN (MT-Text GCN) on the Telugu that leverages to
simultaneously (i) learn the low-dimensional word and sentence graph embeddings
from word-sentence graph reconstruction using graph autoencoder (GAE) and (ii)
perform multi-task text classification using these latent sentence graph
embeddings. We argue that our proposed MT-Text GCN achieves significant
improvements on TEL-NLP over existing Telugu pretrained word embeddings, and
multilingual pretrained Transformer models: mBERT, and XLM-R. On TEL-NLP, we
achieve a high F1-score for four NLP tasks: SA (0.84), EI (0.55), HS (0.83) and
SAR (0.66). Finally, we show our model's quantitative and qualitative analysis
on the four NLP tasks in Telugu."	ArXiv
1319	AEON: A Method for Automatic Evaluation of NLP Test Cases	['Jen-tse Huang', 'Jianping Zhang', 'Wenxuan Wang', 'Pinjia He', 'Yuxin Su', 'Michael R. Lyu']	2022-05-13 03:47:13+00:00	http://arxiv.org/abs/2205.06439v1	"Due to the labor-intensive nature of manual test oracle construction, various
automated testing techniques have been proposed to enhance the reliability of
Natural Language Processing (NLP) software. In theory, these techniques mutate
an existing test case (e.g., a sentence with its label) and assume the
generated one preserves an equivalent or similar semantic meaning and thus, the
same label. However, in practice, many of the generated test cases fail to
preserve similar semantic meaning and are unnatural (e.g., grammar errors),
which leads to a high false alarm rate and unnatural test cases. Our evaluation
study finds that 44% of the test cases generated by the state-of-the-art (SOTA)
approaches are false alarms. These test cases require extensive manual checking
effort, and instead of improving NLP software, they can even degrade NLP
software when utilized in model training. To address this problem, we propose
AEON for Automatic Evaluation Of NLP test cases. For each generated test case,
it outputs scores based on semantic similarity and language naturalness. We
employ AEON to evaluate test cases generated by four popular testing techniques
on five datasets across three typical NLP tasks. The results show that AEON
aligns the best with human judgment. In particular, AEON achieves the best
average precision in detecting semantic inconsistent test cases, outperforming
the best baseline metric by 10%. In addition, AEON also has the highest average
precision of finding unnatural test cases, surpassing the baselines by more
than 15%. Moreover, model training with test cases prioritized by AEON leads to
models that are more accurate and robust, demonstrating AEON's potential in
improving NLP software."	ArXiv
1320	"An Empirical Study on the Bugs Found while Reusing Pre-trained Natural
  Language Processing Models"	['Rangeet Pan', 'Sumon Biswas', 'Mohna Chakraborty', 'Breno Dantas Cruz', 'Hridesh Rajan']	2022-11-30 20:25:50+00:00	http://arxiv.org/abs/2212.00105v1	"In NLP, reusing pre-trained models instead of training from scratch has
gained popularity; however, NLP models are mostly black boxes, very large, and
often require significant resources. To ease, models trained with large corpora
are made available, and developers reuse them for different problems. In
contrast, developers mostly build their models from scratch for traditional
DL-related problems. By doing so, they have control over the choice of
algorithms, data processing, model structure, tuning hyperparameters, etc.
Whereas in NLP, due to the reuse of the pre-trained models, NLP developers are
limited to little to no control over such design decisions. They either apply
tuning or transfer learning on pre-trained models to meet their requirements.
Also, NLP models and their corresponding datasets are significantly larger than
the traditional DL models and require heavy computation. Such reasons often
lead to bugs in the system while reusing the pre-trained models. While bugs in
traditional DL software have been intensively studied, the nature of extensive
reuse and black-box structure motivates us to understand the different types of
bugs that occur while reusing NLP models? What are the root causes of those
bugs? How do these bugs affect the system? To answer these questions, We
studied the bugs reported while reusing the 11 popular NLP models. We mined
9,214 issues from GitHub repositories and identified 984 bugs. We created a
taxonomy with bug types, root causes, and impacts. Our observations led to
several findings, including limited access to model internals resulting in a
lack of robustness, lack of input validation leading to the propagation of
algorithmic and data bias, and high-resource consumption causing more crashes,
etc. Our observations suggest several bug patterns, which would greatly
facilitate further efforts in reducing bugs in pre-trained models and code
reuse."	ArXiv
1321	The State of Human-centered NLP Technology for Fact-checking	['Anubrata Das', 'Houjiang Liu', 'Venelin Kovatchev', 'Matthew Lease']	2023-01-08 15:13:13+00:00	http://arxiv.org/abs/2301.03056v1	"Misinformation threatens modern society by promoting distrust in science,
changing narratives in public health, heightening social polarization, and
disrupting democratic elections and financial markets, among a myriad of other
societal harms. To address this, a growing cadre of professional fact-checkers
and journalists provide high-quality investigations into purported facts.
However, these largely manual efforts have struggled to match the enormous
scale of the problem. In response, a growing body of Natural Language
Processing (NLP) technologies have been proposed for more scalable
fact-checking. Despite tremendous growth in such research, however, practical
adoption of NLP technologies for fact-checking still remains in its infancy
today.
  In this work, we review the capabilities and limitations of the current NLP
technologies for fact-checking. Our particular focus is to further chart the
design space for how these technologies can be harnessed and refined in order
to better meet the needs of human fact-checkers. To do so, we review key
aspects of NLP-based fact-checking: task formulation, dataset construction,
modeling, and human-centered strategies, such as explainable models and
human-in-the-loop approaches. Next, we review the efficacy of applying
NLP-based fact-checking tools to assist human fact-checkers. We recommend that
future research include collaboration with fact-checker stakeholders early on
in NLP research, as well as incorporation of human-centered design practices in
model development, in order to further guide technology development for human
use and practical adoption. Finally, we advocate for more research on benchmark
development supporting extrinsic evaluation of human-centered fact-checking
technologies."	ArXiv
1322	"Mining Clinical Notes for Physical Rehabilitation Exercise Information:
  Natural Language Processing Algorithm Development and Validation Study"	['Sonish Sivarajkumar', 'Fengyi Gao', 'Parker E. Denny', 'Bayan M. Aldhahwani', 'Shyam Visweswaran', 'Allyn Bove', 'Yanshan Wang']	2023-03-22 13:46:16+00:00	http://arxiv.org/abs/2303.13466v2	"Post-stroke patient rehabilitation requires precise, personalized treatment
plans. Natural Language Processing (NLP) offers potential to extract valuable
exercise information from clinical notes, aiding in the development of more
effective rehabilitation strategies. Objective: This study aims to develop and
evaluate a variety of NLP algorithms to extract and categorize physical
rehabilitation exercise information from the clinical notes of post-stroke
patients treated at the University of Pittsburgh Medical Center. A cohort of
13,605 patients diagnosed with stroke was identified, and their clinical notes
containing rehabilitation therapy notes were retrieved. A comprehensive
clinical ontology was created to represent various aspects of physical
rehabilitation exercises. State-of-the-art NLP algorithms were then developed
and compared, including rule-based, machine learning-based algorithms, and
large language model (LLM)-based algorithms (ChatGPT). Analysis was conducted
on a dataset comprising 23,724 notes with detailed demographic and clinical
characteristics. The rule-based NLP algorithm demonstrated superior performance
in most areas, particularly in detecting the 'Right Side' location with an F1
score of 0.975, outperforming Gradient Boosting by 0.063. Gradient Boosting
excelled in 'Lower Extremity' location detection (F1 score: 0.978), surpassing
rule-based NLP by 0.023. It also showed notable performance in 'Passive Range
of Motion' with an F1 score of 0.970, a 0.032 improvement over rule-based NLP.
The rule-based algorithm efficiently handled 'Duration', 'Sets', and 'Reps'
with F1 scores up to 0.65. LLM-based NLP, particularly ChatGPT with few-shot
prompts, achieved high recall but generally lower precision and F1 scores.
However, it notably excelled in 'Backward Plane' motion detection, achieving an
F1 score of 0.846, surpassing the rule-based algorithm's 0.720."	ArXiv
1323	"NLP Verification: Towards a General Methodology for Certifying
  Robustness"	['Marco Casadio', 'Tanvi Dinkar', 'Ekaterina Komendantskaya', 'Luca Arnaboldi', 'Matthew L. Daggitt', 'Omri Isac', 'Guy Katz', 'Verena Rieser', 'Oliver Lemon']	2024-03-15 09:43:52+00:00	http://arxiv.org/abs/2403.10144v2	"Deep neural networks have exhibited substantial success in the field of
Natural Language Processing and ensuring their safety and reliability is
crucial: there are safety critical contexts where such models must be robust to
variability or attack, and give guarantees over their output. Unlike Computer
Vision, NLP lacks a unified verification methodology and, despite recent
advancements in literature, they are often light on the pragmatical issues of
NLP verification. In this paper, we attempt to distil and evaluate general
components of an NLP verification pipeline, that emerges from the progress in
the field to date. Our contributions are two-fold. Firstly, we give a general
(i.e. algorithm-independent) characterisation of verifiable subspaces that
result from embedding sentences into continuous spaces. We identify, and give
an effective method to deal with, the technical challenge of semantic
generalisability of verified subspaces; and propose it as a standard metric in
the NLP verification pipelines (alongside with the standard metrics of model
accuracy and model verifiability). Secondly, we propose a general methodology
to analyse the effect of the embedding gap -- a problem that refers to the
discrepancy between verification of geometric subspaces, and the semantic
meaning of sentences which the geometric subspaces are supposed to represent.
In extreme cases, poor choices in embedding of sentences may invalidate
verification results. We propose a number of practical NLP methods that can
help to quantify the effects of the embedding gap; and in particular we propose
the metric of falsifiability of semantic subspaces as another fundamental
metric to be reported as part of the NLP verification pipeline. We believe that
together these general principles pave the way towards a more consolidated and
effective development of this new domain."	ArXiv
1324	CLIBE: Detecting Dynamic Backdoors in Transformer-based NLP Models	['Rui Zeng', 'Xi Chen', 'Yuwen Pu', 'Xuhong Zhang', 'Tianyu Du', 'Shouling Ji']	2024-09-02 11:59:56+00:00	http://arxiv.org/abs/2409.01193v2	"Backdoors can be injected into NLP models to induce misbehavior when the
input text contains a specific feature, known as a trigger, which the attacker
secretly selects. Unlike fixed words, phrases, or sentences used in the static
text trigger, NLP dynamic backdoor attacks design triggers associated with
abstract and latent text features, making them considerably stealthier than
traditional static backdoor attacks. However, existing research on NLP backdoor
detection primarily focuses on defending against static backdoor attacks, while
detecting dynamic backdoors in NLP models remains largely unexplored. This
paper presents CLIBE, the first framework to detect dynamic backdoors in
Transformer-based NLP models. CLIBE injects a ""few-shot perturbation"" into the
suspect Transformer model by crafting optimized weight perturbation in the
attention layers to make the perturbed model classify a limited number of
reference samples as a target label. Subsequently, CLIBE leverages the
generalization ability of this few-shot perturbation to determine whether the
original model contains a dynamic backdoor. Extensive evaluation on three
advanced NLP dynamic backdoor attacks, two widely-used Transformer frameworks,
and four real-world classification tasks strongly validates the effectiveness
of CLIBE. We also demonstrate the robustness of CLIBE against various adaptive
attacks. Furthermore, we employ CLIBE to scrutinize 49 popular Transformer
models on Hugging Face and discover one exhibiting a high probability of
containing a dynamic backdoor. We have contacted Hugging Face and provided
detailed evidence of this model's backdoor behavior. Moreover, we extend CLIBE
to detect backdoor text generation models modified to exhibit toxic behavior.
To the best of our knowledge, CLIBE is the first framework capable of detecting
backdoors in text generation models without access to trigger input test
samples."	ArXiv
1325	Non-Local Priors for High-Dimensional Estimation	['David Rossell', 'Donatello Telesca']	2014-02-20 19:20:49+00:00	http://arxiv.org/abs/1402.5107v3	"Simultaneously achieving parsimony and good predictive power in high
dimensions is a main challenge in statistics. Non-local priors (NLPs) possess
appealing properties for high-dimensional model choice, but their use for
estimation has not been studied in detail. We show that, for regular models,
Bayesian model averaging (BMA) estimates based on NLPs shrink spurious
parameters either at fast polynomial or quasi-exponential rates as the sample
size $n$ increases (depending on the chosen prior density). Non-spurious
parameter estimates only differ from the oracle MLE by a factor of $n^{-1}$. We
extend some results to linear models with dimension $p$ growing with $n$.
  Coupled with our theoretical investigations, we outline the constructive
representation of NLPs as mixtures of truncated distributions. From a
practitioners' perspective, our work enables simple posterior sampling and
extending NLPs beyond previous proposals. Our results show notable
high-dimensional estimation for linear models with $p>>n$ at reduced
computational cost. NLPs provided lower estimation error than benchmark and
hyper-g priors, SCAD and LASSO in simulations, and in gene expression data
achieved higher cross-validated $R^2$ with an order of magnitude less
predictors. Remarkably, these results were obtained without the need to
pre-screen predictors. Our findings contribute to the debate of whether
different priors should be used for estimation and model selection, showing
that selection priors may actually be desirable for high-dimensional
estimation."	ArXiv
1326	"Interpreting and improving natural-language processing (in machines)
  with natural language-processing (in the brain)"	['Mariya Toneva', 'Leila Wehbe']	2019-05-28 14:13:09+00:00	http://arxiv.org/abs/1905.11833v4	"Neural networks models for NLP are typically implemented without the explicit
encoding of language rules and yet they are able to break one performance
record after another. This has generated a lot of research interest in
interpreting the representations learned by these networks. We propose here a
novel interpretation approach that relies on the only processing system we have
that does understand language: the human brain. We use brain imaging recordings
of subjects reading complex natural text to interpret word and sequence
embeddings from 4 recent NLP models - ELMo, USE, BERT and Transformer-XL. We
study how their representations differ across layer depth, context length, and
attention type. Our results reveal differences in the context-related
representations across these models. Further, in the transformer models, we
find an interaction between layer depth and context length, and between layer
depth and attention type. We finally hypothesize that altering BERT to better
align with brain recordings would enable it to also better understand language.
Probing the altered BERT using syntactic NLP tasks reveals that the model with
increased brain-alignment outperforms the original model. Cognitive
neuroscientists have already begun using NLP networks to study the brain, and
this work closes the loop to allow the interaction between NLP and cognitive
neuroscience to be a true cross-pollination."	ArXiv
1327	"English dictionaries, gold and silver standard corpora for biomedical
  natural language processing related to SARS-CoV-2 and COVID-19"	['Salma Kazemi Rashed', 'Rafsan Ahmed', 'Johan Frid', 'Sonja Aits']	2020-03-22 11:37:58+00:00	http://arxiv.org/abs/2003.09865v3	"Automated information extraction with natural language processing (NLP) tools
is required to gain systematic insights from the large number of COVID-19
publications, reports and social media posts, which far exceed human processing
capabilities. A key challenge for NLP is the extensive variation in terminology
used to describe medical entities, which was especially pronounced for this
newly emergent disease. Here we present an NLP toolbox comprising very large
English dictionaries of synonyms for SARS-CoV-2 (including variant names) and
COVID-19, which can be used with dictionary-based NLP tools. We also present a
silver standard corpus generated with the dictionaries, and a gold standard
corpus, consisting of PubMed abstracts manually annotated for disease, virus,
symptom, protein/gene, cell type, chemical and species terms, which can be used
to train and evaluate COVID-19-related NLP tools. Code for annotation, which
can be used to expand the silver standard corpus or for text mining is also
included. This toolbox is freely available on GitHub (on
https://github.com/Aitslab/corona) and zenodo
(https://doi.org/10.5281/zenodo.6642275). The toolbox can be used for a variety
of text analytics tasks related to the COVID-19 crisis and has already been
used to create a COVID-19 knowledge graph, study the variability and evolution
of COVID-19-related terminology and develop and benchmark text mining tools."	ArXiv
1328	"TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and
  Adversarial Training in NLP"	['John X. Morris', 'Eli Lifland', 'Jin Yong Yoo', 'Jake Grigsby', 'Di Jin', 'Yanjun Qi']	2020-04-29 21:33:35+00:00	http://arxiv.org/abs/2005.05909v4	"While there has been substantial research using adversarial attacks to
analyze NLP models, each attack is implemented in its own code repository. It
remains challenging to develop NLP attacks and utilize them to improve model
performance. This paper introduces TextAttack, a Python framework for
adversarial attacks, data augmentation, and adversarial training in NLP.
TextAttack builds attacks from four components: a goal function, a set of
constraints, a transformation, and a search method. TextAttack's modular design
enables researchers to easily construct attacks from combinations of novel and
existing components. TextAttack provides implementations of 16 adversarial
attacks from the literature and supports a variety of models and datasets,
including BERT and other transformers, and all GLUE tasks. TextAttack also
includes data augmentation and adversarial training modules for using
components of adversarial attacks to improve model accuracy and robustness.
TextAttack is democratizing NLP: anyone can try data augmentation and
adversarial training on any model or dataset, with just a few lines of code.
Code and tutorials are available at https://github.com/QData/TextAttack."	ArXiv
1329	An Interactive Tool for Natural Language Processing on Clinical Text	['Gaurav Trivedi', 'Phuong Pham', 'Wendy Chapman', 'Rebecca Hwa', 'Janyce Wiebe', 'Harry Hochheiser']	2017-07-06 17:44:15+00:00	http://arxiv.org/abs/1707.01890v2	"Natural Language Processing (NLP) systems often make use of machine learning
techniques that are unfamiliar to end-users who are interested in analyzing
clinical records. Although NLP has been widely used in extracting information
from clinical text, current systems generally do not support model revision
based on feedback from domain experts.
  We present a prototype tool that allows end users to visualize and review the
outputs of an NLP system that extracts binary variables from clinical text. Our
tool combines multiple visualizations to help the users understand these
results and make any necessary corrections, thus forming a feedback loop and
helping improve the accuracy of the NLP models. We have tested our prototype in
a formative think-aloud user study with clinicians and researchers involved in
colonoscopy research. Results from semi-structured interviews and a System
Usability Scale (SUS) analysis show that the users are able to quickly start
refining NLP models, despite having very little or no experience with machine
learning. Observations from these sessions suggest revisions to the interface
to better support review workflow and interpretation of results."	ArXiv
1330	"One Model to Rule them all: Multitask and Multilingual Modelling for
  Lexical Analysis"	['Johannes Bjerva']	2017-11-03 10:53:05+00:00	http://arxiv.org/abs/1711.01100v1	"When learning a new skill, you take advantage of your preexisting skills and
knowledge. For instance, if you are a skilled violinist, you will likely have
an easier time learning to play cello. Similarly, when learning a new language
you take advantage of the languages you already speak. For instance, if your
native language is Norwegian and you decide to learn Dutch, the lexical overlap
between these two languages will likely benefit your rate of language
acquisition. This thesis deals with the intersection of learning multiple tasks
and learning multiple languages in the context of Natural Language Processing
(NLP), which can be defined as the study of computational processing of human
language. Although these two types of learning may seem different on the
surface, we will see that they share many similarities.
  The traditional approach in NLP is to consider a single task for a single
language at a time. However, recent advances allow for broadening this
approach, by considering data for multiple tasks and languages simultaneously.
This is an important approach to explore further as the key to improving the
reliability of NLP, especially for low-resource languages, is to take advantage
of all relevant data whenever possible. In doing so, the hope is that in the
long term, low-resource languages can benefit from the advances made in NLP
which are currently to a large extent reserved for high-resource languages.
This, in turn, may then have positive consequences for, e.g., language
preservation, as speakers of minority languages will have a lower degree of
pressure to using high-resource languages. In the short term, answering the
specific research questions posed should be of use to NLP researchers working
towards the same goal."	ArXiv
1331	"T3: Tree-Autoencoder Constrained Adversarial Text Generation for
  Targeted Attack"	['Boxin Wang', 'Hengzhi Pei', 'Boyuan Pan', 'Qian Chen', 'Shuohang Wang', 'Bo Li']	2019-12-22 03:02:42+00:00	http://arxiv.org/abs/1912.10375v2	"Adversarial attacks against natural language processing systems, which
perform seemingly innocuous modifications to inputs, can induce arbitrary
mistakes to the target models. Though raised great concerns, such adversarial
attacks can be leveraged to estimate the robustness of NLP models. Compared
with the adversarial example generation in continuous data domain (e.g.,
image), generating adversarial text that preserves the original meaning is
challenging since the text space is discrete and non-differentiable. To handle
these challenges, we propose a target-controllable adversarial attack framework
T3, which is applicable to a range of NLP tasks. In particular, we propose a
tree-based autoencoder to embed the discrete text data into a continuous
representation space, upon which we optimize the adversarial perturbation. A
novel tree-based decoder is then applied to regularize the syntactic
correctness of the generated text and manipulate it on either sentence
(T3(Sent)) or word (T3(Word)) level. We consider two most representative NLP
tasks: sentiment analysis and question answering (QA). Extensive experimental
results and human studies show that T3 generated adversarial texts can
successfully manipulate the NLP models to output the targeted incorrect answer
without misleading the human. Moreover, we show that the generated adversarial
texts have high transferability which enables the black-box attacks in
practice. Our work sheds light on an effective and general way to examine the
robustness of NLP models. Our code is publicly available at
https://github.com/AI-secure/T3/."	ArXiv
1332	BoostingBERT:Integrating Multi-Class Boosting into BERT for NLP Tasks	['Tongwen Huang', 'Qingyun She', 'Junlin Zhang']	2020-09-13 09:07:14+00:00	http://arxiv.org/abs/2009.05959v1	"As a pre-trained Transformer model, BERT (Bidirectional Encoder
Representations from Transformers) has achieved ground-breaking performance on
multiple NLP tasks. On the other hand, Boosting is a popular ensemble learning
technique which combines many base classifiers and has been demonstrated to
yield better generalization performance in many machine learning tasks. Some
works have indicated that ensemble of BERT can further improve the application
performance. However, current ensemble approaches focus on bagging or stacking
and there has not been much effort on exploring the boosting. In this work, we
proposed a novel Boosting BERT model to integrate multi-class boosting into the
BERT. Our proposed model uses the pre-trained Transformer as the base
classifier to choose harder training sets to fine-tune and gains the benefits
of both the pre-training language knowledge and boosting ensemble in NLP tasks.
We evaluate the proposed model on the GLUE dataset and 3 popular Chinese NLU
benchmarks. Experimental results demonstrate that our proposed model
significantly outperforms BERT on all datasets and proves its effectiveness in
many NLP tasks. Replacing the BERT base with RoBERTa as base classifier,
BoostingBERT achieves new state-of-the-art results in several NLP Tasks. We
also use knowledge distillation within the ""teacher-student"" framework to
reduce the computational overhead and model storage of BoostingBERT while
keeping its performance for practical application."	ArXiv
1333	FewJoint: A Few-shot Learning Benchmark for Joint Language Understanding	['Yutai Hou', 'Jiafeng Mao', 'Yongkui Lai', 'Cheng Chen', 'Wanxiang Che', 'Zhigang Chen', 'Ting Liu']	2020-09-17 08:17:12+00:00	http://arxiv.org/abs/2009.08138v3	"Few-shot learning (FSL) is one of the key future steps in machine learning
and has raised a lot of attention. However, in contrast to the rapid
development in other domains, such as Computer Vision, the progress of FSL in
Nature Language Processing (NLP) is much slower. One of the key reasons for
this is the lacking of public benchmarks. NLP FSL researches always report new
results on their own constructed few-shot datasets, which is pretty inefficient
in results comparison and thus impedes cumulative progress. In this paper, we
present FewJoint, a novel Few-Shot Learning benchmark for NLP. Different from
most NLP FSL research that only focus on simple N-classification problems, our
benchmark introduces few-shot joint dialogue language understanding, which
additionally covers the structure prediction and multi-task reliance problems.
This allows our benchmark to reflect the real-word NLP complexity beyond simple
N-classification. Our benchmark is used in the few-shot learning contest of
SMP2020-ECDT task-1. We also provide a compatible FSL platform to ease
experiment set-up."	ArXiv
1334	Utility is in the Eye of the User: A Critique of NLP Leaderboards	['Kawin Ethayarajh', 'Dan Jurafsky']	2020-09-29 09:25:31+00:00	http://arxiv.org/abs/2009.13888v4	"Benchmarks such as GLUE have helped drive advances in NLP by incentivizing
the creation of more accurate models. While this leaderboard paradigm has been
remarkably successful, a historical focus on performance-based evaluation has
been at the expense of other qualities that the NLP community values in models,
such as compactness, fairness, and energy efficiency. In this opinion paper, we
study the divergence between what is incentivized by leaderboards and what is
useful in practice through the lens of microeconomic theory. We frame both the
leaderboard and NLP practitioners as consumers and the benefit they get from a
model as its utility to them. With this framing, we formalize how leaderboards
-- in their current form -- can be poor proxies for the NLP community at large.
For example, a highly inefficient model would provide less utility to
practitioners but not to a leaderboard, since it is a cost that only the former
must bear. To allow practitioners to better estimate a model's utility to them,
we advocate for more transparency on leaderboards, such as the reporting of
statistics that are of practical concern (e.g., model size, energy efficiency,
and inference latency)."	ArXiv
1335	"Causal Inference in Natural Language Processing: Estimation, Prediction,
  Interpretation and Beyond"	['Amir Feder', 'Katherine A. Keith', 'Emaad Manzoor', 'Reid Pryzant', 'Dhanya Sridhar', 'Zach Wood-Doughty', 'Jacob Eisenstein', 'Justin Grimmer', 'Roi Reichart', 'Margaret E. Roberts', 'Brandon M. Stewart', 'Victor Veitch', 'Diyi Yang']	2021-09-02 05:40:08+00:00	http://arxiv.org/abs/2109.00725v2	"A fundamental goal of scientific research is to learn about causal
relationships. However, despite its critical role in the life and social
sciences, causality has not had the same importance in Natural Language
Processing (NLP), which has traditionally placed more emphasis on predictive
tasks. This distinction is beginning to fade, with an emerging area of
interdisciplinary research at the convergence of causal inference and language
processing. Still, research on causality in NLP remains scattered across
domains without unified definitions, benchmark datasets and clear articulations
of the challenges and opportunities in the application of causal inference to
the textual domain, with its unique properties. In this survey, we consolidate
research across academic areas and situate it in the broader NLP landscape. We
introduce the statistical challenge of estimating causal effects with text,
encompassing settings where text is used as an outcome, treatment, or to
address confounding. In addition, we explore potential uses of causal inference
to improve the robustness, fairness, and interpretability of NLP models. We
thus provide a unified overview of causal inference for the NLP community."	ArXiv
1336	"Borrowing from Similar Code: A Deep Learning NLP-Based Approach for Log
  Statement Automation"	['Sina Gholamian', 'Paul A. S. Ward']	2021-12-02 14:03:49+00:00	http://arxiv.org/abs/2112.01259v1	"Software developers embed logging statements inside the source code as an
imperative duty in modern software development as log files are necessary for
tracking down runtime system issues and troubleshooting system management
tasks. However, the current logging process is mostly manual, and thus, proper
placement and content of logging statements remain as challenges. To overcome
these challenges, methods that aim to automate log placement and predict its
content, i.e., 'where and what to log', are of high interest. Thus, we focus on
predicting the location (i.e., where) and description (i.e., what) for log
statements by utilizing source code clones and natural language processing
(NLP), as these approaches provide additional context and advantage for log
prediction. Specifically, we guide our research with three research questions
(RQs): (RQ1) how similar code snippets, i.e., code clones, can be leveraged for
log statements prediction? (RQ2) how the approach can be extended to automate
log statements' descriptions? and (RQ3) how effective the proposed methods are
for log location and description prediction? To pursue our RQs, we perform an
experimental study on seven open-source Java projects. We introduce an updated
and improved log-aware code-clone detection method to predict the location of
logging statements (RQ1). Then, we incorporate natural language processing
(NLP) and deep learning methods to automate the log statements' description
prediction (RQ2). Our analysis shows that our hybrid NLP and code-clone
detection approach (NLP CC'd) outperforms conventional clone detectors in
finding log statement locations on average by 15.60% and achieves 40.86% higher
performance on BLEU and ROUGE scores for predicting the description of logging
statements when compared to prior research (RQ3)."	ArXiv
1337	"The Web Is Your Oyster - Knowledge-Intensive NLP against a Very Large
  Web Corpus"	['Aleksandra Piktus', 'Fabio Petroni', 'Vladimir Karpukhin', 'Dmytro Okhonko', 'Samuel Broscheit', 'Gautier Izacard', 'Patrick Lewis', 'Barlas Oğuz', 'Edouard Grave', 'Wen-tau Yih', 'Sebastian Riedel']	2021-12-18 13:15:34+00:00	http://arxiv.org/abs/2112.09924v2	"In order to address increasing demands of real-world applications, the
research for knowledge-intensive NLP (KI-NLP) should advance by capturing the
challenges of a truly open-domain environment: web-scale knowledge, lack of
structure, inconsistent quality and noise. To this end, we propose a new setup
for evaluating existing knowledge intensive tasks in which we generalize the
background corpus to a universal web snapshot. We investigate a slate of NLP
tasks which rely on knowledge - either factual or common sense, and ask systems
to use a subset of CCNet - the Sphere corpus - as a knowledge source. In
contrast to Wikipedia, otherwise a common background corpus in KI-NLP, Sphere
is orders of magnitude larger and better reflects the full diversity of
knowledge on the web. Despite potential gaps in coverage, challenges of scale,
lack of structure and lower quality, we find that retrieval from Sphere enables
a state of the art system to match and even outperform Wikipedia-based models
on several tasks. We also observe that while a dense index can outperform a
sparse BM25 baseline on Wikipedia, on Sphere this is not yet possible. To
facilitate further research and minimise the community's reliance on
proprietary, black-box search engines, we share our indices, evaluation metrics
and infrastructure."	ArXiv
1338	Geographic Citation Gaps in NLP Research	['Mukund Rungta', 'Janvijay Singh', 'Saif M. Mohammad', 'Diyi Yang']	2022-10-26 02:25:23+00:00	http://arxiv.org/abs/2210.14424v1	"In a fair world, people have equitable opportunities to education, to conduct
scientific research, to publish, and to get credit for their work, regardless
of where they live. However, it is common knowledge among researchers that a
vast number of papers accepted at top NLP venues come from a handful of western
countries and (lately) China; whereas, very few papers from Africa and South
America get published. Similar disparities are also believed to exist for paper
citation counts. In the spirit of ""what we do not measure, we cannot improve"",
this work asks a series of questions on the relationship between geographical
location and publication success (acceptance in top NLP venues and citation
impact). We first created a dataset of 70,000 papers from the ACL Anthology,
extracted their meta-information, and generated their citation network. We then
show that not only are there substantial geographical disparities in paper
acceptance and citation but also that these disparities persist even when
controlling for a number of variables such as venue of publication and
sub-field of NLP. Further, despite some steps taken by the NLP community to
improve geographical diversity, we show that the disparity in publication
metrics across locations is still on an increasing trend since the early 2000s.
We release our code and dataset here:
https://github.com/iamjanvijay/acl-cite-net"	ArXiv
1339	"Next-to-leading power corrections to $V+1$ jet production in
  $N$-jettiness subtraction"	['Radja Boughezal', 'Andrea Isgrò', 'Frank Petriello']	2019-07-29 04:54:24+00:00	http://arxiv.org/abs/1907.12213v3	"We discuss the subleading power corrections to one-jet production processes
in $N$-jettiness subtraction using vector-boson plus jet production as an
example. We analytically derive the next-to-leading power leading logarithmic
corrections (NLP-LL) through ${\cal O}(\alpha_S)$ in perturbative QCD, and
outline the calculation of the next-to-leading logarithmic corrections
(NLP-NLL). Our result is differential in the jet transverse momentum and
rapidity, and in the vector boson momentum squared and rapidity. We present
simple formulae that separate the NLP corrections into universal factors valid
for any one-jet cross section and process-dependent matrix-element corrections.
We discuss in detail features of the NLP corrections such as the process
independence of the leading-logarithmic result that occurs due to the
factorization of matrix elements in the subleading soft limit, the occurrence
of poles in the non-hemisphere soft function at NLP and the cancellation of
potential $\sqrt{\mathcal{T}_1/Q}$ corrections to the $N$-jettiness
factorization theorem. We validate our analytic result by comparing them to
numerically-fitted coefficients, finding good agreement for both the inclusive
and the differential cross sections."	ArXiv
1340	ERASER: A Benchmark to Evaluate Rationalized NLP Models	['Jay DeYoung', 'Sarthak Jain', 'Nazneen Fatema Rajani', 'Eric Lehman', 'Caiming Xiong', 'Richard Socher', 'Byron C. Wallace']	2019-11-08 18:29:03+00:00	http://arxiv.org/abs/1911.03429v2	"State-of-the-art models in NLP are now predominantly based on deep neural
networks that are opaque in terms of how they come to make predictions. This
limitation has increased interest in designing more interpretable deep models
for NLP that reveal the `reasoning' behind model outputs. But work in this
direction has been conducted on different datasets and tasks with
correspondingly unique aims and metrics; this makes it difficult to track
progress. We propose the Evaluating Rationales And Simple English Reasoning
(ERASER) benchmark to advance research on interpretable models in NLP. This
benchmark comprises multiple datasets and tasks for which human annotations of
""rationales"" (supporting evidence) have been collected. We propose several
metrics that aim to capture how well the rationales provided by models align
with human rationales, and also how faithful these rationales are (i.e., the
degree to which provided rationales influenced the corresponding predictions).
Our hope is that releasing this benchmark facilitates progress on designing
more interpretable NLP systems. The benchmark, code, and documentation are
available at https://www.eraserbenchmark.com/"	ArXiv
1341	"A Natural Language Processing Pipeline of Chinese Free-text Radiology
  Reports for Liver Cancer Diagnosis"	['Honglei Liu', 'Yan Xu', 'Zhiqiang Zhang', 'Ni Wang', 'Yanqun Huang', 'Yanjun Hu', 'Zhenghan Yang', 'Rui Jiang', 'Hui Chen']	2020-04-10 09:32:07+00:00	http://arxiv.org/abs/2004.13848v2	"Despite the rapid development of natural language processing (NLP)
implementation in electronic medical records (EMRs), Chinese EMRs processing
remains challenging due to the limited corpus and specific grammatical
characteristics, especially for radiology reports. In this study, we designed
an NLP pipeline for the direct extraction of clinically relevant features from
Chinese radiology reports, which is the first key step in computer-aided
radiologic diagnosis. The pipeline was comprised of named entity recognition,
synonyms normalization, and relationship extraction to finally derive the
radiological features composed of one or more terms. In named entity
recognition, we incorporated lexicon into deep learning model bidirectional
long short-term memory-conditional random field (BiLSTM-CRF), and the model
finally achieved an F1 score of 93.00%. With the extracted radiological
features, least absolute shrinkage and selection operator and machine learning
methods (support vector machine, random forest, decision tree, and logistic
regression) were used to build the classifiers for liver cancer prediction. For
liver cancer diagnosis, random forest had the highest predictive performance in
liver cancer diagnosis (F1 score 86.97%, precision 87.71%, and recall 86.25%).
This work was a comprehensive NLP study focusing on Chinese radiology reports
and the application of NLP in cancer risk prediction. The proposed NLP pipeline
for the radiological feature extraction could be easily implemented in other
kinds of Chinese clinical texts and other disease predictive tasks."	ArXiv
1342	"EasyTransfer -- A Simple and Scalable Deep Transfer Learning Platform
  for NLP Applications"	['Minghui Qiu', 'Peng Li', 'Chengyu Wang', 'Hanjie Pan', 'Ang Wang', 'Cen Chen', 'Xianyan Jia', 'Yaliang Li', 'Jun Huang', 'Deng Cai', 'Wei Lin']	2020-11-18 18:41:27+00:00	http://arxiv.org/abs/2011.09463v3	"The literature has witnessed the success of leveraging Pre-trained Language
Models (PLMs) and Transfer Learning (TL) algorithms to a wide range of Natural
Language Processing (NLP) applications, yet it is not easy to build an
easy-to-use and scalable TL toolkit for this purpose. To bridge this gap, the
EasyTransfer platform is designed to develop deep TL algorithms for NLP
applications. EasyTransfer is backended with a high-performance and scalable
engine for efficient training and inference, and also integrates comprehensive
deep TL algorithms, to make the development of industrial-scale TL applications
easier. In EasyTransfer, the built-in data and model parallelism strategies,
combined with AI compiler optimization, show to be 4.0x faster than the
community version of distributed training. EasyTransfer supports various NLP
models in the ModelZoo, including mainstream PLMs and multi-modality models. It
also features various in-house developed TL algorithms, together with the
AppZoo for NLP applications. The toolkit is convenient for users to quickly
start model training, evaluation, and online deployment. EasyTransfer is
currently deployed at Alibaba to support a variety of business scenarios,
including item recommendation, personalized search, conversational question
answering, etc. Extensive experiments on real-world datasets and online
applications show that EasyTransfer is suitable for online production with
cutting-edge performance for various applications. The source code of
EasyTransfer is released at Github (https://github.com/alibaba/EasyTransfer)."	ArXiv
1343	Grammar-aware sentence classification on quantum computers	['Konstantinos Meichanetzidis', 'Alexis Toumi', 'Giovanni de Felice', 'Bob Coecke']	2020-12-07 14:49:34+00:00	http://arxiv.org/abs/2012.03756v2	"Natural language processing (NLP) is at the forefront of great advances in
contemporary AI, and it is arguably one of the most challenging areas of the
field. At the same time, in the area of Quantum Computing (QC), with the steady
growth of quantum hardware and notable improvements towards implementations of
quantum algorithms, we are approaching an era when quantum computers perform
tasks that cannot be done on classical computers with a reasonable amount of
resources. This provides a new range of opportunities for AI, and for NLP
specifically. In this work, we work with the Categorical Distributional
Compositional (DisCoCat) model of natural language meaning, whose underlying
mathematical underpinnings make it amenable to quantum instantiations. Earlier
work on fault-tolerant quantum algorithms has already demonstrated potential
quantum advantage for NLP, notably employing DisCoCat. In this work, we focus
on the capabilities of noisy intermediate-scale quantum (NISQ) hardware and
perform the first implementation of an NLP task on a NISQ processor, using the
DisCoCat framework. Sentences are instantiated as parameterised quantum
circuits; word-meanings are embedded in quantum states using parameterised
quantum-circuits and the sentence's grammatical structure faithfully manifests
as a pattern of entangling operations which compose the word-circuits into a
sentence-circuit. The circuits' parameters are trained using a classical
optimiser in a supervised NLP task of binary classification. Our novel QNLP
model shows concrete promise for scalability as the quality of the quantum
hardware improves in the near future and solidifies a novel branch of
experimental research at the intersection of QC and AI."	ArXiv
1344	Beyond Fair Pay: Ethical Implications of NLP Crowdsourcing	['Boaz Shmueli', 'Jan Fell', 'Soumya Ray', 'Lun-Wei Ku']	2021-04-20 16:30:59+00:00	http://arxiv.org/abs/2104.10097v1	"The use of crowdworkers in NLP research is growing rapidly, in tandem with
the exponential increase in research production in machine learning and AI.
Ethical discussion regarding the use of crowdworkers within the NLP research
community is typically confined in scope to issues related to labor conditions
such as fair pay. We draw attention to the lack of ethical considerations
related to the various tasks performed by workers, including labeling,
evaluation, and production. We find that the Final Rule, the common ethical
framework used by researchers, did not anticipate the use of online
crowdsourcing platforms for data collection, resulting in gaps between the
spirit and practice of human-subjects ethics in NLP research. We enumerate
common scenarios where crowdworkers performing NLP tasks are at risk of harm.
We thus recommend that researchers evaluate these risks by considering the
three ethical principles set up by the Belmont Report. We also clarify some
common misconceptions regarding the Institutional Review Board (IRB)
application. We hope this paper will serve to reopen the discussion within our
community regarding the ethical use of crowdworkers."	ArXiv
1345	"Teaching NLP with Bracelets and Restaurant Menus: An Interactive
  Workshop for Italian Students"	['Ludovica Pannitto', 'Lucia Busso', 'Claudia Roberta Combei', 'Lucio Messina', 'Alessio Miaschi', 'Gabriele Sarti', 'Malvina Nissim']	2021-04-26 09:23:52+00:00	http://arxiv.org/abs/2104.12422v2	"Although Natural Language Processing (NLP) is at the core of many tools young
people use in their everyday life, high school curricula (in Italy) do not
include any computational linguistics education. This lack of exposure makes
the use of such tools less responsible than it could be and makes choosing
computational linguistics as a university degree unlikely. To raise awareness,
curiosity, and longer-term interest in young people, we have developed an
interactive workshop designed to illustrate the basic principles of NLP and
computational linguistics to high school Italian students aged between 13 and
18 years. The workshop takes the form of a game in which participants play the
role of machines needing to solve some of the most common problems a computer
faces in understanding language: from voice recognition to Markov chains to
syntactic parsing. Participants are guided through the workshop with the help
of instructors, who present the activities and explain core concepts from
computational linguistics. The workshop was presented at numerous outlets in
Italy between 2019 and 2021, both face-to-face and online."	ArXiv
1346	"Transformers: ""The End of History"" for NLP?"	['Anton Chernyavskiy', 'Dmitry Ilvovsky', 'Preslav Nakov']	2021-04-09 08:29:42+00:00	http://arxiv.org/abs/2105.00813v2	"Recent advances in neural architectures, such as the Transformer, coupled
with the emergence of large-scale pre-trained models such as BERT, have
revolutionized the field of Natural Language Processing (NLP), pushing the
state of the art for a number of NLP tasks. A rich family of variations of
these models has been proposed, such as RoBERTa, ALBERT, and XLNet, but
fundamentally, they all remain limited in their ability to model certain kinds
of information, and they cannot cope with certain information sources, which
was easy for pre-existing models. Thus, here we aim to shed light on some
important theoretical limitations of pre-trained BERT-style models that are
inherent in the general Transformer architecture. First, we demonstrate in
practice on two general types of tasks -- segmentation and segment labeling --
and on four datasets that these limitations are indeed harmful and that
addressing them, even in some very simple and naive ways, can yield sizable
improvements over vanilla RoBERTa and XLNet models. Then, we offer a more
general discussion on desiderata for future additions to the Transformer
architecture that would increase its expressiveness, which we hope could help
in the design of the next generation of deep NLP architectures."	ArXiv
1347	"Multilingual Medical Question Answering and Information Retrieval for
  Rural Health Intelligence Access"	['Vishal Vinod', 'Susmit Agrawal', 'Vipul Gaurav', 'Pallavi R', 'Savita Choudhary']	2021-06-02 16:05:24+00:00	http://arxiv.org/abs/2106.01251v1	"In rural regions of several developing countries, access to quality
healthcare, medical infrastructure, and professional diagnosis is largely
unavailable. Many of these regions are gradually gaining access to internet
infrastructure, although not with a strong enough connection to allow for
sustained communication with a medical practitioner. Several deaths resulting
from this lack of medical access, absence of patient's previous health records,
and the unavailability of information in indigenous languages can be easily
prevented. In this paper, we describe an approach leveraging the phenomenal
progress in Machine Learning and NLP (Natural Language Processing) techniques
to design a model that is low-resource, multilingual, and a preliminary
first-point-of-contact medical assistant. Our contribution includes defining
the NLP pipeline required for named-entity-recognition, language-agnostic
sentence embedding, natural language translation, information retrieval,
question answering, and generative pre-training for final query processing. We
obtain promising results for this pipeline and preliminary results for EHR
(Electronic Health Record) analysis with text summarization for medical
practitioners to peruse for their diagnosis. Through this NLP pipeline, we aim
to provide preliminary medical information to the user and do not claim to
supplant diagnosis from qualified medical practitioners. Using the input from
subject matter experts, we have compiled a large corpus to pre-train and
fine-tune our BioBERT based NLP model for the specific tasks. We expect recent
advances in NLP architectures, several of which are efficient and
privacy-preserving models, to further the impact of our solution and improve on
individual task performance."	ArXiv
1348	"Causal Direction of Data Collection Matters: Implications of Causal and
  Anticausal Learning for NLP"	['Zhijing Jin', 'Julius von Kügelgen', 'Jingwei Ni', 'Tejas Vaidhya', 'Ayush Kaushal', 'Mrinmaya Sachan', 'Bernhard Schölkopf']	2021-10-07 16:56:17+00:00	http://arxiv.org/abs/2110.03618v2	"The principle of independent causal mechanisms (ICM) states that generative
processes of real world data consist of independent modules which do not
influence or inform each other. While this idea has led to fruitful
developments in the field of causal inference, it is not widely-known in the
NLP community. In this work, we argue that the causal direction of the data
collection process bears nontrivial implications that can explain a number of
published NLP findings, such as differences in semi-supervised learning (SSL)
and domain adaptation (DA) performance across different settings. We categorize
common NLP tasks according to their causal direction and empirically assay the
validity of the ICM principle for text data using minimum description length.
We conduct an extensive meta-analysis of over 100 published SSL and 30 DA
studies, and find that the results are consistent with our expectations based
on causal insights. This work presents the first attempt to analyze the ICM
principle in NLP, and provides constructive suggestions for future modeling
choices. Code available at https://github.com/zhijing-jin/icm4nlp"	ArXiv
1349	"Dim Wihl Gat Tun: The Case for Linguistic Expertise in NLP for
  Underdocumented Languages"	['Clarissa Forbes', 'Farhan Samir', 'Bruce Harold Oliver', 'Changbing Yang', 'Edith Coates', 'Garrett Nicolai', 'Miikka Silfverberg']	2022-03-17 22:02:25+00:00	http://arxiv.org/abs/2203.09632v1	"Recent progress in NLP is driven by pretrained models leveraging massive
datasets and has predominantly benefited the world's political and economic
superpowers. Technologically underserved languages are left behind because they
lack such resources. Hundreds of underserved languages, nevertheless, have
available data sources in the form of interlinear glossed text (IGT) from
language documentation efforts. IGT remains underutilized in NLP work, perhaps
because its annotations are only semi-structured and often language-specific.
With this paper, we make the case that IGT data can be leveraged successfully
provided that target language expertise is available. We specifically advocate
for collaboration with documentary linguists. Our paper provides a roadmap for
successful projects utilizing IGT data: (1) It is essential to define which NLP
tasks can be accomplished with the given IGT data and how these will benefit
the speech community. (2) Great care and target language expertise is required
when converting the data into structured formats commonly employed in NLP. (3)
Task-specific and user-specific evaluation can help to ascertain that the tools
which are created benefit the target language speech community. We illustrate
each step through a case study on developing a morphological reinflection
system for the Tsimchianic language Gitksan."	ArXiv
1350	"Analysing similarities between legal court documents using natural
  language processing approaches based on Transformers"	['Raphael Souza de Oliveira', 'Erick Giovani Sperandio Nascimento']	2022-04-14 18:25:56+00:00	http://arxiv.org/abs/2204.07182v3	"Recent advances in Artificial Intelligence (AI) have leveraged promising
results in solving complex problems in the area of Natural Language Processing
(NLP), being an important tool to help in the expeditious resolution of
judicial proceedings in the legal area. In this context, this work targets the
problem of detecting the degree of similarity between judicial documents that
can be achieved in the inference group, by applying six NLP techniques based on
the transformers architecture to a case study of legal proceedings in the
Brazilian judicial system. The NLP transformer-based models, namely BERT, GPT-2
and RoBERTa, were pre-trained using a general purpose corpora of the Brazilian
Portuguese language, and then were fine-tuned and specialised for the legal
sector using 210,000 legal proceedings. Vector representations of each legal
document were calculated based on their embeddings, which were used to cluster
the lawsuits, calculating the quality of each model based on the cosine of the
distance between the elements of the group to its centroid. We noticed that
models based on transformers presented better performance when compared to
previous traditional NLP techniques, with the RoBERTa model specialised for the
Brazilian Portuguese language presenting the best results. This methodology can
be also applied to other case studies for different languages, making it
possible to advance in the current state of the art in the area of NLP applied
to the legal sector."	ArXiv
1351	"Characterizing the Efficiency vs. Accuracy Trade-off for Long-Context
  NLP Models"	['Phyllis Ang', 'Bhuwan Dhingra', 'Lisa Wu Wills']	2022-04-15 01:52:45+00:00	http://arxiv.org/abs/2204.07288v1	"With many real-world applications of Natural Language Processing (NLP)
comprising of long texts, there has been a rise in NLP benchmarks that measure
the accuracy of models that can handle longer input sequences. However, these
benchmarks do not consider the trade-offs between accuracy, speed, and power
consumption as input sizes or model sizes are varied. In this work, we perform
a systematic study of this accuracy vs. efficiency trade-off on two widely used
long-sequence models - Longformer-Encoder-Decoder (LED) and Big Bird - during
fine-tuning and inference on four datasets from the SCROLLS benchmark. To study
how this trade-off differs across hyperparameter settings, we compare the
models across four sequence lengths (1024, 2048, 3072, 4096) and two model
sizes (base and large) under a fixed resource budget. We find that LED
consistently achieves better accuracy at lower energy costs than Big Bird. For
summarization, we find that increasing model size is more energy efficient than
increasing sequence length for higher accuracy. However, this comes at the cost
of a large drop in inference speed. For question answering, we find that
smaller models are both more efficient and more accurate due to the larger
training batch sizes possible under a fixed resource budget."	ArXiv
1352	What Do NLP Researchers Believe? Results of the NLP Community Metasurvey	['Julian Michael', 'Ari Holtzman', 'Alicia Parrish', 'Aaron Mueller', 'Alex Wang', 'Angelica Chen', 'Divyam Madaan', 'Nikita Nangia', 'Richard Yuanzhe Pang', 'Jason Phang', 'Samuel R. Bowman']	2022-08-26 19:45:51+00:00	http://arxiv.org/abs/2208.12852v1	"We present the results of the NLP Community Metasurvey. Run from May to June
2022, the survey elicited opinions on controversial issues, including industry
influence in the field, concerns about AGI, and ethics. Our results put
concrete numbers to several controversies: For example, respondents are split
almost exactly in half on questions about the importance of artificial general
intelligence, whether language models understand language, and the necessity of
linguistic structure and inductive bias for solving NLP problems. In addition,
the survey posed meta-questions, asking respondents to predict the distribution
of survey responses. This allows us not only to gain insight on the spectrum of
beliefs held by NLP researchers, but also to uncover false sociological beliefs
where the community's predictions don't match reality. We find such mismatches
on a wide range of issues. Among other results, the community greatly
overestimates its own belief in the usefulness of benchmarks and the potential
for scaling to solve real-world problems, while underestimating its own belief
in the importance of linguistic structure, inductive bias, and
interdisciplinary science."	ArXiv
1353	Undesirable Biases in NLP: Addressing Challenges of Measurement	['Oskar van der Wal', 'Dominik Bachmann', 'Alina Leidinger', 'Leendert van Maanen', 'Willem Zuidema', 'Katrin Schulz']	2022-11-24 16:53:18+00:00	http://arxiv.org/abs/2211.13709v4	"As Large Language Models and Natural Language Processing (NLP) technology
rapidly develop and spread into daily life, it becomes crucial to anticipate
how their use could harm people. One problem that has received a lot of
attention in recent years is that this technology has displayed harmful biases,
from generating derogatory stereotypes to producing disparate outcomes for
different social groups. Although a lot of effort has been invested in
assessing and mitigating these biases, our methods of measuring the biases of
NLP models have serious problems and it is often unclear what they actually
measure. In this paper, we provide an interdisciplinary approach to discussing
the issue of NLP model bias by adopting the lens of psychometrics -- a field
specialized in the measurement of concepts like bias that are not directly
observable. In particular, we will explore two central notions from
psychometrics, the construct validity and the reliability of measurement tools,
and discuss how they can be applied in the context of measuring model bias. Our
goal is to provide NLP practitioners with methodological tools for designing
better bias measures, and to inspire them more generally to explore tools from
psychometrics when working on bias measurement tools."	ArXiv
1354	"Beyond Counting Datasets: A Survey of Multilingual Dataset Construction
  and Necessary Resources"	['Xinyan Velocity Yu', 'Akari Asai', 'Trina Chatterjee', 'Junjie Hu', 'Eunsol Choi']	2022-11-28 18:54:33+00:00	http://arxiv.org/abs/2211.15649v1	"While the NLP community is generally aware of resource disparities among
languages, we lack research that quantifies the extent and types of such
disparity. Prior surveys estimating the availability of resources based on the
number of datasets can be misleading as dataset quality varies: many datasets
are automatically induced or translated from English data. To provide a more
comprehensive picture of language resources, we examine the characteristics of
156 publicly available NLP datasets. We manually annotate how they are created,
including input text and label sources and tools used to build them, and what
they study, tasks they address and motivations for their creation. After
quantifying the qualitative NLP resource gap across languages, we discuss how
to improve data collection in low-resource languages. We survey
language-proficient NLP researchers and crowd workers per language, finding
that their estimated availability correlates with dataset availability. Through
crowdsourcing experiments, we identify strategies for collecting high-quality
multilingual data on the Mechanical Turk platform. We conclude by making macro
and micro-level suggestions to the NLP community and individual researchers for
future multilingual data development."	ArXiv
1355	Federated Few-Shot Learning for Mobile NLP	['Dongqi Cai', 'Shangguang Wang', 'Yaozong Wu', 'Felix Xiaozhu Lin', 'Mengwei Xu']	2022-12-12 15:29:48+00:00	http://arxiv.org/abs/2212.05974v2	"Natural language processing (NLP) sees rich mobile applications. To support
various language understanding tasks, a foundation NLP model is often
fine-tuned in a federated, privacy-preserving setting (FL). This process
currently relies on at least hundreds of thousands of labeled training samples
from mobile clients; yet mobile users often lack willingness or knowledge to
label their data. Such an inadequacy of data labels is known as a few-shot
scenario; it becomes the key blocker for mobile NLP applications.
  For the first time, this work investigates federated NLP in the few-shot
scenario (FedFSL). By retrofitting algorithmic advances of pseudo labeling and
prompt learning, we first establish a training pipeline that delivers
competitive accuracy when only 0.05% (fewer than 100) of the training data is
labeled and the remaining is unlabeled. To instantiate the workflow, we further
present a system FeS, addressing the high execution cost with novel designs.
(1) Curriculum pacing, which injects pseudo labels to the training workflow at
a rate commensurate to the learning progress; (2) Representational diversity, a
mechanism for selecting the most learnable data, only for which pseudo labels
will be generated; (3) Co-planning of a model's training depth and layer
capacity. Together, these designs reduce the training delay, client energy, and
network traffic by up to 46.0$\times$, 41.2$\times$ and 3000.0$\times$,
respectively. Through algorithm/system co-design, FFNLP demonstrates that FL
can apply to challenging settings where most training samples are unlabeled."	ArXiv
1356	Rationalization for Explainable NLP: A Survey	['Sai Gurrapu', 'Ajay Kulkarni', 'Lifu Huang', 'Ismini Lourentzou', 'Laura Freeman', 'Feras A. Batarseh']	2023-01-21 07:58:03+00:00	http://arxiv.org/abs/2301.08912v1	"Recent advances in deep learning have improved the performance of many
Natural Language Processing (NLP) tasks such as translation,
question-answering, and text classification. However, this improvement comes at
the expense of model explainability. Black-box models make it difficult to
understand the internals of a system and the process it takes to arrive at an
output. Numerical (LIME, Shapley) and visualization (saliency heatmap)
explainability techniques are helpful; however, they are insufficient because
they require specialized knowledge. These factors led rationalization to emerge
as a more accessible explainable technique in NLP. Rationalization justifies a
model's output by providing a natural language explanation (rationale). Recent
improvements in natural language generation have made rationalization an
attractive technique because it is intuitive, human-comprehensible, and
accessible to non-technical users. Since rationalization is a relatively new
field, it is disorganized. As the first survey, rationalization literature in
NLP from 2007-2022 is analyzed. This survey presents available methods,
explainable evaluations, code, and datasets used across various NLP tasks that
use rationalization. Further, a new subfield in Explainable AI (XAI), namely,
Rational AI (RAI), is introduced to advance the current state of
rationalization. A discussion on observed insights, challenges, and future
directions is provided to point to promising research opportunities."	ArXiv
1357	"Analyzing the impact of climate change on critical infrastructure from
  the scientific literature: A weakly supervised NLP approach"	['Tanwi Mallick', 'Joshua David Bergerson', 'Duane R. Verner', 'John K Hutchison', 'Leslie-Anne Levy', 'Prasanna Balaprakash']	2023-02-03 17:47:42+00:00	http://arxiv.org/abs/2302.01887v2	"Natural language processing (NLP) is a promising approach for analyzing large
volumes of climate-change and infrastructure-related scientific literature.
However, best-in-practice NLP techniques require large collections of relevant
documents (corpus). Furthermore, NLP techniques using machine learning and deep
learning techniques require labels grouping the articles based on user-defined
criteria for a significant subset of a corpus in order to train the supervised
model. Even labeling a few hundred documents with human subject-matter experts
is a time-consuming process. To expedite this process, we developed a weak
supervision-based NLP approach that leverages semantic similarity between
categories and documents to (i) establish a topic-specific corpus by subsetting
a large-scale open-access corpus and (ii) generate category labels for the
topic-specific corpus. In comparison with a months-long process of
subject-matter expert labeling, we assign category labels to the whole corpus
using weak supervision and supervised learning in about 13 hours. The labeled
climate and NCF corpus enable targeted, efficient identification of documents
discussing a topic (or combination of topics) of interest and identification of
various effects of climate change on critical infrastructure, improving the
usability of scientific literature and ultimately supporting enhanced policy
and decision making. To demonstrate this capability, we conduct topic modeling
on pairs of climate hazards and NCFs to discover trending topics at the
intersection of these categories. This method is useful for analysts and
decision-makers to quickly grasp the relevant topics and most important
documents linked to the topic."	ArXiv
1358	German BERT Model for Legal Named Entity Recognition	['Harshil Darji', 'Jelena Mitrović', 'Michael Granitzer']	2023-03-07 11:54:39+00:00	http://arxiv.org/abs/2303.05388v1	"The use of BERT, one of the most popular language models, has led to
improvements in many Natural Language Processing (NLP) tasks. One such task is
Named Entity Recognition (NER) i.e. automatic identification of named entities
such as location, person, organization, etc. from a given text. It is also an
important base step for many NLP tasks such as information extraction and
argumentation mining. Even though there is much research done on NER using BERT
and other popular language models, the same is not explored in detail when it
comes to Legal NLP or Legal Tech. Legal NLP applies various NLP techniques such
as sentence similarity or NER specifically on legal data. There are only a
handful of models for NER tasks using BERT language models, however, none of
these are aimed at legal documents in German. In this paper, we fine-tune a
popular BERT language model trained on German data (German BERT) on a Legal
Entity Recognition (LER) dataset. To make sure our model is not overfitting, we
performed a stratified 10-fold cross-validation. The results we achieve by
fine-tuning German BERT on the LER dataset outperform the BiLSTM-CRF+ model
used by the authors of the same LER dataset. Finally, we make the model openly
available via HuggingFace."	ArXiv
1359	"Extracting Thyroid Nodules Characteristics from Ultrasound Reports Using
  Transformer-based Natural Language Processing Methods"	['Aman Pathak', 'Zehao Yu', 'Daniel Paredes', 'Elio Paul Monsour', 'Andrea Ortiz Rocha', 'Juan P. Brito', 'Naykky Singh Ospina', 'Yonghui Wu']	2023-03-31 20:23:58+00:00	http://arxiv.org/abs/2304.00115v1	"The ultrasound characteristics of thyroid nodules guide the evaluation of
thyroid cancer in patients with thyroid nodules. However, the characteristics
of thyroid nodules are often documented in clinical narratives such as
ultrasound reports. Previous studies have examined natural language processing
(NLP) methods in extracting a limited number of characteristics (<9) using
rule-based NLP systems. In this study, a multidisciplinary team of NLP experts
and thyroid specialists, identified thyroid nodule characteristics that are
important for clinical care, composed annotation guidelines, developed a
corpus, and compared 5 state-of-the-art transformer-based NLP methods,
including BERT, RoBERTa, LongFormer, DeBERTa, and GatorTron, for extraction of
thyroid nodule characteristics from ultrasound reports. Our GatorTron model, a
transformer-based large language model trained using over 90 billion words of
text, achieved the best strict and lenient F1-score of 0.8851 and 0.9495 for
the extraction of a total number of 16 thyroid nodule characteristics, and
0.9321 for linking characteristics to nodules, outperforming other clinical
transformer models. To the best of our knowledge, this is the first study to
systematically categorize and apply transformer-based NLP models to extract a
large number of clinical relevant thyroid nodule characteristics from
ultrasound reports. This study lays ground for assessing the documentation
quality of thyroid ultrasound reports and examining outcomes of patients with
thyroid nodules using electronic health records."	ArXiv
1360	Replication in Requirements Engineering: the NLP for RE Case	"['Sallam Abualhaija', 'F. BaŞAk Aydemir', 'Fabiano Dalpiaz', ""Davide Dell'Anna"", 'Alessio Ferrari', 'Xavier Franch', 'Davide Fucci']"	2023-04-20 12:45:21+00:00	http://arxiv.org/abs/2304.10265v2	"[Context]} Natural language processing (NLP) techniques have been widely
applied in the requirements engineering (RE) field to support tasks such as
classification and ambiguity detection. Despite its empirical vocation, RE
research has given limited attention to replication of NLP for RE studies.
Replication is hampered by several factors, including the context specificity
of the studies, the heterogeneity of the tasks involving NLP, the tasks'
inherent hairiness, and, in turn, the heterogeneous reporting structure.
[Solution] To address these issues, we propose a new artifact, referred to as
ID-Card, whose goal is to provide a structured summary of research papers
emphasizing replication-relevant information. We construct the ID-Card through
a structured, iterative process based on design science. [Results] In this
paper: (i) we report on hands-on experiences of replication, (ii) we review the
state-of-the-art and extract replication-relevant information, (iii) we
identify, through focus groups, challenges across two typical dimensions of
replication: data annotation and tool reconstruction, and (iv) we present the
concept and structure of the ID-Card to mitigate the identified challenges.
[Contribution] This study aims to create awareness of replication in NLP for
RE. We propose an ID-Card that is intended to foster study replication, but can
also be used in other contexts, e.g., for educational purposes."	ArXiv
1361	"Beyond Good Intentions: Reporting the Research Landscape of NLP for
  Social Good"	['Fernando Gonzalez', 'Zhijing Jin', 'Bernhard Schölkopf', 'Tom Hope', 'Mrinmaya Sachan', 'Rada Mihalcea']	2023-05-09 14:16:25+00:00	http://arxiv.org/abs/2305.05471v3	"With the recent advances in natural language processing (NLP), a vast number
of applications have emerged across various use cases. Among the plethora of
NLP applications, many academic researchers are motivated to do work that has a
positive social impact, in line with the recent initiatives of NLP for Social
Good (NLP4SG). However, it is not always obvious to researchers how their
research efforts are tackling today's big social problems. Thus, in this paper,
we introduce NLP4SG Papers, a scientific dataset with three associated tasks
that can help identify NLP4SG papers and characterize the NLP4SG landscape by:
(1) identifying the papers that address a social problem, (2) mapping them to
the corresponding UN Sustainable Development Goals (SDGs), and (3) identifying
the task they are solving and the methods they are using. Using
state-of-the-art NLP models, we address each of these tasks and use them on the
entire ACL Anthology, resulting in a visualization workspace that gives
researchers a comprehensive overview of the field of NLP4SG. Our website is
available at https://nlp4sg.vercel.app. We released our data at
https://huggingface.co/datasets/feradauto/NLP4SGPapers and code at
https://github.com/feradauto/nlp4sg"	ArXiv
1362	"GAIA Search: Hugging Face and Pyserini Interoperability for NLP Training
  Data Exploration"	['Aleksandra Piktus', 'Odunayo Ogundepo', 'Christopher Akiki', 'Akintunde Oladipo', 'Xinyu Zhang', 'Hailey Schoelkopf', 'Stella Biderman', 'Martin Potthast', 'Jimmy Lin']	2023-06-02 12:09:59+00:00	http://arxiv.org/abs/2306.01481v1	"Noticing the urgent need to provide tools for fast and user-friendly
qualitative analysis of large-scale textual corpora of the modern NLP, we
propose to turn to the mature and well-tested methods from the domain of
Information Retrieval (IR) - a research field with a long history of tackling
TB-scale document collections. We discuss how Pyserini - a widely used toolkit
for reproducible IR research can be integrated with the Hugging Face ecosystem
of open-source AI libraries and artifacts. We leverage the existing
functionalities of both platforms while proposing novel features further
facilitating their integration. Our goal is to give NLP researchers tools that
will allow them to develop retrieval-based instrumentation for their data
analytics needs with ease and agility. We include a Jupyter Notebook-based walk
through the core interoperability features, available on GitHub at
https://github.com/huggingface/gaia. We then demonstrate how the ideas we
present can be operationalized to create a powerful tool for qualitative data
analysis in NLP. We present GAIA Search - a search engine built following
previously laid out principles, giving access to four popular large-scale text
collections. GAIA serves a dual purpose of illustrating the potential of
methodologies we discuss but also as a standalone qualitative analysis tool
that can be leveraged by NLP researchers aiming to understand datasets prior to
using them in training. GAIA is hosted live on Hugging Face Spaces -
https://huggingface.co/spaces/spacerini/gaia."	ArXiv
1363	"Exploring New Frontiers in Agricultural NLP: Investigating the Potential
  of Large Language Models for Food Applications"	['Saed Rezayi', 'Zhengliang Liu', 'Zihao Wu', 'Chandra Dhakal', 'Bao Ge', 'Haixing Dai', 'Gengchen Mai', 'Ninghao Liu', 'Chen Zhen', 'Tianming Liu', 'Sheng Li']	2023-06-20 21:12:16+00:00	http://arxiv.org/abs/2306.11892v1	"This paper explores new frontiers in agricultural natural language processing
by investigating the effectiveness of using food-related text corpora for
pretraining transformer-based language models. In particular, we focus on the
task of semantic matching, which involves establishing mappings between food
descriptions and nutrition data. To accomplish this, we fine-tune a pre-trained
transformer-based language model, AgriBERT, on this task, utilizing an external
source of knowledge, such as the FoodOn ontology. To advance the field of
agricultural NLP, we propose two new avenues of exploration: (1) utilizing
GPT-based models as a baseline and (2) leveraging ChatGPT as an external source
of knowledge. ChatGPT has shown to be a strong baseline in many NLP tasks, and
we believe it has the potential to improve our model in the task of semantic
matching and enhance our model's understanding of food-related concepts and
relationships. Additionally, we experiment with other applications, such as
cuisine prediction based on food ingredients, and expand the scope of our
research to include other NLP tasks beyond semantic matching. Overall, this
paper provides promising avenues for future research in this field, with
potential implications for improving the performance of agricultural NLP
applications."	ArXiv
1364	"Mitigating Task Interference in Multi-Task Learning via Explicit Task
  Routing with Non-Learnable Primitives"	['Chuntao Ding', 'Zhichao Lu', 'Shangguang Wang', 'Ran Cheng', 'Vishnu Naresh Boddeti']	2023-08-03 22:34:16+00:00	http://arxiv.org/abs/2308.02066v1	"Multi-task learning (MTL) seeks to learn a single model to accomplish
multiple tasks by leveraging shared information among the tasks. Existing MTL
models, however, have been known to suffer from negative interference among
tasks. Efforts to mitigate task interference have focused on either
loss/gradient balancing or implicit parameter partitioning with partial
overlaps among the tasks. In this paper, we propose ETR-NLP to mitigate task
interference through a synergistic combination of non-learnable primitives
(NLPs) and explicit task routing (ETR). Our key idea is to employ non-learnable
primitives to extract a diverse set of task-agnostic features and recombine
them into a shared branch common to all tasks and explicit task-specific
branches reserved for each task. The non-learnable primitives and the explicit
decoupling of learnable parameters into shared and task-specific ones afford
the flexibility needed for minimizing task interference. We evaluate the
efficacy of ETR-NLP networks for both image-level classification and
pixel-level dense prediction MTL problems. Experimental results indicate that
ETR-NLP significantly outperforms state-of-the-art baselines with fewer
learnable parameters and similar FLOPs across all datasets. Code is available
at this \href{https://github.com/zhichao-lu/etr-nlp-mtl}."	ArXiv
1365	"From Ambiguity to Explicitness: NLP-Assisted 5G Specification
  Abstraction for Formal Analysis"	['Shiyu Yuan', 'Jingda Yang', 'Sudhanshu Arya', 'Carlo Lipizzi', 'Ying Wang']	2023-08-07 03:37:31+00:00	http://arxiv.org/abs/2308.03277v1	"Formal method-based analysis of the 5G Wireless Communication Protocol is
crucial for identifying logical vulnerabilities and facilitating an
all-encompassing security assessment, especially in the design phase. Natural
Language Processing (NLP) assisted techniques and most of the tools are not
widely adopted by the industry and research community. Traditional formal
verification through a mathematics approach heavily relied on manual logical
abstraction prone to being time-consuming, and error-prone. The reason that the
NLP-assisted method did not apply in industrial research may be due to the
ambiguity in the natural language of the protocol designs nature is
controversial to the explicitness of formal verification. To address the
challenge of adopting the formal methods in protocol designs, targeting (3GPP)
protocols that are written in natural language, in this study, we propose a
hybrid approach to streamline the analysis of protocols. We introduce a
two-step pipeline that first uses NLP tools to construct data and then uses
constructed data to extract identifiers and formal properties by using the NLP
model. The identifiers and formal properties are further used for formal
analysis. We implemented three models that take different dependencies between
identifiers and formal properties as criteria. Our results of the optimal model
reach valid accuracy of 39% for identifier extraction and 42% for formal
properties predictions. Our work is proof of concept for an efficient procedure
in performing formal analysis for largescale complicate specification and
protocol analysis, especially for 5G and nextG communications."	ArXiv
1366	"An Empirical Evaluation of Prompting Strategies for Large Language
  Models in Zero-Shot Clinical Natural Language Processing"	['Sonish Sivarajkumar', 'Mark Kelley', 'Alyssa Samolyk-Mazzanti', 'Shyam Visweswaran', 'Yanshan Wang']	2023-09-14 19:35:00+00:00	http://arxiv.org/abs/2309.08008v1	"Large language models (LLMs) have shown remarkable capabilities in Natural
Language Processing (NLP), especially in domains where labeled data is scarce
or expensive, such as clinical domain. However, to unlock the clinical
knowledge hidden in these LLMs, we need to design effective prompts that can
guide them to perform specific clinical NLP tasks without any task-specific
training data. This is known as in-context learning, which is an art and
science that requires understanding the strengths and weaknesses of different
LLMs and prompt engineering approaches. In this paper, we present a
comprehensive and systematic experimental study on prompt engineering for five
clinical NLP tasks: Clinical Sense Disambiguation, Biomedical Evidence
Extraction, Coreference Resolution, Medication Status Extraction, and
Medication Attribute Extraction. We assessed the prompts proposed in recent
literature, including simple prefix, simple cloze, chain of thought, and
anticipatory prompts, and introduced two new types of prompts, namely heuristic
prompting and ensemble prompting. We evaluated the performance of these prompts
on three state-of-the-art LLMs: GPT-3.5, BARD, and LLAMA2. We also contrasted
zero-shot prompting with few-shot prompting, and provide novel insights and
guidelines for prompt engineering for LLMs in clinical NLP. To the best of our
knowledge, this is one of the first works on the empirical evaluation of
different prompt engineering approaches for clinical NLP in this era of
generative AI, and we hope that it will inspire and inform future research in
this area."	ArXiv
1367	"Classifying Organizations for Food System Ontologies using Natural
  Language Processing"	['Tianyu Jiang', 'Sonia Vinogradova', 'Nathan Stringham', 'E. Louise Earl', 'Allan D. Hollander', 'Patrick R. Huber', 'Ellen Riloff', 'R. Sandra Schillo', 'Giorgio A. Ubbiali', 'Matthew Lange']	2023-09-19 19:07:48+00:00	http://arxiv.org/abs/2309.10880v1	"Our research explores the use of natural language processing (NLP) methods to
automatically classify entities for the purpose of knowledge graph population
and integration with food system ontologies. We have created NLP models that
can automatically classify organizations with respect to categories associated
with environmental issues as well as Standard Industrial Classification (SIC)
codes, which are used by the U.S. government to characterize business
activities. As input, the NLP models are provided with text snippets retrieved
by the Google search engine for each organization, which serves as a textual
description of the organization that is used for learning. Our experimental
results show that NLP models can achieve reasonably good performance for these
two classification tasks, and they rely on a general framework that could be
applied to many other classification problems as well. We believe that NLP
models represent a promising approach for automatically harvesting information
to populate knowledge graphs and aligning the information with existing
ontologies through shared categories and concepts."	ArXiv
1368	"Improving VTE Identification through Adaptive NLP Model Selection and
  Clinical Expert Rule-based Classifier from Radiology Reports"	['Jamie Deng', 'Yusen Wu', 'Hilary Hayssen', 'Brain Englum', 'Aman Kankaria', 'Minerva Mayorga-Carlin', 'Shalini Sahoo', 'John Sorkin', 'Brajesh Lal', 'Yelena Yesha', 'Phuong Nguyen']	2023-09-21 17:29:37+00:00	http://arxiv.org/abs/2309.12273v2	"Rapid and accurate identification of Venous thromboembolism (VTE), a severe
cardiovascular condition including deep vein thrombosis (DVT) and pulmonary
embolism (PE), is important for effective treatment. Leveraging Natural
Language Processing (NLP) on radiology reports, automated methods have shown
promising advancements in identifying VTE events from retrospective data
cohorts or aiding clinical experts in identifying VTE events from radiology
reports. However, effectively training Deep Learning (DL) and the NLP models is
challenging due to limited labeled medical text data, the complexity and
heterogeneity of radiology reports, and data imbalance. This study proposes
novel method combinations of DL methods, along with data augmentation, adaptive
pre-trained NLP model selection, and a clinical expert NLP rule-based
classifier, to improve the accuracy of VTE identification in unstructured
(free-text) radiology reports. Our experimental results demonstrate the model's
efficacy, achieving an impressive 97\% accuracy and 97\% F1 score in predicting
DVT, and an outstanding 98.3\% accuracy and 98.4\% F1 score in predicting PE.
These findings emphasize the model's robustness and its potential to
significantly contribute to VTE research."	ArXiv
1369	"InterroLang: Exploring NLP Models and Datasets through Dialogue-based
  Explanations"	['Nils Feldhus', 'Qianli Wang', 'Tatiana Anikina', 'Sahil Chopra', 'Cennet Oguz', 'Sebastian Möller']	2023-10-09 10:27:26+00:00	http://arxiv.org/abs/2310.05592v2	"While recently developed NLP explainability methods let us open the black box
in various ways (Madsen et al., 2022), a missing ingredient in this endeavor is
an interactive tool offering a conversational interface. Such a dialogue system
can help users explore datasets and models with explanations in a
contextualized manner, e.g. via clarification or follow-up questions, and
through a natural language interface. We adapt the conversational explanation
framework TalkToModel (Slack et al., 2022) to the NLP domain, add new
NLP-specific operations such as free-text rationalization, and illustrate its
generalizability on three NLP tasks (dialogue act classification, question
answering, hate speech detection). To recognize user queries for explanations,
we evaluate fine-tuned and few-shot prompting models and implement a novel
Adapter-based approach. We then conduct two user studies on (1) the perceived
correctness and helpfulness of the dialogues, and (2) the simulatability, i.e.
how objectively helpful dialogical explanations are for humans in figuring out
the model's predicted label when it's not shown. We found rationalization and
feature attribution were helpful in explaining the model behavior. Moreover,
users could more reliably predict the model outcome based on an explanation
dialogue rather than one-off explanations."	ArXiv
1370	"SNNLP: Energy-Efficient Natural Language Processing Using Spiking Neural
  Networks"	['R. Alexander Knipper', 'Kaniz Mishty', 'Mehdi Sadi', 'Shubhra Kanti Karmaker Santu']	2024-01-31 15:16:25+00:00	http://arxiv.org/abs/2401.17911v1	"As spiking neural networks receive more attention, we look toward
applications of this computing paradigm in fields other than computer vision
and signal processing. One major field, underexplored in the neuromorphic
setting, is Natural Language Processing (NLP), where most state-of-the-art
solutions still heavily rely on resource-consuming and power-hungry traditional
deep learning architectures. Therefore, it is compelling to design NLP models
for neuromorphic architectures due to their low energy requirements, with the
additional benefit of a more human-brain-like operating model for processing
information. However, one of the biggest issues with bringing NLP to the
neuromorphic setting is in properly encoding text into a spike train so that it
can be seamlessly handled by both current and future SNN architectures. In this
paper, we compare various methods of encoding text as spikes and assess each
method's performance in an associated SNN on a downstream NLP task, namely,
sentiment analysis. Furthermore, we go on to propose a new method of encoding
text as spikes that outperforms a widely-used rate-coding technique, Poisson
rate-coding, by around 13\% on our benchmark NLP tasks. Subsequently, we
demonstrate the energy efficiency of SNNs implemented in hardware for the
sentiment analysis task compared to traditional deep neural networks, observing
an energy efficiency increase of more than 32x during inference and 60x during
training while incurring the expected energy-performance tradeoff."	ArXiv
1371	Citation Amnesia: On The Recency Bias of NLP and Other Academic Fields	['Jan Philip Wahle', 'Terry Ruas', 'Mohamed Abdalla', 'Bela Gipp', 'Saif M. Mohammad']	2024-02-19 10:59:29+00:00	http://arxiv.org/abs/2402.12046v2	"This study examines the tendency to cite older work across 20 fields of study
over 43 years (1980--2023). We put NLP's propensity to cite older work in the
context of these 20 other fields to analyze whether NLP shows similar temporal
citation patterns to these other fields over time or whether differences can be
observed. Our analysis, based on a dataset of approximately 240 million papers,
reveals a broader scientific trend: many fields have markedly declined in
citing older works (e.g., psychology, computer science). We term this decline a
'citation age recession', analogous to how economists define periods of reduced
economic activity. The trend is strongest in NLP and ML research (-12.8% and
-5.5% in citation age from previous peaks). Our results suggest that citing
more recent works is not directly driven by the growth in publication rates
(-3.4% across fields; -5.2% in humanities; -5.5% in formal sciences) -- even
when controlling for an increase in the volume of papers. Our findings raise
questions about the scientific community's engagement with past literature,
particularly for NLP, and the potential consequences of neglecting older but
relevant research. The data and a demo showcasing our results are publicly
available."	ArXiv
1372	"From Explainable to Interpretable Deep Learning for Natural Language
  Processing in Healthcare: How Far from Reality?"	['Guangming Huang', 'Yingya Li', 'Shoaib Jameel', 'Yunfei Long', 'Giorgos Papanastasiou']	2024-03-18 15:53:33+00:00	http://arxiv.org/abs/2403.11894v4	"Deep learning (DL) has substantially enhanced natural language processing
(NLP) in healthcare research. However, the increasing complexity of DL-based
NLP necessitates transparent model interpretability, or at least
explainability, for reliable decision-making. This work presents a thorough
scoping review of explainable and interpretable DL in healthcare NLP. The term
""eXplainable and Interpretable Artificial Intelligence"" (XIAI) is introduced to
distinguish XAI from IAI. Different models are further categorized based on
their functionality (model-, input-, output-based) and scope (local, global).
Our analysis shows that attention mechanisms are the most prevalent emerging
IAI technique. The use of IAI is growing, distinguishing it from XAI. The major
challenges identified are that most XIAI does not explore ""global"" modelling
processes, the lack of best practices, and the lack of systematic evaluation
and benchmarks. One important opportunity is to use attention mechanisms to
enhance multi-modal XIAI for personalized medicine. Additionally, combining DL
with causal logic holds promise. Our discussion encourages the integration of
XIAI in Large Language Models (LLMs) and domain-specific smaller models. In
conclusion, XIAI adoption in healthcare requires dedicated in-house expertise.
Collaboration with domain experts, end-users, and policymakers can lead to
ready-to-use XIAI methods across NLP and medical tasks. While challenges exist,
XIAI techniques offer a valuable foundation for interpretable NLP algorithms in
healthcare."	ArXiv
1373	"Zero-shot LLM-guided Counterfactual Generation: A Case Study on NLP
  Model Evaluation"	['Amrita Bhattacharjee', 'Raha Moraffah', 'Joshua Garland', 'Huan Liu']	2024-05-08 03:57:45+00:00	http://arxiv.org/abs/2405.04793v2	"With the development and proliferation of large, complex, black-box models
for solving many natural language processing (NLP) tasks, there is also an
increasing necessity of methods to stress-test these models and provide some
degree of interpretability or explainability. While counterfactual examples are
useful in this regard, automated generation of counterfactuals is a data and
resource intensive process. such methods depend on models such as pre-trained
language models that are then fine-tuned on auxiliary, often task-specific
datasets, that may be infeasible to build in practice, especially for new tasks
and data domains. Therefore, in this work we explore the possibility of
leveraging large language models (LLMs) for zero-shot counterfactual generation
in order to stress-test NLP models. We propose a structured pipeline to
facilitate this generation, and we hypothesize that the instruction-following
and textual understanding capabilities of recent LLMs can be effectively
leveraged for generating high quality counterfactuals in a zero-shot manner,
without requiring any training or fine-tuning. Through comprehensive
experiments on a variety of propreitary and open-source LLMs, along with
various downstream tasks in NLP, we explore the efficacy of LLMs as zero-shot
counterfactual generators in evaluating and explaining black-box NLP models."	ArXiv
1374	Developing an efficient corpus using Ensemble Data cleaning approach	['Md Taimur Ahad']	2024-06-02 16:03:31+00:00	http://arxiv.org/abs/2406.00789v1	"Despite the observable benefit of Natural Language Processing (NLP) in
processing a large amount of textual medical data within a limited time for
information retrieval, a handful of research efforts have been devoted to
uncovering novel data-cleaning methods. Data cleaning in NLP is at the centre
point for extracting validated information. Another observed limitation in the
NLP domain is having limited medical corpora that provide answers to a given
medical question. Realising the limitations and challenges from two
perspectives, this research aims to clean a medical dataset using ensemble
techniques and to develop a corpus. The corpora expect that it will answer the
question based on the semantic relationship of corpus sequences. However, the
data cleaning method in this research suggests that the ensemble technique
provides the highest accuracy (94%) compared to the single process, which
includes vectorisation, exploratory data analysis, and feeding the vectorised
data. The second aim of having an adequate corpus was realised by extracting
answers from the dataset. This research is significant in machine learning,
specifically data cleaning and the medical sector, but it also underscores the
importance of NLP in the medical field, where accurate and timely information
extraction can be a matter of life and death. It establishes text data
processing using NLP as a powerful tool for extracting valuable information
like image data."	ArXiv
1375	Privacy Evaluation Benchmarks for NLP Models	['Wei Huang', 'Yinggui Wang', 'Cen Chen']	2024-09-24 08:41:26+00:00	http://arxiv.org/abs/2409.15868v3	"By inducing privacy attacks on NLP models, attackers can obtain sensitive
information such as training data and model parameters, etc. Although
researchers have studied, in-depth, several kinds of attacks in NLP models,
they are non-systematic analyses. It lacks a comprehensive understanding of the
impact caused by the attacks. For example, we must consider which scenarios can
apply to which attacks, what the common factors are that affect the performance
of different attacks, the nature of the relationships between different
attacks, and the influence of various datasets and models on the effectiveness
of the attacks, etc. Therefore, we need a benchmark to holistically assess the
privacy risks faced by NLP models. In this paper, we present a privacy attack
and defense evaluation benchmark in the field of NLP, which includes the
conventional/small models and large language models (LLMs). This benchmark
supports a variety of models, datasets, and protocols, along with standardized
modules for comprehensive evaluation of attacks and defense strategies. Based
on the above framework, we present a study on the association between auxiliary
data from different domains and the strength of privacy attacks. And we provide
an improved attack method in this scenario with the help of Knowledge
Distillation (KD). Furthermore, we propose a chained framework for privacy
attacks. Allowing a practitioner to chain multiple attacks to achieve a
higher-level attack objective. Based on this, we provide some defense and
enhanced attack strategies. The code for reproducing the results can be found
at https://github.com/user2311717757/nlp_doctor."	ArXiv
1376	"Geometry is All You Need: A Unified Taxonomy of Matrix and Tensor
  Factorization for Compression of Generative Language Models"	['Mingxue Xu', 'Sadia Sharmin', 'Danilo P. Mandic']	2024-10-03 23:12:20+00:00	http://arxiv.org/abs/2410.03040v1	"Matrix and tensor-guided parametrization for Natural Language Processing
(NLP) models is fundamentally useful for the improvement of the model's
systematic efficiency. However, the internal links between these two algebra
structures and language model parametrization are poorly understood. Also, the
existing matrix and tensor research is math-heavy and far away from machine
learning (ML) and NLP research concepts. These two issues result in the recent
progress on matrices and tensors for model parametrization being more like a
loose collection of separate components from matrix/tensor and NLP studies,
rather than a well-structured unified approach, further hindering algorithm
design. To this end, we propose a unified taxonomy, which bridges the
matrix/tensor compression approaches and model compression concepts in ML and
NLP research. Namely, we adopt an elementary concept in linear algebra, that of
a subspace, which is also the core concept in geometric algebra, to reformulate
the matrix/tensor and ML/NLP concepts (e.g. attention mechanism) under one
umbrella. In this way, based on our subspace formalization, typical matrix and
tensor decomposition algorithms can be interpreted as geometric
transformations. Finally, we revisit recent literature on matrix- or
tensor-guided language model compression, rephrase and compare their core
ideas, and then point out the current research gap and potential solutions."	ArXiv
1377	"AI Adoption to Combat Financial Crime: Study on Natural Language
  Processing in Adverse Media Screening of Financial Services in English and
  Bangla multilingual interpretation"	['Soumita Roy']	2024-12-12 07:17:05+00:00	http://arxiv.org/abs/2412.12171v1	"This document explores the potential of employing Artificial Intelligence
(AI), specifically Natural Language Processing (NLP), to strengthen the
detection and prevention of financial crimes within the Mobile Financial
Services(MFS) of Bangladesh with multilingual scenario. The analysis focuses on
the utilization of NLP for adverse media screening, a vital aspect of
compliance with anti-money laundering (AML) and combating financial terrorism
(CFT) regulations. Additionally, it investigates the overall reception and
obstacles related to the integration of AI in Bangladeshi banks. This report
measures the effectiveness of NLP is promising with an accuracy around 94\%.
NLP algorithms display substantial promise in accurately identifying adverse
media content linked to financial crimes. The lack of progress in this aspect
is visible in Bangladesh, whereas globally the technology is already being used
to increase effectiveness and efficiency. Hence, it is clear there is an issue
with the acceptance of AI in Bangladesh. Some AML \& CFT concerns are already
being addressed by AI technology. For example, Image Recognition OCR technology
are being used in KYC procedures. Primary hindrances to AI integration involve
a lack of technical expertise, high expenses, and uncertainties surrounding
regulations. This investigation underscores the potential of AI-driven NLP
solutions in fortifying efforts to prevent financial crimes in Bangladesh."	ArXiv
1378	"Efficiently Reusing Natural Language Processing Models for
  Phenotype-Mention Identification in Free-text Electronic Medical Records:
  Methodology Study"	['Honghan Wu', 'Karen Hodgson', 'Sue Dyson', 'Katherine I. Morley', 'Zina M. Ibrahim', 'Ehtesham Iqbal', 'Robert Stewart', 'Richard JB Dobson', 'Cathie Sudlow']	2019-03-10 14:05:08+00:00	http://arxiv.org/abs/1903.03995v3	"Background: Many efforts have been put into the use of automated approaches,
such as natural language processing (NLP), to mine or extract data from
free-text medical records to construct comprehensive patient profiles for
delivering better health-care. Reusing NLP models in new settings, however,
remains cumbersome - requiring validation and/or retraining on new data
iteratively to achieve convergent results.
  Objective: The aim of this work is to minimize the effort involved in reusing
NLP models on free-text medical records.
  Methods: We formally define and analyse the model adaptation problem in
phenotype-mention identification tasks. We identify ""duplicate waste"" and
""imbalance waste"", which collectively impede efficient model reuse. We propose
a phenotype embedding based approach to minimize these sources of waste without
the need for labelled data from new settings.
  Results: We conduct experiments on data from a large mental health registry
to reuse NLP models in four phenotype-mention identification tasks. The
proposed approach can choose the best model for a new task, identifying up to
76% (duplicate waste), i.e. phenotype mentions without the need for validation
and model retraining, and with very good performance (93-97% accuracy). It can
also provide guidance for validating and retraining the selected model for
novel language patterns in new tasks, saving around 80% (imbalance waste), i.e.
the effort required in ""blind"" model-adaptation approaches.
  Conclusions: Adapting pre-trained NLP models for new tasks can be more
efficient and effective if the language pattern landscapes of old settings and
new settings can be made explicit and comparable. Our experiments show that the
phenotype-mention embedding approach is an effective way to model language
patterns for phenotype-mention identification tasks and that its use can guide
efficient NLP model reuse."	ArXiv
1379	State-of-the-art generalisation research in NLP: A taxonomy and review	['Dieuwke Hupkes', 'Mario Giulianelli', 'Verna Dankers', 'Mikel Artetxe', 'Yanai Elazar', 'Tiago Pimentel', 'Christos Christodoulopoulos', 'Karim Lasri', 'Naomi Saphra', 'Arabella Sinclair', 'Dennis Ulmer', 'Florian Schottmann', 'Khuyagbaatar Batsuren', 'Kaiser Sun', 'Koustuv Sinha', 'Leila Khalatbari', 'Maria Ryskina', 'Rita Frieske', 'Ryan Cotterell', 'Zhijing Jin']	2022-10-06 16:53:33+00:00	http://arxiv.org/abs/2210.03050v4	"The ability to generalise well is one of the primary desiderata of natural
language processing (NLP). Yet, what 'good generalisation' entails and how it
should be evaluated is not well understood, nor are there any evaluation
standards for generalisation. In this paper, we lay the groundwork to address
both of these issues. We present a taxonomy for characterising and
understanding generalisation research in NLP. Our taxonomy is based on an
extensive literature review of generalisation research, and contains five axes
along which studies can differ: their main motivation, the type of
generalisation they investigate, the type of data shift they consider, the
source of this data shift, and the locus of the shift within the modelling
pipeline. We use our taxonomy to classify over 400 papers that test
generalisation, for a total of more than 600 individual experiments.
Considering the results of this review, we present an in-depth analysis that
maps out the current state of generalisation research in NLP, and we make
recommendations for which areas might deserve attention in the future. Along
with this paper, we release a webpage where the results of our review can be
dynamically explored, and which we intend to update as new NLP generalisation
studies are published. With this work, we aim to take steps towards making
state-of-the-art generalisation testing the new status quo in NLP."	ArXiv
1380	"Natural Language Processing (NLP) for Requirements Engineering: A
  Systematic Mapping Study"	['Liping Zhao', 'Waad Alhoshan', 'Alessio Ferrari', 'Keletso J. Letsholo', 'Muideen A. Ajagbe', 'Erol-Valeriu Chioasca', 'Riza T. Batista-Navarro']	2020-04-02 16:03:48+00:00	http://arxiv.org/abs/2004.01099v2	"Natural language processing supported requirements engineering is an area of
research and development that seeks to apply NLP techniques, tools and
resources to a variety of requirements documents or artifacts to support a
range of linguistic analysis tasks performed at various RE phases. Such tasks
include detecting language issues, identifying key domain concepts and
establishing traceability links between requirements. This article surveys the
landscape of NLP4RE research to understand the state of the art and identify
open problems. The systematic mapping study approach is used to conduct this
survey, which identified 404 relevant primary studies and reviewed them
according to five research questions, cutting across five aspects of NLP4RE
research, concerning the state of the literature, the state of empirical
research, the research focus, the state of the practice, and the NLP
technologies used. Results: 1) NLP4RE is an active and thriving research area
in RE that has amassed a large number of publications and attracted widespread
attention from diverse communities; 2) most NLP4RE studies are solution
proposals having only been evaluated using a laboratory experiment or an
example application; 3) most studies have focused on the analysis phase, with
detection as their central linguistic analysis task and requirements
specification as their commonly processed document type; 4) 130 new tools have
been proposed to support a range of linguistic analysis tasks, but there is
little evidence of adoption in the long term, although some industrial
applications have been published; 5) 140 NLP techniques, 66 NLP tools and 25
NLP resources are extracted from the selected studies."	ArXiv
1381	"A Study of Social and Behavioral Determinants of Health in Lung Cancer
  Patients Using Transformers-based Natural Language Processing Models"	['Zehao Yu', 'Xi Yang', 'Chong Dang', 'Songzi Wu', 'Prakash Adekkanattu', 'Jyotishman Pathak', 'Thomas J. George', 'William R. Hogan', 'Yi Guo', 'Jiang Bian', 'Yonghui Wu']	2021-08-10 22:11:31+00:00	http://arxiv.org/abs/2108.04949v1	"Social and behavioral determinants of health (SBDoH) have important roles in
shaping people's health. In clinical research studies, especially comparative
effectiveness studies, failure to adjust for SBDoH factors will potentially
cause confounding issues and misclassification errors in either statistical
analyses and machine learning-based models. However, there are limited studies
to examine SBDoH factors in clinical outcomes due to the lack of structured
SBDoH information in current electronic health record (EHR) systems, while much
of the SBDoH information is documented in clinical narratives. Natural language
processing (NLP) is thus the key technology to extract such information from
unstructured clinical text. However, there is not a mature clinical NLP system
focusing on SBDoH. In this study, we examined two state-of-the-art
transformer-based NLP models, including BERT and RoBERTa, to extract SBDoH
concepts from clinical narratives, applied the best performing model to extract
SBDoH concepts on a lung cancer screening patient cohort, and examined the
difference of SBDoH information between NLP extracted results and structured
EHRs (SBDoH information captured in standard vocabularies such as the
International Classification of Diseases codes). The experimental results show
that the BERT-based NLP model achieved the best strict/lenient F1-score of
0.8791 and 0.8999, respectively. The comparison between NLP extracted SBDoH
information and structured EHRs in the lung cancer patient cohort of 864
patients with 161,933 various types of clinical notes showed that much more
detailed information about smoking, education, and employment were only
captured in clinical narratives and that it is necessary to use both clinical
narratives and structured EHRs to construct a more complete picture of
patients' SBDoH factors."	ArXiv
1382	"Missing Information, Unresponsive Authors, Experimental Flaws: The
  Impossibility of Assessing the Reproducibility of Previous Human Evaluations
  in NLP"	['Anya Belz', 'Craig Thomson', 'Ehud Reiter', 'Gavin Abercrombie', 'Jose M. Alonso-Moral', 'Mohammad Arvan', 'Anouck Braggaar', 'Mark Cieliebak', 'Elizabeth Clark', 'Kees van Deemter', 'Tanvi Dinkar', 'Ondřej Dušek', 'Steffen Eger', 'Qixiang Fang', 'Mingqi Gao', 'Albert Gatt', 'Dimitra Gkatzia', 'Javier González-Corbelle', 'Dirk Hovy', 'Manuela Hürlimann', 'Takumi Ito', 'John D. Kelleher', 'Filip Klubicka', 'Emiel Krahmer', 'Huiyuan Lai', 'Chris van der Lee', 'Yiru Li', 'Saad Mahamood', 'Margot Mieskes', 'Emiel van Miltenburg', 'Pablo Mosteiro', 'Malvina Nissim', 'Natalie Parde', 'Ondřej Plátek', 'Verena Rieser', 'Jie Ruan', 'Joel Tetreault', 'Antonio Toral', 'Xiaojun Wan', 'Leo Wanner', 'Lewis Watson', 'Diyi Yang']	2023-05-02 17:46:12+00:00	http://arxiv.org/abs/2305.01633v2	"We report our efforts in identifying a set of previous human evaluations in
NLP that would be suitable for a coordinated study examining what makes human
evaluations in NLP more/less reproducible. We present our results and findings,
which include that just 13\% of papers had (i) sufficiently low barriers to
reproduction, and (ii) enough obtainable information, to be considered for
reproduction, and that all but one of the experiments we selected for
reproduction was discovered to have flaws that made the meaningfulness of
conducting a reproduction questionable. As a result, we had to change our
coordinated study design from a reproduce approach to a
standardise-then-reproduce-twice approach. Our overall (negative) finding that
the great majority of human evaluations in NLP is not repeatable and/or not
reproducible and/or too flawed to justify reproduction, paints a dire picture,
but presents an opportunity for a rethink about how to design and report human
evaluations in NLP."	ArXiv
1383	Pushing the Limits of ChatGPT on NLP Tasks	['Xiaofei Sun', 'Linfeng Dong', 'Xiaoya Li', 'Zhen Wan', 'Shuhe Wang', 'Tianwei Zhang', 'Jiwei Li', 'Fei Cheng', 'Lingjuan Lyu', 'Fei Wu', 'Guoyin Wang']	2023-06-16 09:40:05+00:00	http://arxiv.org/abs/2306.09719v2	"Despite the success of ChatGPT, its performances on most NLP tasks are still
well below the supervised baselines. In this work, we looked into the causes,
and discovered that its subpar performance was caused by the following factors:
(1) token limit in the prompt does not allow for the full utilization of the
supervised datasets; (2) mismatch between the generation nature of ChatGPT and
NLP tasks; (3) intrinsic pitfalls of LLMs models, e.g., hallucination, overly
focus on certain keywords, etc.
  In this work, we propose a collection of general modules to address these
issues, in an attempt to push the limits of ChatGPT on NLP tasks. Our proposed
modules include (1) a one-input-multiple-prompts strategy that employs multiple
prompts for one input to accommodate more demonstrations; (2) using fine-tuned
models for better demonstration retrieval; (3) transforming tasks to formats
that are more tailored to the generation nature; (4) employing reasoning
strategies that are tailored to addressing the task-specific complexity; (5)
the self-verification strategy to address the hallucination issue of LLMs; (6)
the paraphrase strategy to improve the robustness of model predictions.
  We conduct experiments on 21 datasets of 10 representative NLP tasks,
including question answering, commonsense reasoning, natural language
inference, sentiment analysis, named entity recognition, entity-relation
extraction, event extraction, dependency parsing, semantic role labeling, and
part-of-speech tagging. Using the proposed assemble of techniques, we are able
to significantly boost the performance of ChatGPT on the selected NLP tasks,
achieving performances comparable to or better than supervised baselines, or
even existing SOTA performances."	ArXiv
1384	"A Comparison of Veterans with Problematic Opioid Use Identified through
  Natural Language Processing of Clinical Notes versus Using Diagnostic Codes"	['Terri Elizabeth Workman', 'Joel Kupersmith', 'Phillip Ma', 'Christopher Spevak', 'Friedhelm Sandbrink', 'Yan Cheng Qing Zeng-Treitler']	2024-01-18 18:08:16+00:00	http://arxiv.org/abs/2401.12996v1	"Background: Electronic health records (EHRs) are a data source for opioid
research. Opioid use disorder is known to be under-coded as a diagnosis, yet
problematic opioid use can be documented in clinical notes.
  Objectives: Our goals were 1) to identify problematic opioid use from a full
range of clinical notes; and 2) to compare the characteristics of patients
identified as having problematic opioid use, exclusively documented in clinical
notes, to those having documented ICD opioid use disorder diagnostic codes.
  Materials and Methods: We developed and applied a natural language processing
(NLP) tool to the clinical notes of a patient cohort (n=222,371) from two
Veteran Affairs service regions to identify patients with problematic opioid
use. We also used a set of ICD diagnostic codes to identify patients with
opioid use disorder from the same cohort. We compared the demographic and
clinical characteristics of patients identified only through NLP, to those of
patients identified through ICD codes.
  Results: NLP exclusively identified 57,331 patients; 6,997 patients had
positive ICD code identifications. Patients exclusively identified through NLP
were more likely to be women. Those identified through ICD codes were more
likely to be male, younger, have concurrent benzodiazepine prescriptions, more
comorbidities, more care encounters, and less likely to be married. Patients in
the NLP and ICD groups had substantially elevated comorbidity levels compared
to patients not documented as experiencing problematic opioid use.
  Conclusions: NLP is a feasible approach for identifying problematic opioid
use not otherwise recorded by ICD codes. Clinicians may be reluctant to code
for opioid use disorder. It is therefore incumbent on the healthcare team to
search for documentation of opioid concerns within clinical notes."	ArXiv
1385	"A mapping-free NLP-based technique for sequence search in Nanopore
  long-reads"	['Tomasz Strzoda', 'Lourdes Cruz-Garcia', 'Mustafa Najim', 'Christophe Badie', 'Joanna Polanska']	2024-06-20 10:48:19+00:00	http://arxiv.org/abs/2406.14187v1	"In unforeseen situations, such as nuclear power plant's or civilian radiation
accidents, there is a need for effective and computationally inexpensive
methods to determine the expression level of a selected gene panel, allowing
for rough dose estimates in thousands of donors. The new generation in-situ
mapper, fast and of low energy consumption, working at the level of single
nanopore output, is in demand. We aim to create a sequence identification tool
that utilizes Natural Language Processing (NLP) techniques and ensures a high
level of negative predictive value (NPV) compared to the classical approach.
The training dataset consisted of RNASeq data from 6 samples. Having tested
multiple NLP models, the best configuration analyses the entire sequence and
uses a word length of 3 base pairs with one-word neighbor on each side. For the
considered FDXR gene, the achieved mean balanced accuracy (BACC) was 98.29% and
NPV 99.25%, compared to minimap2's performance in a cross-validation scenario.
Reducing the dictionary from 1024 to 145 changed BACC to 96.49% and the NPV to
98.15%. Obtained NLP model, validated on an external independent genome
sequencing dataset, gave NPV of 99.64% for complete and 95.87% for reduced
dictionary. The salmon-estimated read counts differed from the classical
approach on average by 3.48% for the complete dictionary and by 5.82% for the
reduced one. We conclude that for long Oxford Nanopore reads, an NLP-based
approach can successfully replace classical mapping in case of emergency. The
developed NLP model can be easily retrained to identify selected transcripts
and/or work with various long-read sequencing techniques. Our results of the
study clearly demonstrate the potential of applying techniques known from
classical text processing to nucleotide sequences and represent a significant
advancement in this field of science."	ArXiv
1386	How much is enough?: Data requirements for statistical NLP	['Mark Lauer']	1995-09-07 07:53:23+00:00	http://arxiv.org/abs/cmp-lg/9509001v1	"In this paper I explore a number of issues in the analysis of data
requirements for statistical NLP systems. A preliminary framework for viewing
such systems is proposed and a sample of existing works are compared within
this framework. The first steps toward a theory of data requirements are made
by establishing some results relevant to bounding the expected error rate of a
class of simplified statistical language learners as a function of the volume
of training data."	ArXiv
1387	The Theoretical Status of Ontologies in Natural Language Processing	['John A. Bateman']	1997-04-25 13:00:14+00:00	http://arxiv.org/abs/cmp-lg/9704010v1	"This paper discusses the use of `ontologies' in Natural Language Processing.
It classifies various kinds of ontologies that have been employed in NLP and
discusses various benefits and problems with those designs. Particular focus is
then placed on experiences gained in the use of the Upper Model, a
linguistically-motivated `ontology' originally designed for use with the Penman
text generation system. Some proposals for further NLP ontology design criteria
are then made."	ArXiv
1388	"Semantic robust parsing for noun extraction from natural language
  queries"	['Afzal Ballim', 'Vincenzo Pallotta']	1999-09-02 15:53:07+00:00	http://arxiv.org/abs/cs/9909002v1	"This paper describes how robust parsing techniques can be fruitful applied
for building a query generation module which is part of a pipelined NLP
architecture aimed at process natural language queries in a restricted domain.
We want to show that semantic robustness represents a key issue in those NLP
systems where it is more likely to have partial and ill-formed utterances due
to various factors (e.g. noisy environments, low quality of speech recognition
modules, etc...) and where it is necessary to succeed, even if partially, in
extracting some meaningful information."	ArXiv
1389	"Using the Distribution of Performance for Studying Statistical NLP
  Systems and Corpora"	['Yuval Krymolowski']	2001-06-20 14:16:17+00:00	http://arxiv.org/abs/cs/0106043v1	"Statistical NLP systems are frequently evaluated and compared on the basis of
their performances on a single split of training and test data. Results
obtained using a single split are, however, subject to sampling noise. In this
paper we argue in favour of reporting a distribution of performance figures,
obtained by resampling the training data, rather than a single number. The
additional information from distributions can be used to make statistically
quantified statements about differences across parameter settings, systems, and
corpora."	ArXiv
1390	Understanding Exhaustive Pattern Learning	['Libin Shen']	2011-04-20 02:49:59+00:00	http://arxiv.org/abs/1104.3929v1	"Pattern learning in an important problem in Natural Language Processing
(NLP). Some exhaustive pattern learning (EPL) methods (Bod, 1992) were proved
to be flawed (Johnson, 2002), while similar algorithms (Och and Ney, 2004)
showed great advantages on other tasks, such as machine translation. In this
article, we first formalize EPL, and then show that the probability given by an
EPL model is constant-factor approximation of the probability given by an
ensemble method that integrates exponential number of models obtained with
various segmentations of the training data. This work for the first time
provides theoretical justification for the widely used EPL algorithm in NLP,
which was previously viewed as a flawed heuristic method. Better understanding
of EPL may lead to improved pattern learning algorithms in future."	ArXiv
1391	Heavy quarkonium production and polarization	['Zhong-Bo Kang', 'Jian-Wei Qiu', 'George Sterman']	2011-09-07 18:03:00+00:00	http://arxiv.org/abs/1109.1520v1	"We present a perturbative QCD factorization formalism for the production of
heavy quarkonia of large transverse momentum $p_T$ at collider energies, which
includes both the leading power (LP) and next-to-leading power (NLP)
contributions to the cross section in the $m_Q^2/p_T^2$ expansion for heavy
quark mass $m_Q$. We estimate fragmentation functions in the non-relativistic
QCD formalism, and reproduce the bulk of the large enhancement found in
explicit NLO calculations in the color singlet model. Heavy quarkonia produced
from NLP channels prefer longitudinal polarization."	ArXiv
1392	Du TAL au TIL	['Michael Zock', 'Guy Lapalme']	2012-01-20 17:35:29+00:00	http://arxiv.org/abs/1201.4733v1	"Historically two types of NLP have been investigated: fully automated
processing of language by machines (NLP) and autonomous processing of natural
language by people, i.e. the human brain (psycholinguistics). We believe that
there is room and need for another kind, INLP: interactive natural language
processing. This intermediate approach starts from peoples' needs, trying to
bridge the gap between their actual knowledge and a given goal. Given the fact
that peoples' knowledge is variable and often incomplete, the aim is to build
bridges linking a given knowledge state to a given goal. We present some
examples, trying to show that this goal is worth pursuing, achievable and at a
reasonable cost."	ArXiv
1393	SpeedRead: A Fast Named Entity Recognition Pipeline	"[""Rami Al-Rfou'"", 'Steven Skiena']"	2013-01-14 04:01:25+00:00	http://arxiv.org/abs/1301.2857v1	"Online content analysis employs algorithmic methods to identify entities in
unstructured text. Both machine learning and knowledge-base approaches lie at
the foundation of contemporary named entities extraction systems. However, the
progress in deploying these approaches on web-scale has been been hampered by
the computational cost of NLP over massive text corpora. We present SpeedRead
(SR), a named entity recognition pipeline that runs at least 10 times faster
than Stanford NLP pipeline. This pipeline consists of a high performance Penn
Treebank- compliant tokenizer, close to state-of-art part-of-speech (POS)
tagger and knowledge-based named entity recognizer."	ArXiv
1394	Stemmers for Tamil Language: Performance Analysis	['M. Thangarasu', 'R. Manavalan']	2013-10-02 16:23:00+00:00	http://arxiv.org/abs/1310.0754v1	"Stemming is the process of extracting root word from the given inflection
word and also plays significant role in numerous application of Natural
Language Processing (NLP). Tamil Language raises several challenges to NLP,
since it has rich morphological patterns than other languages. The rule based
approach light-stemmer is proposed in this paper, to find stem word for given
inflection Tamil word. The performance of proposed approach is compared to a
rule based suffix removal stemmer based on correctly and incorrectly predicted.
The experimental result clearly show that the proposed approach light stemmer
for Tamil language perform better than suffix removal stemmer and also more
effective in Information Retrieval System (IRS)."	ArXiv
1395	"A State of the Art of Word Sense Induction: A Way Towards Word Sense
  Disambiguation for Under-Resourced Languages"	['Mohammad Nasiruddin']	2013-10-05 00:33:46+00:00	http://arxiv.org/abs/1310.1425v1	"Word Sense Disambiguation (WSD), the process of automatically identifying the
meaning of a polysemous word in a sentence, is a fundamental task in Natural
Language Processing (NLP). Progress in this approach to WSD opens up many
promising developments in the field of NLP and its applications. Indeed,
improvement over current performance levels could allow us to take a first step
towards natural language understanding. Due to the lack of lexical resources it
is sometimes difficult to perform WSD for under-resourced languages. This paper
is an investigation on how to initiate research in WSD for under-resourced
languages by applying Word Sense Induction (WSI) and suggests some interesting
topics to focus on."	ArXiv
1396	"Autonomous requirements specification processing using natural language
  processing"	['S. G. Macdonell', 'K. Min', 'A. M. Connor']	2014-07-23 03:29:44+00:00	http://arxiv.org/abs/1407.6099v1	"We describe our ongoing research that centres on the application of natural
language processing (NLP) to software engineering and systems development
activities. In particular, this paper addresses the use of NLP in the
requirements analysis and systems design processes. We have developed a
prototype toolset that can assist the systems analyst or software engineer to
select and verify terms relevant to a project. In this paper we describe the
processes employed by the system to extract and classify objects of interest
from requirements documents. These processes are illustrated using a small
example."	ArXiv
1397	"Raman-scattering-assistant broadband noise-like pulse generation in
  all-normal-dispersion fiber lasers"	['Daojing Li', 'Deyuan Shen', 'Lei Li', 'Hao Chen', 'Dingyuan Tang', 'Luming Zhao']	2015-07-30 12:02:53+00:00	http://arxiv.org/abs/1507.08470v1	"We report on the observation of both stable dissipative solitons and
noise-like pulses with the presence of strong Raman scattering in a relatively
short all-normal-dispersion Yb-doped fiber laser. We show that Raman scattering
can be filtered out by intracavity filter. Furthermore, by appropriate
intracavity polarization control, the Raman effect can be utilized to generate
broadband noise-like pulses (NLPs) with bandwidth up to 61.4 nm. To the best of
our knowledge, this is the broadest NLP achieved in all-normal-dispersion fiber
lasers"	ArXiv
1398	"A Comparative Study on Regularization Strategies for Embedding-based
  Neural Networks"	['Hao Peng', 'Lili Mou', 'Ge Li', 'Yunchuan Chen', 'Yangyang Lu', 'Zhi Jin']	2015-08-15 11:16:39+00:00	http://arxiv.org/abs/1508.03721v1	"This paper aims to compare different regularization strategies to address a
common phenomenon, severe overfitting, in embedding-based neural networks for
NLP. We chose two widely studied neural models and tasks as our testbed. We
tried several frequently applied or newly proposed regularization strategies,
including penalizing weights (embeddings excluded), penalizing embeddings,
re-embedding words, and dropout. We also emphasized on incremental
hyperparameter tuning, and combining different regularizations. The results
provide a picture on tuning hyperparameters for neural NLP models."	ArXiv
1399	"Posterior calibration and exploratory analysis for natural language
  processing models"	"['Khanh Nguyen', ""Brendan O'Connor""]"	2015-08-21 00:25:51+00:00	http://arxiv.org/abs/1508.05154v2	"Many models in natural language processing define probabilistic distributions
over linguistic structures. We argue that (1) the quality of a model' s
posterior distribution can and should be directly evaluated, as to whether
probabilities correspond to empirical frequencies, and (2) NLP uncertainty can
be projected not only to pipeline components, but also to exploratory data
analysis, telling a user when to trust and not trust the NLP analysis. We
present a method to analyze calibration, and apply it to compare the
miscalibration of several commonly used models. We also contribute a
coreference sampling algorithm that can create confidence intervals for a
political event extraction task."	ArXiv
1400	"Measuring the State of the Art of Automated Pathway Curation Using Graph
  Algorithms - A Case Study of the mTOR Pathway"	['Michael Spranger', 'Sucheendra K. Palaniappan', 'Samik Ghosh']	2016-08-12 12:10:24+00:00	http://arxiv.org/abs/1608.03767v1	"This paper evaluates the difference between human pathway curation and
current NLP systems. We propose graph analysis methods for quantifying the gap
between human curated pathway maps and the output of state-of-the-art automatic
NLP systems. Evaluation is performed on the popular mTOR pathway. Based on
analyzing where current systems perform well and where they fail, we identify
possible avenues for progress."	ArXiv
1401	"Survey on the Use of Typological Information in Natural Language
  Processing"	"[""Helen O'Horan"", 'Yevgeni Berzak', 'Ivan Vulić', 'Roi Reichart', 'Anna Korhonen']"	2016-10-11 14:11:55+00:00	http://arxiv.org/abs/1610.03349v1	"In recent years linguistic typology, which classifies the world's languages
according to their functional and structural properties, has been widely used
to support multilingual NLP. While the growing importance of typological
information in supporting multilingual tasks has been recognised, no systematic
survey of existing typological resources and their use in NLP has been
published. This paper provides such a survey as well as discussion which we
hope will both inform and inspire future work in the area."	ArXiv
1402	"Why we have switched from building full-fledged taxonomies to simply
  detecting hypernymy relations"	['Jose Camacho-Collados']	2017-03-12 21:07:54+00:00	http://arxiv.org/abs/1703.04178v2	"The study of taxonomies and hypernymy relations has been extensive on the
Natural Language Processing (NLP) literature. However, the evaluation of
taxonomy learning approaches has been traditionally troublesome, as it mainly
relies on ad-hoc experiments which are hardly reproducible and manually
expensive. Partly because of this, current research has been lately focusing on
the hypernymy detection task. In this paper we reflect on this trend, analyzing
issues related to current evaluation procedures. Finally, we propose three
potential avenues for future work so that is-a relations and resources based on
them play a more important role in downstream NLP applications."	ArXiv
1403	"The risk of sub-optimal use of Open Source NLP Software: UKB is
  inadvertently state-of-the-art in knowledge-based WSD"	['Eneko Agirre', 'Oier López de Lacalle', 'Aitor Soroa']	2018-05-11 08:46:15+00:00	http://arxiv.org/abs/1805.04277v1	"UKB is an open source collection of programs for performing, among other
tasks, knowledge-based Word Sense Disambiguation (WSD). Since it was released
in 2009 it has been often used out-of-the-box in sub-optimal settings. We show
that nine years later it is the state-of-the-art on knowledge-based WSD. This
case shows the pitfalls of releasing open source NLP software without optimal
default settings and precise instructions for reproducibility."	ArXiv
1404	Mixed-Precision Training for NLP and Speech Recognition with OpenSeq2Seq	['Oleksii Kuchaiev', 'Boris Ginsburg', 'Igor Gitman', 'Vitaly Lavrukhin', 'Jason Li', 'Huyen Nguyen', 'Carl Case', 'Paulius Micikevicius']	2018-05-25 22:54:38+00:00	http://arxiv.org/abs/1805.10387v2	"We present OpenSeq2Seq - a TensorFlow-based toolkit for training
sequence-to-sequence models that features distributed and mixed-precision
training. Benchmarks on machine translation and speech recognition tasks show
that models built using OpenSeq2Seq give state-of-the-art performance at 1.5-3x
less training time. OpenSeq2Seq currently provides building blocks for models
that solve a wide range of tasks including neural machine translation,
automatic speech recognition, and speech synthesis."	ArXiv
1405	Natural Language Processing for Music Knowledge Discovery	['Sergio Oramas', 'Luis Espinosa-Anke', 'Francisco Gómez', 'Xavier Serra']	2018-07-06 00:07:27+00:00	http://arxiv.org/abs/1807.02200v1	"Today, a massive amount of musical knowledge is stored in written form, with
testimonies dated as far back as several centuries ago. In this work, we
present different Natural Language Processing (NLP) approaches to harness the
potential of these text collections for automatic music knowledge discovery,
covering different phases in a prototypical NLP pipeline, namely corpus
compilation, text-mining, information extraction, knowledge graph generation
and sentiment analysis. Each of these approaches is presented alongside
different use cases (i.e., flamenco, Renaissance and popular music) where large
collections of documents are processed, and conclusions stemming from
data-driven analyses are presented and discussed."	ArXiv
1406	"emrQA: A Large Corpus for Question Answering on Electronic Medical
  Records"	['Anusri Pampari', 'Preethi Raghavan', 'Jennifer Liang', 'Jian Peng']	2018-09-03 21:56:47+00:00	http://arxiv.org/abs/1809.00732v1	"We propose a novel methodology to generate domain-specific large-scale
question answering (QA) datasets by re-purposing existing annotations for other
NLP tasks. We demonstrate an instance of this methodology in generating a
large-scale QA dataset for electronic medical records by leveraging existing
expert annotations on clinical notes for various NLP tasks from the community
shared i2b2 datasets. The resulting corpus (emrQA) has 1 million
question-logical form and 400,000+ question-answer evidence pairs. We
characterize the dataset and explore its learning potential by training
baseline models for question to logical form and question to answer mapping."	ArXiv
1407	Interpretable Textual Neuron Representations for NLP	['Nina Poerner', 'Benjamin Roth', 'Hinrich Schütze']	2018-09-19 16:32:47+00:00	http://arxiv.org/abs/1809.07291v1	"Input optimization methods, such as Google Deep Dream, create interpretable
representations of neurons for computer vision DNNs. We propose and evaluate
ways of transferring this technology to NLP. Our results suggest that gradient
ascent with a gumbel softmax layer produces n-gram representations that
outperform naive corpus search in terms of target neuron activation. The
representations highlight differences in syntax awareness between the language
and visual models of the Imaginet architecture."	ArXiv
1408	Analyzing and Interpreting Convolutional Neural Networks in NLP	['Mahnaz Koupaee', 'William Yang Wang']	2018-10-18 05:18:04+00:00	http://arxiv.org/abs/1810.09312v1	"Convolutional neural networks have been successfully applied to various NLP
tasks. However, it is not obvious whether they model different linguistic
patterns such as negation, intensification, and clause compositionality to help
the decision-making process. In this paper, we apply visualization techniques
to observe how the model can capture different linguistic features and how
these features can affect the performance of the model. Later on, we try to
identify the model errors and their sources. We believe that interpreting CNNs
is the first step to understand the underlying semantic features which can
raise awareness to further improve the performance and explainability of CNN
models."	ArXiv
1409	"Universal Language Model Fine-Tuning with Subword Tokenization for
  Polish"	['Piotr Czapla', 'Jeremy Howard', 'Marcin Kardas']	2018-10-24 07:34:45+00:00	http://arxiv.org/abs/1810.10222v1	"Universal Language Model for Fine-tuning [arXiv:1801.06146] (ULMFiT) is one
of the first NLP methods for efficient inductive transfer learning.
Unsupervised pretraining results in improvements on many NLP tasks for English.
In this paper, we describe a new method that uses subword tokenization to adapt
ULMFiT to languages with high inflection. Our approach results in a new
state-of-the-art for the Polish language, taking first place in Task 3 of
PolEval'18. After further training, our final model outperformed the second
best model by 35%. We have open-sourced our pretrained models and code."	ArXiv
1410	An Introductory Survey on Attention Mechanisms in NLP Problems	['Dichao Hu']	2018-11-12 16:19:22+00:00	http://arxiv.org/abs/1811.05544v1	"First derived from human intuition, later adapted to machine translation for
automatic token alignment, attention mechanism, a simple method that can be
used for encoding sequence data based on the importance score each element is
assigned, has been widely applied to and attained significant improvement in
various tasks in natural language processing, including sentiment
classification, text summarization, question answering, dependency parsing,
etc. In this paper, we survey through recent works and conduct an introductory
summary of the attention mechanism in different NLP problems, aiming to provide
our readers with basic knowledge on this widely used method, discuss its
different variants for different tasks, explore its association with other
techniques in machine learning, and examine methods for evaluating its
performance."	ArXiv
1411	Quantifying Uncertainties in Natural Language Processing Tasks	['Yijun Xiao', 'William Yang Wang']	2018-11-18 01:36:05+00:00	http://arxiv.org/abs/1811.07253v1	"Reliable uncertainty quantification is a first step towards building
explainable, transparent, and accountable artificial intelligent systems.
Recent progress in Bayesian deep learning has made such quantification
realizable. In this paper, we propose novel methods to study the benefits of
characterizing model and data uncertainties for natural language processing
(NLP) tasks. With empirical experiments on sentiment analysis, named entity
recognition, and language modeling using convolutional and recurrent neural
network models, we show that explicitly modeling uncertainties is not only
necessary to measure output confidence levels, but also useful at enhancing
model performances in various NLP tasks."	ArXiv
1412	"Recent advances in conversational NLP : Towards the standardization of
  Chatbot building"	['Maali Mnasri']	2019-03-21 14:30:55+00:00	http://arxiv.org/abs/1903.09025v1	"Dialogue systems have become recently essential in our life. Their use is
getting more and more fluid and easy throughout the time. This boils down to
the improvements made in NLP and AI fields. In this paper, we try to provide an
overview to the current state of the art of dialogue systems, their categories
and the different approaches to build them. We end up with a discussion that
compares all the techniques and analyzes the strengths and weaknesses of each.
Finally, we present an opinion piece suggesting to orientate the research
towards the standardization of dialogue systems building."	ArXiv
1413	Task-specific Word-Clustering for Part-of-Speech Tagging	['Yoav Goldberg']	2012-05-19 05:04:31+00:00	http://arxiv.org/abs/1205.4298v1	"While the use of cluster features became ubiquitous in core NLP tasks, most
cluster features in NLP are based on distributional similarity. We propose a
new type of clustering criteria, specific to the task of part-of-speech
tagging. Instead of distributional similarity, these clusters are based on the
beha vior of a baseline tagger when applied to a large corpus. These cluster
features provide similar gains in accuracy to those achieved by
distributional-similarity derived clusters. Using both types of cluster
features together further improve tagging accuracies. We show that the method
is effective for both the in-domain and out-of-domain scenarios for English,
and for French, German and Italian. The effect is larger for out-of-domain
text."	ArXiv
1414	"Latent Tree Learning with Differentiable Parsers: Shift-Reduce Parsing
  and Chart Parsing"	['Jean Maillard', 'Stephen Clark']	2018-06-03 17:34:41+00:00	http://arxiv.org/abs/1806.00840v1	"Latent tree learning models represent sentences by composing their words
according to an induced parse tree, all based on a downstream task. These
models often outperform baselines which use (externally provided) syntax trees
to drive the composition order. This work contributes (a) a new latent tree
learning model based on shift-reduce parsing, with competitive downstream
performance and non-trivial induced trees, and (b) an analysis of the trees
learned by our shift-reduce model and by a chart-based model."	ArXiv
1415	"Challenges of language technologies for the indigenous languages of the
  Americas"	['Manuel Mager', 'Ximena Gutierrez-Vasques', 'Gerardo Sierra', 'Ivan Meza']	2018-06-12 01:26:55+00:00	http://arxiv.org/abs/1806.04291v1	"Indigenous languages of the American continent are highly diverse. However,
they have received little attention from the technological perspective. In this
paper, we review the research, the digital resources and the available NLP
systems that focus on these languages. We present the main challenges and
research questions that arise when distant languages and low-resource scenarios
are faced. We would like to encourage NLP research in linguistically rich and
diverse areas like the Americas."	ArXiv
1416	Par4Sim -- Adaptive Paraphrasing for Text Simplification	['Seid Muhie Yimam', 'Chris Biemann']	2018-06-21 16:24:31+00:00	http://arxiv.org/abs/1806.08309v1	"Learning from a real-world data stream and continuously updating the model
without explicit supervision is a new challenge for NLP applications with
machine learning components. In this work, we have developed an adaptive
learning system for text simplification, which improves the underlying
learning-to-rank model from usage data, i.e. how users have employed the system
for the task of simplification. Our experimental result shows that, over a
period of time, the performance of the embedded paraphrase ranking model
increases steadily improving from a score of 62.88% up to 75.70% based on the
NDCG@10 evaluation metrics. To our knowledge, this is the first study where an
NLP component is adaptively improved through usage."	ArXiv
1417	PyText: A Seamless Path from NLP research to production	['Ahmed Aly', 'Kushal Lakhotia', 'Shicong Zhao', 'Mrinal Mohit', 'Barlas Oguz', 'Abhinav Arora', 'Sonal Gupta', 'Christopher Dewan', 'Stef Nelson-Lindall', 'Rushin Shah']	2018-12-12 23:06:43+00:00	http://arxiv.org/abs/1812.08729v1	"We introduce PyText - a deep learning based NLP modeling framework built on
PyTorch. PyText addresses the often-conflicting requirements of enabling rapid
experimentation and of serving models at scale. It achieves this by providing
simple and extensible interfaces for model components, and by using PyTorch's
capabilities of exporting models for inference via the optimized Caffe2
execution engine. We report our own experience of migrating experimentation and
production workflows to PyText, which enabled us to iterate faster on novel
modeling ideas and then seamlessly ship them at industrial scale."	ArXiv
1418	PhoBERT: Pre-trained language models for Vietnamese	['Dat Quoc Nguyen', 'Anh Tuan Nguyen']	2020-03-02 10:21:17+00:00	http://arxiv.org/abs/2003.00744v3	"We present PhoBERT with two versions, PhoBERT-base and PhoBERT-large, the
first public large-scale monolingual language models pre-trained for
Vietnamese. Experimental results show that PhoBERT consistently outperforms the
recent best pre-trained multilingual model XLM-R (Conneau et al., 2020) and
improves the state-of-the-art in multiple Vietnamese-specific NLP tasks
including Part-of-speech tagging, Dependency parsing, Named-entity recognition
and Natural language inference. We release PhoBERT to facilitate future
research and downstream applications for Vietnamese NLP. Our PhoBERT models are
available at https://github.com/VinAIResearch/PhoBERT"	ArXiv
1419	(Re)construing Meaning in NLP	['Sean Trott', 'Tiago Timponi Torrent', 'Nancy Chang', 'Nathan Schneider']	2020-05-18 21:21:34+00:00	http://arxiv.org/abs/2005.09099v1	"Human speakers have an extensive toolkit of ways to express themselves. In
this paper, we engage with an idea largely absent from discussions of meaning
in natural language understanding--namely, that the way something is expressed
reflects different ways of conceptualizing or construing the information being
conveyed. We first define this phenomenon more precisely, drawing on
considerable prior work in theoretical cognitive semantics and
psycholinguistics. We then survey some dimensions of construed meaning and show
how insights from construal could inform theoretical and practical work in NLP."	ArXiv
1420	Exploring Segment Representations for Neural Segmentation Models	['Yijia Liu', 'Wanxiang Che', 'Jiang Guo', 'Bing Qin', 'Ting Liu']	2016-04-19 10:08:49+00:00	http://arxiv.org/abs/1604.05499v1	"Many natural language processing (NLP) tasks can be generalized into
segmentation problem. In this paper, we combine semi-CRF with neural network to
solve NLP segmentation tasks. Our model represents a segment both by composing
the input units and embedding the entire segment. We thoroughly study different
composition functions and different segment embeddings. We conduct extensive
experiments on two typical segmentation tasks: named entity recognition (NER)
and Chinese word segmentation (CWS). Experimental results show that our neural
semi-CRF model benefits from representing the entire segment and achieves the
state-of-the-art performance on CWS benchmark dataset and competitive results
on the CoNLL03 dataset."	ArXiv
1421	Nilpotent linearized polynomials over finite fields and applications	['Lucas Reis']	2016-09-29 15:05:35+00:00	http://arxiv.org/abs/1609.09379v1	"Let $q$ be a prime power and $\mathbb F_{q^n}$ be the finite field with $q^n$
elements, where $n>1$. We introduce the class of the linearized polynomials
$L(x)$ over $\mathbb F_{q^n}$ such that
$$L^{(t)}(x):=\underbrace{L(L(\cdots(x)\cdots))}_{t \quad\text{times}}\equiv
0\pmod {x^{q^n}-x}$$ for some $t\ge 2$, called nilpotent linearized polynomials
(NLP's). We discuss the existence and construction of NLP's and, as an
application, we show how to construct permutations of $\mathbb F_{q^n}$ from
these polynomials. For some of those permutations, we can explicitly give the
compositional inverse map and the cycle structure. This paper also contains a
method for constructing involutions over binary fields with no fixed points,
which are useful in block ciphers."	ArXiv
1422	Strawman: an Ensemble of Deep Bag-of-Ngrams for Sentiment Analysis	['Kyunghyun Cho']	2017-07-26 17:30:57+00:00	http://arxiv.org/abs/1707.08939v1	"This paper describes a builder entry, named ""strawman"", to the sentence-level
sentiment analysis task of the ""Build It, Break It"" shared task of the First
Workshop on Building Linguistically Generalizable NLP Systems. The goal of a
builder is to provide an automated sentiment analyzer that would serve as a
target for breakers whose goal is to find pairs of minimally-differing
sentences that break the analyzer."	ArXiv
1423	"Towards Semantic Modeling of Contradictions and Disagreements: A Case
  Study of Medical Guidelines"	['Wlodek Zadrozny', 'Hossein Hematialam', 'Luciana Garbayo']	2017-08-02 17:54:32+00:00	http://arxiv.org/abs/1708.00850v1	"We introduce a formal distinction between contradictions and disagreements in
natural language texts, motivated by the need to formally reason about
contradictory medical guidelines. This is a novel and potentially very useful
distinction, and has not been discussed so far in NLP and logic. We also
describe a NLP system capable of automated finding contradictory medical
guidelines; the system uses a combination of text analysis and information
retrieval modules. We also report positive evaluation results on a small corpus
of contradictory medical recommendations."	ArXiv
1424	Rookie: A unique approach for exploring news archives	"['Abram Handler', ""Brendan O'Connor""]"	2017-08-06 22:20:02+00:00	http://arxiv.org/abs/1708.01944v1	"News archives are an invaluable primary source for placing current events in
historical context. But current search engine tools do a poor job at uncovering
broad themes and narratives across documents. We present Rookie: a practical
software system which uses natural language processing (NLP) to help readers,
reporters and editors uncover broad stories in news archives. Unlike prior
work, Rookie's design emerged from 18 months of iterative development in
consultation with editors and computational journalists. This process lead to a
dramatically different approach from previous academic systems with similar
goals. Our efforts offer a generalizable case study for others building
real-world journalism software using NLP."	ArXiv
1425	Dynamic Meta-Embeddings for Improved Sentence Representations	['Douwe Kiela', 'Changhan Wang', 'Kyunghyun Cho']	2018-04-21 15:32:32+00:00	http://arxiv.org/abs/1804.07983v2	"While one of the first steps in many NLP systems is selecting what
pre-trained word embeddings to use, we argue that such a step is better left
for neural networks to figure out by themselves. To that end, we introduce
dynamic meta-embeddings, a simple yet effective method for the supervised
learning of embedding ensembles, which leads to state-of-the-art performance
within the same model class on a variety of tasks. We subsequently show how the
technique can be used to shed new light on the usage of word embeddings in NLP
systems."	ArXiv
1426	Neural Vector Conceptualization for Word Vector Space Interpretation	['Robert Schwarzenberg', 'Lisa Raithel', 'David Harbecke']	2019-04-02 15:39:27+00:00	http://arxiv.org/abs/1904.01500v1	"Distributed word vector spaces are considered hard to interpret which hinders
the understanding of natural language processing (NLP) models. In this work, we
introduce a new method to interpret arbitrary samples from a word vector space.
To this end, we train a neural model to conceptualize word vectors, which means
that it activates higher order concepts it recognizes in a given vector.
Contrary to prior approaches, our model operates in the original vector space
and is capable of learning non-linear relations between word vectors and
concepts. Furthermore, we show that it produces considerably less entropic
concept activation profiles than the popular cosine similarity."	ArXiv
1427	Controllable pulse patterns in fiber lasers	['Xingliang Li', 'Shumin Zhang', 'Jingmin Liu', 'Zhenjun Yang']	2019-06-04 16:15:46+00:00	http://arxiv.org/abs/1906.01555v2	"An all-optical pulse power editing (PPE) technique is reported. Using the PPE
technique, pulses with different peak powers are output and directed to the
positive or reverse saturable absorption (SA) range of the saturable absorber.
Further, under the combined action of the PPE technique and SA, four pulse
patterns including dissipative soliton (DS), DS molecules, soliton compounds
composed of DS and noise-like pulse (NLP), and pure NLP are controllably
generated in fiber lasers. The results are conducive for developing advanced DS
lasers and can further clarify the onset of pulse dynamic patterns."	ArXiv
1428	Pitfalls in the Evaluation of Sentence Embeddings	['Steffen Eger', 'Andreas Rücklé', 'Iryna Gurevych']	2019-06-04 16:41:15+00:00	http://arxiv.org/abs/1906.01575v1	"Deep learning models continuously break new records across different NLP
tasks. At the same time, their success exposes weaknesses of model evaluation.
Here, we compile several key pitfalls of evaluation of sentence embeddings, a
currently very popular NLP paradigm. These pitfalls include the comparison of
embeddings of different sizes, normalization of embeddings, and the low (and
diverging) correlations between transfer and probing tasks. Our motivation is
to challenge the current evaluation of sentence embeddings and to provide an
easy-to-access reference for future research. Based on our insights, we also
recommend better practices for better future evaluations of sentence
embeddings."	ArXiv
1429	Principled Frameworks for Evaluating Ethics in NLP Systems	['Shrimai Prabhumoye', 'Elijah Mayfield', 'Alan W Black']	2019-06-14 22:52:21+00:00	http://arxiv.org/abs/1906.06425v1	"We critique recent work on ethics in natural language processing. Those
discussions have focused on data collection, experimental design, and
interventions in modeling. But we argue that we ought to first understand the
frameworks of ethics that are being used to evaluate the fairness and justice
of algorithmic systems. Here, we begin that discussion by outlining
deontological ethics, and envision a research agenda prioritized by it."	ArXiv
1430	Sparsity Emerges Naturally in Neural Language Models	['Naomi Saphra', 'Adam Lopez']	2019-07-22 14:06:15+00:00	http://arxiv.org/abs/1908.01817v1	"Concerns about interpretability, computational resources, and principled
inductive priors have motivated efforts to engineer sparse neural models for
NLP tasks. If sparsity is important for NLP, might well-trained neural models
naturally become roughly sparse? Using the Taxi-Euclidean norm to measure
sparsity, we find that frequent input words are associated with concentrated or
sparse activations, while frequent target words are associated with dispersed
activations but concentrated gradients. We find that gradients associated with
function words are more concentrated than the gradients of content words, even
controlling for word frequency."	ArXiv
1431	"Applying Recent Innovations from NLP to MOOC Student Course Trajectory
  Modeling"	['Clarence Chen', 'Zachary Pardos']	2020-01-23 01:36:57+00:00	http://arxiv.org/abs/2001.08333v2	"This paper presents several strategies that can improve neural network-based
predictive methods for MOOC student course trajectory modeling, applying
multiple ideas previously applied to tackle NLP (Natural Language Processing)
tasks. In particular, this paper investigates LSTM networks enhanced with two
forms of regularization, along with the more recently introduced Transformer
architecture."	ArXiv
1432	"Pragmatic information in translation: a corpus-based study of tense and
  mood in English and German"	['Anita Ramm', 'Ekaterina Lapshinova-Koltunski', 'Alexander Fraser']	2020-07-10 08:15:59+00:00	http://arxiv.org/abs/2007.05234v1	"Grammatical tense and mood are important linguistic phenomena to consider in
natural language processing (NLP) research. We consider the correspondence
between English and German tense and mood in translation. Human translators do
not find this correspondence easy, and as we will show through careful
analysis, there are no simplistic ways to map tense and mood from one language
to another. Our observations about the challenges of human translation of tense
and mood have important implications for multilingual NLP. Of particular
importance is the challenge of modeling tense and mood in rule-based,
phrase-based statistical and neural machine translation."	ArXiv
1433	"Recent Trends in the Use of Deep Learning Models for Grammar Error
  Handling"	['Mina Naghshnejad', 'Tarun Joshi', 'Vijayan N. Nair']	2020-09-04 18:50:13+00:00	http://arxiv.org/abs/2009.02358v1	"Grammar error handling (GEH) is an important topic in natural language
processing (NLP). GEH includes both grammar error detection and grammar error
correction. Recent advances in computation systems have promoted the use of
deep learning (DL) models for NLP problems such as GEH. In this survey we focus
on two main DL approaches for GEH: neural machine translation models and editor
models. We describe the three main stages of the pipeline for these models:
data preparation, training, and inference. Additionally, we discuss different
techniques to improve the performance of these models at each stage of the
pipeline. We compare the performance of different models and conclude with
proposed future directions."	ArXiv
1434	"Mimic and Conquer: Heterogeneous Tree Structure Distillation for
  Syntactic NLP"	['Hao Fei', 'Yafeng Ren', 'Donghong Ji']	2020-09-16 01:30:21+00:00	http://arxiv.org/abs/2009.07411v1	"Syntax has been shown useful for various NLP tasks, while existing work
mostly encodes singleton syntactic tree using one hierarchical neural network.
In this paper, we investigate a simple and effective method, Knowledge
Distillation, to integrate heterogeneous structure knowledge into a unified
sequential LSTM encoder. Experimental results on four typical syntax-dependent
tasks show that our method outperforms tree encoders by effectively integrating
rich heterogeneous structure syntax, meanwhile reducing error propagation, and
also outperforms ensemble methods, in terms of both the efficiency and
accuracy."	ArXiv
1435	A Gamification of Japanese Dependency Parsing	['Masayuki Asahara']	2021-01-09 01:42:07+00:00	http://arxiv.org/abs/2101.03269v1	"Gamification approaches have been used as a way for creating language
resources for NLP. It is also used for presenting and teaching the algorithms
in NLP and linguistic phenomena. This paper argues about a design of
gamification for Japanese syntactic dependendency parsing for the latter
objective. The user interface design is based on a transition-based shift
reduce dependency parsing which needs only two actions of SHIFT (not attach)
and REDUCE (attach) in Japanese dependency structure. We assign the two actions
for two-way directional control on a gamepad or other devices. We also design
the target sentences from psycholinguistics researches."	ArXiv
1436	Transfer Learning and Augmentation for Word Sense Disambiguation	['Harsh Kohli']	2021-01-10 19:56:39+00:00	http://arxiv.org/abs/2101.03617v1	"Many downstream NLP tasks have shown significant improvement through
continual pre-training, transfer learning and multi-task learning.
State-of-the-art approaches in Word Sense Disambiguation today benefit from
some of these approaches in conjunction with information sources such as
semantic relationships and gloss definitions contained within WordNet. Our work
builds upon these systems and uses data augmentation along with extensive
pre-training on various different NLP tasks and datasets. Our transfer learning
and augmentation pipeline achieves state-of-the-art single model performance in
WSD and is at par with the best ensemble results."	ArXiv
1437	"The Human Evaluation Datasheet 1.0: A Template for Recording Details of
  Human Evaluation Experiments in NLP"	['Anastasia Shimorina', 'Anya Belz']	2021-03-17 15:08:50+00:00	http://arxiv.org/abs/2103.09710v1	"This paper introduces the Human Evaluation Datasheet, a template for
recording the details of individual human evaluation experiments in Natural
Language Processing (NLP). Originally taking inspiration from seminal papers by
Bender and Friedman (2018), Mitchell et al. (2019), and Gebru et al. (2020),
the Human Evaluation Datasheet is intended to facilitate the recording of
properties of human evaluations in sufficient detail, and with sufficient
standardisation, to support comparability, meta-evaluation, and reproducibility
tests."	ArXiv
1438	SwissDial: Parallel Multidialectal Corpus of Spoken Swiss German	['Pelin Dogan-Schönberger', 'Julian Mäder', 'Thomas Hofmann']	2021-03-21 14:00:09+00:00	http://arxiv.org/abs/2103.11401v1	"Swiss German is a dialect continuum whose natively acquired dialects
significantly differ from the formal variety of the language. These dialects
are mostly used for verbal communication and do not have standard orthography.
This has led to a lack of annotated datasets, rendering the use of many NLP
methods infeasible. In this paper, we introduce the first annotated parallel
corpus of spoken Swiss German across 8 major dialects, plus a Standard German
reference. Our goal has been to create and to make available a basic dataset
for employing data-driven NLP applications in Swiss German. We present our data
collection procedure in detail and validate the quality of our corpus by
conducting experiments with the recent neural models for speech synthesis."	ArXiv
1439	"Collaborative construction of lexicographic and parallel datasets for
  African languages: first assessment"	['Elvis Mboning Tchiaze']	2021-03-30 22:43:13+00:00	http://arxiv.org/abs/2103.16712v1	"Faced with a considerable lack of resources in African languages to carry out
work in Natural Language Processing (NLP), Natural Language Understanding (NLU)
and artificial intelligence, the research teams of NTeALan association has set
itself the objective of building open-source platforms for the collaborative
construction of lexicographic data in African languages. In this article, we
present our first reports after 2 years of collaborative construction of
lexicographic resources useful for African NLP tools."	ArXiv
1440	ParaShoot: A Hebrew Question Answering Dataset	['Omri Keren', 'Omer Levy']	2021-09-23 11:59:38+00:00	http://arxiv.org/abs/2109.11314v1	"NLP research in Hebrew has largely focused on morphology and syntax, where
rich annotated datasets in the spirit of Universal Dependencies are available.
Semantic datasets, however, are in short supply, hindering crucial advances in
the development of NLP technology in Hebrew. In this work, we present
ParaShoot, the first question answering dataset in modern Hebrew. The dataset
follows the format and crowdsourcing methodology of SQuAD, and contains
approximately 3000 annotated examples, similar to other question-answering
datasets in low-resource languages. We provide the first baseline results using
recently-released BERT-style models for Hebrew, showing that there is
significant room for improvement on this task."	ArXiv
1441	Automated Fact-Checking: A Survey	['Xia Zeng', 'Amani S. Abumansour', 'Arkaitz Zubiaga']	2021-09-23 15:13:48+00:00	http://arxiv.org/abs/2109.11427v1	"As online false information continues to grow, automated fact-checking has
gained an increasing amount of attention in recent years. Researchers in the
field of Natural Language Processing (NLP) have contributed to the task by
building fact-checking datasets, devising automated fact-checking pipelines and
proposing NLP methods to further research in the development of different
components. This paper reviews relevant research on automated fact-checking
covering both the claim detection and claim validation components."	ArXiv
1442	NLP Research and Resources at DaSciM, Ecole Polytechnique	['Hadi Abdine', 'Yanzhu Guo', 'Moussa Kamal Eddine', 'Giannis Nikolentzos', 'Stamatis Outsios', 'Guokan Shang', 'Christos Xypolopoulos', 'Michalis Vazirgiannis']	2021-12-01 15:34:39+00:00	http://arxiv.org/abs/2112.00566v1	"DaSciM (Data Science and Mining) part of LIX at Ecole Polytechnique,
established in 2013 and since then producing research results in the area of
large scale data analysis via methods of machine and deep learning. The group
has been specifically active in the area of NLP and text mining with
interesting results at methodological and resources level. Here follow our
different contributions of interest to the AFIA community."	ArXiv
1443	Augmenting Customer Support with an NLP-based Receptionist	['André Barbosa', 'Alan Godoy']	2021-12-03 15:03:25+00:00	http://arxiv.org/abs/2112.01959v1	"In this paper, we show how a Portuguese BERT model can be combined with
structured data in order to deploy a chatbot based on a finite state machine to
create a conversational AI system that helps a real-estate company to predict
its client's contact motivation. The model achieves human level results in a
dataset that contains 235 unbalanced labels. Then, we also show its benefits
considering the business impact comparing it against classical NLP methods."	ArXiv
1444	Analysis and Prediction of NLP Models Via Task Embeddings	['Damien Sileo', 'Marie-Francine Moens']	2021-12-10 16:23:24+00:00	http://arxiv.org/abs/2112.05647v1	"Task embeddings are low-dimensional representations that are trained to
capture task properties. In this paper, we propose MetaEval, a collection of
$101$ NLP tasks. We fit a single transformer to all MetaEval tasks jointly
while conditioning it on learned embeddings. The resulting task embeddings
enable a novel analysis of the space of tasks. We then show that task aspects
can be mapped to task embeddings for new tasks without using any annotated
examples.
  Predicted embeddings can modulate the encoder for zero-shot inference and
outperform a zero-shot baseline on GLUE tasks. The provided multitask setup can
function as a benchmark for future transfer learning research."	ArXiv
1445	BanglaParaphrase: A High-Quality Bangla Paraphrase Dataset	['Ajwad Akil', 'Najrin Sultana', 'Abhik Bhattacharjee', 'Rifat Shahriyar']	2022-10-11 02:52:31+00:00	http://arxiv.org/abs/2210.05109v1	"In this work, we present BanglaParaphrase, a high-quality synthetic Bangla
Paraphrase dataset curated by a novel filtering pipeline. We aim to take a step
towards alleviating the low resource status of the Bangla language in the NLP
domain through the introduction of BanglaParaphrase, which ensures quality by
preserving both semantics and diversity, making it particularly useful to
enhance other Bangla datasets. We show a detailed comparative analysis between
our dataset and models trained on it with other existing works to establish the
viability of our synthetic paraphrase data generation pipeline. We are making
the dataset and models publicly available at
https://github.com/csebuetnlp/banglaparaphrase to further the state of Bangla
NLP."	ArXiv
1446	"Towards Domain-Independent Supervised Discourse Parsing Through Gradient
  Boosting"	['Patrick Huber', 'Giuseppe Carenini']	2022-10-18 03:44:27+00:00	http://arxiv.org/abs/2210.09565v1	"Discourse analysis and discourse parsing have shown great impact on many
important problems in the field of Natural Language Processing (NLP). Given the
direct impact of discourse annotations on model performance and
interpretability, robustly extracting discourse structures from arbitrary
documents is a key task to further improve computational models in NLP. To this
end, we present a new, supervised paradigm directly tackling the domain
adaptation issue in discourse parsing. Specifically, we introduce the first
fully supervised discourse parser designed to alleviate the domain dependency
through a staged model of weak classifiers by introducing the gradient boosting
framework."	ArXiv
1447	A Survey of Active Learning for Natural Language Processing	['Zhisong Zhang', 'Emma Strubell', 'Eduard Hovy']	2022-10-18 19:14:42+00:00	http://arxiv.org/abs/2210.10109v2	"In this work, we provide a survey of active learning (AL) for its
applications in natural language processing (NLP). In addition to a
fine-grained categorization of query strategies, we also investigate several
other important aspects of applying AL to NLP problems. These include AL for
structured prediction tasks, annotation cost, model learning (especially with
deep neural models), and starting and stopping AL. Finally, we conclude with a
discussion of related topics and future directions."	ArXiv
1448	This joke is [MASK]: Recognizing Humor and Offense with Prompting	['Junze Li', 'Mengjie Zhao', 'Yubo Xie', 'Antonis Maronikolakis', 'Pearl Pu', 'Hinrich Schütze']	2022-10-25 13:02:45+00:00	http://arxiv.org/abs/2210.13985v1	"Humor is a magnetic component in everyday human interactions and
communications. Computationally modeling humor enables NLP systems to entertain
and engage with users. We investigate the effectiveness of prompting, a new
transfer learning paradigm for NLP, for humor recognition. We show that
prompting performs similarly to finetuning when numerous annotations are
available, but gives stellar performance in low-resource humor recognition. The
relationship between humor and offense is also inspected by applying influence
functions to prompting; we show that models could rely on offense to determine
humor during transfer."	ArXiv
1449	LDC Arabic Treebanks and Associated Corpora: Data Divisions Manual	['Mona Diab', 'Nizar Habash', 'Owen Rambow', 'Ryan Roth']	2013-09-22 21:09:07+00:00	http://arxiv.org/abs/1309.5652v1	"The Linguistic Data Consortium (LDC) has developed hundreds of data corpora
for natural language processing (NLP) research. Among these are a number of
annotated treebank corpora for Arabic. Typically, these corpora consist of a
single collection of annotated documents. NLP research, however, usually
requires multiple data sets for the purposes of training models, developing
techniques, and final evaluation. Therefore it becomes necessary to divide the
corpora used into the required data sets (divisions). This document details a
set of rules that have been defined to enable consistent divisions for old and
new Arabic treebanks (ATB) and related corpora."	ArXiv
1450	"An HMM Based Named Entity Recognition System for Indian Languages: The
  JU System at ICON 2013"	['Vivekananda Gayen', 'Kamal Sarkar']	2014-05-28 21:05:00+00:00	http://arxiv.org/abs/1405.7397v1	"This paper reports about our work in the ICON 2013 NLP TOOLS CONTEST on Named
Entity Recognition. We submitted runs for Bengali, English, Hindi, Marathi,
Punjabi, Tamil and Telugu. A statistical HMM (Hidden Markov Models) based model
has been used to implement our system. The system has been trained and tested
on the NLP TOOLS CONTEST: ICON 2013 datasets. Our system obtains F-measures of
0.8599, 0.7704, 0.7520, 0.4289, 0.5455, 0.4466, and 0.4003 for Bengali,
English, Hindi, Marathi, Punjabi, Tamil and Telugu respectively."	ArXiv
1451	From Textual Information Sources to Linked Data in the Agatha Project	['Paulo Quaresma', 'Vitor Beires Nogueira', 'Kashyap Raiyani', 'Roy Bayot', 'Teresa Gonçalves']	2019-09-03 08:27:37+00:00	http://arxiv.org/abs/1909.05359v1	"Automatic reasoning about textual information is a challenging task in modern
Natural Language Processing (NLP) systems. In this work we describe our
proposal for representing and reasoning about Portuguese documents by means of
Linked Data like ontologies and thesauri. Our approach resorts to a specialized
pipeline of natural language processing (part-of-speech tagger, named entity
recognition, semantic role labeling) to populate an ontology for the domain of
criminal investigations. The provided architecture and ontology are language
independent. Although some of the NLP modules are language dependent, they can
be built using adequate AI methodologies."	ArXiv
1452	Subword ELMo	['Jiangtong Li', 'Hai Zhao', 'Zuchao Li', 'Wei Bi', 'Xiaojiang Liu']	2019-09-18 11:14:53+00:00	http://arxiv.org/abs/1909.08357v1	"Embedding from Language Models (ELMo) has shown to be effective for improving
many natural language processing (NLP) tasks, and ELMo takes character
information to compose word representation to train language models.However,
the character is an insufficient and unnatural linguistic unit for word
representation.Thus we introduce Embedding from Subword-aware Language Models
(ESuLMo) which learns word representation from subwords using unsupervised
segmentation over words.We show that ESuLMo can enhance four benchmark NLP
tasks more effectively than ELMo, including syntactic dependency parsing,
semantic role labeling, implicit discourse relation recognition and textual
entailment, which brings a meaningful improvement over ELMo."	ArXiv
1453	Attention Interpretability Across NLP Tasks	['Shikhar Vashishth', 'Shyam Upadhyay', 'Gaurav Singh Tomar', 'Manaal Faruqui']	2019-09-24 22:58:44+00:00	http://arxiv.org/abs/1909.11218v1	"The attention layer in a neural network model provides insights into the
model's reasoning behind its prediction, which are usually criticized for being
opaque. Recently, seemingly contradictory viewpoints have emerged about the
interpretability of attention weights (Jain & Wallace, 2019; Vig & Belinkov,
2019). Amid such confusion arises the need to understand attention mechanism
more systematically. In this work, we attempt to fill this gap by giving a
comprehensive explanation which justifies both kinds of observations (i.e.,
when is attention interpretable and when it is not). Through a series of
experiments on diverse NLP tasks, we validate our observations and reinforce
our claim of interpretability of attention through manual evaluation."	ArXiv
1454	Contextual Text Denoising with Masked Language Models	['Yifu Sun', 'Haoming Jiang']	2019-10-30 18:47:37+00:00	http://arxiv.org/abs/1910.14080v2	"Recently, with the help of deep learning models, significant advances have
been made in different Natural Language Processing (NLP) tasks. Unfortunately,
state-of-the-art models are vulnerable to noisy texts. We propose a new
contextual text denoising algorithm based on the ready-to-use masked language
model. The proposed algorithm does not require retraining of the model and can
be integrated into any NLP system without additional training on paired
cleaning training data. We evaluate our method under synthetic noise and
natural noise and show that the proposed algorithm can use context information
to correct noise text and improve the performance of noisy inputs in several
downstream tasks."	ArXiv
1455	"Exploring Chemical Space using Natural Language Processing Methodologies
  for Drug Discovery"	['Hakime Öztürk', 'Arzucan Özgür', 'Philippe Schwaller', 'Teodoro Laino', 'Elif Ozkirimli']	2020-02-10 21:02:05+00:00	http://arxiv.org/abs/2002.06053v1	"Text-based representations of chemicals and proteins can be thought of as
unstructured languages codified by humans to describe domain-specific
knowledge. Advances in natural language processing (NLP) methodologies in the
processing of spoken languages accelerated the application of NLP to elucidate
hidden knowledge in textual representations of these biochemical entities and
then use it to construct models to predict molecular properties or to design
novel molecules. This review outlines the impact made by these advances on drug
discovery and aims to further the dialogue between medicinal chemists and
computer scientists."	ArXiv
1456	Parsing Early Modern English for Linguistic Search	['Seth Kulick', 'Neville Ryant']	2020-02-24 21:04:51+00:00	http://arxiv.org/abs/2002.10546v1	"We investigate the question of whether advances in NLP over the last few
years make it possible to vastly increase the size of data usable for research
in historical syntax. This brings together many of the usual tools in NLP -
word embeddings, tagging, and parsing - in the service of linguistic queries
over automatically annotated corpora. We train a part-of-speech (POS) tagger
and parser on a corpus of historical English, using ELMo embeddings trained
over a billion words of similar text. The evaluation is based on the standard
metrics, as well as on the accuracy of the query searches using the parsed
data."	ArXiv
1457	"Extracting Concepts for Precision Oncology from the Biomedical
  Literature"	['Nicholas Greenspan', 'Yuqi Si', 'Kirk Roberts']	2020-09-30 19:31:04+00:00	http://arxiv.org/abs/2010.00074v1	"This paper describes an initial dataset and automatic natural language
processing (NLP) method for extracting concepts related to precision oncology
from biomedical research articles. We extract five concept types: Cancer,
Mutation, Population, Treatment, Outcome. A corpus of 250 biomedical abstracts
were annotated with these concepts following standard double-annotation
procedures. We then experiment with BERT-based models for concept extraction.
The best-performing model achieved a precision of 63.8%, a recall of 71.9%, and
an F1 of 67.1. Finally, we propose additional directions for research for
improving extraction performance and utilizing the NLP system in downstream
precision oncology applications."	ArXiv
1458	What Can We Do to Improve Peer Review in NLP?	['Anna Rogers', 'Isabelle Augenstein']	2020-10-08 09:32:21+00:00	http://arxiv.org/abs/2010.03863v1	"Peer review is our best tool for judging the quality of conference
submissions, but it is becoming increasingly spurious. We argue that a part of
the problem is that the reviewers and area chairs face a poorly defined task
forcing apples-to-oranges comparisons. There are several potential ways
forward, but the key difficulty is creating the incentives and mechanisms for
their consistent implementation in the NLP community."	ArXiv
1459	fugashi, a Tool for Tokenizing Japanese in Python	['Paul McCann']	2020-10-14 07:52:47+00:00	http://arxiv.org/abs/2010.06858v1	"Recent years have seen an increase in the number of large-scale multilingual
NLP projects. However, even in such projects, languages with special processing
requirements are often excluded. One such language is Japanese. Japanese is
written without spaces, tokenization is non-trivial, and while high quality
open source tokenizers exist they can be hard to use and lack English
documentation. This paper introduces fugashi, a MeCab wrapper for Python, and
gives an introduction to tokenizing Japanese."	ArXiv
1460	"Automatically Identifying Language Family from Acoustic Examples in Low
  Resource Scenarios"	['Peter Wu', 'Yifan Zhong', 'Alan W Black']	2020-12-01 22:44:42+00:00	http://arxiv.org/abs/2012.00876v1	"Existing multilingual speech NLP works focus on a relatively small subset of
languages, and thus current linguistic understanding of languages predominantly
stems from classical approaches. In this work, we propose a method to analyze
language similarity using deep learning. Namely, we train a model on the
Wilderness dataset and investigate how its latent space compares with classical
language family findings. Our approach provides a new direction for
cross-lingual data augmentation in any speech-based NLP task."	ArXiv
1461	"MeDAL: Medical Abbreviation Disambiguation Dataset for Natural Language
  Understanding Pretraining"	['Zhi Wen', 'Xing Han Lu', 'Siva Reddy']	2020-12-27 17:17:39+00:00	http://arxiv.org/abs/2012.13978v1	"One of the biggest challenges that prohibit the use of many current NLP
methods in clinical settings is the availability of public datasets. In this
work, we present MeDAL, a large medical text dataset curated for abbreviation
disambiguation, designed for natural language understanding pre-training in the
medical domain. We pre-trained several models of common architectures on this
dataset and empirically showed that such pre-training leads to improved
performance and convergence speed when fine-tuning on downstream medical tasks."	ArXiv
1462	Adversarial Contrastive Pre-training for Protein Sequences	['Matthew B. A. McDermott', 'Brendan Yap', 'Harry Hsu', 'Di Jin', 'Peter Szolovits']	2021-01-31 15:06:27+00:00	http://arxiv.org/abs/2102.00466v1	"Recent developments in Natural Language Processing (NLP) demonstrate that
large-scale, self-supervised pre-training can be extremely beneficial for
downstream tasks. These ideas have been adapted to other domains, including the
analysis of the amino acid sequences of proteins. However, to date most
attempts on protein sequences rely on direct masked language model style
pre-training. In this work, we design a new, adversarial pre-training method
for proteins, extending and specializing similar advances in NLP. We show
compelling results in comparison to traditional MLM pre-training, though
further development is needed to ensure the gains are worth the significant
computational cost."	ArXiv
1463	Literature review on vulnerability detection using NLP technology	['Jiajie Wu']	2021-04-23 03:16:51+00:00	http://arxiv.org/abs/2104.11230v1	"Vulnerability detection has always been the most important task in the field
of software security. With the development of technology, in the face of
massive source code, automated analysis and detection of vulnerabilities has
become a current research hotspot. For special text files such as source code,
using some of the hottest NLP technologies to build models and realize the
automatic analysis and detection of source code has become one of the most
anticipated studies in the field of vulnerability detection. This article does
a brief survey of some recent new documents and technologies, such as CodeBERT,
and summarizes the previous technologies."	ArXiv
1464	"Security Vulnerability Detection Using Deep Learning Natural Language
  Processing"	['Noah Ziems', 'Shaoen Wu']	2021-05-06 01:28:21+00:00	http://arxiv.org/abs/2105.02388v1	"Detecting security vulnerabilities in software before they are exploited has
been a challenging problem for decades. Traditional code analysis methods have
been proposed, but are often ineffective and inefficient. In this work, we
model software vulnerability detection as a natural language processing (NLP)
problem with source code treated as texts, and address the automated software
venerability detection with recent advanced deep learning NLP models assisted
by transfer learning on written English. For training and testing, we have
preprocessed the NIST NVD/SARD databases and built a dataset of over 100,000
files in $C$ programming language with 123 types of vulnerabilities. The
extensive experiments generate the best performance of over 93\% accuracy in
detecting security vulnerabilities."	ArXiv
1465	"Doing Natural Language Processing in A Natural Way: An NLP toolkit based
  on object-oriented knowledge base and multi-level grammar base"	['Yu Guo']	2021-05-11 17:43:06+00:00	http://arxiv.org/abs/2105.05227v2	"We introduce an NLP toolkit based on object-oriented knowledge base and
multi-level grammar base. This toolkit focuses on semantic parsing, it also has
abilities to discover new knowledge and grammar automatically, new discovered
knowledge and grammar will be identified by human, and will be used to update
the knowledge base and grammar base. This process can be iterated many times to
improve the toolkit continuously."	ArXiv
1466	"The Flipped Classroom model for teaching Conditional Random Fields in an
  NLP course"	['Manex Agirrezabal']	2021-05-04 11:21:03+00:00	http://arxiv.org/abs/2105.07850v1	"In this article, we show and discuss our experience in applying the flipped
classroom method for teaching Conditional Random Fields in a Natural Language
Processing course. We present the activities that we developed together with
their relationship to a cognitive complexity model (Bloom's taxonomy). After
this, we provide our own reflections and expectations of the model itself.
Based on the evaluation got from students, it seems that students learn about
the topic and also that the method is rewarding for some students.
Additionally, we discuss some shortcomings and we propose possible solutions to
them. We conclude the paper with some possible future work."	ArXiv
1467	Visualization Techniques to Enhance Automated Event Extraction	['Sophia Henn', 'Abigail Sticha', 'Timothy Burley', 'Ernesto Verdeja', 'Paul Brenner']	2021-06-11 19:24:54+00:00	http://arxiv.org/abs/2106.06588v1	"Robust visualization of complex data is critical for the effective use of NLP
for event classification, as the volume of data is large and the
high-dimensional structure of text makes data challenging to summarize
succinctly. In event extraction tasks in particular, visualization can aid in
understanding and illustrating the textual relationships from which machine
learning tools produce insights. Through our case study which seeks to identify
potential triggers of state-led mass killings from news articles using NLP, we
demonstrate how visualizations can aid in each stage, from exploratory analysis
of raw data, to machine learning training analysis, and finally post-inference
validation."	ArXiv
1468	Buildup dynamics of broadband Q-switched noise-like pulse	['Ji Zhou', 'Yuhang Li', 'Qing Yang', 'Yaoguang Ma', 'Qiang Liu']	2021-08-23 07:20:31+00:00	http://arxiv.org/abs/2108.09978v2	"We investigate the buildup dynamics of broadband Q-switched noise-like pulse
(QS-NLP) driven by slow gain dynamics in a microfiber-based passively
mode-locked fiber laser. Based on shot-to-shot tracing of the transient optical
spectra and qualitatively reproduced numerial simulation, we demonstrate that
slow gain dynamics is deeply involved in the onset of such complex temporal and
spectral instabilities of QS-NLP. The proposed gain dynamics model could
contribute to deeper insight into such nonlinear phenomenon and transient
dynamics simulation in ultrafast fiber laser."	ArXiv
1469	"End-To-End Anomaly Detection for Identifying Malicious Cyber Behavior
  through NLP-Based Log Embeddings"	['Andrew Golczynski', 'John A. Emanuello']	2021-08-27 13:49:00+00:00	http://arxiv.org/abs/2108.12276v1	"Rule-based IDS (intrusion detection systems) are being replaced by more
robust neural IDS, which demonstrate great potential in the field of
Cybersecurity. However, these ML approaches continue to rely on ad-hoc feature
engineering techniques, which lack the capacity to vectorize inputs in ways
that are fully relevant to the discovery of anomalous cyber activity. We
propose a deep end-to-end framework with NLP-inspired components for
identifying potentially malicious behaviors on enterprise computer networks. We
also demonstrate the efficacy of this technique on the recently released DARPA
OpTC data set."	ArXiv
1470	"Unpacking the Interdependent Systems of Discrimination: Ableist Bias in
  NLP Systems through an Intersectional Lens"	['Saad Hassan', 'Matt Huenerfauth', 'Cecilia Ovesdotter Alm']	2021-10-01 16:40:58+00:00	http://arxiv.org/abs/2110.00521v1	"Much of the world's population experiences some form of disability during
their lifetime. Caution must be exercised while designing natural language
processing (NLP) systems to prevent systems from inadvertently perpetuating
ableist bias against people with disabilities, i.e., prejudice that favors
those with typical abilities. We report on various analyses based on word
predictions of a large-scale BERT language model. Statistically significant
results demonstrate that people with disabilities can be disadvantaged.
Findings also explore overlapping forms of discrimination related to
interconnected gender and race identities."	ArXiv
1471	Transfer Learning for Multi-lingual Tasks -- a Survey	['Amir Reza Jafari', 'Behnam Heidary', 'Reza Farahbakhsh', 'Mostafa Salehi', 'Mahdi Jalili']	2021-08-28 20:29:43+00:00	http://arxiv.org/abs/2110.02052v1	"These days different platforms such as social media provide their clients
from different backgrounds and languages the possibility to connect and
exchange information. It is not surprising anymore to see comments from
different languages in posts published by international celebrities or data
providers. In this era, understanding cross languages content and
multilingualism in natural language processing (NLP) are hot topics, and
multiple efforts have tried to leverage existing technologies in NLP to tackle
this challenging research problem. In this survey, we provide a comprehensive
overview of the existing literature with a focus on transfer learning
techniques in multilingual tasks. We also identify potential opportunities for
further research in this domain."	ArXiv
1472	Clinical Trial Information Extraction with BERT	['Xiong Liu', 'Greg L. Hersch', 'Iya Khalil', 'Murthy Devarakonda']	2021-09-11 17:15:10+00:00	http://arxiv.org/abs/2110.10027v1	"Natural language processing (NLP) of clinical trial documents can be useful
in new trial design. Here we identify entity types relevant to clinical trial
design and propose a framework called CT-BERT for information extraction from
clinical trial text. We trained named entity recognition (NER) models to
extract eligibility criteria entities by fine-tuning a set of pre-trained BERT
models. We then compared the performance of CT-BERT with recent baseline
methods including attention-based BiLSTM and Criteria2Query. The results
demonstrate the superiority of CT-BERT in clinical trial NLP."	ArXiv
1473	Transformer for Polyp Detection	['Shijie Liu', 'Hongyu Zhou', 'Xiaozhou Shi', 'Junwen Pan']	2021-10-14 11:58:57+00:00	http://arxiv.org/abs/2111.07918v1	"In recent years, as the Transformer has performed increasingly well on NLP
tasks, many researchers have ported the Transformer structure to vision tasks
,bridging the gap between NLP and CV tasks. In this work, we evaluate some deep
learning network for the detection track. Because the ground truth is mask, so
we can try both the current detection and segmentation method. We select the
DETR as our baseline through experiment. Besides, we modify the train strategy
to fit the dataset."	ArXiv
1474	Relative Position Prediction as Pre-training for Text Encoders	['Rickard Brüel-Gabrielsson', 'Chris Scarvelis']	2022-02-02 17:13:31+00:00	http://arxiv.org/abs/2202.01145v1	"Meaning is defined by the company it keeps. However, company is two-fold:
It's based on the identity of tokens and also on their position (topology). We
argue that a position-centric perspective is more general and useful. The
classic MLM and CLM objectives in NLP are easily phrased as position
predictions over the whole vocabulary. Adapting the relative position encoding
paradigm in NLP to create relative labels for self-supervised learning, we seek
to show superior pre-training judged by performance on downstream tasks."	ArXiv
1475	StyleBERT: Chinese pretraining by font style information	['Chao Lv', 'Han Zhang', 'XinKai Du', 'Yunhao Zhang', 'Ying Huang', 'Wenhao Li', 'Jia Han', 'Shanshan Gu']	2022-02-21 02:45:12+00:00	http://arxiv.org/abs/2202.09955v2	"With the success of down streaming task using English pre-trained language
model, the pre-trained Chinese language model is also necessary to get a better
performance of Chinese NLP task. Unlike the English language, Chinese has its
special characters such as glyph information. So in this article, we propose
the Chinese pre-trained language model StyleBERT which incorporate the
following embedding information to enhance the savvy of language model, such as
word, pinyin, five stroke and chaizi. The experiments show that the model
achieves well performances on a wide range of Chinese NLP tasks."	ArXiv
1476	TextPruner: A Model Pruning Toolkit for Pre-Trained Language Models	['Ziqing Yang', 'Yiming Cui', 'Zhigang Chen']	2022-03-30 02:10:33+00:00	http://arxiv.org/abs/2203.15996v1	"Pre-trained language models have been prevailed in natural language
processing and become the backbones of many NLP tasks, but the demands for
computational resources have limited their applications. In this paper, we
introduce TextPruner, an open-source model pruning toolkit designed for
pre-trained language models, targeting fast and easy model compression.
TextPruner offers structured post-training pruning methods, including
vocabulary pruning and transformer pruning, and can be applied to various
models and tasks. We also propose a self-supervised pruning method that can be
applied without the labeled data. Our experiments with several NLP tasks
demonstrate the ability of TextPruner to reduce the model size without
re-training the model."	ArXiv
1477	Odor Descriptor Understanding through Prompting	['Laura Sisson']	2022-05-07 20:44:22+00:00	http://arxiv.org/abs/2205.03719v1	"Embeddings from contemporary natural language processing (NLP) models are
commonly used as numerical representations for words or sentences. However,
odor descriptor words, like ""leather"" or ""fruity"", vary significantly between
their commonplace usage and their olfactory usage, as a result traditional
methods for generating these embeddings do not suffice. In this paper, we
present two methods to generate embeddings for odor words that are more closely
aligned with their olfactory meanings when compared to off-the-shelf
embeddings. These generated embeddings outperform the previous state-of-the-art
and contemporary fine-tuning/prompting methods on a pre-existing zero-shot
odor-specific NLP benchmark."	ArXiv
1478	Fair NLP Models with Differentially Private Text Encoders	['Gaurav Maheshwari', 'Pascal Denis', 'Mikaela Keller', 'Aurélien Bellet']	2022-05-12 14:58:38+00:00	http://arxiv.org/abs/2205.06135v1	"Encoded text representations often capture sensitive attributes about
individuals (e.g., race or gender), which raise privacy concerns and can make
downstream models unfair to certain groups. In this work, we propose FEDERATE,
an approach that combines ideas from differential privacy and adversarial
training to learn private text representations which also induces fairer
models. We empirically evaluate the trade-off between the privacy of the
representations and the fairness and accuracy of the downstream model on four
NLP datasets. Our results show that FEDERATE consistently improves upon
previous methods, and thus suggest that privacy and fairness can positively
reinforce each other."	ArXiv
1479	"Why only Micro-F1? Class Weighting of Measures for Relation
  Classification"	['David Harbecke', 'Yuxuan Chen', 'Leonhard Hennig', 'Christoph Alt']	2022-05-19 10:33:28+00:00	http://arxiv.org/abs/2205.09460v1	"Relation classification models are conventionally evaluated using only a
single measure, e.g., micro-F1, macro-F1 or AUC. In this work, we analyze
weighting schemes, such as micro and macro, for imbalanced datasets. We
introduce a framework for weighting schemes, where existing schemes are
extremes, and two new intermediate schemes. We show that reporting results of
different weighting schemes better highlights strengths and weaknesses of a
model."	ArXiv
1480	Asking the Right Questions in Low Resource Template Extraction	['Nils Holzenberger', 'Yunmo Chen', 'Benjamin Van Durme']	2022-05-25 10:39:09+00:00	http://arxiv.org/abs/2205.12643v1	"Information Extraction (IE) researchers are mapping tasks to Question
Answering (QA) in order to leverage existing large QA resources, and thereby
improve data efficiency. Especially in template extraction (TE), mapping an
ontology to a set of questions can be more time-efficient than collecting
labeled examples. We ask whether end users of TE systems can design these
questions, and whether it is beneficial to involve an NLP practitioner in the
process. We compare questions to other ways of phrasing natural language
prompts for TE. We propose a novel model to perform TE with prompts, and find
it benefits from questions over other styles of prompts, and that they do not
require an NLP background to author."	ArXiv
1481	"Challenges in Applying Explainability Methods to Improve the Fairness of
  NLP Models"	['Esma Balkir', 'Svetlana Kiritchenko', 'Isar Nejadgholi', 'Kathleen C. Fraser']	2022-06-08 15:09:04+00:00	http://arxiv.org/abs/2206.03945v1	"Motivations for methods in explainable artificial intelligence (XAI) often
include detecting, quantifying and mitigating bias, and contributing to making
machine learning models fairer. However, exactly how an XAI method can help in
combating biases is often left unspecified. In this paper, we briefly review
trends in explainability and fairness in NLP research, identify the current
practices in which explainability methods are applied to detect and mitigate
bias, and investigate the barriers preventing XAI methods from being used more
widely in tackling fairness issues."	ArXiv
1482	A Simple Yet Efficient Method for Adversarial Word-Substitute Attack	['Tianle Li', 'Yi Yang']	2022-05-07 14:20:57+00:00	http://arxiv.org/abs/2206.05015v1	"NLP researchers propose different word-substitute black-box attacks that can
fool text classification models. In such attack, an adversary keeps sending
crafted adversarial queries to the target model until it can successfully
achieve the intended outcome. State-of-the-art attack methods usually require
hundreds or thousands of queries to find one adversarial example. In this
paper, we study whether a sophisticated adversary can attack the system with
much less queries. We propose a simple yet efficient method that can reduce the
average number of adversarial queries by 3-30 times and maintain the attack
effectiveness. This research highlights that an adversary can fool a deep NLP
model with much less cost."	ArXiv
1483	Mediators: Conversational Agents Explaining NLP Model Behavior	['Nils Feldhus', 'Ajay Madhavan Ravichandran', 'Sebastian Möller']	2022-06-13 10:31:18+00:00	http://arxiv.org/abs/2206.06029v1	"The human-centric explainable artificial intelligence (HCXAI) community has
raised the need for framing the explanation process as a conversation between
human and machine. In this position paper, we establish desiderata for
Mediators, text-based conversational agents which are capable of explaining the
behavior of neural models interactively using natural language. From the
perspective of natural language processing (NLP) research, we engineer a
blueprint of such a Mediator for the task of sentiment analysis and assess how
far along current research is on the path towards dialogue-based explanations."	ArXiv
1484	"Towards a Deep Multi-layered Dialectal Language Analysis: A Case Study
  of African-American English"	['Jamell Dacon']	2022-06-03 01:05:58+00:00	http://arxiv.org/abs/2206.08978v1	"Currently, natural language processing (NLP) models proliferate language
discrimination leading to potentially harmful societal impacts as a result of
biased outcomes. For example, part-of-speech taggers trained on Mainstream
American English (MAE) produce non-interpretable results when applied to
African American English (AAE) as a result of language features not seen during
training. In this work, we incorporate a human-in-the-loop paradigm to gain a
better understanding of AAE speakers' behavior and their language use, and
highlight the need for dialectal language inclusivity so that native AAE
speakers can extensively interact with NLP systems while reducing feelings of
disenfranchisement."	ArXiv
1485	Modern Question Answering Datasets and Benchmarks: A Survey	['Zhen Wang']	2022-06-30 05:53:56+00:00	http://arxiv.org/abs/2206.15030v1	"Question Answering (QA) is one of the most important natural language
processing (NLP) tasks. It aims using NLP technologies to generate a
corresponding answer to a given question based on the massive unstructured
corpus. With the development of deep learning, more and more challenging QA
datasets are being proposed, and lots of new methods for solving them are also
emerging. In this paper, we investigate influential QA datasets that have been
released in the era of deep learning. Specifically, we begin with introducing
two of the most common QA tasks - textual question answer and visual question
answering - separately, covering the most representative datasets, and then
give some current challenges of QA research."	ArXiv
1486	"A Survey in Automatic Irony Processing: Linguistic, Cognitive, and
  Multi-X Perspectives"	['Qingcheng Zeng', 'An-Ran Li']	2022-09-10 17:03:34+00:00	http://arxiv.org/abs/2209.04712v1	"Irony is a ubiquitous figurative language in daily communication. Previously,
many researchers have approached irony from linguistic, cognitive science, and
computational aspects. Recently, some progress have been witnessed in automatic
irony processing due to the rapid development in deep neural models in natural
language processing (NLP). In this paper, we will provide a comprehensive
overview of computational irony, insights from linguistic theory and cognitive
science, as well as its interactions with downstream NLP tasks and newly
proposed multi-X irony processing perspectives."	ArXiv
1487	The Effects of In-domain Corpus Size on pre-training BERT	['Chris Sanchez', 'Zheyuan Zhang']	2022-12-15 15:49:27+00:00	http://arxiv.org/abs/2212.07914v1	"Many prior language modeling efforts have shown that pre-training on an
in-domain corpus can significantly improve performance on downstream
domain-specific NLP tasks. However, the difficulties associated with collecting
enough in-domain data might discourage researchers from approaching this
pre-training task. In this paper, we conducted a series of experiments by
pre-training Bidirectional Encoder Representations from Transformers (BERT)
with different sizes of biomedical corpora. The results demonstrate that
pre-training on a relatively small amount of in-domain data (4GB) with limited
training steps, can lead to better performance on downstream domain-specific
NLP tasks compared with fine-tuning models pre-trained on general corpora."	ArXiv
1488	"GlobalNER: Incorporating Non-local Information into Named Entity
  Recognition"	['Chiao-Wei Hsu', 'Keh-Yih Su']	2023-03-06 06:20:55+00:00	http://arxiv.org/abs/2303.02915v1	"Nowadays, many Natural Language Processing (NLP) tasks see the demand for
incorporating knowledge external to the local information to further improve
the performance. However, there is little related work on Named Entity
Recognition (NER), which is one of the foundations of NLP. Specifically, no
studies were conducted on the query generation and re-ranking for retrieving
the related information for the purpose of improving NER. This work
demonstrates the effectiveness of a DNN-based query generation method and a
mention-aware re-ranking architecture based on BERTScore particularly for NER.
In the end, a state-of-the-art performance of 61.56 micro-f1 score on WNUT17
dataset is achieved."	ArXiv
1489	Features matching using natural language processing	['Muhammad Danial Khilji']	2023-03-14 13:31:19+00:00	http://arxiv.org/abs/2303.12804v1	"The feature matching is a basic step in matching different datasets. This
article proposes shows a new hybrid model of a pretrained Natural Language
Processing (NLP) based model called BERT used in parallel with a statistical
model based on Jaccard similarity to measure the similarity between list of
features from two different datasets. This reduces the time required to search
for correlations or manually match each feature from one dataset to another."	ArXiv
1490	Feature Collapse	['Thomas Laurent', 'James H. von Brecht', 'Xavier Bresson']	2023-05-25 15:25:34+00:00	http://arxiv.org/abs/2305.16162v1	"We formalize and study a phenomenon called feature collapse that makes
precise the intuitive idea that entities playing a similar role in a learning
task receive similar representations. As feature collapse requires a notion of
task, we leverage a simple but prototypical NLP task to study it. We start by
showing experimentally that feature collapse goes hand in hand with
generalization. We then prove that, in the large sample limit, distinct words
that play identical roles in this NLP task receive identical local feature
representations in a neural network. This analysis reveals the crucial role
that normalization mechanisms, such as LayerNorm, play in feature collapse and
in generalization."	ArXiv
1491	TADA: Task-Agnostic Dialect Adapters for English	['Will Held', 'Caleb Ziems', 'Diyi Yang']	2023-05-26 05:45:03+00:00	http://arxiv.org/abs/2305.16651v1	"Large Language Models, the dominant starting point for Natural Language
Processing (NLP) applications, fail at a higher rate for speakers of English
dialects other than Standard American English (SAE). Prior work addresses this
using task-specific data or synthetic data augmentation, both of which require
intervention for each dialect and task pair. This poses a scalability issue
that prevents the broad adoption of robust dialectal English NLP. We introduce
a simple yet effective method for task-agnostic dialect adaptation by aligning
non-SAE dialects using adapters and composing them with task-specific adapters
from SAE. Task-Agnostic Dialect Adapters (TADA) improve dialectal robustness on
4 dialectal variants of the GLUE benchmark without task-specific supervision."	ArXiv
1492	"Privacy- and Utility-Preserving NLP with Anonymized Data: A case study
  of Pseudonymization"	['Oleksandr Yermilov', 'Vipul Raheja', 'Artem Chernodub']	2023-06-08 21:06:19+00:00	http://arxiv.org/abs/2306.05561v1	"This work investigates the effectiveness of different pseudonymization
techniques, ranging from rule-based substitutions to using pre-trained Large
Language Models (LLMs), on a variety of datasets and models used for two widely
used NLP tasks: text classification and summarization. Our work provides
crucial insights into the gaps between original and anonymized data (focusing
on the pseudonymization technique) and model quality and fosters future
research into higher-quality anonymization techniques to better balance the
trade-offs between data protection and utility preservation. We make our code,
pseudonymized datasets, and downstream models publicly available"	ArXiv
1493	Gradient Ascent Post-training Enhances Language Model Generalization	['Dongkeun Yoon', 'Joel Jang', 'Sungdong Kim', 'Minjoon Seo']	2023-06-12 11:59:33+00:00	http://arxiv.org/abs/2306.07052v1	"In this work, we empirically show that updating pretrained LMs (350M, 1.3B,
2.7B) with just a few steps of Gradient Ascent Post-training (GAP) on random,
unlabeled text corpora enhances its zero-shot generalization capabilities
across diverse NLP tasks. Specifically, we show that GAP can allow LMs to
become comparable to 2-3x times larger LMs across 12 different NLP tasks. We
also show that applying GAP on out-of-distribution corpora leads to the most
reliable performance improvements. Our findings indicate that GAP can be a
promising method for improving the generalization capability of LMs without any
task-specific fine-tuning."	ArXiv
1494	A Survey on Out-of-Distribution Evaluation of Neural NLP Models	['Xinzhe Li', 'Ming Liu', 'Shang Gao', 'Wray Buntine']	2023-06-27 07:44:25+00:00	http://arxiv.org/abs/2306.15261v1	"Adversarial robustness, domain generalization and dataset biases are three
active lines of research contributing to out-of-distribution (OOD) evaluation
on neural NLP models. However, a comprehensive, integrated discussion of the
three research lines is still lacking in the literature. In this survey, we 1)
compare the three lines of research under a unifying definition; 2) summarize
the data-generating processes and evaluation protocols for each line of
research; and 3) emphasize the challenges and opportunities for future work."	ArXiv
1495	"Can Model Fusing Help Transformers in Long Document Classification? An
  Empirical Study"	['Damith Premasiri', 'Tharindu Ranasinghe', 'Ruslan Mitkov']	2023-07-18 18:21:26+00:00	http://arxiv.org/abs/2307.09532v1	"Text classification is an area of research which has been studied over the
years in Natural Language Processing (NLP). Adapting NLP to multiple domains
has introduced many new challenges for text classification and one of them is
long document classification. While state-of-the-art transformer models provide
excellent results in text classification, most of them have limitations in the
maximum sequence length of the input sequence. The majority of the transformer
models are limited to 512 tokens, and therefore, they struggle with long
document classification problems. In this research, we explore on employing
Model Fusing for long document classification while comparing the results with
well-known BERT and Longformer architectures."	ArXiv
1496	"Artificial intelligence-aided protein engineering: from topological data
  analysis to deep protein language models"	['Yuchi Qiu', 'Guo-Wei Wei']	2023-07-27 02:14:09+00:00	http://arxiv.org/abs/2307.14587v1	"Protein engineering is an emerging field in biotechnology that has the
potential to revolutionize various areas, such as antibody design, drug
discovery, food security, ecology, and more. However, the mutational space
involved is too vast to be handled through experimental means alone. Leveraging
accumulative protein databases, machine learning (ML) models, particularly
those based on natural language processing (NLP), have considerably expedited
protein engineering. Moreover, advances in topological data analysis (TDA) and
artificial intelligence-based protein structure prediction, such as AlphaFold2,
have made more powerful structure-based ML-assisted protein engineering
strategies possible. This review aims to offer a comprehensive, systematic, and
indispensable set of methodological components, including TDA and NLP, for
protein engineering and to facilitate their future development."	ArXiv
1497	A Survey of Document-Level Information Extraction	['Hanwen Zheng', 'Sijia Wang', 'Lifu Huang']	2023-09-23 04:18:24+00:00	http://arxiv.org/abs/2309.13249v1	"Document-level information extraction (IE) is a crucial task in natural
language processing (NLP). This paper conducts a systematic review of recent
document-level IE literature. In addition, we conduct a thorough error analysis
with current state-of-the-art algorithms and identify their limitations as well
as the remaining challenges for the task of document-level IE. According to our
findings, labeling noises, entity coreference resolution, and lack of
reasoning, severely affect the performance of document-level IE. The objective
of this survey paper is to provide more insights and help NLP researchers to
further enhance document-level IE performance."	ArXiv
1498	GD-COMET: A Geo-Diverse Commonsense Inference Model	['Mehar Bhatia', 'Vered Shwartz']	2023-10-23 22:03:56+00:00	http://arxiv.org/abs/2310.15383v1	"With the increasing integration of AI into everyday life, it's becoming
crucial to design AI systems that serve users from diverse backgrounds by
making them culturally aware. In this paper, we present GD-COMET, a geo-diverse
version of the COMET commonsense inference model. GD-COMET goes beyond Western
commonsense knowledge and is capable of generating inferences pertaining to a
broad range of cultures. We demonstrate the effectiveness of GD-COMET through a
comprehensive human evaluation across 5 diverse cultures, as well as extrinsic
evaluation on a geo-diverse task. The evaluation shows that GD-COMET captures
and generates culturally nuanced commonsense knowledge, demonstrating its
potential to benefit NLP applications across the board and contribute to making
NLP more inclusive."	ArXiv
1499	"Explaining with Contrastive Phrasal Highlighting: A Case Study in
  Assisting Humans to Detect Translation Differences"	['Eleftheria Briakou', 'Navita Goyal', 'Marine Carpuat']	2023-12-04 02:40:28+00:00	http://arxiv.org/abs/2312.01582v1	"Explainable NLP techniques primarily explain by answering ""Which tokens in
the input are responsible for this prediction?''. We argue that for NLP models
that make predictions by comparing two input texts, it is more useful to
explain by answering ""What differences between the two inputs explain this
prediction?''. We introduce a technique to generate contrastive highlights that
explain the predictions of a semantic divergence model via
phrase-alignment-guided erasure. We show that the resulting highlights match
human rationales of cross-lingual semantic differences better than popular
post-hoc saliency techniques and that they successfully help people detect
fine-grained meaning differences in human translations and critical machine
translation errors."	ArXiv
1500	The emission of soft-photons and the LBK theorem, revisited	['Roger Balsach', 'Domenico Bonocore', 'Anna Kulesza']	2024-01-03 16:26:06+00:00	http://arxiv.org/abs/2401.01820v1	"Predictions for processes involving soft photons, up to next-to-leading power
(NLP) in the photon energy, can be obtained using the Low-Burnett-Kroll (LBK)
theorem. The consistency of the theorem has been a recent topic of
investigation since it is traditionally formulated in terms of a non-radiative
amplitude, which is evaluated with unphysical momenta. We address such
questions and propose a formulation of the LBK theorem which relies on the
evaluation of the non-radiative amplitude with on-shell, physical momenta. We
use this form to numerically study the impact of NLP contributions to
cross-sections for $pp$ and $e^-e^+$ processes involving soft-photon emission."	ArXiv
1501	"Automated Scoring of Clinical Patient Notes using Advanced NLP and
  Pseudo Labeling"	['Jingyu Xu', 'Yifeng Jiang', 'Bin Yuan', 'Shulin Li', 'Tianbo Song']	2024-01-18 05:17:18+00:00	http://arxiv.org/abs/2401.12994v1	"Clinical patient notes are critical for documenting patient interactions,
diagnoses, and treatment plans in medical practice. Ensuring accurate
evaluation of these notes is essential for medical education and certification.
However, manual evaluation is complex and time-consuming, often resulting in
variability and resource-intensive assessments. To tackle these challenges,
this research introduces an approach leveraging state-of-the-art Natural
Language Processing (NLP) techniques, specifically Masked Language Modeling
(MLM) pretraining, and pseudo labeling. Our methodology enhances efficiency and
effectiveness, significantly reducing training time without compromising
performance. Experimental results showcase improved model performance,
indicating a potential transformation in clinical note assessment."	ArXiv
1502	Check News in One Click: NLP-Empowered Pro-Kremlin Propaganda Detection	['Veronika Solopova', 'Viktoriia Herman', 'Christoph Benzmüller', 'Tim Landgraf']	2024-01-28 17:51:47+00:00	http://arxiv.org/abs/2401.15717v1	"Many European citizens become targets of the Kremlin propaganda campaigns,
aiming to minimise public support for Ukraine, foster a climate of mistrust and
disunity, and shape elections (Meister, 2022). To address this challenge, we
developed ''Check News in 1 Click'', the first NLP-empowered pro-Kremlin
propaganda detection application available in 7 languages, which provides the
lay user with feedback on their news, and explains manipulative linguistic
features and keywords. We conducted a user study, analysed user entries and
models' behaviour paired with questionnaire answers, and investigated the
advantages and disadvantages of the proposed interpretative solution."	ArXiv
1503	"High Throughput Phenotyping of Physician Notes with Large Language and
  Hybrid NLP Models"	['Syed I. Munzir', 'Daniel B. Hier', 'Michael D. Carrithers']	2024-03-09 14:02:59+00:00	http://arxiv.org/abs/2403.05920v1	"Deep phenotyping is the detailed description of patient signs and symptoms
using concepts from an ontology. The deep phenotyping of the numerous physician
notes in electronic health records requires high throughput methods. Over the
past thirty years, progress toward making high throughput phenotyping feasible.
In this study, we demonstrate that a large language model and a hybrid NLP
model (combining word vectors with a machine learning classifier) can perform
high throughput phenotyping on physician notes with high accuracy. Large
language models will likely emerge as the preferred method for high throughput
deep phenotyping of physician notes."	ArXiv
1504	"Since the Scientific Literature Is Multilingual, Our Models Should Be
  Too"	['Abteen Ebrahimi', 'Kenneth Church']	2024-03-27 04:47:10+00:00	http://arxiv.org/abs/2403.18251v1	"English has long been assumed the $\textit{lingua franca}$ of scientific
research, and this notion is reflected in the natural language processing (NLP)
research involving scientific document representation. In this position piece,
we quantitatively show that the literature is largely multilingual and argue
that current models and benchmarks should reflect this linguistic diversity. We
provide evidence that text-based models fail to create meaningful
representations for non-English papers and highlight the negative user-facing
impacts of using English-only models non-discriminately across a multilingual
domain. We end with suggestions for the NLP community on how to improve
performance on non-English documents."	ArXiv
1505	"Empirical Analysis for Unsupervised Universal Dependency Parse Tree
  Aggregation"	['Adithya Kulkarni', 'Oliver Eulenstein', 'Qi Li']	2024-03-28 07:27:10+00:00	http://arxiv.org/abs/2403.19183v2	"Dependency parsing is an essential task in NLP, and the quality of dependency
parsers is crucial for many downstream tasks. Parsers' quality often varies
depending on the domain and the language involved. Therefore, it is essential
to combat the issue of varying quality to achieve stable performance. In
various NLP tasks, aggregation methods are used for post-processing aggregation
and have been shown to combat the issue of varying quality. However,
aggregation methods for post-processing aggregation have not been sufficiently
studied in dependency parsing tasks. In an extensive empirical study, we
compare different unsupervised post-processing aggregation methods to identify
the most suitable dependency tree structure aggregation method."	ArXiv
1506	Related Work and Citation Text Generation: A Survey	['Xiangci Li', 'Jessica Ouyang']	2024-04-17 17:37:30+00:00	http://arxiv.org/abs/2404.11588v1	"To convince readers of the novelty of their research paper, authors must
perform a literature review and compose a coherent story that connects and
relates prior works to the current work. This challenging nature of literature
review writing makes automatic related work generation (RWG) academically and
computationally interesting, and also makes it an excellent test bed for
examining the capability of SOTA natural language processing (NLP) models.
Since the initial proposal of the RWG task, its popularity has waxed and waned,
following the capabilities of mainstream NLP approaches. In this work, we
survey the zoo of RWG historical works, summarizing the key approaches and task
definitions and discussing the ongoing challenges of RWG."	ArXiv
1507	"A NLP Approach to ""Review Bombing"" in Metacritic PC Videogames User
  Ratings"	['Javier Coronado-Blázquez']	2024-05-10 08:31:04+00:00	http://arxiv.org/abs/2405.06306v1	"Many videogames suffer ""review bombing"" -a large volume of unusually low
scores that in many cases do not reflect the real quality of the product- when
rated by users. By taking Metacritic's 50,000+ user score aggregations for PC
games in English language, we use a Natural Language Processing (NLP) approach
to try to understand the main words and concepts appearing in such cases,
reaching a 0.88 accuracy on a validation set when distinguishing between just
bad ratings and review bombings. By uncovering and analyzing the patterns
driving this phenomenon, these results could be used to further mitigate these
situations."	ArXiv
1508	Designing NLP Systems That Adapt to Diverse Worldviews	['Claudiu Creanga', 'Liviu P. Dinu']	2024-05-18 06:48:09+00:00	http://arxiv.org/abs/2405.11197v1	"Natural Language Inference (NLI) is foundational for evaluating language
understanding in AI. However, progress has plateaued, with models failing on
ambiguous examples and exhibiting poor generalization. We argue that this stems
from disregarding the subjective nature of meaning, which is intrinsically tied
to an individual's \textit{weltanschauung} (which roughly translates to
worldview). Existing NLP datasets often obscure this by aggregating labels or
filtering out disagreement. We propose a perspectivist approach: building
datasets that capture annotator demographics, values, and justifications for
their labels. Such datasets would explicitly model diverse worldviews. Our
initial experiments with a subset of the SBIC dataset demonstrate that even
limited annotator metadata can improve model performance."	ArXiv
1509	Mining United Nations General Assembly Debates	['Mateusz Grzyb', 'Mateusz Krzyziński', 'Bartłomiej Sobieski', 'Mikołaj Spytek', 'Bartosz Pieliński', 'Daniel Dan', 'Anna Wróblewska']	2024-06-19 13:43:27+00:00	http://arxiv.org/abs/2406.13553v1	"This project explores the application of Natural Language Processing (NLP)
techniques to analyse United Nations General Assembly (UNGA) speeches. Using
NLP allows for the efficient processing and analysis of large volumes of
textual data, enabling the extraction of semantic patterns, sentiment analysis,
and topic modelling. Our goal is to deliver a comprehensive dataset and a tool
(interface with descriptive statistics and automatically extracted topics) from
which political scientists can derive insights into international relations and
have the opportunity to have a nuanced understanding of global diplomatic
discourse."	ArXiv
1510	"Renard: A Modular Pipeline for Extracting Character Networks from
  Narrative Texts"	['Arthur Amalvy', 'Vincent Labatut', 'Richard Dufour']	2024-07-02 14:14:59+00:00	http://arxiv.org/abs/2407.02284v1	"Renard (Relationships Extraction from NARrative Documents) is a Python
library that allows users to define custom natural language processing (NLP)
pipelines to extract character networks from narrative texts. Contrary to the
few existing tools, Renard can extract dynamic networks, as well as the more
common static networks. Renard pipelines are modular: users can choose the
implementation of each NLP subtask needed to extract a character network. This
allows users to specialize pipelines to particular types of texts and to study
the impact of each subtask on the extracted network."	ArXiv
1511	Optimal and efficient text counterfactuals using Graph Neural Networks	['Dimitris Lymperopoulos', 'Maria Lymperaiou', 'Giorgos Filandrianos', 'Giorgos Stamou']	2024-08-04 09:09:13+00:00	http://arxiv.org/abs/2408.01969v2	"As NLP models become increasingly integral to decision-making processes, the
need for explainability and interpretability has become paramount. In this
work, we propose a framework that achieves the aforementioned by generating
semantically edited inputs, known as counterfactual interventions, which change
the model prediction, thus providing a form of counterfactual explanations for
the model. We test our framework on two NLP tasks - binary sentiment
classification and topic classification - and show that the generated edits are
contrastive, fluent and minimal, while the whole process remains significantly
faster that other state-of-the-art counterfactual editors."	ArXiv
1512	PhysBERT: A Text Embedding Model for Physics Scientific Literature	['Thorsten Hellert', 'João Montenegro', 'Andrea Pollastro']	2024-08-18 19:18:12+00:00	http://arxiv.org/abs/2408.09574v1	"The specialized language and complex concepts in physics pose significant
challenges for information extraction through Natural Language Processing
(NLP). Central to effective NLP applications is the text embedding model, which
converts text into dense vector representations for efficient information
retrieval and semantic analysis. In this work, we introduce PhysBERT, the first
physics-specific text embedding model. Pre-trained on a curated corpus of 1.2
million arXiv physics papers and fine-tuned with supervised data, PhysBERT
outperforms leading general-purpose models on physics-specific tasks including
the effectiveness in fine-tuning for specific physics subdomains."	ArXiv
1513	J2N -- Nominal Adjective Identification and its Application	['Lemeng Qi', 'Yang Han', 'Zhuotong Xie']	2024-09-22 09:33:54+00:00	http://arxiv.org/abs/2409.14374v3	"This paper explores the challenges posed by nominal adjectives (NAs) in
natural language processing (NLP) tasks, particularly in part-of-speech (POS)
tagging. We propose treating NAs as a distinct POS tag, ""JN,"" and investigate
its impact on POS tagging, BIO chunking, and coreference resolution. Our study
shows that reclassifying NAs can improve the accuracy of syntactic analysis and
structural understanding in NLP. We present experimental results using Hidden
Markov Models (HMMs), Maximum Entropy (MaxEnt) models, and Spacy, demonstrating
the feasibility and potential benefits of this approach. Additionally we
finetuned a bert model to identify the NA in untagged text."	ArXiv
1514	Compact Broadband Light Source Based on Noise-Like Pulses	['Fanglin Chen', 'Xiahui Tang', 'Ming Tang', 'Luming Zhao']	2024-09-23 15:21:04+00:00	http://arxiv.org/abs/2409.15115v1	"We report on broadband generation based on noise-like pulse (NLP) fiber
lasers at 1.55 {\mu}m and 1.06 {\mu}m, respectively. The 1.55 {\mu}m laser
system can generate a broadband spectrum with a 20 dB bandwidth of up to 205
nm, while the 1.06 {\mu}m one can achieve a 20 dB bandwidth of 341 nm after
amplification and spectral broadening. Simulation results reproduce
experimental details and highlight the role of nonlinear effects in achieving
broad spectral outputs, underscoring the suitability of NLPs for advanced
applications."	ArXiv
1515	"Traversing Emotional Landscapes and Linguistic Patterns in Bernard-Marie
  Koltès' Plays: An NLP Perspective"	['Arezou Zahiri Pourzarandi', 'Farshad Jafari']	2024-10-12 18:13:47+00:00	http://arxiv.org/abs/2410.09609v1	"This study employs Natural Language Processing (NLP) to analyze the intricate
linguistic and emotional dimensions within the plays of Bernard-Marie Kolt\`es,
a central figure in contemporary French theatre. By integrating advanced
computational techniques, we dissect Kolt\`es' narrative style, revealing the
subtle interplay between language and emotion across his dramatic oeuvre. Our
findings highlight how Kolt\`es crafts his narratives, enriching our
understanding of his thematic explorations and contributing to the broader
field of digital humanities in literary analysis."	ArXiv
1516	The Large Language Model GreekLegalRoBERTa	['Vasileios Saketos', 'Despina-Athanasia Pantazi', 'Manolis Koubarakis']	2024-10-10 20:54:39+00:00	http://arxiv.org/abs/2410.12852v1	"We develop four versions of GreekLegalRoBERTa, which are four large language
models trained on Greek legal and nonlegal text. We show that our models
surpass the performance of GreekLegalBERT, Greek- LegalBERT-v2, and GreekBERT
in two tasks involving Greek legal documents: named entity recognition and
multi-class legal topic classification. We view our work as a contribution to
the study of domain-specific NLP tasks in low-resource languages, like Greek,
using modern NLP techniques and methodologies."	ArXiv
1517	Don't Touch My Diacritics	['Kyle Gorman', 'Yuval Pinter']	2024-10-31 17:03:44+00:00	http://arxiv.org/abs/2410.24140v1	"The common practice of preprocessing text before feeding it into NLP models
introduces many decision points which have unintended consequences on model
performance. In this opinion piece, we focus on the handling of diacritics in
texts originating in many languages and scripts. We demonstrate, through
several case studies, the adverse effects of inconsistent encoding of
diacritized characters and of removing diacritics altogether. We call on the
community to adopt simple but necessary steps across all models and toolkits in
order to improve handling of diacritized text and, by extension, increase
equity in multilingual NLP."	ArXiv
1518	On the Efficiency of NLP-Inspired Methods for Tabular Deep Learning	['Anton Frederik Thielmann', 'Soheila Samiee']	2024-11-26 08:23:29+00:00	http://arxiv.org/abs/2411.17207v1	"Recent advancements in tabular deep learning (DL) have led to substantial
performance improvements, surpassing the capabilities of traditional models.
With the adoption of techniques from natural language processing (NLP), such as
language model-based approaches, DL models for tabular data have also grown in
complexity and size. Although tabular datasets do not typically pose
scalability issues, the escalating size of these models has raised efficiency
concerns. Despite its importance, efficiency has been relatively underexplored
in tabular DL research. This paper critically examines the latest innovations
in tabular DL, with a dual focus on performance and computational efficiency.
The source code is available at https://github.com/basf/mamba-tabular."	ArXiv
1519	"Self-Adaptive ERP: Embedding NLP into Petri-Net creation and Model
  Matching"	['Ahmed Maged', 'Gamal Kassem']	2025-01-07 14:01:59+00:00	http://arxiv.org/abs/2501.03795v1	"Enterprise Resource Planning (ERP) consultants play a vital role in
customizing systems to meet specific business needs by processing large amounts
of data and adapting functionalities. However, the process is
resource-intensive, time-consuming, and requires continuous adjustments as
business demands evolve. This research introduces a Self-Adaptive ERP Framework
that automates customization using enterprise process models and system usage
analysis. It leverages Artificial Intelligence (AI) & Natural Language
Processing (NLP) for Petri nets to transform business processes into adaptable
models, addressing both structural and functional matching. The framework,
built using Design Science Research (DSR) and a Systematic Literature Review
(SLR), reduces reliance on manual adjustments, improving ERP customization
efficiency and accuracy while minimizing the need for consultants."	ArXiv
1520	A Rhetorical Analysis Approach to Natural Language Processing	['Benjamin Englard']	2013-01-16 01:42:53+00:00	http://arxiv.org/abs/1301.3547v1	"The goal of this research was to find a way to extend the capabilities of
computers through the processing of language in a more human way, and present
applications which demonstrate the power of this method. This research presents
a novel approach, Rhetorical Analysis, to solving problems in Natural Language
Processing (NLP). The main benefit of Rhetorical Analysis, as opposed to
previous approaches, is that it does not require the accumulation of large sets
of training data, but can be used to solve a multitude of problems within the
field of NLP. The NLP problems investigated with Rhetorical Analysis were the
Author Identification problem - predicting the author of a piece of text based
on its rhetorical strategies, Election Prediction - predicting the winner of a
presidential candidate's re-election campaign based on rhetorical strategies
within that president's inaugural address, Natural Language Generation - having
a computer produce text containing rhetorical strategies, and Document
Summarization. The results of this research indicate that an Author
Identification system based on Rhetorical Analysis could predict the correct
author 100% of the time, that a re-election predictor based on Rhetorical
Analysis could predict the correct winner of a re-election campaign 55% of the
time, that a Natural Language Generation system based on Rhetorical Analysis
could output text with up to 87.3% similarity to Shakespeare in style, and that
a Document Summarization system based on Rhetorical Analysis could extract
highly relevant sentences. Overall, this study demonstrated that Rhetorical
Analysis could be a useful approach to solving problems in NLP."	ArXiv
1521	Proceedings of the LexSem+Logics Workshop 2016	['Steven Neale', 'Valeria de Paiva', 'Arantxa Otegi', 'Alexandre Rademaker']	2016-08-14 16:23:55+00:00	http://arxiv.org/abs/1608.04767v1	"Lexical semantics continues to play an important role in driving research
directions in NLP, with the recognition and understanding of context becoming
increasingly important in delivering successful outcomes in NLP tasks. Besides
traditional processing areas such as word sense and named entity
disambiguation, the creation and maintenance of dictionaries, annotated corpora
and resources have become cornerstones of lexical semantics research and
produced a wealth of contextual information that NLP processes can exploit. New
efforts both to link and construct from scratch such information - as Linked
Open Data or by way of formal tools coming from logic, ontologies and automated
reasoning - have increased the interoperability and accessibility of resources
for lexical and computational semantics, even in those languages for which they
have previously been limited.
  LexSem+Logics 2016 combines the 1st Workshop on Lexical Semantics for
Lesser-Resources Languages and the 3rd Workshop on Logics and Ontologies. The
accepted papers in our program covered topics across these two areas,
including: the encoding of plurals in Wordnets, the creation of a thesaurus
from multiple sources based on semantic similarity metrics, and the use of
cross-lingual treebanks and annotations for universal part-of-speech tagging.
We also welcomed talks from two distinguished speakers: on Portuguese lexical
knowledge bases (different approaches, results and their application in NLP
tasks) and on new strategies for open information extraction (the capture of
verb-based propositions from massive text corpora)."	ArXiv
1522	"TutorialBank: A Manually-Collected Corpus for Prerequisite Chains,
  Survey Extraction and Resource Recommendation"	['Alexander R. Fabbri', 'Irene Li', 'Prawat Trairatvorakul', 'Yijiao He', 'Wei Tai Ting', 'Robert Tung', 'Caitlin Westerfield', 'Dragomir R. Radev']	2018-05-11 23:13:34+00:00	http://arxiv.org/abs/1805.04617v1	"The field of Natural Language Processing (NLP) is growing rapidly, with new
research published daily along with an abundance of tutorials, codebases and
other online resources. In order to learn this dynamic field or stay up-to-date
on the latest research, students as well as educators and researchers must
constantly sift through multiple sources to find valuable, relevant
information. To address this situation, we introduce TutorialBank, a new,
publicly available dataset which aims to facilitate NLP education and research.
We have manually collected and categorized over 6,300 resources on NLP as well
as the related fields of Artificial Intelligence (AI), Machine Learning (ML)
and Information Retrieval (IR). Our dataset is notably the largest
manually-picked corpus of resources intended for NLP education which does not
include only academic papers. Additionally, we have created both a search
engine and a command-line tool for the resources and have annotated the corpus
to include lists of research topics, relevant resources for each topic,
prerequisite relations among topics, relevant sub-parts of individual
resources, among other annotations. We are releasing the dataset and present
several avenues for further research."	ArXiv
1523	Learning Explanations from Language Data	['David Harbecke', 'Robert Schwarzenberg', 'Christoph Alt']	2018-08-13 09:51:46+00:00	http://arxiv.org/abs/1808.04127v1	"PatternAttribution is a recent method, introduced in the vision domain, that
explains classifications of deep neural networks. We demonstrate that it also
generates meaningful interpretations in the language domain."	ArXiv
1524	A Survey on Natural Language Processing for Fake News Detection	['Ray Oshikawa', 'Jing Qian', 'William Yang Wang']	2018-11-02 08:10:21+00:00	http://arxiv.org/abs/1811.00770v2	"Fake news detection is a critical yet challenging problem in Natural Language
Processing (NLP). The rapid rise of social networking platforms has not only
yielded a vast increase in information accessibility but has also accelerated
the spread of fake news. Thus, the effect of fake news has been growing,
sometimes extending to the offline world and threatening public safety. Given
the massive amount of Web content, automatic fake news detection is a practical
NLP problem useful to all online content providers, in order to reduce the
human time and effort to detect and prevent the spread of fake news. In this
paper, we describe the challenges involved in fake news detection and also
describe related tasks. We systematically review and compare the task
formulations, datasets and NLP solutions that have been developed for this
task, and also discuss the potentials and limitations of them. Based on our
insights, we outline promising research directions, including more
fine-grained, detailed, fair, and practical detection models. We also highlight
the difference between fake news detection and other related tasks, and the
importance of NLP solutions for fake news detection."	ArXiv
1525	"CREATE: Cohort Retrieval Enhanced by Analysis of Text from Electronic
  Health Records using OMOP Common Data Model"	['Sijia Liu', 'Yanshan Wang', 'Andrew Wen', 'Liwei Wang', 'Na Hong', 'Feichen Shen', 'Steven Bedrick', 'William Hersh', 'Hongfang Liu']	2019-01-22 20:05:11+00:00	http://arxiv.org/abs/1901.07601v1	"Background: Widespread adoption of electronic health records (EHRs) has
enabled secondary use of EHR data for clinical research and healthcare
delivery. Natural language processing (NLP) techniques have shown promise in
their capability to extract the embedded information in unstructured clinical
data, and information retrieval (IR) techniques provide flexible and scalable
solutions that can augment the NLP systems for retrieving and ranking relevant
records. Methods: In this paper, we present the implementation of Cohort
Retrieval Enhanced by Analysis of Text from EHRs (CREATE), a cohort retrieval
system that can execute textual cohort selection queries on both structured and
unstructured EHR data. CREATE is a proof-of-concept system that leverages a
combination of structured queries and IR techniques on NLP results to improve
cohort retrieval performance while adopting the Observational Medical Outcomes
Partnership (OMOP) Common Data Model (CDM) to enhance model portability. The
NLP component empowered by cTAKES is used to extract CDM concepts from textual
queries. We design a hierarchical index in Elasticsearch to support CDM concept
search utilizing IR techniques and frameworks. Results: Our case study on 5
cohort identification queries evaluated using the IR metric, P@5 (Precision at
5) at both the patient-level and document-level, demonstrates that CREATE
achieves an average P@5 of 0.90, which outperforms systems using only
structured data or only unstructured data with average P@5s of 0.54 and 0.74,
respectively."	ArXiv
1526	"A Cross-Architecture Instruction Embedding Model for Natural Language
  Processing-Inspired Binary Code Analysis"	['Kimberly Redmond', 'Lannan Luo', 'Qiang Zeng']	2018-12-23 03:44:03+00:00	http://arxiv.org/abs/1812.09652v1	"Given a closed-source program, such as most of proprietary software and
viruses, binary code analysis is indispensable for many tasks, such as code
plagiarism detection and malware analysis. Today, source code is very often
compiled for various architectures, making cross-architecture binary code
analysis increasingly important. A binary, after being disassembled, is
expressed in an assembly languages. Thus, recent work starts exploring Natural
Language Processing (NLP) inspired binary code analysis. In NLP, words are
usually represented in high-dimensional vectors (i.e., embeddings) to
facilitate further processing, which is one of the most common and critical
steps in many NLP tasks. We regard instructions as words in NLP-inspired binary
code analysis, and aim to represent instructions as embeddings as well.
  To facilitate cross-architecture binary code analysis, our goal is that
similar instructions, regardless of their architectures, have embeddings close
to each other. To this end, we propose a joint learning approach to generating
instruction embeddings that capture not only the semantics of instructions
within an architecture, but also their semantic relationships across
architectures. To the best of our knowledge, this is the first work on building
cross-architecture instruction embedding model. As a showcase, we apply the
model to resolving one of the most fundamental problems for binary code
similarity comparison---semantics-based basic block comparison, and the
solution outperforms the code statistics based approach. It demonstrates that
it is promising to apply the model to other cross-architecture binary code
analysis tasks."	ArXiv
1527	AraBERT: Transformer-based Model for Arabic Language Understanding	['Wissam Antoun', 'Fady Baly', 'Hazem Hajj']	2020-02-28 22:59:24+00:00	http://arxiv.org/abs/2003.00104v4	"The Arabic language is a morphologically rich language with relatively few
resources and a less explored syntax compared to English. Given these
limitations, Arabic Natural Language Processing (NLP) tasks like Sentiment
Analysis (SA), Named Entity Recognition (NER), and Question Answering (QA),
have proven to be very challenging to tackle. Recently, with the surge of
transformers based models, language-specific BERT based models have proven to
be very efficient at language understanding, provided they are pre-trained on a
very large corpus. Such models were able to set new standards and achieve
state-of-the-art results for most NLP tasks. In this paper, we pre-trained BERT
specifically for the Arabic language in the pursuit of achieving the same
success that BERT did for the English language. The performance of AraBERT is
compared to multilingual BERT from Google and other state-of-the-art
approaches. The results showed that the newly developed AraBERT achieved
state-of-the-art performance on most tested Arabic NLP tasks. The pretrained
araBERT models are publicly available on https://github.com/aub-mind/arabert
hoping to encourage research and applications for Arabic NLP."	ArXiv
1528	Noisy Text Data: Achilles' Heel of BERT	['Ankit Kumar', 'Piyush Makhija', 'Anuj Gupta']	2020-03-29 02:49:11+00:00	http://arxiv.org/abs/2003.12932v3	"Owing to the phenomenal success of BERT on various NLP tasks and benchmark
datasets, industry practitioners are actively experimenting with fine-tuning
BERT to build NLP applications for solving industry use cases. For most
datasets that are used by practitioners to build industrial NLP applications,
it is hard to guarantee absence of any noise in the data. While BERT has
performed exceedingly well for transferring the learnings from one use case to
another, it remains unclear how BERT performs when fine-tuned on noisy text. In
this work, we explore the sensitivity of BERT to noise in the data. We work
with most commonly occurring noise (spelling mistakes, typos) and show that
this results in significant degradation in the performance of BERT. We present
experimental results to show that BERT's performance on fundamental NLP tasks
like sentiment analysis and textual similarity drops significantly in the
presence of (simulated) noise on benchmark datasets viz. IMDB Movie Review,
STS-B, SST-2. Further, we identify shortcomings in the existing BERT pipeline
that are responsible for this drop in performance. Our findings suggest that
practitioners need to be vary of presence of noise in their datasets while
fine-tuning BERT to solve industry use cases."	ArXiv
1529	"Playing the lottery with rewards and multiple languages: lottery tickets
  in RL and NLP"	['Haonan Yu', 'Sergey Edunov', 'Yuandong Tian', 'Ari S. Morcos']	2019-06-06 18:38:38+00:00	http://arxiv.org/abs/1906.02768v3	"The lottery ticket hypothesis proposes that over-parameterization of deep
neural networks (DNNs) aids training by increasing the probability of a ""lucky""
sub-network initialization being present rather than by helping the
optimization process (Frankle & Carbin, 2019). Intriguingly, this phenomenon
suggests that initialization strategies for DNNs can be improved substantially,
but the lottery ticket hypothesis has only previously been tested in the
context of supervised learning for natural image tasks. Here, we evaluate
whether ""winning ticket"" initializations exist in two different domains:
natural language processing (NLP) and reinforcement learning (RL).For NLP, we
examined both recurrent LSTM models and large-scale Transformer models (Vaswani
et al., 2017). For RL, we analyzed a number of discrete-action space tasks,
including both classic control and pixel control. Consistent with workin
supervised image classification, we confirm that winning ticket initializations
generally outperform parameter-matched random initializations, even at extreme
pruning rates for both NLP and RL. Notably, we are able to find winning ticket
initializations for Transformers which enable models one-third the size to
achieve nearly equivalent performance. Together, these results suggest that the
lottery ticket hypothesis is not restricted to supervised learning of natural
images, but rather represents a broader phenomenon in DNNs."	ArXiv
1530	"SemClinBr -- a multi institutional and multi specialty semantically
  annotated corpus for Portuguese clinical NLP tasks"	['Lucas Emanuel Silva e Oliveira', 'Ana Carolina Peters', 'Adalniza Moura Pucca da Silva', 'Caroline P. Gebeluca', 'Yohan Bonescki Gumiel', 'Lilian Mie Mukai Cintho', 'Deborah Ribeiro Carvalho', 'Sadid A. Hasan', 'Claudia Maria Cabral Moro']	2020-01-27 20:39:32+00:00	http://arxiv.org/abs/2001.10071v1	"The high volume of research focusing on extracting patient's information from
electronic health records (EHR) has led to an increase in the demand for
annotated corpora, which are a very valuable resource for both the development
and evaluation of natural language processing (NLP) algorithms. The absence of
a multi-purpose clinical corpus outside the scope of the English language,
especially in Brazilian Portuguese, is glaring and severely impacts scientific
progress in the biomedical NLP field. In this study, we developed a
semantically annotated corpus using clinical texts from multiple medical
specialties, document types, and institutions. We present the following: (1) a
survey listing common aspects and lessons learned from previous research, (2) a
fine-grained annotation schema which could be replicated and guide other
annotation initiatives, (3) a web-based annotation tool focusing on an
annotation suggestion feature, and (4) both intrinsic and extrinsic evaluation
of the annotations. The result of this work is the SemClinBr, a corpus that has
1,000 clinical notes, labeled with 65,117 entities and 11,263 relations, and
can support a variety of clinical NLP tasks and boost the EHR's secondary use
for the Portuguese language."	ArXiv
1531	Meta-learning for Few-shot Natural Language Processing: A Survey	['Wenpeng Yin']	2020-07-19 06:36:41+00:00	http://arxiv.org/abs/2007.09604v1	"Few-shot natural language processing (NLP) refers to NLP tasks that are
accompanied with merely a handful of labeled examples. This is a real-world
challenge that an AI system must learn to handle. Usually we rely on collecting
more auxiliary information or developing a more efficient learning algorithm.
However, the general gradient-based optimization in high capacity models, if
training from scratch, requires many parameter-updating steps over a large
number of labeled examples to perform well (Snell et al., 2017). If the target
task itself cannot provide more information, how about collecting more tasks
equipped with rich annotations to help the model learning? The goal of
meta-learning is to train a model on a variety of tasks with rich annotations,
such that it can solve a new task using only a few labeled samples. The key
idea is to train the model's initial parameters such that the model has maximal
performance on a new task after the parameters have been updated through zero
or a couple of gradient steps. There are already some surveys for
meta-learning, such as (Vilalta and Drissi, 2002; Vanschoren, 2018; Hospedales
et al., 2020). Nevertheless, this paper focuses on NLP domain, especially
few-shot applications. We try to provide clearer definitions, progress summary
and some common datasets of applying meta-learning to few-shot NLP."	ArXiv
1532	"Domain-Specific Language Model Pretraining for Biomedical Natural
  Language Processing"	['Yu Gu', 'Robert Tinn', 'Hao Cheng', 'Michael Lucas', 'Naoto Usuyama', 'Xiaodong Liu', 'Tristan Naumann', 'Jianfeng Gao', 'Hoifung Poon']	2020-07-31 00:04:15+00:00	http://arxiv.org/abs/2007.15779v6	"Pretraining large neural language models, such as BERT, has led to impressive
gains on many natural language processing (NLP) tasks. However, most
pretraining efforts focus on general domain corpora, such as newswire and Web.
A prevailing assumption is that even domain-specific pretraining can benefit by
starting from general-domain language models. In this paper, we challenge this
assumption by showing that for domains with abundant unlabeled text, such as
biomedicine, pretraining language models from scratch results in substantial
gains over continual pretraining of general-domain language models. To
facilitate this investigation, we compile a comprehensive biomedical NLP
benchmark from publicly-available datasets. Our experiments show that
domain-specific pretraining serves as a solid foundation for a wide range of
biomedical NLP tasks, leading to new state-of-the-art results across the board.
Further, in conducting a thorough evaluation of modeling choices, both for
pretraining and task-specific fine-tuning, we discover that some common
practices are unnecessary with BERT models, such as using complex tagging
schemes in named entity recognition (NER). To help accelerate research in
biomedical NLP, we have released our state-of-the-art pretrained and
task-specific models for the community, and created a leaderboard featuring our
BLURB benchmark (short for Biomedical Language Understanding & Reasoning
Benchmark) at https://aka.ms/BLURB."	ArXiv
1533	"Searching for a Search Method: Benchmarking Search Algorithms for
  Generating NLP Adversarial Examples"	['Jin Yong Yoo', 'John X. Morris', 'Eli Lifland', 'Yanjun Qi']	2020-09-09 17:04:42+00:00	http://arxiv.org/abs/2009.06368v2	"We study the behavior of several black-box search algorithms used for
generating adversarial examples for natural language processing (NLP) tasks. We
perform a fine-grained analysis of three elements relevant to search: search
algorithm, search space, and search budget. When new search algorithms are
proposed in past work, the attack search space is often modified alongside the
search algorithm. Without ablation studies benchmarking the search algorithm
change with the search space held constant, one cannot tell if an increase in
attack success rate is a result of an improved search algorithm or a less
restrictive search space. Additionally, many previous studies fail to properly
consider the search algorithms' run-time cost, which is essential for
downstream tasks like adversarial training. Our experiments provide a
reproducible benchmark of search algorithms across a variety of search spaces
and query budgets to guide future research in adversarial NLP. Based on our
experiments, we recommend greedy attacks with word importance ranking when
under a time constraint or attacking long inputs, and either beam search or
particle swarm optimization otherwise. Code implementation shared via
https://github.com/QData/TextAttack-Search-Benchmark"	ArXiv
1534	"Trankit: A Light-Weight Transformer-based Toolkit for Multilingual
  Natural Language Processing"	['Minh Van Nguyen', 'Viet Dac Lai', 'Amir Pouran Ben Veyseh', 'Thien Huu Nguyen']	2021-01-09 04:55:52+00:00	http://arxiv.org/abs/2101.03289v5	"We introduce Trankit, a light-weight Transformer-based Toolkit for
multilingual Natural Language Processing (NLP). It provides a trainable
pipeline for fundamental NLP tasks over 100 languages, and 90 pretrained
pipelines for 56 languages. Built on a state-of-the-art pretrained language
model, Trankit significantly outperforms prior multilingual NLP pipelines over
sentence segmentation, part-of-speech tagging, morphological feature tagging,
and dependency parsing while maintaining competitive performance for
tokenization, multi-word token expansion, and lemmatization over 90 Universal
Dependencies treebanks. Despite the use of a large pretrained transformer, our
toolkit is still efficient in memory usage and speed. This is achieved by our
novel plug-and-play mechanism with Adapters where a multilingual pretrained
transformer is shared across pipelines for different languages. Our toolkit
along with pretrained models and code are publicly available at:
https://github.com/nlp-uoregon/trankit. A demo website for our toolkit is also
available at: http://nlp.uoregon.edu/trankit. Finally, we create a demo video
for Trankit at: https://youtu.be/q0KGP3zGjGc."	ArXiv
1535	"Adversarially Robust and Explainable Model Compression with On-Device
  Personalization for Text Classification"	['Yao Qiang', 'Supriya Tumkur Suresh Kumar', 'Marco Brocanelli', 'Dongxiao Zhu']	2021-01-10 15:06:55+00:00	http://arxiv.org/abs/2101.05624v3	"On-device Deep Neural Networks (DNNs) have recently gained more attention due
to the increasing computing power of the mobile devices and the number of
applications in Computer Vision (CV), Natural Language Processing (NLP), and
Internet of Things (IoTs). Unfortunately, the existing efficient convolutional
neural network (CNN) architectures designed for CV tasks are not directly
applicable to NLP tasks and the tiny Recurrent Neural Network (RNN)
architectures have been designed primarily for IoT applications. In NLP
applications, although model compression has seen initial success in on-device
text classification, there are at least three major challenges yet to be
addressed: adversarial robustness, explainability, and personalization. Here we
attempt to tackle these challenges by designing a new training scheme for model
compression and adversarial robustness, including the optimization of an
explainable feature mapping objective, a knowledge distillation objective, and
an adversarially robustness objective. The resulting compressed model is
personalized using on-device private training data via fine-tuning. We perform
extensive experiments to compare our approach with both compact RNN (e.g.,
FastGRNN) and compressed RNN (e.g., PRADO) architectures in both natural and
adversarial NLP test settings."	ArXiv
1536	Automated Software Vulnerability Assessment with Concept Drift	['Triet H. M. Le', 'Bushra Sabir', 'M. Ali Babar']	2021-03-21 06:28:45+00:00	http://arxiv.org/abs/2103.11316v1	"Software Engineering researchers are increasingly using Natural Language
Processing (NLP) techniques to automate Software Vulnerabilities (SVs)
assessment using the descriptions in public repositories. However, the existing
NLP-based approaches suffer from concept drift. This problem is caused by a
lack of proper treatment of new (out-of-vocabulary) terms for the evaluation of
unseen SVs over time. To perform automated SVs assessment with concept drift
using SVs' descriptions, we propose a systematic approach that combines both
character and word features. The proposed approach is used to predict seven
Vulnerability Characteristics (VCs). The optimal model of each VC is selected
using our customized time-based cross-validation method from a list of eight
NLP representations and six well-known Machine Learning models. We have used
the proposed approach to conduct large-scale experiments on more than 100,000
SVs in the National Vulnerability Database (NVD). The results show that our
approach can effectively tackle the concept drift issue of the SVs'
descriptions reported from 2000 to 2018 in NVD even without retraining the
model. In addition, our approach performs competitively compared to the
existing word-only method. We also investigate how to build compact
concept-drift-aware models with much fewer features and give some
recommendations on the choice of classifiers and NLP representations for SVs
assessment."	ArXiv
1537	GPT-3 Models are Poor Few-Shot Learners in the Biomedical Domain	['Milad Moradi', 'Kathrin Blagec', 'Florian Haberl', 'Matthias Samwald']	2021-09-06 15:50:37+00:00	http://arxiv.org/abs/2109.02555v2	"Deep neural language models have set new breakthroughs in many tasks of
Natural Language Processing (NLP). Recent work has shown that deep transformer
language models (pretrained on large amounts of texts) can achieve high levels
of task-specific few-shot performance comparable to state-of-the-art models.
However, the ability of these large language models in few-shot transfer
learning has not yet been explored in the biomedical domain. We investigated
the performance of two powerful transformer language models, i.e. GPT-3 and
BioBERT, in few-shot settings on various biomedical NLP tasks. The experimental
results showed that, to a great extent, both the models underperform a language
model fine-tuned on the full training data. Although GPT-3 had already achieved
near state-of-the-art results in few-shot knowledge transfer on open-domain NLP
tasks, it could not perform as effectively as BioBERT, which is orders of
magnitude smaller than GPT-3. Regarding that BioBERT was already pretrained on
large biomedical text corpora, our study suggests that language models may
largely benefit from in-domain pretraining in task-specific few-shot learning.
However, in-domain pretraining seems not to be sufficient; novel pretraining
and few-shot learning strategies are required in the biomedical NLP domain."	ArXiv
1538	Adversarial Training with Contrastive Learning in NLP	['Daniela N. Rim', 'DongNyeong Heo', 'Heeyoul Choi']	2021-09-19 07:23:45+00:00	http://arxiv.org/abs/2109.09075v1	"For years, adversarial training has been extensively studied in natural
language processing (NLP) settings. The main goal is to make models robust so
that similar inputs derive in semantically similar outcomes, which is not a
trivial problem since there is no objective measure of semantic similarity in
language. Previous works use an external pre-trained NLP model to tackle this
challenge, introducing an extra training stage with huge memory consumption
during training. However, the recent popular approach of contrastive learning
in language processing hints a convenient way of obtaining such similarity
restrictions. The main advantage of the contrastive learning approach is that
it aims for similar data points to be mapped close to each other and further
from different ones in the representation space. In this work, we propose
adversarial training with contrastive learning (ATCL) to adversarially train a
language processing task using the benefits of contrastive learning. The core
idea is to make linear perturbations in the embedding space of the input via
fast gradient methods (FGM) and train the model to keep the original and
perturbed representations close via contrastive learning. In NLP experiments,
we applied ATCL to language modeling and neural machine translation tasks. The
results show not only an improvement in the quantitative (perplexity and BLEU)
scores when compared to the baselines, but ATCL also achieves good qualitative
results in the semantic level for both tasks without using a pre-trained model."	ArXiv
1539	"CLICKER: A Computational LInguistics Classification Scheme for
  Educational Resources"	['Swapnil Hingmire', 'Irene Li', 'Rena Kawamura', 'Benjamin Chen', 'Alexander Fabbri', 'Xiangru Tang', 'Yixin Liu', 'Thomas George', 'Tammy Liao', 'Wai Pan Wong', 'Vanessa Yan', 'Richard Zhou', 'Girish K. Palshikar', 'Dragomir Radev']	2021-12-16 02:40:43+00:00	http://arxiv.org/abs/2112.08578v1	"A classification scheme of a scientific subject gives an overview of its body
of knowledge. It can also be used to facilitate access to research articles and
other materials related to the subject. For example, the ACM Computing
Classification System (CCS) is used in the ACM Digital Library search interface
and also for indexing computer science papers. We observed that a comprehensive
classification system like CCS or Mathematics Subject Classification (MSC) does
not exist for Computational Linguistics (CL) and Natural Language Processing
(NLP). We propose a classification scheme -- CLICKER for CL/NLP based on the
analysis of online lectures from 77 university courses on this subject. The
currently proposed taxonomy includes 334 topics and focuses on educational
aspects of CL/NLP; it is based primarily, but not exclusively, on lecture notes
from NLP courses. We discuss how such a taxonomy can help in various real-world
applications, including tutoring platforms, resource retrieval, resource
recommendation, prerequisite chain learning, and survey generation."	ArXiv
1540	AED: An black-box NLP classifier model attacker	['Yueyang Liu', 'Yan Huang', 'Zhipeng Cai']	2021-12-22 04:25:23+00:00	http://arxiv.org/abs/2112.11660v4	"Deep Neural Networks (DNNs) have been successful in solving real-world tasks
in domains such as connected and automated vehicles, disease, and job hiring.
However, their implications are far-reaching in critical application areas.
Hence, there is a growing concern regarding the potential bias and robustness
of these DNN models. A transparency and robust model is always demanded in
high-stakes domains where reliability and safety are enforced, such as
healthcare and finance. While most studies have focused on adversarial image
attack scenarios, fewer studies have investigated the robustness of DNN models
in natural language processing (NLP) due to their adversarial samples are
difficult to generate. To address this gap, we propose a word-level NLP
classifier attack model called ""AED,"" which stands for Attention mechanism
enabled post-model Explanation with Density peaks clustering algorithm for
synonyms search and substitution. AED aims to test the robustness of NLP DNN
models by interpretability their weaknesses and exploring alternative ways to
optimize them. By identifying vulnerabilities and providing explanations, AED
can help improve the reliability and safety of DNN models in critical
application areas such as healthcare and automated transportation. Our
experiment results demonstrate that compared with other existing models, AED
can effectively generate adversarial examples that can fool the victim model
while maintaining the original meaning of the input."	ArXiv
1541	"NLP in Human Rights Research -- Extracting Knowledge Graphs About Police
  and Army Units and Their Commanders"	['Daniel Bauer', 'Tom Longley', 'Yueen Ma', 'Tony Wilson']	2022-01-13 21:57:21+00:00	http://arxiv.org/abs/2201.05230v1	"In this working paper we explore the use of an NLP system to assist the work
of Security Force Monitor (SFM). SFM creates data about the organizational
structure, command personnel and operations of police, army and other security
forces, which assists human rights researchers, journalists and litigators in
their work to help identify and bring to account specific units and personnel
alleged to have committed abuses of human rights and international criminal
law. This working paper presents an NLP system that extracts from English
language news reports the names of security force units and the biographical
details of their personnel, and infers the formal relationship between them.
Published alongside this working paper are the system's code and training
dataset. We find that the experimental NLP system performs the task at a fair
to good level. Its performance is sufficient to justify further development
into a live workflow that will give insight into whether its performance
translates into savings in time and resource that would make it an effective
technical intervention."	ArXiv
1542	A Large and Diverse Arabic Corpus for Language Modeling	['Abbas Raza Ali', 'Muhammad Ajmal Siddiqui', 'Rema Algunaibet', 'Hasan Raza Ali']	2022-01-23 11:17:53+00:00	http://arxiv.org/abs/2201.09227v3	"Language models (LMs) have introduced a major paradigm shift in Natural
Language Processing (NLP) modeling where large pre-trained LMs became integral
to most of the NLP tasks. The LMs are intelligent enough to find useful and
relevant representations of the language without any supervision. Perhaps,
these models are used to fine-tune typical NLP tasks with significantly high
accuracy as compared to the traditional approaches. Conversely, the training of
these models requires a massively large corpus that is a good representation of
the language. English LMs generally perform better than their other language
counterparts, due to the availability of massive English corpora. This work
elaborates on the design and development of a large Arabic corpus. It consists
of over 500 GB of Arabic cleaned text targeted at improving cross-domain
knowledge and downstream generalization capability of large-scale language
models. Moreover, the corpus is utilized in the training of a large Arabic LM.
In order to evaluate the effectiveness of the LM, a number of typical NLP tasks
are fine-tuned. The tasks demonstrate a significant boost from 4.5 to 8.5% when
compared to tasks fine-tuned on multi-lingual BERT (mBERT). To the best of my
knowledge, this is currently the largest clean and diverse Arabic corpus ever
collected."	ArXiv
1543	Understanding the Failure of Batch Normalization for Transformers in NLP	['Jiaxi Wang', 'Ji Wu', 'Lei Huang']	2022-10-11 05:18:47+00:00	http://arxiv.org/abs/2210.05153v1	"Batch Normalization (BN) is a core and prevalent technique in accelerating
the training of deep neural networks and improving the generalization on
Computer Vision (CV) tasks. However, it fails to defend its position in Natural
Language Processing (NLP), which is dominated by Layer Normalization (LN). In
this paper, we are trying to answer why BN usually performs worse than LN in
NLP tasks with Transformer models. We find that the inconsistency between
training and inference of BN is the leading cause that results in the failure
of BN in NLP. We define Training Inference Discrepancy (TID) to quantitatively
measure this inconsistency and reveal that TID can indicate BN's performance,
supported by extensive experiments, including image classification, neural
machine translation, language modeling, sequence labeling, and text
classification tasks. We find that BN can obtain much better test performance
than LN when TID keeps small through training. To suppress the explosion of
TID, we propose Regularized BN (RBN) that adds a simple regularization term to
narrow the gap between batch statistics and population statistics of BN. RBN
improves the performance of BN consistently and outperforms or is on par with
LN on 17 out of 20 settings, involving ten datasets and two common variants of
Transformer
  Our code is available at https://github.com/wjxts/RegularizedBN."	ArXiv
1544	"Why Should Adversarial Perturbations be Imperceptible? Rethink the
  Research Paradigm in Adversarial NLP"	['Yangyi Chen', 'Hongcheng Gao', 'Ganqu Cui', 'Fanchao Qi', 'Longtao Huang', 'Zhiyuan Liu', 'Maosong Sun']	2022-10-19 15:53:36+00:00	http://arxiv.org/abs/2210.10683v1	"Textual adversarial samples play important roles in multiple subfields of NLP
research, including security, evaluation, explainability, and data
augmentation. However, most work mixes all these roles, obscuring the problem
definitions and research goals of the security role that aims to reveal the
practical concerns of NLP models. In this paper, we rethink the research
paradigm of textual adversarial samples in security scenarios. We discuss the
deficiencies in previous work and propose our suggestions that the research on
the Security-oriented adversarial NLP (SoadNLP) should: (1) evaluate their
methods on security tasks to demonstrate the real-world concerns; (2) consider
real-world attackers' goals, instead of developing impractical methods. To this
end, we first collect, process, and release a security datasets collection
Advbench. Then, we reformalize the task and adjust the emphasis on different
goals in SoadNLP. Next, we propose a simple method based on heuristic rules
that can easily fulfill the actual adversarial goals to simulate real-world
attack methods. We conduct experiments on both the attack and the defense sides
on Advbench. Experimental results show that our method has higher practical
value, indicating that the research paradigm in SoadNLP may start from our new
benchmark. All the code and data of Advbench can be obtained at
\url{https://github.com/thunlp/Advbench}."	ArXiv
1545	"Standardization of the formal representation of lexical information for
  NLP"	['Laurent Romary']	2009-11-26 16:27:58+00:00	http://arxiv.org/abs/0911.5116v1	"A survey of dictionary models and formats is presented as well as a
presentation of corresponding recent standardisation activities."	ArXiv
1546	"A First Step in Combining Cognitive Event Features and Natural Language
  Representations to Predict Emotions"	['Andres Campero', 'Bjarke Felbo', 'Joshua B. Tenenbaum', 'Rebecca Saxe']	2017-10-23 00:26:50+00:00	http://arxiv.org/abs/1710.08048v1	"We explore the representational space of emotions by combining methods from
different academic fields. Cognitive science has proposed appraisal theory as a
view on human emotion with previous research showing how human-rated abstract
event features can predict fine-grained emotions and capture the similarity
space of neural patterns in mentalizing brain regions. At the same time,
natural language processing (NLP) has demonstrated how transfer and multitask
learning can be used to cope with scarcity of annotated data for text modeling.
  The contribution of this work is to show that appraisal theory can be
combined with NLP for mutual benefit. First, fine-grained emotion prediction
can be improved to human-level performance by using NLP representations in
addition to appraisal features. Second, using the appraisal features as
auxiliary targets during training can improve predictions even when only text
is available as input. Third, we obtain a representation with a similarity
matrix that better correlates with the neural activity across regions. Best
results are achieved when the model is trained to simultaneously predict
appraisals, emotions and emojis using a shared representation.
  While these results are preliminary, the integration of cognitive
neuroscience and NLP techniques opens up an interesting direction for future
research."	ArXiv
1547	Dice Loss for Data-imbalanced NLP Tasks	['Xiaoya Li', 'Xiaofei Sun', 'Yuxian Meng', 'Junjun Liang', 'Fei Wu', 'Jiwei Li']	2019-11-07 11:14:05+00:00	http://arxiv.org/abs/1911.02855v3	"Many NLP tasks such as tagging and machine reading comprehension are faced
with the severe data imbalance issue: negative examples significantly outnumber
positive examples, and the huge number of background examples (or easy-negative
examples) overwhelms the training. The most commonly used cross entropy (CE)
criteria is actually an accuracy-oriented objective, and thus creates a
discrepancy between training and test: at training time, each training instance
contributes equally to the objective function, while at test time F1 score
concerns more about positive examples. In this paper, we propose to use dice
loss in replacement of the standard cross-entropy objective for data-imbalanced
NLP tasks. Dice loss is based on the Sorensen-Dice coefficient or Tversky
index, which attaches similar importance to false positives and false
negatives, and is more immune to the data-imbalance issue. To further alleviate
the dominating influence from easy-negative examples in training, we propose to
associate training examples with dynamically adjusted weights to deemphasize
easy-negative examples.Theoretical analysis shows that this strategy narrows
down the gap between the F1 score in evaluation and the dice loss in training.
With the proposed training objective, we observe significant performance boost
on a wide range of data imbalanced NLP tasks. Notably, we are able to achieve
SOTA results on CTB5, CTB6 and UD1.4 for the part of speech tagging task; SOTA
results on CoNLL03, OntoNotes5.0, MSRA and OntoNotes4.0 for the named entity
recognition task; along with competitive results on the tasks of machine
reading comprehension and paraphrase identification."	ArXiv
1548	With Little Power Comes Great Responsibility	['Dallas Card', 'Peter Henderson', 'Urvashi Khandelwal', 'Robin Jia', 'Kyle Mahowald', 'Dan Jurafsky']	2020-10-13 18:00:02+00:00	http://arxiv.org/abs/2010.06595v1	"Despite its importance to experimental design, statistical power (the
probability that, given a real effect, an experiment will reject the null
hypothesis) has largely been ignored by the NLP community. Underpowered
experiments make it more difficult to discern the difference between
statistical noise and meaningful model improvements, and increase the chances
of exaggerated findings. By meta-analyzing a set of existing NLP papers and
datasets, we characterize typical power for a variety of settings and conclude
that underpowered experiments are common in the NLP literature. In particular,
for several tasks in the popular GLUE benchmark, small test sets mean that most
attempted comparisons to state of the art models will not be adequately
powered. Similarly, based on reasonable assumptions, we find that the most
typical experimental design for human rating studies will be underpowered to
detect small model differences, of the sort that are frequently studied. For
machine translation, we find that typical test sets of 2000 sentences have
approximately 75% power to detect differences of 1 BLEU point. To improve the
situation going forward, we give an overview of best practices for power
analysis in NLP and release a series of notebooks to assist with future power
analyses."	ArXiv
1549	"Artificial Intelligence (AI) in Action: Addressing the COVID-19 Pandemic
  with Natural Language Processing (NLP)"	['Qingyu Chen', 'Robert Leaman', 'Alexis Allot', 'Ling Luo', 'Chih-Hsuan Wei', 'Shankai Yan', 'Zhiyong Lu']	2020-10-09 22:10:43+00:00	http://arxiv.org/abs/2010.16413v3	"The COVID-19 pandemic has had a significant impact on society, both because
of the serious health effects of COVID-19 and because of public health measures
implemented to slow its spread. Many of these difficulties are fundamentally
information needs; attempts to address these needs have caused an information
overload for both researchers and the public. Natural language processing
(NLP), the branch of artificial intelligence that interprets human language,
can be applied to address many of the information needs made urgent by the
COVID-19 pandemic. This review surveys approximately 150 NLP studies and more
than 50 systems and datasets addressing the COVID-19 pandemic. We detail work
on four core NLP tasks: information retrieval, named entity recognition,
literature-based discovery, and question answering. We also describe work that
directly addresses aspects of the pandemic through four additional tasks: topic
modeling, sentiment and emotion analysis, caseload forecasting, and
misinformation detection. We conclude by discussing observable trends and
remaining challenges."	ArXiv
1550	CPM: A Large-scale Generative Chinese Pre-trained Language Model	['Zhengyan Zhang', 'Xu Han', 'Hao Zhou', 'Pei Ke', 'Yuxian Gu', 'Deming Ye', 'Yujia Qin', 'Yusheng Su', 'Haozhe Ji', 'Jian Guan', 'Fanchao Qi', 'Xiaozhi Wang', 'Yanan Zheng', 'Guoyang Zeng', 'Huanqi Cao', 'Shengqi Chen', 'Daixuan Li', 'Zhenbo Sun', 'Zhiyuan Liu', 'Minlie Huang', 'Wentao Han', 'Jie Tang', 'Juanzi Li', 'Xiaoyan Zhu', 'Maosong Sun']	2020-12-01 11:32:56+00:00	http://arxiv.org/abs/2012.00413v1	"Pre-trained Language Models (PLMs) have proven to be beneficial for various
downstream NLP tasks. Recently, GPT-3, with 175 billion parameters and 570GB
training data, drew a lot of attention due to the capacity of few-shot (even
zero-shot) learning. However, applying GPT-3 to address Chinese NLP tasks is
still challenging, as the training corpus of GPT-3 is primarily English, and
the parameters are not publicly available. In this technical report, we release
the Chinese Pre-trained Language Model (CPM) with generative pre-training on
large-scale Chinese training data. To the best of our knowledge, CPM, with 2.6
billion parameters and 100GB Chinese training data, is the largest Chinese
pre-trained language model, which could facilitate several downstream Chinese
NLP tasks, such as conversation, essay generation, cloze test, and language
understanding. Extensive experiments demonstrate that CPM achieves strong
performance on many NLP tasks in the settings of few-shot (even zero-shot)
learning. The code and parameters are available at
https://github.com/TsinghuaAI/CPM-Generate."	ArXiv
1551	"Enhancing Model Robustness By Incorporating Adversarial Knowledge Into
  Semantic Representation"	['Jinfeng Li', 'Tianyu Du', 'Xiangyu Liu', 'Rong Zhang', 'Hui Xue', 'Shouling Ji']	2021-02-23 09:47:45+00:00	http://arxiv.org/abs/2102.11584v1	"Despite that deep neural networks (DNNs) have achieved enormous success in
many domains like natural language processing (NLP), they have also been proven
to be vulnerable to maliciously generated adversarial examples. Such inherent
vulnerability has threatened various real-world deployed DNNs-based
applications. To strength the model robustness, several countermeasures have
been proposed in the English NLP domain and obtained satisfactory performance.
However, due to the unique language properties of Chinese, it is not trivial to
extend existing defenses to the Chinese domain. Therefore, we propose AdvGraph,
a novel defense which enhances the robustness of Chinese-based NLP models by
incorporating adversarial knowledge into the semantic representation of the
input. Extensive experiments on two real-world tasks show that AdvGraph
exhibits better performance compared with previous work: (i) effective - it
significantly strengthens the model robustness even under the adaptive attacks
setting without negative impact on model performance over legitimate input;
(ii) generic - its key component, i.e., the representation of connotative
adversarial knowledge is task-agnostic, which can be reused in any
Chinese-based NLP models without retraining; and (iii) efficient - it is a
light-weight defense with sub-linear computational complexity, which can
guarantee the efficiency required in practical scenarios."	ArXiv
1552	"QNLP in Practice: Running Compositional Models of Meaning on a Quantum
  Computer"	['Robin Lorenz', 'Anna Pearson', 'Konstantinos Meichanetzidis', 'Dimitri Kartsaklis', 'Bob Coecke']	2021-02-25 13:37:33+00:00	http://arxiv.org/abs/2102.12846v2	"Quantum Natural Language Processing (QNLP) deals with the design and
implementation of NLP models intended to be run on quantum hardware. In this
paper, we present results on the first NLP experiments conducted on Noisy
Intermediate-Scale Quantum (NISQ) computers for datasets of size greater than
100 sentences. Exploiting the formal similarity of the compositional model of
meaning by Coecke, Sadrzadeh and Clark (2010) with quantum theory, we create
representations for sentences that have a natural mapping to quantum circuits.
We use these representations to implement and successfully train NLP models
that solve simple sentence classification tasks on quantum hardware. We conduct
quantum simulations that compare the syntax-sensitive model of Coecke et al.
with two baselines that use less or no syntax; specifically, we implement the
quantum analogues of a ""bag-of-words"" model, where syntax is not taken into
account at all, and of a word-sequence model, where only word order is
respected. We demonstrate that all models converge smoothly both in simulations
and when run on quantum hardware, and that the results are the expected ones
based on the nature of the tasks and the datasets used. Another important goal
of this paper is to describe in a way accessible to AI and NLP researchers the
main principles, process and challenges of experiments on quantum hardware. Our
aim in doing this is to take the first small steps in this unexplored research
territory and pave the way for practical Quantum Natural Language Processing."	ArXiv
1553	NPE: An FPGA-based Overlay Processor for Natural Language Processing	['Hamza Khan', 'Asma Khan', 'Zainab Khan', 'Lun Bin Huang', 'Kun Wang', 'Lei He']	2021-04-13 22:34:33+00:00	http://arxiv.org/abs/2104.06535v1	"In recent years, transformer-based models have shown state-of-the-art results
for Natural Language Processing (NLP). In particular, the introduction of the
BERT language model brought with it breakthroughs in tasks such as question
answering and natural language inference, advancing applications that allow
humans to interact naturally with embedded devices. FPGA-based overlay
processors have been shown as effective solutions for edge image and video
processing applications, which mostly rely on low precision linear matrix
operations. In contrast, transformer-based NLP techniques employ a variety of
higher precision nonlinear operations with significantly higher frequency. We
present NPE, an FPGA-based overlay processor that can efficiently execute a
variety of NLP models. NPE offers software-like programmability to the end user
and, unlike FPGA designs that implement specialized accelerators for each
nonlinear function, can be upgraded for future NLP models without requiring
reconfiguration. We demonstrate that NPE can meet real-time conversational AI
latency targets for the BERT language model with $4\times$ lower power than
CPUs and $6\times$ lower power than GPUs. We also show NPE uses $3\times$ fewer
FPGA resources relative to comparable BERT network-specific accelerators in the
literature. NPE provides a cost-effective and power-efficient FPGA-based
solution for Natural Language Processing at the edge."	ArXiv
1554	"Decrypting Cryptic Crosswords: Semantically Complex Wordplay Puzzles as
  a Target for NLP"	['Joshua Rozner', 'Christopher Potts', 'Kyle Mahowald']	2021-04-17 18:54:00+00:00	http://arxiv.org/abs/2104.08620v3	"Cryptic crosswords, the dominant crossword variety in the UK, are a promising
target for advancing NLP systems that seek to process semantically complex,
highly compositional language. Cryptic clues read like fluent natural language
but are adversarially composed of two parts: a definition and a wordplay cipher
requiring character-level manipulations. Expert humans use creative
intelligence to solve cryptics, flexibly combining linguistic, world, and
domain knowledge. In this paper, we make two main contributions. First, we
present a dataset of cryptic clues as a challenging new benchmark for NLP
systems that seek to process compositional language in more creative,
human-like ways. After showing that three non-neural approaches and T5, a
state-of-the-art neural language model, do not achieve good performance, we
make our second main contribution: a novel curriculum approach, in which the
model is first fine-tuned on related tasks such as unscrambling words.We also
introduce a challenging data split, examine the meta-linguistic capabilities of
subword-tokenized models, and investigate model systematicity by perturbing the
wordplay part of clues, showing that T5 exhibits behavior partially consistent
with human solving strategies. Although our curricular approach considerably
improves on the T5 baseline, our best-performing model still fails to
generalize to the extent that humans can. Thus, cryptic crosswords remain an
unsolved challenge for NLP systems and a potential source of future innovation."	ArXiv
1555	"belabBERT: a Dutch RoBERTa-based language model applied to psychiatric
  classification"	['Joppe Wouts', 'Janna de Boer', 'Alban Voppel', 'Sanne Brederoo', 'Sander van Splunter', 'Iris Sommer']	2021-06-02 11:50:49+00:00	http://arxiv.org/abs/2106.01091v1	"Natural language processing (NLP) is becoming an important means for
automatic recognition of human traits and states, such as intoxication,
presence of psychiatric disorders, presence of airway disorders and states of
stress. Such applications have the potential to be an important pillar for
online help lines, and may gradually be introduced into eHealth modules.
However, NLP is language specific and for languages such as Dutch, NLP models
are scarce. As a result, recent Dutch NLP models have a low capture of long
range semantic dependencies over sentences. To overcome this, here we present
belabBERT, a new Dutch language model extending the RoBERTa architecture.
belabBERT is trained on a large Dutch corpus (+32 GB) of web crawled texts. We
applied belabBERT to the classification of psychiatric illnesses. First, we
evaluated the strength of text-based classification using belabBERT, and
compared the results to the existing RobBERT model. Then, we compared the
performance of belabBERT to audio classification for psychiatric disorders.
Finally, a brief exploration was performed, extending the framework to a hybrid
text- and audio-based classification. Our results show that belabBERT
outperformed the current best text classification network for Dutch, RobBERT.
belabBERT also outperformed classification based on audio alone."	ArXiv
1556	Neural Models for Offensive Language Detection	['Ehab Hamdy']	2021-05-30 13:02:45+00:00	http://arxiv.org/abs/2106.14609v1	"Offensive language detection is an ever-growing natural language processing
(NLP) application. This growth is mainly because of the widespread usage of
social networks, which becomes a mainstream channel for people to communicate,
work, and enjoy entertainment content. Many incidents of sharing aggressive and
offensive content negatively impacted society to a great extend. We believe
contributing to improving and comparing different machine learning models to
fight such harmful contents is an important and challenging goal for this
thesis. We targeted the problem of offensive language detection for building
efficient automated models for offensive language detection. With the recent
advancements of NLP models, specifically, the Transformer model, which tackled
many shortcomings of the standard seq-to-seq techniques. The BERT model has
shown state-of-the-art results on many NLP tasks. Although the literature still
exploring the reasons for the BERT achievements in the NLP field. Other
efficient variants have been developed to improve upon the standard BERT, such
as RoBERTa and ALBERT. Moreover, due to the multilingual nature of text on
social media that could affect the model decision on a given tween, it is
becoming essential to examine multilingual models such as XLM-RoBERTa trained
on 100 languages and how did it compare to unilingual models. The RoBERTa based
model proved to be the most capable model and achieved the highest F1 score for
the tasks. Another critical aspect of a well-rounded offensive language
detection system is the speed at which a model can be trained and make
inferences. In that respect, we have considered the model run-time and
fine-tuned the very efficient implementation of FastText called BlazingText
that achieved good results, which is much faster than BERT-based models."	ArXiv
1557	A Bytecode-based Approach for Smart Contract Classification	['Chaochen Shi', 'Yong Xiang', 'Robin Ram Mohan Doss', 'Jiangshan Yu', 'Keshav Sood', 'Longxiang Gao']	2021-05-31 03:00:29+00:00	http://arxiv.org/abs/2106.15497v1	"With the development of blockchain technologies, the number of smart
contracts deployed on blockchain platforms is growing exponentially, which
makes it difficult for users to find desired services by manual screening. The
automatic classification of smart contracts can provide blockchain users with
keyword-based contract searching and helps to manage smart contracts
effectively. Current research on smart contract classification focuses on
Natural Language Processing (NLP) solutions which are based on contract source
code. However, more than 94% of smart contracts are not open-source, so the
application scenarios of NLP methods are very limited. Meanwhile, NLP models
are vulnerable to adversarial attacks. This paper proposes a classification
model based on features from contract bytecode instead of source code to solve
these problems. We also use feature selection and ensemble learning to optimize
the model. Our experimental studies on over 3,300 real-world Ethereum smart
contracts show that our model can classify smart contracts without source code
and has better performance than baseline models. Our model also has good
resistance to adversarial attacks compared with NLP-based models. In addition,
our analysis reveals that account features used in many smart contract
classification models have little effect on classification and can be excluded."	ArXiv
1558	"Reusable Templates and Guides For Documenting Datasets and Models for
  Natural Language Processing and Generation: A Case Study of the HuggingFace
  and GEM Data and Model Cards"	['Angelina McMillan-Major', 'Salomey Osei', 'Juan Diego Rodriguez', 'Pawan Sasanka Ammanamanchi', 'Sebastian Gehrmann', 'Yacine Jernite']	2021-08-16 23:15:09+00:00	http://arxiv.org/abs/2108.07374v1	"Developing documentation guidelines and easy-to-use templates for datasets
and models is a challenging task, especially given the variety of backgrounds,
skills, and incentives of the people involved in the building of natural
language processing (NLP) tools. Nevertheless, the adoption of standard
documentation practices across the field of NLP promotes more accessible and
detailed descriptions of NLP datasets and models, while supporting researchers
and developers in reflecting on their work. To help with the standardization of
documentation, we present two case studies of efforts that aim to develop
reusable documentation templates -- the HuggingFace data card, a general
purpose card for datasets in NLP, and the GEM benchmark data and model cards
with a focus on natural language generation. We describe our process for
developing these templates, including the identification of relevant
stakeholder groups, the definition of a set of guiding principles, the use of
existing templates as our foundation, and iterative revisions based on
feedback."	ArXiv
1559	Deep learning models are not robust against noise in clinical text	['Milad Moradi', 'Kathrin Blagec', 'Matthias Samwald']	2021-08-27 12:47:19+00:00	http://arxiv.org/abs/2108.12242v1	"Artificial Intelligence (AI) systems are attracting increasing interest in
the medical domain due to their ability to learn complicated tasks that require
human intelligence and expert knowledge. AI systems that utilize
high-performance Natural Language Processing (NLP) models have achieved
state-of-the-art results on a wide variety of clinical text processing
benchmarks. They have even outperformed human accuracy on some tasks. However,
performance evaluation of such AI systems have been limited to accuracy
measures on curated and clean benchmark datasets that may not properly reflect
how robustly these systems can operate in real-world situations. In order to
address this challenge, we introduce and implement a wide variety of
perturbation methods that simulate different types of noise and variability in
clinical text data. While noisy samples produced by these perturbation methods
can often be understood by humans, they may cause AI systems to make erroneous
decisions. Conducting extensive experiments on several clinical text processing
tasks, we evaluated the robustness of high-performance NLP models against
various types of character-level and word-level noise. The results revealed
that the NLP models performance degrades when the input contains small amounts
of noise. This study is a significant step towards exposing vulnerabilities of
AI models utilized in clinical text processing systems. The proposed
perturbation methods can be used in performance evaluation tests to assess how
robustly clinical NLP models can operate on noisy data, in real-world settings."	ArXiv
1560	"Learning Energy-Based Approximate Inference Networks for Structured
  Applications in NLP"	['Lifu Tu']	2021-08-27 22:48:20+00:00	http://arxiv.org/abs/2108.12522v1	"Structured prediction in natural language processing (NLP) has a long
history. The complex models of structured application come at the difficulty of
learning and inference. These difficulties lead researchers to focus more on
models with simple structure components (e.g., local classifier). Deep
representation learning has become increasingly popular in recent years. The
structure components of their method, on the other hand, are usually relatively
simple. We concentrate on complex structured models in this dissertation. We
provide a learning framework for complicated structured models as well as an
inference method with a better speed/accuracy/search error trade-off. The
dissertation begins with a general introduction to energy-based models. In NLP
and other applications, an energy function is comparable to the concept of a
scoring function. In this dissertation, we discuss the concept of the energy
function and structured models with different energy functions. Then, we
propose a method in which we train a neural network to do argmax inference
under a structured energy function, referring to the trained networks as
""inference networks"" or ""energy-based inference networks"". We then develop ways
of jointly learning energy functions and inference networks using an
adversarial learning framework. Despite the inference and learning difficulties
of energy-based models, we present approaches in this thesis that enable
energy-based models more easily to be applied in structured NLP applications."	ArXiv
1561	Towards Efficient NLP: A Standard Evaluation and A Strong Baseline	['Xiangyang Liu', 'Tianxiang Sun', 'Junliang He', 'Jiawen Wu', 'Lingling Wu', 'Xinyu Zhang', 'Hao Jiang', 'Zhao Cao', 'Xuanjing Huang', 'Xipeng Qiu']	2021-10-13 21:17:15+00:00	http://arxiv.org/abs/2110.07038v2	"Supersized pre-trained language models have pushed the accuracy of various
natural language processing (NLP) tasks to a new state-of-the-art (SOTA).
Rather than pursuing the reachless SOTA accuracy, more and more researchers
start paying attention on model efficiency and usability. Different from
accuracy, the metric for efficiency varies across different studies, making
them hard to be fairly compared. To that end, this work presents ELUE
(Efficient Language Understanding Evaluation), a standard evaluation, and a
public leaderboard for efficient NLP models. ELUE is dedicated to depict the
Pareto Frontier for various language understanding tasks, such that it can tell
whether and how much a method achieves Pareto improvement. Along with the
benchmark, we also release a strong baseline, ElasticBERT, which allows BERT to
exit at any layer in both static and dynamic ways. We demonstrate the
ElasticBERT, despite its simplicity, outperforms or performs on par with SOTA
compressed and early exiting models. With ElasticBERT, the proposed ELUE has a
strong Pareto Frontier and makes a better evaluation for efficient NLP models."	ArXiv
1562	Exploring Universal Intrinsic Task Subspace via Prompt Tuning	['Yujia Qin', 'Xiaozhi Wang', 'Yusheng Su', 'Yankai Lin', 'Ning Ding', 'Jing Yi', 'Weize Chen', 'Zhiyuan Liu', 'Juanzi Li', 'Lei Hou', 'Peng Li', 'Maosong Sun', 'Jie Zhou']	2021-10-15 05:43:59+00:00	http://arxiv.org/abs/2110.07867v3	"Why can pre-trained language models (PLMs) learn universal representations
and effectively adapt to broad NLP tasks differing a lot superficially? In this
work, we empirically find evidence indicating that the adaptations of PLMs to
various few-shot tasks can be reparameterized as optimizing only a few free
parameters in a unified low-dimensional intrinsic task subspace, which may help
us understand why PLMs could easily adapt to various NLP tasks with small-scale
data. To find such a subspace and examine its universality, we propose an
analysis pipeline called intrinsic prompt tuning (IPT). Specifically, we resort
to the recent success of prompt tuning and decompose the soft prompts of
multiple NLP tasks into the same low-dimensional nonlinear subspace, then we
learn to adapt the PLM to unseen data or tasks by only tuning parameters in
this subspace. In the experiments, we study diverse few-shot NLP tasks and
surprisingly find that in a 250-dimensional subspace found with 100 tasks, by
only tuning 250 free parameters, we can recover 97% and 83% of the full prompt
tuning performance for 100 seen tasks (using different training data) and 20
unseen tasks, respectively, showing great generalization ability of the found
intrinsic task subspace. Besides being an analysis tool, IPT could further help
us improve the prompt tuning stability."	ArXiv
1563	Backdoor Pre-trained Models Can Transfer to All	['Lujia Shen', 'Shouling Ji', 'Xuhong Zhang', 'Jinfeng Li', 'Jing Chen', 'Jie Shi', 'Chengfang Fang', 'Jianwei Yin', 'Ting Wang']	2021-10-30 07:11:24+00:00	http://arxiv.org/abs/2111.00197v1	"Pre-trained general-purpose language models have been a dominating component
in enabling real-world natural language processing (NLP) applications. However,
a pre-trained model with backdoor can be a severe threat to the applications.
Most existing backdoor attacks in NLP are conducted in the fine-tuning phase by
introducing malicious triggers in the targeted class, thus relying greatly on
the prior knowledge of the fine-tuning task. In this paper, we propose a new
approach to map the inputs containing triggers directly to a predefined output
representation of the pre-trained NLP models, e.g., a predefined output
representation for the classification token in BERT, instead of a target label.
It can thus introduce backdoor to a wide range of downstream tasks without any
prior knowledge. Additionally, in light of the unique properties of triggers in
NLP, we propose two new metrics to measure the performance of backdoor attacks
in terms of both effectiveness and stealthiness. Our experiments with various
types of triggers show that our method is widely applicable to different
fine-tuning tasks (classification and named entity recognition) and to
different models (such as BERT, XLNet, BART), which poses a severe threat.
Furthermore, by collaborating with the popular online model repository Hugging
Face, the threat brought by our method has been confirmed. Finally, we analyze
the factors that may affect the attack performance and share insights on the
causes of the success of our backdoor attack."	ArXiv
1564	"A Prompting-based Approach for Adversarial Example Generation and
  Robustness Enhancement"	['Yuting Yang', 'Pei Huang', 'Juan Cao', 'Jintao Li', 'Yun Lin', 'Jin Song Dong', 'Feifei Ma', 'Jian Zhang']	2022-03-21 03:21:32+00:00	http://arxiv.org/abs/2203.10714v1	"Recent years have seen the wide application of NLP models in crucial areas
such as finance, medical treatment, and news media, raising concerns of the
model robustness and vulnerabilities. In this paper, we propose a novel
prompt-based adversarial attack to compromise NLP models and robustness
enhancement technique. We first construct malicious prompts for each instance
and generate adversarial examples via mask-and-filling under the effect of a
malicious purpose. Our attack technique targets the inherent vulnerabilities of
NLP models, allowing us to generate samples even without interacting with the
victim NLP model, as long as it is based on pre-trained language models (PLMs).
Furthermore, we design a prompt-based adversarial training method to improve
the robustness of PLMs. As our training method does not actually generate
adversarial samples, it can be applied to large-scale training sets
efficiently. The experimental results show that our attack method can achieve a
high attack success rate with more diverse, fluent and natural adversarial
examples. In addition, our robustness enhancement method can significantly
improve the robustness of models to resist adversarial attacks. Our work
indicates that prompting paradigm has great potential in probing some
fundamental flaws of PLMs and fine-tuning them for downstream tasks."	ArXiv
1565	"Checking HateCheck: a cross-functional analysis of behaviour-aware
  learning for hate speech detection"	['Pedro Henrique Luz de Araujo', 'Benjamin Roth']	2022-04-08 13:03:01+00:00	http://arxiv.org/abs/2204.04042v1	"Behavioural testing -- verifying system capabilities by validating
human-designed input-output pairs -- is an alternative evaluation method of
natural language processing systems proposed to address the shortcomings of the
standard approach: computing metrics on held-out data. While behavioural tests
capture human prior knowledge and insights, there has been little exploration
on how to leverage them for model training and development. With this in mind,
we explore behaviour-aware learning by examining several fine-tuning schemes
using HateCheck, a suite of functional tests for hate speech detection systems.
To address potential pitfalls of training on data originally intended for
evaluation, we train and evaluate models on different configurations of
HateCheck by holding out categories of test cases, which enables us to estimate
performance on potentially overlooked system properties. The fine-tuning
procedure led to improvements in the classification accuracy of held-out
functionalities and identity groups, suggesting that models can potentially
generalise to overlooked functionalities. However, performance on held-out
functionality classes and i.i.d. hate speech detection data decreased, which
indicates that generalisation occurs mostly across functionalities from the
same class and that the procedure led to overfitting to the HateCheck data
distribution."	ArXiv
1566	"Towards an Enhanced Understanding of Bias in Pre-trained Neural Language
  Models: A Survey with Special Emphasis on Affective Bias"	['Anoop K.', 'Manjary P. Gangan', 'Deepak P.', 'Lajish V. L']	2022-04-21 18:51:19+00:00	http://arxiv.org/abs/2204.10365v1	"The remarkable progress in Natural Language Processing (NLP) brought about by
deep learning, particularly with the recent advent of large pre-trained neural
language models, is brought into scrutiny as several studies began to discuss
and report potential biases in NLP applications. Bias in NLP is found to
originate from latent historical biases encoded by humans into textual data
which gets perpetuated or even amplified by NLP algorithm. We present a survey
to comprehend bias in large pre-trained language models, analyze the stages at
which they occur in these models, and various ways in which these biases could
be quantified and mitigated. Considering wide applicability of textual
affective computing based downstream tasks in real-world systems such as
business, healthcare, education, etc., we give a special emphasis on
investigating bias in the context of affect (emotion) i.e., Affective Bias, in
large pre-trained language models. We present a summary of various bias
evaluation corpora that help to aid future research and discuss challenges in
the research on bias in pre-trained language models. We believe that our
attempt to draw a comprehensive view of bias in pre-trained language models,
and especially the exploration of affective bias will be highly beneficial to
researchers interested in this evolving field."	ArXiv
1567	"Theories of ""Gender"" in NLP Bias Research"	['Hannah Devinney', 'Jenny Björklund', 'Henrik Björklund']	2022-05-05 09:20:53+00:00	http://arxiv.org/abs/2205.02526v1	"The rise of concern around Natural Language Processing (NLP) technologies
containing and perpetuating social biases has led to a rich and rapidly growing
area of research. Gender bias is one of the central biases being analyzed, but
to date there is no comprehensive analysis of how ""gender"" is theorized in the
field. We survey nearly 200 articles concerning gender bias in NLP to discover
how the field conceptualizes gender both explicitly (e.g. through definitions
of terms) and implicitly (e.g. through how gender is operationalized in
practice). In order to get a better idea of emerging trajectories of thought,
we split these articles into two sections by time.
  We find that the majority of the articles do not make their theorization of
gender explicit, even if they clearly define ""bias."" Almost none use a model of
gender that is intersectional or inclusive of nonbinary genders; and many
conflate sex characteristics, social gender, and linguistic gender in ways that
disregard the existence and experience of trans, nonbinary, and intersex
people. There is an increase between the two time-sections in statements
acknowledging that gender is a complicated reality, however, very few articles
manage to put this acknowledgment into practice. In addition to analyzing these
findings, we provide specific recommendations to facilitate interdisciplinary
work, and to incorporate theory and methodology from Gender Studies. Our hope
is that this will produce more inclusive gender bias research in NLP."	ArXiv
1568	"Interactive Model Cards: A Human-Centered Approach to Model
  Documentation"	['Anamaria Crisan', 'Margaret Drouhard', 'Jesse Vig', 'Nazneen Rajani']	2022-05-05 19:19:28+00:00	http://arxiv.org/abs/2205.02894v1	"Deep learning models for natural language processing (NLP) are increasingly
adopted and deployed by analysts without formal training in NLP or machine
learning (ML). However, the documentation intended to convey the model's
details and appropriate use is tailored primarily to individuals with ML or NLP
expertise. To address this gap, we conduct a design inquiry into interactive
model cards, which augment traditionally static model cards with affordances
for exploring model documentation and interacting with the models themselves.
Our investigation consists of an initial conceptual study with experts in ML,
NLP, and AI Ethics, followed by a separate evaluative study with non-expert
analysts who use ML models in their work. Using a semi-structured interview
format coupled with a think-aloud protocol, we collected feedback from a total
of 30 participants who engaged with different versions of standard and
interactive model cards. Through a thematic analysis of the collected data, we
identified several conceptual dimensions that summarize the strengths and
limitations of standard and interactive model cards, including: stakeholders;
design; guidance; understandability & interpretability; sensemaking &
skepticism; and trust & safety. Our findings demonstrate the importance of
carefully considered design and interactivity for orienting and supporting
non-expert analysts using deep learning models, along with a need for
consideration of broader sociotechnical contexts and organizational dynamics.
We have also identified design elements, such as language, visual cues, and
warnings, among others, that support interactivity and make non-interactive
content accessible. We summarize our findings as design guidelines and discuss
their implications for a human-centered approach towards AI/ML documentation."	ArXiv
1569	Towards Unified Prompt Tuning for Few-shot Text Classification	['Jianing Wang', 'Chengyu Wang', 'Fuli Luo', 'Chuanqi Tan', 'Minghui Qiu', 'Fei Yang', 'Qiuhui Shi', 'Songfang Huang', 'Ming Gao']	2022-05-11 07:40:45+00:00	http://arxiv.org/abs/2205.05313v1	"Prompt-based fine-tuning has boosted the performance of Pre-trained Language
Models (PLMs) on few-shot text classification by employing task-specific
prompts. Yet, PLMs are unfamiliar with prompt-style expressions during
pre-training, which limits the few-shot learning performance on downstream
tasks. It would be desirable if the models can acquire some prompting knowledge
before adaptation to specific NLP tasks. We present the Unified Prompt Tuning
(UPT) framework, leading to better few-shot text classification for BERT-style
models by explicitly capturing prompting semantics from non-target NLP
datasets. In UPT, a novel paradigm Prompt-Options-Verbalizer is proposed for
joint prompt learning across different NLP tasks, forcing PLMs to capture
task-invariant prompting knowledge. We further design a self-supervised task
named Knowledge-enhanced Selective Masked Language Modeling to improve the
PLM's generalization abilities for accurate adaptation to previously unseen
tasks. After multi-task learning across multiple tasks, the PLM can be better
prompt-tuned towards any dissimilar target tasks in low-resourced settings.
Experiments over a variety of NLP tasks show that UPT consistently outperforms
state-of-the-arts for prompt-based fine-tuning."	ArXiv
1570	reStructured Pre-training	['Weizhe Yuan', 'Pengfei Liu']	2022-06-22 14:49:24+00:00	http://arxiv.org/abs/2206.11147v2	"In this work, we try to decipher the internal connection of NLP technology
development in the past decades, searching for essence, which rewards us with a
(potential) new learning paradigm for NLP tasks, dubbed as reStructured
Pre-training (RST). In such a paradigm, the role of data will be re-emphasized,
and model pre-training and fine-tuning of downstream tasks are viewed as a
process of data storing and accessing. Based on that, we operationalize the
simple principle that a good storage mechanism should not only have the ability
to cache a large amount of data but also consider the ease of access. We
achieve this by pre-training models over restructured data that consist of a
variety of valuable information instead of raw data after overcoming several
engineering challenges. Experimentally, RST models not only surpass strong
competitors (e.g., T0) on 52/55 popular datasets from a variety of NLP tasks,
but also achieve superior performance in National College Entrance Examination
- English (Gaokao-English),the most authoritative examination in China.
Specifically, the proposed system Qin achieves 40 points higher than the
average scores made by students and 15 points higher than GPT3 with 1/16
parameters. In particular, Qin gets a high score of 138.5 (the full mark is
150) in the 2018 English exam (national paper III). We have released the Gaokao
Benchmark with an online submission platform.
  In addition, we test our model in the 2022 College Entrance Examination
English that happened a few days ago (2022.06.08), and it gets a total score of
134 (v.s. GPT3's 108)."	ArXiv
1571	How Do Multilingual Encoders Learn Cross-lingual Representation?	['Shijie Wu']	2022-07-12 17:57:05+00:00	http://arxiv.org/abs/2207.05737v1	"NLP systems typically require support for more than one language. As
different languages have different amounts of supervision, cross-lingual
transfer benefits languages with little to no training data by transferring
from other languages. From an engineering perspective, multilingual NLP
benefits development and maintenance by serving multiple languages with a
single system. Both cross-lingual transfer and multilingual NLP rely on
cross-lingual representations serving as the foundation. As BERT revolutionized
representation learning and NLP, it also revolutionized cross-lingual
representations and cross-lingual transfer. Multilingual BERT was released as a
replacement for single-language BERT, trained with Wikipedia data in 104
languages.
  Surprisingly, without any explicit cross-lingual signal, multilingual BERT
learns cross-lingual representations in addition to representations for
individual languages. This thesis first shows such surprising cross-lingual
effectiveness compared against prior art on various tasks. Naturally, it raises
a set of questions, most notably how do these multilingual encoders learn
cross-lingual representations. In exploring these questions, this thesis will
analyze the behavior of multilingual models in a variety of settings on high
and low resource languages. We also look at how to inject different
cross-lingual signals into multilingual encoders, and the optimization behavior
of cross-lingual transfer with these models. Together, they provide a better
understanding of multilingual encoders on cross-lingual transfer. Our findings
will lead us to suggested improvements to multilingual encoders and
cross-lingual transfer."	ArXiv
1572	Review of Natural Language Processing in Pharmacology	['Dimitar Trajanov', 'Vangel Trajkovski', 'Makedonka Dimitrieva', 'Jovana Dobreva', 'Milos Jovanovik', 'Matej Klemen', 'Aleš Žagar', 'Marko Robnik-Šikonja']	2022-08-22 12:10:27+00:00	http://arxiv.org/abs/2208.10228v2	"Natural language processing (NLP) is an area of artificial intelligence that
applies information technologies to process the human language, understand it
to a certain degree, and use it in various applications. This area has rapidly
developed in the last few years and now employs modern variants of deep neural
networks to extract relevant patterns from large text corpora. The main
objective of this work is to survey the recent use of NLP in the field of
pharmacology. As our work shows, NLP is a highly relevant information
extraction and processing approach for pharmacology. It has been used
extensively, from intelligent searches through thousands of medical documents
to finding traces of adversarial drug interactions in social media. We split
our coverage into five categories to survey modern NLP methodology, commonly
addressed tasks, relevant textual data, knowledge bases, and useful programming
libraries. We split each of the five categories into appropriate subcategories,
describe their main properties and ideas, and summarize them in a tabular form.
The resulting survey presents a comprehensive overview of the area, useful to
practitioners and interested observers."	ArXiv
1573	Drawing Causal Inferences About Performance Effects in NLP	['Sandra Wankmüller']	2022-09-14 17:18:21+00:00	http://arxiv.org/abs/2209.06790v1	"This article emphasizes that NLP as a science seeks to make inferences about
the performance effects that result from applying one method (compared to
another method) in the processing of natural language. Yet NLP research in
practice usually does not achieve this goal: In NLP research articles,
typically only a few models are compared. Each model results from a specific
procedural pipeline (here named processing system) that is composed of a
specific collection of methods that are used in preprocessing, pretraining,
hyperparameter tuning, and training on the target task. To make generalizing
inferences about the performance effect that is caused by applying some method
A vs. another method B, it is not sufficient to compare a few specific models
that are produced by a few specific (probably incomparable) processing systems.
Rather, the following procedure would allow drawing inferences about methods'
performance effects: (1) A population of processing systems that researchers
seek to infer to has to be defined. (2) A random sample of processing systems
from this population is drawn. (The drawn processing systems in the sample will
vary with regard to the methods they apply along their procedural pipelines and
also will vary regarding the compositions of their training and test data sets
used for training and evaluation.) (3) Each processing system is applied once
with method A and once with method B. (4) Based on the sample of applied
processing systems, the expected generalization errors of method A and method B
are approximated. (5) The difference between the expected generalization errors
of method A and method B is the estimated average treatment effect due to
applying method A compared to method B in the population of processing systems."	ArXiv
1574	"Searching for Carriers of the Diffuse Interstellar Bands Across
  Disciplines, using Natural Language Processing"	"[""Corentin van den Broek d'Obrenan"", 'Frédéric Galliano', 'Jeremy Minton', 'Viktor Botev', 'Ronin Wu']"	2022-11-15 21:16:59+00:00	http://arxiv.org/abs/2211.08513v2	"The explosion of scientific publications overloads researchers with
information. This is even more dramatic for interdisciplinary studies, where
several fields need to be explored. A tool to help researchers overcome this is
Natural Language Processing (NLP): a machine-learning (ML) technique that
allows scientists to automatically synthesize information from many articles.
As a practical example, we have used NLP to conduct an interdisciplinary search
for compounds that could be carriers for Diffuse Interstellar Bands (DIBs), a
long-standing open question in astrophysics. We have trained a NLP model on a
corpus of 1.5 million cross-domain articles in open access, and fine-tuned this
model with a corpus of astrophysical publications about DIBs. Our analysis
points us toward several molecules, studied primarily in biology, having
transitions at the wavelengths of several DIBs and composed of abundant
interstellar atoms. Several of these molecules contain chromophores, small
molecular groups responsible for the molecule's colour, that could be promising
candidate carriers. Identifying viable carriers demonstrates the value of using
NLP to tackle open scientific questions, in an interdisciplinary manner."	ArXiv
1575	Deanthropomorphising NLP: Can a Language Model Be Conscious?	['Matthew Shardlow', 'Piotr Przybyła']	2022-11-21 14:18:25+00:00	http://arxiv.org/abs/2211.11483v5	"This work is intended as a voice in the discussion over previous claims that
a pretrained large language model (LLM) based on the Transformer model
architecture can be sentient. Such claims have been made concerning the LaMDA
model and also concerning the current wave of LLM-powered chatbots, such as
ChatGPT. This claim, if confirmed, would have serious ramifications in the
Natural Language Processing (NLP) community due to wide-spread use of similar
models. However, here we take the position that such a large language model
cannot be sentient, or conscious, and that LaMDA in particular exhibits no
advances over other similar models that would qualify it. We justify this by
analysing the Transformer architecture through Integrated Information Theory of
consciousness. We see the claims of sentience as part of a wider tendency to
use anthropomorphic language in NLP reporting. Regardless of the veracity of
the claims, we consider this an opportune moment to take stock of progress in
language modelling and consider the ethical implications of the task. In order
to make this work helpful for readers outside the NLP community, we also
present the necessary background in language modelling."	ArXiv
1576	"Embedding generation for text classification of Brazilian Portuguese
  user reviews: from bag-of-words to transformers"	['Frederico Dias Souza', 'João Baptista de Oliveira e Souza Filho']	2022-12-01 15:24:19+00:00	http://arxiv.org/abs/2212.00587v1	"Text classification is a natural language processing (NLP) task relevant to
many commercial applications, like e-commerce and customer service. Naturally,
classifying such excerpts accurately often represents a challenge, due to
intrinsic language aspects, like irony and nuance. To accomplish this task, one
must provide a robust numerical representation for documents, a process known
as embedding. Embedding represents a key NLP field nowadays, having faced a
significant advance in the last decade, especially after the introduction of
the word-to-vector concept and the popularization of Deep Learning models for
solving NLP tasks, including Convolutional Neural Networks (CNNs), Recurrent
Neural Networks (RNNs), and Transformer-based Language Models (TLMs). Despite
the impressive achievements in this field, the literature coverage regarding
generating embeddings for Brazilian Portuguese texts is scarce, especially when
considering commercial user reviews. Therefore, this work aims to provide a
comprehensive experimental study of embedding approaches targeting a binary
sentiment classification of user reviews in Brazilian Portuguese. This study
includes from classical (Bag-of-Words) to state-of-the-art (Transformer-based)
NLP models. The methods are evaluated with five open-source databases with
pre-defined data partitions made available in an open digital repository to
encourage reproducibility. The Fine-tuned TLMs achieved the best results for
all cases, being followed by the Feature-based TLM, LSTM, and CNN, with
alternate ranks, depending on the database under analysis."	ArXiv
1577	"Mining Healthcare Procurement Data Using Text Mining and Natural
  Language Processing -- Reflection From An Industrial Project"	['Ziqi Zhang', 'Tomas Jasaitis', 'Richard Freeman', 'Rowida Alfrjani', 'Adam Funk']	2023-01-09 15:59:55+00:00	http://arxiv.org/abs/2301.03458v1	"While text mining and NLP research has been established for decades, there
remain gaps in the literature that reports the use of these techniques in
building real-world applications. For example, they typically look at single
and sometimes simplified tasks, and do not discuss in-depth data heterogeneity
and inconsistency that is common in real-world problems or their implication on
the development of their methods. Also, few prior work has focused on the
healthcare domain. In this work, we describe an industry project that developed
text mining and NLP solutions to mine millions of heterogeneous, multilingual
procurement documents in the healthcare sector. We extract structured
procurement contract data that is used to power a platform for dynamically
assessing supplier risks. Our work makes unique contributions in a number of
ways. First, we deal with highly heterogeneous, multilingual data and we
document our approach to tackle these challenges. This is mainly based on a
method that effectively uses domain knowledge and generalises to multiple text
mining and NLP tasks and languages. Second, applying this method to mine
millions of procurement documents, we develop the first structured procurement
contract database that will help facilitate the tendering process. Second,
Finally, we discuss lessons learned for practical text mining/NLP development,
and make recommendations for future research and practice."	ArXiv
1578	"Everyone's Voice Matters: Quantifying Annotation Disagreement Using
  Demographic Information"	['Ruyuan Wan', 'Jaehyung Kim', 'Dongyeop Kang']	2023-01-12 14:04:53+00:00	http://arxiv.org/abs/2301.05036v1	"In NLP annotation, it is common to have multiple annotators label the text
and then obtain the ground truth labels based on the agreement of major
annotators. However, annotators are individuals with different backgrounds, and
minors' opinions should not be simply ignored. As annotation tasks become
subjective and topics are controversial in modern NLP tasks, we need NLP
systems that can represent people's diverse voices on subjective matters and
predict the level of diversity. This paper examines whether the text of the
task and annotators' demographic background information can be used to estimate
the level of disagreement among annotators. Particularly, we extract
disagreement labels from the annotators' voting histories in the five
subjective datasets, and then fine-tune language models to predict annotators'
disagreement. Our results show that knowing annotators' demographic
information, like gender, ethnicity, and education level, helps predict
disagreements. In order to distinguish the disagreement from the inherent
controversy from text content and the disagreement in the annotators' different
perspectives, we simulate everyone's voices with different combinations of
annotators' artificial demographics and examine its variance of the finetuned
disagreement predictor. Our paper aims to improve the annotation process for
more efficient and inclusive NLP systems through a novel disagreement
prediction mechanism. Our code and dataset are publicly available."	ArXiv
1579	"Optimus-CC: Efficient Large NLP Model Training with 3D Parallelism Aware
  Communication Compression"	['Jaeyong Song', 'Jinkyu Yim', 'Jaewon Jung', 'Hongsun Jang', 'Hyung-Jin Kim', 'Youngsok Kim', 'Jinho Lee']	2023-01-24 06:07:55+00:00	http://arxiv.org/abs/2301.09830v1	"In training of modern large natural language processing (NLP) models, it has
become a common practice to split models using 3D parallelism to multiple GPUs.
Such technique, however, suffers from a high overhead of inter-node
communication. Compressing the communication is one way to mitigate the
overhead by reducing the inter-node traffic volume; however, the existing
compression techniques have critical limitations to be applied for NLP models
with 3D parallelism in that 1) only the data parallelism traffic is targeted,
and 2) the existing compression schemes already harm the model quality too
much.
  In this paper, we present Optimus-CC, a fast and scalable distributed
training framework for large NLP models with aggressive communication
compression. Optimus-CC differs from existing communication compression
frameworks in the following ways: First, we compress pipeline parallel
(inter-stage) traffic. In specific, we compress the inter-stage backpropagation
and the embedding synchronization in addition to the existing data-parallel
traffic compression methods. Second, we propose techniques to avoid the model
quality drop that comes from the compression. We further provide mathematical
and empirical analyses to show that our techniques can successfully suppress
the compression error. Lastly, we analyze the pipeline and opt to selectively
compress those traffic lying on the critical path. This further helps reduce
the compression error. We demonstrate our solution on a GPU cluster, and
achieve superior speedup from the baseline state-of-the-art solutions for
distributed training without sacrificing the model quality."	ArXiv
1580	"NLP-based Decision Support System for Examination of Eligibility
  Criteria from Securities Prospectuses at the German Central Bank"	['Christian Hänig', 'Markus Schlösser', 'Serhii Hamotskyi', 'Gent Zambaku', 'Janek Blankenburg']	2023-02-09 11:00:58+00:00	http://arxiv.org/abs/2302.04562v1	"As part of its digitization initiative, the German Central Bank (Deutsche
Bundesbank) wants to examine the extent to which natural Language Processing
(NLP) can be used to make independent decisions upon the eligibility criteria
of securities prospectuses. Every month, the Directorate General Markets at the
German Central Bank receives hundreds of scanned prospectuses in PDF format,
which must be manually processed to decide upon their eligibility. We found
that this tedious and time-consuming process can be (semi-)automated by
employing modern NLP model architectures, which learn the linguistic feature
representation in text to identify the present eligible and ineligible
criteria. The proposed Decision Support System provides decisions of
document-level eligibility criteria accompanied by human-understandable
explanations of the decisions. The aim of this project is to model the
described use case and to evaluate the extent to which current research results
from the field of NLP can be applied to this problem. After creating a
heterogeneous domain-specific dataset containing annotations of eligible and
non-eligible mentions of relevant criteria, we were able to successfully build,
train and deploy a semi-automatic decider model. This model is based on
transformer-based language models and decision trees, which integrate the
established rule-based parts of the decision processes. Results suggest that it
is possible to efficiently model the problem and automate decision making to
more than 90% for many of the considered eligibility criteria."	ArXiv
1581	TextDefense: Adversarial Text Detection based on Word Importance Entropy	['Lujia Shen', 'Xuhong Zhang', 'Shouling Ji', 'Yuwen Pu', 'Chunpeng Ge', 'Xing Yang', 'Yanghe Feng']	2023-02-12 11:12:44+00:00	http://arxiv.org/abs/2302.05892v1	"Currently, natural language processing (NLP) models are wildly used in
various scenarios. However, NLP models, like all deep models, are vulnerable to
adversarially generated text. Numerous works have been working on mitigating
the vulnerability from adversarial attacks. Nevertheless, there is no
comprehensive defense in existing works where each work targets a specific
attack category or suffers from the limitation of computation overhead,
irresistible to adaptive attack, etc.
  In this paper, we exhaustively investigate the adversarial attack algorithms
in NLP, and our empirical studies have discovered that the attack algorithms
mainly disrupt the importance distribution of words in a text. A well-trained
model can distinguish subtle importance distribution differences between clean
and adversarial texts. Based on this intuition, we propose TextDefense, a new
adversarial example detection framework that utilizes the target model's
capability to defend against adversarial attacks while requiring no prior
knowledge. TextDefense differs from previous approaches, where it utilizes the
target model for detection and thus is attack type agnostic. Our extensive
experiments show that TextDefense can be applied to different architectures,
datasets, and attack methods and outperforms existing methods. We also discover
that the leading factor influencing the performance of TextDefense is the
target model's generalizability. By analyzing the property of the target model
and the property of the adversarial example, we provide our insights into the
adversarial attacks in NLP and the principles of our defense method."	ArXiv
1582	"SanskritShala: A Neural Sanskrit NLP Toolkit with Web-Based Interface
  for Pedagogical and Annotation Purposes"	['Jivnesh Sandhan', 'Anshul Agarwal', 'Laxmidhar Behera', 'Tushar Sandhan', 'Pawan Goyal']	2023-02-19 09:58:55+00:00	http://arxiv.org/abs/2302.09527v2	"We present a neural Sanskrit Natural Language Processing (NLP) toolkit named
SanskritShala (a school of Sanskrit) to facilitate computational linguistic
analyses for several tasks such as word segmentation, morphological tagging,
dependency parsing, and compound type identification. Our systems currently
report state-of-the-art performance on available benchmark datasets for all
tasks. SanskritShala is deployed as a web-based application, which allows a
user to get real-time analysis for the given input. It is built with
easy-to-use interactive data annotation features that allow annotators to
correct the system predictions when it makes mistakes. We publicly release the
source codes of the 4 modules included in the toolkit, 7 word embedding models
that have been trained on publicly available Sanskrit corpora and multiple
annotated datasets such as word similarity, relatedness, categorization,
analogy prediction to assess intrinsic properties of word embeddings. So far as
we know, this is the first neural-based Sanskrit NLP toolkit that has a
web-based interface and a number of NLP modules. We are sure that the people
who are willing to work with Sanskrit will find it useful for pedagogical and
annotative purposes. SanskritShala is available at:
https://cnerg.iitkgp.ac.in/sanskritshala. The demo video of our platform can be
accessed at: https://youtu.be/x0X31Y9k0mw4."	ArXiv
1583	"Intergenerational Test Generation for Natural Language Processing
  Applications"	['Pin Ji', 'Yang Feng', 'Weitao Huang', 'Jia Liu', 'Zhihong Zhao']	2023-02-21 07:57:59+00:00	http://arxiv.org/abs/2302.10499v2	"The development of modern NLP applications often relies on various benchmark
datasets containing plenty of manually labeled tests to evaluate performance.
While constructing datasets often costs many resources, the performance on the
held-out data may not properly reflect their capability in real-world
application scenarios and thus cause tremendous misunderstanding and monetary
loss. To alleviate this problem, in this paper, we propose an automated test
generation method for detecting erroneous behaviors of various NLP
applications. Our method is designed based on the sentence parsing process of
classic linguistics, and thus it is capable of assembling basic grammatical
elements and adjuncts into a grammatically correct test with proper oracle
information. We implement this method into NLPLego, which is designed to fully
exploit the potential of seed sentences to automate the test generation.
NLPLego disassembles the seed sentence into the template and adjuncts and then
generates new sentences by assembling context-appropriate adjuncts with the
template in a specific order. Unlike the taskspecific methods, the tests
generated by NLPLego have derivation relations and different degrees of
variation, which makes constructing appropriate metamorphic relations easier.
Thus, NLPLego is general, meaning it can meet the testing requirements of
various NLP applications. To validate NLPLego, we experiment with three common
NLP tasks, identifying failures in four state-of-art models. Given seed tests
from SQuAD 2.0, SST, and QQP, NLPLego successfully detects 1,732, 5301, and
261,879 incorrect behaviors with around 95.7% precision in three tasks,
respectively."	ArXiv
1584	"Multi-resolution Interpretation and Diagnostics Tool for Natural
  Language Classifiers"	['Peyman Jalali', 'Nengfeng Zhou', 'Yufei Yu']	2023-03-06 22:59:02+00:00	http://arxiv.org/abs/2303.03542v1	"Developing explainability methods for Natural Language Processing (NLP)
models is a challenging task, for two main reasons. First, the high
dimensionality of the data (large number of tokens) results in low coverage and
in turn small contributions for the top tokens, compared to the overall model
performance. Second, owing to their textual nature, the input variables, after
appropriate transformations, are effectively binary (presence or absence of a
token in an observation), making the input-output relationship difficult to
understand. Common NLP interpretation techniques do not have flexibility in
resolution, because they usually operate at word-level and provide fully local
(message level) or fully global (over all messages) summaries. The goal of this
paper is to create more flexible model explainability summaries by segments of
observation or clusters of words that are semantically related to each other.
In addition, we introduce a root cause analysis method for NLP models, by
analyzing representative False Positive and False Negative examples from
different segments. At the end, we illustrate, using a Yelp review data set
with three segments (Restaurant, Hotel, and Beauty), that exploiting
group/cluster structures in words and/or messages can aid in the interpretation
of decisions made by NLP models and can be utilized to assess the model's
sensitivity or bias towards gender, syntax, and word meanings."	ArXiv
1585	"Student's t-Distribution: On Measuring the Inter-Rater Reliability When
  the Observations are Scarce"	['Serge Gladkoff', 'Lifeng Han', 'Goran Nenadic']	2023-03-08 11:51:26+00:00	http://arxiv.org/abs/2303.04526v2	"In natural language processing (NLP) we always rely on human judgement as the
golden quality evaluation method. However, there has been an ongoing debate on
how to better evaluate inter-rater reliability (IRR) levels for certain
evaluation tasks, such as translation quality evaluation (TQE), especially when
the data samples (observations) are very scarce. In this work, we first
introduce the study on how to estimate the confidence interval for the
measurement value when only one data (evaluation) point is available. Then,
this leads to our example with two human-generated observational scores, for
which, we introduce ``Student's \textit{t}-Distribution'' method and explain
how to use it to measure the IRR score using only these two data points, as
well as the confidence intervals (CIs) of the quality evaluation. We give
quantitative analysis on how the evaluation confidence can be greatly improved
by introducing more observations, even if only one extra observation. We
encourage researchers to report their IRR scores in all possible means, e.g.
using Student's \textit{t}-Distribution method whenever possible; thus making
the NLP evaluation more meaningful, transparent, and trustworthy. This
\textit{t}-Distribution method can be also used outside of NLP fields to
measure IRR level for trustworthy evaluation of experimental investigations,
whenever the observational data is scarce.
  Keywords: Inter-Rater Reliability (IRR); Scarce Observations; Confidence
Intervals (CIs); Natural Language Processing (NLP); Translation Quality
Evaluation (TQE); Student's \textit{t}-Distribution"	ArXiv
1586	Model-tuning Via Prompts Makes NLP Models Adversarially Robust	['Mrigank Raman', 'Pratyush Maini', 'J. Zico Kolter', 'Zachary C. Lipton', 'Danish Pruthi']	2023-03-13 17:41:57+00:00	http://arxiv.org/abs/2303.07320v2	"In recent years, NLP practitioners have converged on the following practice:
(i) import an off-the-shelf pretrained (masked) language model; (ii) append a
multilayer perceptron atop the CLS token's hidden representation (with randomly
initialized weights); and (iii) fine-tune the entire model on a downstream task
(MLP-FT). This procedure has produced massive gains on standard NLP benchmarks,
but these models remain brittle, even to mild adversarial perturbations. In
this work, we demonstrate surprising gains in adversarial robustness enjoyed by
Model-tuning Via Prompts (MVP), an alternative method of adapting to downstream
tasks. Rather than appending an MLP head to make output prediction, MVP appends
a prompt template to the input, and makes prediction via text
infilling/completion. Across 5 NLP datasets, 4 adversarial attacks, and 3
different models, MVP improves performance against adversarial substitutions by
an average of 8% over standard methods and even outperforms adversarial
training-based state-of-art defenses by 3.5%. By combining MVP with adversarial
training, we achieve further improvements in adversarial robustness while
maintaining performance on unperturbed examples. Finally, we conduct ablations
to investigate the mechanism underlying these gains. Notably, we find that the
main causes of vulnerability of MLP-FT can be attributed to the misalignment
between pre-training and fine-tuning tasks, and the randomly initialized MLP
parameters."	ArXiv
1587	"Progress Note Understanding -- Assessment and Plan Reasoning: Overview
  of the 2022 N2C2 Track 3 Shared Task"	['Yanjun Gao', 'Dmitriy Dligach', 'Timothy Miller', 'Matthew M Churpek', 'Ozlem Uzuner', 'Majid Afshar']	2023-03-14 16:17:55+00:00	http://arxiv.org/abs/2303.08038v1	"Daily progress notes are common types in the electronic health record (EHR)
where healthcare providers document the patient's daily progress and treatment
plans. The EHR is designed to document all the care provided to patients, but
it also enables note bloat with extraneous information that distracts from the
diagnoses and treatment plans. Applications of natural language processing
(NLP) in the EHR is a growing field with the majority of methods in information
extraction. Few tasks use NLP methods for downstream diagnostic decision
support. We introduced the 2022 National NLP Clinical Challenge (N2C2) Track 3:
Progress Note Understanding - Assessment and Plan Reasoning as one step towards
a new suite of tasks. The Assessment and Plan Reasoning task focuses on the
most critical components of progress notes, Assessment and Plan subsections
where health problems and diagnoses are contained. The goal of the task was to
develop and evaluate NLP systems that automatically predict causal relations
between the overall status of the patient contained in the Assessment section
and its relation to each component of the Plan section which contains the
diagnoses and treatment plans. The goal of the task was to identify and
prioritize diagnoses as the first steps in diagnostic decision support to find
the most relevant information in long documents like daily progress notes. We
present the results of 2022 n2c2 Track 3 and provide a description of the data,
evaluation, participation and system performance."	ArXiv
1588	"A Cross-institutional Evaluation on Breast Cancer Phenotyping NLP
  Algorithms on Electronic Health Records"	['Sicheng Zhou', 'Nan Wang', 'Liwei Wang', 'Ju Sun', 'Anne Blaes', 'Hongfang Liu', 'Rui Zhang']	2023-03-15 08:44:07+00:00	http://arxiv.org/abs/2303.08448v1	"Objective: The generalizability of clinical large language models is usually
ignored during the model development process. This study evaluated the
generalizability of BERT-based clinical NLP models across different clinical
settings through a breast cancer phenotype extraction task.
  Materials and Methods: Two clinical corpora of breast cancer patients were
collected from the electronic health records from the University of Minnesota
and the Mayo Clinic, and annotated following the same guideline. We developed
three types of NLP models (i.e., conditional random field, bi-directional long
short-term memory and CancerBERT) to extract cancer phenotypes from clinical
texts. The models were evaluated for their generalizability on different test
sets with different learning strategies (model transfer vs. locally trained).
The entity coverage score was assessed with their association with the model
performances.
  Results: We manually annotated 200 and 161 clinical documents at UMN and MC,
respectively. The corpora of the two institutes were found to have higher
similarity between the target entities than the overall corpora. The CancerBERT
models obtained the best performances among the independent test sets from two
clinical institutes and the permutation test set. The CancerBERT model
developed in one institute and further fine-tuned in another institute achieved
reasonable performance compared to the model developed on local data (micro-F1:
0.925 vs 0.932).
  Conclusions: The results indicate the CancerBERT model has the best learning
ability and generalizability among the three types of clinical NLP models. The
generalizability of the models was found to be correlated with the similarity
of the target entities between the corpora."	ArXiv
1589	"Energy-efficient Task Adaptation for NLP Edge Inference Leveraging
  Heterogeneous Memory Architectures"	['Zirui Fu', 'Aleksandre Avaliani', 'Marco Donato']	2023-03-25 14:40:59+00:00	http://arxiv.org/abs/2303.16100v2	"Executing machine learning inference tasks on resource-constrained edge
devices requires careful hardware-software co-design optimizations. Recent
examples have shown how transformer-based deep neural network models such as
ALBERT can be used to enable the execution of natural language processing (NLP)
inference on mobile systems-on-chip housing custom hardware accelerators.
However, while these existing solutions are effective in alleviating the
latency, energy, and area costs of running single NLP tasks, achieving
multi-task inference requires running computations over multiple variants of
the model parameters, which are tailored to each of the targeted tasks. This
approach leads to either prohibitive on-chip memory requirements or paying the
cost of off-chip memory access. This paper proposes adapter-ALBERT, an
efficient model optimization for maximal data reuse across different tasks. The
proposed model's performance and robustness to data compression methods are
evaluated across several language tasks from the GLUE benchmark. Additionally,
we demonstrate the advantage of mapping the model to a heterogeneous on-chip
memory architecture by performing simulations on a validated NLP edge
accelerator to extrapolate performance, power, and area improvements over the
execution of a traditional ALBERT model on the same hardware platform."	ArXiv
1590	"Socio-economic landscape of digital transformation & public NLP systems:
  A critical review"	['Satyam Mohla', 'Anupam Guha']	2023-04-04 09:17:58+00:00	http://arxiv.org/abs/2304.01651v2	"The current wave of digital transformation has spurred digitisation reforms
and has led to prodigious development of AI & NLP systems, with several of them
entering the public domain. There is a perception that these systems have a non
trivial impact on society but there is a dearth of literature in critical AI
exploring what kinds of systems exist and how do they operate. This paper
constructs a broad taxonomy of NLP systems which impact or are impacted by the
``public'' and provides a concrete analyses via various instrumental and
normative lenses on the socio-technical nature of these systems. This paper
categorises thirty examples of these systems into seven families, namely;
finance, customer service, policy making, education, healthcare, law, and
security, based on their public use cases. It then critically analyses these
applications, first the priors and assumptions they are based on, then their
mechanisms, possible methods of data collection, the models and error functions
used, etc. This paper further delves into exploring the socio-economic and
political contexts in which these families of systems are generally used and
their potential impact on the same, and the function creep of these systems. It
provides commentary on the potential long-term downstream impact of these
systems on communities which use them. Aside from providing a birds eye view of
what exists our in depth analysis provides insights on what is lacking in the
current discourse on NLP in particular and critical AI in general, proposes
additions to the current framework of analysis, provides recommendations future
research direction, and highlights the need to importance of exploring the
social in this socio-technical system."	ArXiv
1591	"Glot500: Scaling Multilingual Corpora and Language Models to 500
  Languages"	['Ayyoob Imani', 'Peiqin Lin', 'Amir Hossein Kargaran', 'Silvia Severini', 'Masoud Jalili Sabet', 'Nora Kassner', 'Chunlan Ma', 'Helmut Schmid', 'André F. T. Martins', 'François Yvon', 'Hinrich Schütze']	2023-05-20 12:26:41+00:00	http://arxiv.org/abs/2305.12182v2	"The NLP community has mainly focused on scaling Large Language Models (LLMs)
vertically, i.e., making them better for about 100 languages. We instead scale
LLMs horizontally: we create, through continued pretraining, Glot500-m, an LLM
that covers 511 predominantly low-resource languages. An important part of this
effort is to collect and clean Glot500-c, a corpus that covers these 511
languages and allows us to train Glot500-m. We evaluate Glot500-m on five
diverse tasks across these languages. We observe large improvements for both
high-resource and low-resource languages compared to an XLM-R baseline. Our
analysis shows that no single factor explains the quality of multilingual LLM
representations. Rather, a combination of factors determines quality including
corpus size, script, ""help"" from related languages and the total capacity of
the model. Our work addresses an important goal of NLP research: we should not
limit NLP to a small fraction of the world's languages and instead strive to
support as many languages as possible to bring the benefits of NLP technology
to all languages and cultures. Code, data and models are available at
https://github.com/cisnlp/Glot500."	ArXiv
1592	A Survey of Diffusion Models in Natural Language Processing	['Hao Zou', 'Zae Myung Kim', 'Dongyeop Kang']	2023-05-24 03:25:32+00:00	http://arxiv.org/abs/2305.14671v2	"This survey paper provides a comprehensive review of the use of diffusion
models in natural language processing (NLP). Diffusion models are a class of
mathematical models that aim to capture the diffusion of information or signals
across a network or manifold. In NLP, diffusion models have been used in a
variety of applications, such as natural language generation, sentiment
analysis, topic modeling, and machine translation. This paper discusses the
different formulations of diffusion models used in NLP, their strengths and
limitations, and their applications. We also perform a thorough comparison
between diffusion models and alternative generative models, specifically
highlighting the autoregressive (AR) models, while also examining how diverse
architectures incorporate the Transformer in conjunction with diffusion models.
Compared to AR models, diffusion models have significant advantages for
parallel generation, text interpolation, token-level controls such as syntactic
structures and semantic contents, and robustness. Exploring further
permutations of integrating Transformers into diffusion models would be a
valuable pursuit. Also, the development of multimodal diffusion models and
large-scale diffusion language models with notable capabilities for few-shot
learning would be important directions for the future advance of diffusion
models in NLP."	ArXiv
1593	Reproducibility in NLP: What Have We Learned from the Checklist?	['Ian Magnusson', 'Noah A. Smith', 'Jesse Dodge']	2023-06-16 00:39:25+00:00	http://arxiv.org/abs/2306.09562v1	"Scientific progress in NLP rests on the reproducibility of researchers'
claims. The *CL conferences created the NLP Reproducibility Checklist in 2020
to be completed by authors at submission to remind them of key information to
include. We provide the first analysis of the Checklist by examining 10,405
anonymous responses to it. First, we find evidence of an increase in reporting
of information on efficiency, validation performance, summary statistics, and
hyperparameters after the Checklist's introduction. Further, we show acceptance
rate grows for submissions with more Yes responses. We find that the 44% of
submissions that gather new data are 5% less likely to be accepted than those
that did not; the average reviewer-rated reproducibility of these submissions
is also 2% lower relative to the rest. We find that only 46% of submissions
claim to open-source their code, though submissions that do have 8% higher
reproducibility score relative to those that do not, the most for any item. We
discuss what can be inferred about the state of reproducibility in NLP, and
provide a set of recommendations for future conferences, including: a) allowing
submitting code and appendices one week after the deadline, and b) measuring
dataset reproducibility by a checklist of data collection practices."	ArXiv
1594	"Natural Language Processing in Electronic Health Records in Relation to
  Healthcare Decision-making: A Systematic Review"	['Elias Hossain', 'Rajib Rana', 'Niall Higgins', 'Jeffrey Soar', 'Prabal Datta Barua', 'Anthony R. Pisani', 'Ph. D', 'Kathryn Turner}']	2023-06-22 12:10:41+00:00	http://arxiv.org/abs/2306.12834v1	"Background: Natural Language Processing (NLP) is widely used to extract
clinical insights from Electronic Health Records (EHRs). However, the lack of
annotated data, automated tools, and other challenges hinder the full
utilisation of NLP for EHRs. Various Machine Learning (ML), Deep Learning (DL)
and NLP techniques are studied and compared to understand the limitations and
opportunities in this space comprehensively.
  Methodology: After screening 261 articles from 11 databases, we included 127
papers for full-text review covering seven categories of articles: 1) medical
note classification, 2) clinical entity recognition, 3) text summarisation, 4)
deep learning (DL) and transfer learning architecture, 5) information
extraction, 6) Medical language translation and 7) other NLP applications. This
study follows the Preferred Reporting Items for Systematic Reviews and
Meta-Analyses (PRISMA) guidelines.
  Result and Discussion: EHR was the most commonly used data type among the
selected articles, and the datasets were primarily unstructured. Various ML and
DL methods were used, with prediction or classification being the most common
application of ML or DL. The most common use cases were: the International
Classification of Diseases, Ninth Revision (ICD-9) classification, clinical
note analysis, and named entity recognition (NER) for clinical descriptions and
research on psychiatric disorders.
  Conclusion: We find that the adopted ML models were not adequately assessed.
In addition, the data imbalance problem is quite important, yet we must find
techniques to address this underlining problem. Future studies should address
key limitations in studies, primarily identifying Lupus Nephritis, Suicide
Attempts, perinatal self-harmed and ICD-9 classification."	ArXiv
1595	"Generative User-Experience Research for Developing Domain-specific
  Natural Language Processing Applications"	['Anastasia Zhukova', 'Lukas von Sperl', 'Christian E. Matt', 'Bela Gipp']	2023-06-28 12:17:45+00:00	http://arxiv.org/abs/2306.16143v5	"User experience (UX) is a part of human-computer interaction (HCI) research
and focuses on increasing intuitiveness, transparency, simplicity, and trust
for the system users. Most UX research for machine learning (ML) or natural
language processing (NLP) focuses on a data-driven methodology. It engages
domain users mainly for usability evaluation. Moreover, more typical UX methods
tailor the systems towards user usability, unlike learning about the user needs
first. This paper proposes a new methodology for integrating generative UX
research into developing domain NLP applications. Generative UX research
employs domain users at the initial stages of prototype development, i.e.,
ideation and concept evaluation, and the last stage for evaluating system
usefulness and user utility. The methodology emerged from and is evaluated on a
case study about the full-cycle prototype development of a domain-specific
semantic search for daily operations in the process industry. A key finding of
our case study is that involving domain experts increases their interest and
trust in the final NLP application. The combined UX+NLP research of the
proposed method efficiently considers data- and user-driven opportunities and
constraints, which can be crucial for developing NLP applications."	ArXiv
1596	"Investigating ChatGPT's Potential to Assist in Requirements Elicitation
  Processes"	['Krishna Ronanki', 'Christian Berger', 'Jennifer Horkoff']	2023-07-14 14:45:36+00:00	http://arxiv.org/abs/2307.07381v1	"Natural Language Processing (NLP) for Requirements Engineering (RE) (NLP4RE)
seeks to apply NLP tools, techniques, and resources to the RE process to
increase the quality of the requirements. There is little research involving
the utilization of Generative AI-based NLP tools and techniques for
requirements elicitation. In recent times, Large Language Models (LLM) like
ChatGPT have gained significant recognition due to their notably improved
performance in NLP tasks. To explore the potential of ChatGPT to assist in
requirements elicitation processes, we formulated six questions to elicit
requirements using ChatGPT. Using the same six questions, we conducted
interview-based surveys with five RE experts from academia and industry and
collected 30 responses containing requirements. The quality of these 36
responses (human-formulated + ChatGPT-generated) was evaluated over seven
different requirements quality attributes by another five RE experts through a
second round of interview-based surveys. In comparing the quality of
requirements generated by ChatGPT with those formulated by human experts, we
found that ChatGPT-generated requirements are highly Abstract, Atomic,
Consistent, Correct, and Understandable. Based on these results, we present the
most pressing issues related to LLMs and what future research should focus on
to leverage the emergent behaviour of LLMs more effectively in natural
language-based RE activities."	ArXiv
1597	"Lessons in Reproducibility: Insights from NLP Studies in Materials
  Science"	['Xiangyun Lei', 'Edward Kim', 'Viktoriia Baibakova', 'Shijing Sun']	2023-07-28 18:36:42+00:00	http://arxiv.org/abs/2307.15759v1	"Natural Language Processing (NLP), a cornerstone field within artificial
intelligence, has been increasingly utilized in the field of materials science
literature. Our study conducts a reproducibility analysis of two pioneering
works within this domain: ""Machine-learned and codified synthesis parameters of
oxide materials"" by Kim et al., and ""Unsupervised word embeddings capture
latent knowledge from materials science literature"" by Tshitoyan et al. We aim
to comprehend these studies from a reproducibility perspective, acknowledging
their significant influence on the field of materials informatics, rather than
critiquing them. Our study indicates that both papers offered thorough
workflows, tidy and well-documented codebases, and clear guidance for model
evaluation. This makes it easier to replicate their results successfully and
partially reproduce their findings. In doing so, they set commendable standards
for future materials science publications to aspire to. However, our analysis
also highlights areas for improvement such as to provide access to training
data where copyright restrictions permit, more transparency on model
architecture and the training process, and specifications of software
dependency versions. We also cross-compare the word embedding models between
papers, and find that some key differences in reproducibility and
cross-compatibility are attributable to design choices outside the bounds of
the models themselves. In summary, our study appreciates the benchmark set by
these seminal papers while advocating for further enhancements in research
reproducibility practices in the field of NLP for materials science. This
balance of understanding and continuous improvement will ultimately propel the
intersecting domains of NLP and materials science literature into a future of
exciting discoveries."	ArXiv
1598	"Challenges and Opportunities of Using Transformer-Based Multi-Task
  Learning in NLP Through ML Lifecycle: A Survey"	['Lovre Torbarina', 'Tin Ferkovic', 'Lukasz Roguski', 'Velimir Mihelcic', 'Bruno Sarlija', 'Zeljko Kraljevic']	2023-08-16 09:11:00+00:00	http://arxiv.org/abs/2308.08234v1	"The increasing adoption of natural language processing (NLP) models across
industries has led to practitioners' need for machine learning systems to
handle these models efficiently, from training to serving them in production.
However, training, deploying, and updating multiple models can be complex,
costly, and time-consuming, mainly when using transformer-based pre-trained
language models. Multi-Task Learning (MTL) has emerged as a promising approach
to improve efficiency and performance through joint training, rather than
training separate models. Motivated by this, we first provide an overview of
transformer-based MTL approaches in NLP. Then, we discuss the challenges and
opportunities of using MTL approaches throughout typical ML lifecycle phases,
specifically focusing on the challenges related to data engineering, model
development, deployment, and monitoring phases. This survey focuses on
transformer-based MTL architectures and, to the best of our knowledge, is novel
in that it systematically analyses how transformer-based MTL in NLP fits into
ML lifecycle phases. Furthermore, we motivate research on the connection
between MTL and continual learning (CL), as this area remains unexplored. We
believe it would be practical to have a model that can handle both MTL and CL,
as this would make it easier to periodically re-train the model, update it due
to distribution shifts, and add new capabilities to meet real-world
requirements."	ArXiv
1599	"Linguistically-Informed Neural Architectures for Lexical, Syntactic and
  Semantic Tasks in Sanskrit"	['Jivnesh Sandhan']	2023-08-17 06:33:33+00:00	http://arxiv.org/abs/2308.08807v1	"The primary focus of this thesis is to make Sanskrit manuscripts more
accessible to the end-users through natural language technologies. The
morphological richness, compounding, free word orderliness, and low-resource
nature of Sanskrit pose significant challenges for developing deep learning
solutions. We identify four fundamental tasks, which are crucial for developing
a robust NLP technology for Sanskrit: word segmentation, dependency parsing,
compound type identification, and poetry analysis. The first task, Sanskrit
Word Segmentation (SWS), is a fundamental text processing task for any other
downstream applications. However, it is challenging due to the sandhi
phenomenon that modifies characters at word boundaries. Similarly, the existing
dependency parsing approaches struggle with morphologically rich and
low-resource languages like Sanskrit. Compound type identification is also
challenging for Sanskrit due to the context-sensitive semantic relation between
components. All these challenges result in sub-optimal performance in NLP
applications like question answering and machine translation. Finally, Sanskrit
poetry has not been extensively studied in computational linguistics.
  While addressing these challenges, this thesis makes various contributions:
(1) The thesis proposes linguistically-informed neural architectures for these
tasks. (2) We showcase the interpretability and multilingual extension of the
proposed systems. (3) Our proposed systems report state-of-the-art performance.
(4) Finally, we present a neural toolkit named SanskritShala, a web-based
application that provides real-time analysis of input for various NLP tasks.
Overall, this thesis contributes to making Sanskrit manuscripts more accessible
by developing robust NLP technology and releasing various resources, datasets,
and web-based toolkit."	ArXiv
1600	LEAP: Efficient and Automated Test Method for NLP Software	['Mingxuan Xiao', 'Yan Xiao', 'Hai Dong', 'Shunhui Ji', 'Pengcheng Zhang']	2023-08-22 08:51:10+00:00	http://arxiv.org/abs/2308.11284v1	"The widespread adoption of DNNs in NLP software has highlighted the need for
robustness. Researchers proposed various automatic testing techniques for
adversarial test cases. However, existing methods suffer from two limitations:
weak error-discovering capabilities, with success rates ranging from 0% to
24.6% for BERT-based NLP software, and time inefficiency, taking 177.8s to
205.28s per test case, making them challenging for time-constrained scenarios.
To address these issues, this paper proposes LEAP, an automated test method
that uses LEvy flight-based Adaptive Particle swarm optimization integrated
with textual features to generate adversarial test cases. Specifically, we
adopt Levy flight for population initialization to increase the diversity of
generated test cases. We also design an inertial weight adaptive update
operator to improve the efficiency of LEAP's global optimization of
high-dimensional text examples and a mutation operator based on the greedy
strategy to reduce the search time. We conducted a series of experiments to
validate LEAP's ability to test NLP software and found that the average success
rate of LEAP in generating adversarial test cases is 79.1%, which is 6.1%
higher than the next best approach (PSOattack). While ensuring high success
rates, LEAP significantly reduces time overhead by up to 147.6s compared to
other heuristic-based methods. Additionally, the experimental results
demonstrate that LEAP can generate more transferable test cases and
significantly enhance the robustness of DNN-based systems."	ArXiv
1601	When Do Discourse Markers Affect Computational Sentence Understanding?	['Ruiqi Li', 'Liesbeth Allein', 'Damien Sileo', 'Marie-Francine Moens']	2023-09-01 09:54:28+00:00	http://arxiv.org/abs/2309.00368v1	"The capabilities and use cases of automatic natural language processing (NLP)
have grown significantly over the last few years. While much work has been
devoted to understanding how humans deal with discourse connectives, this
phenomenon is understudied in computational systems. Therefore, it is important
to put NLP models under the microscope and examine whether they can adequately
comprehend, process, and reason within the complexity of natural language. In
this chapter, we introduce the main mechanisms behind automatic sentence
processing systems step by step and then focus on evaluating discourse
connective processing. We assess nine popular systems in their ability to
understand English discourse connectives and analyze how context and language
understanding tasks affect their connective comprehension. The results show
that NLP systems do not process all discourse connectives equally well and that
the computational processing complexity of different connective kinds is not
always consistently in line with the presumed complexity order found in human
processing. In addition, while humans are more inclined to be influenced during
the reading procedure but not necessarily in the final comprehension
performance, discourse connectives have a significant impact on the final
accuracy of NLP systems. The richer knowledge of connectives a system learns,
the more negative effect inappropriate connectives have on it. This suggests
that the correct explicitation of discourse connectives is important for
computational natural language processing."	ArXiv
1602	"Not Enough Labeled Data? Just Add Semantics: A Data-Efficient Method for
  Inferring Online Health Texts"	['Joseph Gatto', 'Sarah M. Preum']	2023-09-18 15:37:30+00:00	http://arxiv.org/abs/2309.09877v1	"User-generated texts available on the web and social platforms are often long
and semantically challenging, making them difficult to annotate. Obtaining
human annotation becomes increasingly difficult as problem domains become more
specialized. For example, many health NLP problems require domain experts to be
a part of the annotation pipeline. Thus, it is crucial that we develop
low-resource NLP solutions able to work with this set of limited-data problems.
In this study, we employ Abstract Meaning Representation (AMR) graphs as a
means to model low-resource Health NLP tasks sourced from various online health
resources and communities. AMRs are well suited to model online health texts as
they can represent multi-sentence inputs, abstract away from complex
terminology, and model long-distance relationships between co-referring tokens.
AMRs thus improve the ability of pre-trained language models to reason about
high-complexity texts. Our experiments show that we can improve performance on
6 low-resource health NLP tasks by augmenting text embeddings with semantic
graph embeddings. Our approach is task agnostic and easy to merge into any
standard text classification pipeline. We experimentally validate that AMRs are
useful in the modeling of complex texts by analyzing performance through the
lens of two textual complexity measures: the Flesch Kincaid Reading Level and
Syntactic Complexity. Our error analysis shows that AMR-infused language models
perform better on complex texts and generally show less predictive variance in
the presence of changing complexity."	ArXiv
1603	"BenLLMEval: A Comprehensive Evaluation into the Potentials and Pitfalls
  of Large Language Models on Bengali NLP"	['Mohsinul Kabir', 'Mohammed Saidul Islam', 'Md Tahmid Rahman Laskar', 'Mir Tafseer Nayeem', 'M Saiful Bari', 'Enamul Hoque']	2023-09-22 20:29:34+00:00	http://arxiv.org/abs/2309.13173v2	"Large Language Models (LLMs) have emerged as one of the most important
breakthroughs in NLP for their impressive skills in language generation and
other language-specific tasks. Though LLMs have been evaluated in various
tasks, mostly in English, they have not yet undergone thorough evaluation in
under-resourced languages such as Bengali (Bangla). To this end, this paper
introduces BenLLM-Eval, which consists of a comprehensive evaluation of LLMs to
benchmark their performance in the Bengali language that has modest resources.
In this regard, we select various important and diverse Bengali NLP tasks, such
as text summarization, question answering, paraphrasing, natural language
inference, transliteration, text classification, and sentiment analysis for
zero-shot evaluation of popular LLMs, namely, GPT-3.5, LLaMA-2-13b-chat, and
Claude-2. Our experimental results demonstrate that while in some Bengali NLP
tasks, zero-shot LLMs could achieve performance on par, or even better than
current SOTA fine-tuned models; in most tasks, their performance is quite poor
(with the performance of open-source LLMs like LLaMA-2-13b-chat being
significantly bad) in comparison to the current SOTA results. Therefore, it
calls for further efforts to develop a better understanding of LLMs in
modest-resourced languages like Bengali."	ArXiv
1604	"Antarlekhaka: A Comprehensive Tool for Multi-task Natural Language
  Annotation"	['Hrishikesh Terdalkar', 'Arnab Bhattacharya']	2023-10-11 19:09:07+00:00	http://arxiv.org/abs/2310.07826v1	"One of the primary obstacles in the advancement of Natural Language
Processing (NLP) technologies for low-resource languages is the lack of
annotated datasets for training and testing machine learning models. In this
paper, we present Antarlekhaka, a tool for manual annotation of a comprehensive
set of tasks relevant to NLP. The tool is Unicode-compatible,
language-agnostic, Web-deployable and supports distributed annotation by
multiple simultaneous annotators. The system sports user-friendly interfaces
for 8 categories of annotation tasks. These, in turn, enable the annotation of
a considerably larger set of NLP tasks. The task categories include two
linguistic tasks not handled by any other tool, namely, sentence boundary
detection and deciding canonical word order, which are important tasks for text
that is in the form of poetry. We propose the idea of sequential annotation
based on small text units, where an annotator performs several tasks related to
a single text unit before proceeding to the next unit. The research
applications of the proposed mode of multi-task annotation are also discussed.
Antarlekhaka outperforms other annotation tools in objective evaluation. It has
been also used for two real-life annotation tasks on two different languages,
namely, Sanskrit and Bengali. The tool is available at
https://github.com/Antarlekhaka/code."	ArXiv
1605	"Explainable Identification of Hate Speech towards Islam using Graph
  Neural Networks"	['Azmine Toushik Wasi']	2023-11-02 04:01:04+00:00	http://arxiv.org/abs/2311.04916v4	"Islamophobic language on online platforms fosters intolerance, making
detection and elimination crucial for promoting harmony. Traditional hate
speech detection models rely on NLP techniques like tokenization,
part-of-speech tagging, and encoder-decoder models. However, Graph Neural
Networks (GNNs), with their ability to utilize relationships between data
points, offer more effective detection and greater explainability. In this
work, we represent speeches as nodes and connect them with edges based on their
context and similarity to develop the graph. This study introduces a novel
paradigm using GNNs to identify and explain hate speech towards Islam. Our
model leverages GNNs to understand the context and patterns of hate speech by
connecting texts via pretrained NLP-generated word embeddings, achieving
state-of-the-art performance and enhancing detection accuracy while providing
valuable explanations. This highlights the potential of GNNs in combating
online hate speech and fostering a safer, more inclusive online environment."	ArXiv
1606	"TARGET: Template-Transferable Backdoor Attack Against Prompt-based NLP
  Models via GPT4"	['Zihao Tan', 'Qingliang Chen', 'Yongjian Huang', 'Chen Liang']	2023-11-29 08:12:09+00:00	http://arxiv.org/abs/2311.17429v1	"Prompt-based learning has been widely applied in many low-resource NLP tasks
such as few-shot scenarios. However, this paradigm has been shown to be
vulnerable to backdoor attacks. Most of the existing attack methods focus on
inserting manually predefined templates as triggers in the pre-training phase
to train the victim model and utilize the same triggers in the downstream task
to perform inference, which tends to ignore the transferability and
stealthiness of the templates. In this work, we propose a novel approach of
TARGET (Template-trAnsfeRable backdoor attack aGainst prompt-basEd NLP models
via GPT4), which is a data-independent attack method. Specifically, we first
utilize GPT4 to reformulate manual templates to generate tone-strong and normal
templates, and the former are injected into the model as a backdoor trigger in
the pre-training phase. Then, we not only directly employ the above templates
in the downstream task, but also use GPT4 to generate templates with similar
tone to the above templates to carry out transferable attacks. Finally we have
conducted extensive experiments on five NLP datasets and three BERT series
models, with experimental results justifying that our TARGET method has better
attack performance and stealthiness compared to the two-external baseline
methods on direct attacks, and in addition achieves satisfactory attack
capability in the unseen tone-similar templates."	ArXiv
1607	"NLLG Quarterly arXiv Report 09/23: What are the most influential current
  AI Papers?"	['Ran Zhang', 'Aida Kostikova', 'Christoph Leiter', 'Jonas Belouadi', 'Daniil Larionov', 'Yanran Chen', 'Vivian Fresen', 'Steffen Eger']	2023-12-09 21:42:20+00:00	http://arxiv.org/abs/2312.05688v1	"Artificial Intelligence (AI) has witnessed rapid growth, especially in the
subfields Natural Language Processing (NLP), Machine Learning (ML) and Computer
Vision (CV). Keeping pace with this rapid progress poses a considerable
challenge for researchers and professionals in the field. In this arXiv report,
the second of its kind, which covers the period from January to September 2023,
we aim to provide insights and analysis that help navigate these dynamic areas
of AI. We accomplish this by 1) identifying the top-40 most cited papers from
arXiv in the given period, comparing the current top-40 papers to the previous
report, which covered the period January to June; 2) analyzing dataset
characteristics and keyword popularity; 3) examining the global sectoral
distribution of institutions to reveal differences in engagement across
geographical areas. Our findings highlight the continued dominance of NLP:
while only 16% of all submitted papers have NLP as primary category (more than
25% have CV and ML as primary category), 50% of the most cited papers have NLP
as primary category, 90% of which target LLMs. Additionally, we show that i)
the US dominates among both top-40 and top-9k papers, followed by China; ii)
Europe clearly lags behind and is hardly represented in the top-40 most cited
papers; iii) US industry is largely overrepresented in the top-40 most
influential papers."	ArXiv
1608	"Generative Large Language Models Are All-purpose Text Analytics Engines:
  Text-to-text Learning Is All Your Need"	['Cheng Peng', 'Xi Yang', 'Aokun Chen', 'Zehao Yu', 'Kaleb E Smith', 'Anthony B Costa', 'Mona G Flores', 'Jiang Bian', 'Yonghui Wu']	2023-12-11 04:00:26+00:00	http://arxiv.org/abs/2312.06099v1	"Objective To solve major clinical natural language processing (NLP) tasks
using a unified text-to-text learning architecture based on a generative large
language model (LLM) via prompt tuning. Methods We formulated 7 key clinical
NLP tasks as text-to-text learning and solved them using one unified generative
clinical LLM, GatorTronGPT, developed using GPT-3 architecture and trained with
up to 20 billion parameters. We adopted soft prompts (i.e., trainable vectors)
with frozen LLM, where the LLM parameters were not updated (i.e., frozen) and
only the vectors of soft prompts were updated, known as prompt tuning. We added
additional soft prompts as a prefix to the input layer, which were optimized
during the prompt tuning. We evaluated the proposed method using 7 clinical NLP
tasks and compared them with previous task-specific solutions based on
Transformer models. Results and Conclusion The proposed approach achieved
state-of-the-art performance for 5 out of 7 major clinical NLP tasks using one
unified generative LLM. Our approach outperformed previous task-specific
transformer models by ~3% for concept extraction and 7% for relation extraction
applied to social determinants of health, 3.4% for clinical concept
normalization, 3.4~10% for clinical abbreviation disambiguation, and 5.5~9% for
natural language inference. Our approach also outperformed a previously
developed prompt-based machine reading comprehension (MRC) model,
GatorTron-MRC, for clinical concept and relation extraction. The proposed
approach can deliver the ``one model for all`` promise from training to
deployment using a unified generative LLM."	ArXiv
1609	"SecureReg: Combining NLP and MLP for Enhanced Detection of Malicious
  Domain Name Registrations"	['Furkan Çolhak', 'Mert İlhan Ecevit', 'Hasan Dağ', 'Reiner Creutzburg']	2024-01-06 11:43:57+00:00	http://arxiv.org/abs/2401.03196v3	"The escalating landscape of cyber threats, characterized by the registration
of thousands of new domains daily for large-scale Internet attacks such as
spam, phishing, and drive-by downloads, underscores the imperative for
innovative detection methodologies. This paper introduces a cutting-edge
approach for identifying suspicious domains at the onset of the registration
process. The accompanying data pipeline generates crucial features by comparing
new domains to registered domains, emphasizing the crucial similarity score.
The proposed system analyzes semantic and numerical attributes by leveraging a
novel combination of Natural Language Processing (NLP) techniques, including a
pretrained CANINE model and Multilayer Perceptron (MLP) models, providing a
robust solution for early threat detection. This integrated Pretrained NLP
(CANINE) + MLP model showcases the outstanding performance, surpassing both
individual pretrained NLP models and standalone MLP models. With an F1 score of
84.86\% and an accuracy of 84.95\% on the SecureReg dataset, it effectively
detects malicious domain registrations. The findings demonstrate the
effectiveness of the integrated approach and contribute to the ongoing efforts
to develop proactive strategies to mitigate the risks associated with illicit
online activities through the early identification of suspicious domain
registrations."	ArXiv
1610	"Dealing with Data for RE: Mitigating Challenges while using NLP and
  Generative AI"	['Smita Ghaisas', 'Anmol Singhal']	2024-02-26 19:19:47+00:00	http://arxiv.org/abs/2402.16977v2	"Across the dynamic business landscape today, enterprises face an
ever-increasing range of challenges. These include the constantly evolving
regulatory environment, the growing demand for personalization within software
applications, and the heightened emphasis on governance. In response to these
multifaceted demands, large enterprises have been adopting automation that
spans from the optimization of core business processes to the enhancement of
customer experiences. Indeed, Artificial Intelligence (AI) has emerged as a
pivotal element of modern software systems. In this context, data plays an
indispensable role. AI-centric software systems based on supervised learning
and operating at an industrial scale require large volumes of training data to
perform effectively. Moreover, the incorporation of generative AI has led to a
growing demand for adequate evaluation benchmarks. Our experience in this field
has revealed that the requirement for large datasets for training and
evaluation introduces a host of intricate challenges. This book chapter
explores the evolving landscape of Software Engineering (SE) in general, and
Requirements Engineering (RE) in particular, in this era marked by AI
integration. We discuss challenges that arise while integrating Natural
Language Processing (NLP) and generative AI into enterprise-critical software
systems. The chapter provides practical insights, solutions, and examples to
equip readers with the knowledge and tools necessary for effectively building
solutions with NLP at their cores. We also reflect on how these text
data-centric tasks sit together with the traditional RE process. We also
highlight new RE tasks that may be necessary for handling the increasingly
important text data-centricity involved in developing software systems."	ArXiv
1611	"Comprehensive Implementation of TextCNN for Enhanced Collaboration
  between Natural Language Processing and System Recommendation"	['Xiaonan Xu', 'Zheng Xu', 'Zhipeng Ling', 'Zhengyu Jin', 'ShuQian Du']	2024-03-12 07:25:53+00:00	http://arxiv.org/abs/2403.09718v1	"Natural Language Processing (NLP) is an important branch of artificial
intelligence that studies how to enable computers to understand, process, and
generate human language. Text classification is a fundamental task in NLP,
which aims to classify text into different predefined categories. Text
classification is the most basic and classic task in natural language
processing, and most of the tasks in natural language processing can be
regarded as classification tasks. In recent years, deep learning has achieved
great success in many research fields, and today, it has also become a standard
technology in the field of NLP, which is widely integrated into text
classification tasks. Unlike numbers and images, text processing emphasizes
fine-grained processing ability. Traditional text classification methods
generally require preprocessing the input model's text data. Additionally, they
also need to obtain good sample features through manual annotation and then use
classical machine learning algorithms for classification. Therefore, this paper
analyzes the application status of deep learning in the three core tasks of NLP
(including text representation, word order modeling, and knowledge
representation). This content explores the improvement and synergy achieved
through natural language processing in the context of text classification,
while also taking into account the challenges posed by adversarial techniques
in text generation, text classification, and semantic parsing. An empirical
study on text classification tasks demonstrates the effectiveness of
interactive integration training, particularly in conjunction with TextCNN,
highlighting the significance of these advancements in text classification
augmentation and enhancement."	ArXiv
1612	"EthioLLM: Multilingual Large Language Models for Ethiopian Languages
  with Task Evaluation"	['Atnafu Lambebo Tonja', 'Israel Abebe Azime', 'Tadesse Destaw Belay', 'Mesay Gemeda Yigezu', 'Moges Ahmed Mehamed', 'Abinew Ali Ayele', 'Ebrahim Chekol Jibril', 'Michael Melese Woldeyohannis', 'Olga Kolesnikova', 'Philipp Slusallek', 'Dietrich Klakow', 'Shengwu Xiong', 'Seid Muhie Yimam']	2024-03-20 16:43:42+00:00	http://arxiv.org/abs/2403.13737v4	"Large language models (LLMs) have gained popularity recently due to their
outstanding performance in various downstream Natural Language Processing (NLP)
tasks. However, low-resource languages are still lagging behind current
state-of-the-art (SOTA) developments in the field of NLP due to insufficient
resources to train LLMs. Ethiopian languages exhibit remarkable linguistic
diversity, encompassing a wide array of scripts, and are imbued with profound
religious and cultural significance. This paper introduces EthioLLM --
multilingual large language models for five Ethiopian languages (Amharic,
Ge'ez, Afan Oromo, Somali, and Tigrinya) and English, and Ethiobenchmark -- a
new benchmark dataset for various downstream NLP tasks. We evaluate the
performance of these models across five downstream NLP tasks. We open-source
our multilingual language models, new benchmark datasets for various downstream
tasks, and task-specific fine-tuned language models and discuss the performance
of the models. Our dataset and models are available at the
https://huggingface.co/EthioNLP repository."	ArXiv
1613	Extracting Biomedical Entities from Noisy Audio Transcripts	['Nima Ebadi', 'Kellen Morgan', 'Adrian Tan', 'Billy Linares', 'Sheri Osborn', 'Emma Majors', 'Jeremy Davis', 'Anthony Rios']	2024-03-26 03:58:52+00:00	http://arxiv.org/abs/2403.17363v1	"Automatic Speech Recognition (ASR) technology is fundamental in transcribing
spoken language into text, with considerable applications in the clinical
realm, including streamlining medical transcription and integrating with
Electronic Health Record (EHR) systems. Nevertheless, challenges persist,
especially when transcriptions contain noise, leading to significant drops in
performance when Natural Language Processing (NLP) models are applied. Named
Entity Recognition (NER), an essential clinical task, is particularly affected
by such noise, often termed the ASR-NLP gap. Prior works have primarily studied
ASR's efficiency in clean recordings, leaving a research gap concerning the
performance in noisy environments. This paper introduces a novel dataset,
BioASR-NER, designed to bridge the ASR-NLP gap in the biomedical domain,
focusing on extracting adverse drug reactions and mentions of entities from the
Brief Test of Adult Cognition by Telephone (BTACT) exam. Our dataset offers a
comprehensive collection of almost 2,000 clean and noisy recordings. In
addressing the noise challenge, we present an innovative transcript-cleaning
method using GPT4, investigating both zero-shot and few-shot methodologies. Our
study further delves into an error analysis, shedding light on the types of
errors in transcription software, corrections by GPT4, and the challenges GPT4
faces. This paper aims to foster improved understanding and potential solutions
for the ASR-NLP gap, ultimately supporting enhanced healthcare documentation
practices."	ArXiv
1614	"From Narratives to Numbers: Valid Inference Using Language Model
  Predictions from Verbal Autopsy Narratives"	['Shuxian Fan', 'Adam Visokay', 'Kentaro Hoffman', 'Stephen Salerno', 'Li Liu', 'Jeffrey T. Leek', 'Tyler H. McCormick']	2024-04-03 03:53:37+00:00	http://arxiv.org/abs/2404.02438v1	"In settings where most deaths occur outside the healthcare system, verbal
autopsies (VAs) are a common tool to monitor trends in causes of death (COD).
VAs are interviews with a surviving caregiver or relative that are used to
predict the decedent's COD. Turning VAs into actionable insights for
researchers and policymakers requires two steps (i) predicting likely COD using
the VA interview and (ii) performing inference with predicted CODs (e.g.
modeling the breakdown of causes by demographic factors using a sample of
deaths). In this paper, we develop a method for valid inference using outcomes
(in our case COD) predicted from free-form text using state-of-the-art NLP
techniques. This method, which we call multiPPI++, extends recent work in
""prediction-powered inference"" to multinomial classification. We leverage a
suite of NLP techniques for COD prediction and, through empirical analysis of
VA data, demonstrate the effectiveness of our approach in handling
transportability issues. multiPPI++ recovers ground truth estimates, regardless
of which NLP model produced predictions and regardless of whether they were
produced by a more accurate predictor like GPT-4-32k or a less accurate
predictor like KNN. Our findings demonstrate the practical importance of
inference correction for public health decision-making and suggests that if
inference tasks are the end goal, having a small amount of contextually
relevant, high quality labeled data is essential regardless of the NLP
algorithm."	ArXiv
1615	"The Promises and Pitfalls of Using Language Models to Measure
  Instruction Quality in Education"	['Paiheng Xu', 'Jing Liu', 'Nathan Jones', 'Julie Cohen', 'Wei Ai']	2024-04-03 04:15:29+00:00	http://arxiv.org/abs/2404.02444v1	"Assessing instruction quality is a fundamental component of any improvement
efforts in the education system. However, traditional manual assessments are
expensive, subjective, and heavily dependent on observers' expertise and
idiosyncratic factors, preventing teachers from getting timely and frequent
feedback. Different from prior research that mostly focuses on low-inference
instructional practices on a singular basis, this paper presents the first
study that leverages Natural Language Processing (NLP) techniques to assess
multiple high-inference instructional practices in two distinct educational
settings: in-person K-12 classrooms and simulated performance tasks for
pre-service teachers. This is also the first study that applies NLP to measure
a teaching practice that is widely acknowledged to be particularly effective
for students with special needs. We confront two challenges inherent in
NLP-based instructional analysis, including noisy and long input data and
highly skewed distributions of human ratings. Our results suggest that
pretrained Language Models (PLMs) demonstrate performances comparable to the
agreement level of human raters for variables that are more discrete and
require lower inference, but their efficacy diminishes with more complex
teaching practices. Interestingly, using only teachers' utterances as input
yields strong results for student-centered variables, alleviating common
concerns over the difficulty of collecting and transcribing high-quality
student speech data in in-person teaching settings. Our findings highlight both
the potential and the limitations of current NLP techniques in the education
domain, opening avenues for further exploration."	ArXiv
1616	"Benchmarking Retrieval-Augmented Large Language Models in Biomedical
  NLP: Application, Robustness, and Self-Awareness"	['Mingchen Li', 'Zaifu Zhan', 'Han Yang', 'Yongkang Xiao', 'Jiatan Huang', 'Rui Zhang']	2024-05-13 19:51:20+00:00	http://arxiv.org/abs/2405.08151v2	"Large language models (LLM) have demonstrated remarkable capabilities in
various biomedical natural language processing (NLP) tasks, leveraging the
demonstration within the input context to adapt to new tasks. However, LLM is
sensitive to the selection of demonstrations. To address the hallucination
issue inherent in LLM, retrieval-augmented LLM (RAL) offers a solution by
retrieving pertinent information from an established database. Nonetheless,
existing research work lacks rigorous evaluation of the impact of
retrieval-augmented large language models on different biomedical NLP tasks.
This deficiency makes it challenging to ascertain the capabilities of RAL
within the biomedical domain. Moreover, the outputs from RAL are affected by
retrieving the unlabeled, counterfactual, or diverse knowledge that is not well
studied in the biomedical domain. However, such knowledge is common in the real
world. Finally, exploring the self-awareness ability is also crucial for the
RAL system. So, in this paper, we systematically investigate the impact of RALs
on 5 different biomedical tasks (triple extraction, link prediction,
classification, question answering, and natural language inference). We analyze
the performance of RALs in four fundamental abilities, including unlabeled
robustness, counterfactual robustness, diverse robustness, and negative
awareness. To this end, we proposed an evaluation framework to assess the RALs'
performance on different biomedical NLP tasks and establish four different
testbeds based on the aforementioned fundamental abilities. Then, we evaluate 3
representative LLMs with 3 different retrievers on 5 tasks over 9 datasets."	ArXiv
1617	"Synergizing Unsupervised and Supervised Learning: A Hybrid Approach for
  Accurate Natural Language Task Modeling"	['Wrick Talukdar', 'Anjanava Biswas']	2024-06-03 08:31:35+00:00	http://arxiv.org/abs/2406.01096v1	"While supervised learning models have shown remarkable performance in various
natural language processing (NLP) tasks, their success heavily relies on the
availability of large-scale labeled datasets, which can be costly and
time-consuming to obtain. Conversely, unsupervised learning techniques can
leverage abundant unlabeled text data to learn rich representations, but they
do not directly optimize for specific NLP tasks. This paper presents a novel
hybrid approach that synergizes unsupervised and supervised learning to improve
the accuracy of NLP task modeling. While supervised models excel at specific
tasks, they rely on large labeled datasets. Unsupervised techniques can learn
rich representations from abundant unlabeled text but don't directly optimize
for tasks. Our methodology integrates an unsupervised module that learns
representations from unlabeled corpora (e.g., language models, word embeddings)
and a supervised module that leverages these representations to enhance
task-specific models. We evaluate our approach on text classification and named
entity recognition (NER), demonstrating consistent performance gains over
supervised baselines. For text classification, contextual word embeddings from
a language model pretrain a recurrent or transformer-based classifier. For NER,
word embeddings initialize a BiLSTM sequence labeler. By synergizing
techniques, our hybrid approach achieves SOTA results on benchmark datasets,
paving the way for more data-efficient and robust NLP systems."	ArXiv
1618	BEADs: Bias Evaluation Across Domains	['Shaina Raza', 'Mizanur Rahman', 'Michael R. Zhang']	2024-06-06 16:18:30+00:00	http://arxiv.org/abs/2406.04220v4	"Recent advancements in large language models (LLMs) have greatly enhanced
natural language processing (NLP) applications. Nevertheless, these models
often inherit biases from their training data. Despite the availability of
various datasets for bias detection, most are limited to one or two NLP tasks
(typically classification or evaluation) and lack comprehensive evaluations
across a broader range of NLP tasks. To address this gap, we introduce the Bias
Evaluations Across Domains BEADs dataset, designed to support a wide array of
NLP tasks, including text classification, token classification, bias
quantification, and benign language generation. A key focus of this paper is
the gold label dataset that is annotated by GPT4 for scalabilty and verified by
experts to ensure high reliability. BEADs provides data for both fine-tuning,
including classification and language generation tasks, and for evaluating
LLMs. Our findings indicate that BEADs effectively identifies numerous biases
when fine-tuned on this dataset. It also reduces biases when used for
fine-tuning language generation task, while preserving language quality. The
results also reveal some prevalent demographic biases in LLMs when BEADs is
used for evaluation in demographic task. We provide the BEADs dataset for
detecting biases in various domains, and this dataset is readily usable for
responsible AI development and application. The dataset can be accessed at
https://huggingface.co/datasets/shainar/BEAD ."	ArXiv
1619	PromptFix: Few-shot Backdoor Removal via Adversarial Prompt Tuning	['Tianrong Zhang', 'Zhaohan Xi', 'Ting Wang', 'Prasenjit Mitra', 'Jinghui Chen']	2024-06-06 20:06:42+00:00	http://arxiv.org/abs/2406.04478v1	"Pre-trained language models (PLMs) have attracted enormous attention over the
past few years with their unparalleled performances. Meanwhile, the soaring
cost to train PLMs as well as their amazing generalizability have jointly
contributed to few-shot fine-tuning and prompting as the most popular training
paradigms for natural language processing (NLP) models. Nevertheless, existing
studies have shown that these NLP models can be backdoored such that model
behavior is manipulated when trigger tokens are presented. In this paper, we
propose PromptFix, a novel backdoor mitigation strategy for NLP models via
adversarial prompt-tuning in few-shot settings. Unlike existing NLP backdoor
removal methods, which rely on accurate trigger inversion and subsequent model
fine-tuning, PromptFix keeps the model parameters intact and only utilizes two
extra sets of soft tokens which approximate the trigger and counteract it
respectively. The use of soft tokens and adversarial optimization eliminates
the need to enumerate possible backdoor configurations and enables an adaptive
balance between trigger finding and preservation of performance. Experiments
with various backdoor attacks validate the effectiveness of the proposed method
and the performances when domain shift is present further shows PromptFix's
applicability to models pretrained on unknown data source which is the common
case in prompt tuning scenarios."	ArXiv
1620	GemmAr: Enhancing LLMs Through Arabic Instruction-Tuning	['Hasna Chouikhi', 'Manel Aloui', 'Cyrine Ben Hammou', 'Ghaith Chaabane', 'Haithem Kchaou', 'Chehir Dhaouadi']	2024-07-02 10:43:49+00:00	http://arxiv.org/abs/2407.02147v2	"Large language models (LLMs) have greatly impacted the natural language
processing (NLP) field, particularly for the English language. These models
have demonstrated capabilities in understanding and generating human-like text.
The success of language models largely depends on the availability of
high-quality instruction datasets, which consist of detailed task descriptions
and corresponding responses that are essential for training the models to
address a variety of prompts accurately. However, the availability and quality
of these resources vary by language. While models perform well in English, they
often need help with languages like Arabic, due to the lack of datasets for
fine-tuning Arabic-specific tasks. To address this issue, we introduce
InstAr-500k, a new Arabic instruction dataset created by generating and
collecting content that covers several domains and instruction types. We assess
this dataset by fine-tuning an open-source Gemma-7B model on several downstream
tasks to improve its functionality. Based on multiple evaluations, our
fine-tuned model achieves excellent performance on several Arabic NLP
benchmarks. These outcomes emphasize the effectiveness of our dataset in
elevating the capabilities of language models for Arabic. Our instruction
dataset bridges the performance gap between English and Arabic language models
by providing resources that amplify Arabic NLP development. Building on this
foundation, we developed a model, GemmAr-7B-V1, specifically tuned to excel at
a wide range of Arabic NLP tasks."	ArXiv
1621	"Leveraging Parameter Efficient Training Methods for Low Resource Text
  Classification: A Case Study in Marathi"	['Pranita Deshmukh', 'Nikita Kulkarni', 'Sanhita Kulkarni', 'Kareena Manghani', 'Raviraj Joshi']	2024-08-06 13:16:16+00:00	http://arxiv.org/abs/2408.03172v1	"With the surge in digital content in low-resource languages, there is an
escalating demand for advanced Natural Language Processing (NLP) techniques
tailored to these languages. BERT (Bidirectional Encoder Representations from
Transformers), serving as the foundational framework for numerous NLP
architectures and language models, is increasingly employed for the development
of low-resource NLP models. Parameter Efficient Fine-Tuning (PEFT) is a method
for fine-tuning Large Language Models (LLMs) and reducing the training
parameters to some extent to decrease the computational costs needed for
training the model and achieve results comparable to a fully fine-tuned model.
In this work, we present a study of PEFT methods for the Indic low-resource
language Marathi. We conduct a comprehensive analysis of PEFT methods applied
to various monolingual and multilingual Marathi BERT models. These approaches
are evaluated on prominent text classification datasets like MahaSent,
MahaHate, and MahaNews. The incorporation of PEFT techniques is demonstrated to
significantly expedite the training speed of the models, addressing a critical
aspect of model development and deployment. In this study, we explore Low-Rank
Adaptation of Large Language Models (LoRA) and adapter methods for low-resource
text classification. We show that these methods are competitive with full
fine-tuning and can be used without loss in accuracy. This study contributes
valuable insights into the effectiveness of Marathi BERT models, offering a
foundation for the continued advancement of NLP capabilities in Marathi and
similar Indic languages."	ArXiv
1622	"One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit
  NLP Tasks"	['Sebastian Nehrdich', 'Oliver Hellwig', 'Kurt Keutzer']	2024-09-20 22:02:26+00:00	http://arxiv.org/abs/2409.13920v1	"Morphologically rich languages are notoriously challenging to process for
downstream NLP applications. This paper presents a new pretrained language
model, ByT5-Sanskrit, designed for NLP applications involving the
morphologically rich language Sanskrit. We evaluate ByT5-Sanskrit on
established Sanskrit word segmentation tasks, where it outperforms previous
data-driven approaches by a considerable margin and matches the performance of
the current best lexicon-based model. It is easier to deploy and more robust to
data not covered by external linguistic resources. It also achieves new
state-of-the-art results in Vedic Sanskrit dependency parsing and OCR
post-correction tasks. Additionally, based on the Digital Corpus of Sanskrit,
we introduce a novel multitask dataset for the joint training of Sanskrit word
segmentation, lemmatization, and morphosyntactic tagging tasks. We fine-tune
ByT5-Sanskrit on this dataset, creating a versatile multitask model for various
downstream Sanskrit applications. We have used this model in Sanskrit
linguistic annotation projects, in information retrieval setups, and as a
preprocessing step in a Sanskrit machine translation pipeline. We also show
that our approach yields new best scores for lemmatization and dependency
parsing of other morphologically rich languages. We thus demonstrate that
byte-level pretrained language models can achieve excellent performance for
morphologically rich languages, outperforming tokenizer-based models and
presenting an important vector of exploration when constructing NLP pipelines
for such languages."	ArXiv
1623	"Exploring transfer learning for Deep NLP systems on rarely annotated
  languages"	['Dipendra Yadav', 'Tobias Strauß', 'Kristina Yordanova']	2024-10-15 13:33:54+00:00	http://arxiv.org/abs/2410.12879v1	"Natural language processing (NLP) has experienced rapid advancements with the
rise of deep learning, significantly outperforming traditional rule-based
methods. By capturing hidden patterns and underlying structures within data,
deep learning has improved performance across various NLP tasks, overcoming the
limitations of rule-based systems. However, most research and development in
NLP has been concentrated on a select few languages, primarily those with large
numbers of speakers or financial significance, leaving many others
underexplored. This lack of research is often attributed to the scarcity of
adequately annotated datasets essential for training deep learning models.
Despite this challenge, there is potential in leveraging the linguistic
similarities between unexplored and well-studied languages, particularly those
in close geographic and linguistic proximity. This thesis investigates the
application of transfer learning for Part-of-Speech (POS) tagging between Hindi
and Nepali, two highly similar languages belonging to the Indo-Aryan language
family. Specifically, the work explores whether joint training of a POS tagging
model for both languages enhances performance. Additionally, we assess whether
multitask learning in Hindi, with auxiliary tasks such as gender and
singular/plural tagging, can contribute to improved POS tagging accuracy. The
deep learning architecture employed is the BLSTM-CNN-CRF model, trained under
different conditions: monolingual word embeddings, vector-mapped embeddings,
and jointly trained Hindi-Nepali word embeddings. Varying dropout rates (0.25
to 0.5) and optimizers (ADAM and AdaDelta) are also evaluated. Results indicate
that jointly trained Hindi-Nepali word embeddings improve performance across
all models compared to monolingual and vector-mapped embeddings."	ArXiv
1624	"Mathematical Derivation Graphs: A Task for Summarizing Equation
  Dependencies in STEM Manuscripts"	['Vishesh Prasad', 'Brian Kim', 'Nickvash Kani']	2024-10-26 16:52:22+00:00	http://arxiv.org/abs/2410.21324v1	"Recent advances in natural language processing (NLP), particularly with the
emergence of large language models (LLMs), have significantly enhanced the
field of textual analysis. However, while these developments have yielded
substantial progress in analyzing textual data, applying analysis to
mathematical equations and their relationships within texts has produced mixed
results. In this paper, we take the initial steps toward understanding the
dependency relationships between mathematical expressions in STEM articles. Our
dataset, sourced from a random sampling of the arXiv corpus, contains an
analysis of 107 published STEM manuscripts whose inter-equation dependency
relationships have been hand-labeled, resulting in a new object we refer to as
a derivation graph that summarizes the mathematical content of the manuscript.
We exhaustively evaluate analytical and NLP-based models to assess their
capability to identify and extract the derivation relationships for each
article and compare the results with the ground truth. Our comprehensive
testing finds that both analytical and NLP models (including LLMs) achieve
$\sim$40-50% F1 scores for extracting derivation graphs from articles,
revealing that the recent advances in NLP have not made significant inroads in
comprehending mathematical texts compared to simpler analytic models. While
current approaches offer a solid foundation for extracting mathematical
information, further research is necessary to improve accuracy and depth in
this area."	ArXiv
1625	"Deciphering genomic codes using advanced NLP techniques: a scoping
  review"	['Shuyan Cheng', 'Yishu Wei', 'Yiliang Zhou', 'Zihan Xu', 'Drew N Wright', 'Jinze Liu', 'Yifan Peng']	2024-11-25 04:35:56+00:00	http://arxiv.org/abs/2411.16084v1	"Objectives: The vast and complex nature of human genomic sequencing data
presents challenges for effective analysis. This review aims to investigate the
application of Natural Language Processing (NLP) techniques, particularly Large
Language Models (LLMs) and transformer architectures, in deciphering genomic
codes, focusing on tokenization, transformer models, and regulatory annotation
prediction. The goal of this review is to assess data and model accessibility
in the most recent literature, gaining a better understanding of the existing
capabilities and constraints of these tools in processing genomic sequencing
data.
  Methods: Following Preferred Reporting Items for Systematic Reviews and
Meta-Analyses (PRISMA) guidelines, our scoping review was conducted across
PubMed, Medline, Scopus, Web of Science, Embase, and ACM Digital Library.
Studies were included if they focused on NLP methodologies applied to genomic
sequencing data analysis, without restrictions on publication date or article
type.
  Results: A total of 26 studies published between 2021 and April 2024 were
selected for review. The review highlights that tokenization and transformer
models enhance the processing and understanding of genomic data, with
applications in predicting regulatory annotations like transcription-factor
binding sites and chromatin accessibility.
  Discussion: The application of NLP and LLMs to genomic sequencing data
interpretation is a promising field that can help streamline the processing of
large-scale genomic data while also providing a better understanding of its
complex structures. It has the potential to drive advancements in personalized
medicine by offering more efficient and scalable solutions for genomic
analysis. Further research is also needed to discuss and overcome current
limitations, enhancing model transparency and applicability."	ArXiv
1626	"Decade of Natural Language Processing in Chronic Pain: A Systematic
  Review"	['Swati Rajwal']	2024-12-19 19:46:09+00:00	http://arxiv.org/abs/2412.15360v1	"In recent years, the intersection of Natural Language Processing (NLP) and
public health has opened innovative pathways for investigating various domains,
including chronic pain in textual datasets. Despite the promise of NLP in
chronic pain, the literature is dispersed across various disciplines, and there
is a need to consolidate existing knowledge, identify knowledge gaps in the
literature, and inform future research directions in this emerging field. This
review aims to investigate the state of the research on NLP-based interventions
designed for chronic pain research. A search strategy was formulated and
executed across PubMed, Web of Science, IEEE Xplore, Scopus, and ACL Anthology
to find studies published in English between 2014 and 2024. After screening 132
papers, 26 studies were included in the final review. Key findings from this
review underscore the significant potential of NLP techniques to address
pressing challenges in chronic pain research. The past 10 years in this field
have showcased the utilization of advanced methods (transformers like RoBERTa
and BERT) achieving high-performance metrics (e.g., F1>0.8) in classification
tasks, while unsupervised approaches like Latent Dirichlet Allocation (LDA) and
k-means clustering have proven effective for exploratory analyses. Results also
reveal persistent challenges such as limited dataset diversity, inadequate
sample sizes, and insufficient representation of underrepresented populations.
Future research studies should explore multimodal data validation systems,
context-aware mechanistic modeling, and the development of standardized
evaluation metrics to enhance reproducibility and equity in chronic pain
research."	ArXiv
1627	"Setting Standards in Turkish NLP: TR-MMLU for Large Language Model
  Evaluation"	['M. Ali Bayram', 'Ali Arda Fincan', 'Ahmet Semih Gümüş', 'Banu Diri', 'Savaş Yıldırım', 'Öner Aytaş']	2024-12-31 18:43:49+00:00	http://arxiv.org/abs/2501.00593v2	"Language models have made remarkable advancements in understanding and
generating human language, achieving notable success across a wide array of
applications. However, evaluating these models remains a significant challenge,
particularly for resource-limited languages such as Turkish. To address this
gap, we introduce the Turkish MMLU (TR-MMLU) benchmark, a comprehensive
evaluation framework designed to assess the linguistic and conceptual
capabilities of large language models (LLMs) in Turkish. TR-MMLU is constructed
from a carefully curated dataset comprising 6200 multiple-choice questions
across 62 sections, selected from a pool of 280000 questions spanning 67
disciplines and over 800 topics within the Turkish education system. This
benchmark provides a transparent, reproducible, and culturally relevant tool
for evaluating model performance. It serves as a standard framework for Turkish
NLP research, enabling detailed analyses of LLMs' capabilities in processing
Turkish text and fostering the development of more robust and accurate language
models. In this study, we evaluate state-of-the-art LLMs on TR-MMLU, providing
insights into their strengths and limitations for Turkish-specific tasks. Our
findings reveal critical challenges, such as the impact of tokenization and
fine-tuning strategies, and highlight areas for improvement in model design. By
setting a new standard for evaluating Turkish language models, TR-MMLU aims to
inspire future innovations and support the advancement of Turkish NLP research."	ArXiv
1628	A Symbolic and Surgical Acquisition of Terms through Variation	['Christian Jacquemin']	1995-05-04 21:32:29+00:00	http://arxiv.org/abs/cmp-lg/9505012v2	"Terminological acquisition is an important issue in learning for NLP due to
the constant terminological renewal through technological changes. Terms play a
key role in several NLP-activities such as machine translation, automatic
indexing or text understanding. In opposition to classical once-and-for-all
approaches, we propose an incremental process for terminological enrichment
which operates on existing reference lists and large corpora. Candidate terms
are acquired by extracting variants of reference terms through {\em FASTR}, a
unification-based partial parser. As acquisition is performed within specific
morpho-syntactic contexts (coordinations, insertions or permutations of
compounds), rich conceptual links are learned together with candidate terms. A
clustering of terms related through coordination yields classes of conceptually
close terms while graphs resulting from insertions denote generic/specific
relations. A graceful degradation of the volume of acquisition on partial
initial lists confirms the robustness of the method to incomplete data."	ArXiv
1629	How Part-of-Speech Tags Affect Text Retrieval and Filtering Performance	['Robert M. Losee']	1996-02-08 15:12:27+00:00	http://arxiv.org/abs/cmp-lg/9602001v1	"Natural language processing (NLP) applied to information retrieval (IR) and
filtering problems may assign part-of-speech tags to terms and, more generally,
modify queries and documents. Analytic models can predict the performance of a
text filtering system as it incorporates changes suggested by NLP, allowing us
to make precise statements about the average effect of NLP operations on IR.
Here we provide a model of retrieval and tagging that allows us to both compute
the performance change due to syntactic parsing and to allow us to understand
what factors affect performance and how. In addition to a prediction of
performance with tags, upper and lower bounds for retrieval performance are
derived, giving the best and worst effects of including part-of-speech tags.
Empirical grounds for selecting sets of tags are considered."	ArXiv
1630	Producing NLP-based On-line Contentware	['Francis Wolinski', 'Frantz Vichot', 'Olivier Gremont']	1998-09-16 14:22:35+00:00	http://arxiv.org/abs/cs/9809021v1	"For its internal needs as well as for commercial purposes, CDC Group has
produced several NLP-based on-line contentware applications for years. The
development process of such applications is subject to numerous constraints
such as quality of service, integration of new advances in NLP, direct
reactions from users, continuous versioning, short delivery deadlines and cost
control. Following this industrial and commercial experience, malleability of
the applications, their openness towards foreign components, efficiency of
applications and their ease of exploitation have appeared to be key points. In
this paper, we describe TalLab, a powerful architecture for on-line contentware
which fulfils these requirements."	ArXiv
1631	Evaluation of the NLP Components of the OVIS2 Spoken Dialogue System	"['Gert Veldhuijzen van Zanten', 'Gosse Bouma', ""Khalil Sima'an"", 'Gertjan van Noord', 'Remko Bonnema']"	1999-06-14 10:06:31+00:00	http://arxiv.org/abs/cs/9906014v1	"The NWO Priority Programme Language and Speech Technology is a 5-year
research programme aiming at the development of spoken language information
systems. In the Programme, two alternative natural language processing (NLP)
modules are developed in parallel: a grammar-based (conventional, rule-based)
module and a data-oriented (memory-based, stochastic, DOP) module. In order to
compare the NLP modules, a formal evaluation has been carried out three years
after the start of the Programme. This paper describes the evaluation procedure
and the evaluation results. The grammar-based component performs much better
than the data-oriented one in this comparison."	ArXiv
1632	An electronic dictionary as a basis for NLP tools: The Greek case	['Ch. Tsalidis', 'A. Vagelatos', 'G. Orphanos']	2004-08-26 13:17:38+00:00	http://arxiv.org/abs/cs/0408061v1	"The existence of a Dictionary in electronic form for Modern Greek (MG) is
mandatory if one is to process MG at the morphological and syntactic levels
since MG is a highly inflectional language with marked stress and a spelling
system with many characteristics carried over from Ancient Greek. Moreover,
such a tool becomes necessary if one is to create efficient and sophisticated
NLP applications with substantial linguistic backing and coverage. The present
paper will focus on the deployment of such an electronic dictionary for Modern
Greek, which was built in two phases: first it was constructed to be the basis
for a spelling correction schema and then it was reconstructed in order to
become the platform for the deployment of a wider spectrum of NLP tools."	ArXiv
1633	Commonsense Knowledge, Ontology and Ordinary Language	['Walid S. Saba']	2008-08-08 14:37:45+00:00	http://arxiv.org/abs/0808.1211v1	"Over two decades ago a ""quite revolution"" overwhelmingly replaced
knowledgebased approaches in natural language processing (NLP) by quantitative
(e.g., statistical, corpus-based, machine learning) methods. Although it is our
firm belief that purely quantitative approaches cannot be the only paradigm for
NLP, dissatisfaction with purely engineering approaches to the construction of
large knowledge bases for NLP are somewhat justified. In this paper we hope to
demonstrate that both trends are partly misguided and that the time has come to
enrich logical semantics with an ontological structure that reflects our
commonsense view of the world and the way we talk about in ordinary language.
In this paper it will be demonstrated that assuming such an ontological
structure a number of challenges in the semantics of natural language (e.g.,
metonymy, intensionality, copredication, nominal compounds, etc.) can be
properly and uniformly addressed."	ArXiv
1634	A generic tool to generate a lexicon for NLP from Lexicon-Grammar tables	['Matthieu Constant', 'Elsa Tolone']	2010-05-31 06:37:40+00:00	http://arxiv.org/abs/1005.5596v1	"Lexicon-Grammar tables constitute a large-coverage syntactic lexicon but they
cannot be directly used in Natural Language Processing (NLP) applications
because they sometimes rely on implicit information. In this paper, we
introduce LGExtract, a generic tool for generating a syntactic lexicon for NLP
from the Lexicon-Grammar tables. It is based on a global table that contains
undefined information and on a unique extraction script including all
operations to be performed for all tables. We also present an experiment that
has been conducted to generate a new lexicon of French verbs and predicative
nouns."	ArXiv
1635	Each normal logic program has a 2-valued Minimal Hypotheses semantics	['Alexandre Miguel Pinto', 'Luś Moniz Pereira']	2011-08-29 21:46:07+00:00	http://arxiv.org/abs/1108.5766v1	"In this paper we explore a unifying approach --- that of hypotheses
assumption --- as a means to provide a semantics for all Normal Logic Programs
(NLPs), the Minimal Hypotheses (MH) semantics. This semantics takes a positive
hypotheses assumption approach as a means to guarantee the desirable properties
of model existence, relevance and cumulativity, and of generalizing the Stable
Models in the process. To do so we first introduce the fundamental semantic
concept of minimality of assumed positive hypotheses, define the MH semantics,
and analyze the semantics' properties and applicability. Indeed, abductive
Logic Programming can be conceptually captured by a strategy centered on the
assumption of abducibles (or hypotheses). Likewise, the Argumentation
perspective of Logic Programs also lends itself to an arguments (or hypotheses)
assumption approach. Previous works on Abduction have depicted the atoms of
default negated literals in NLPs as abducibles, i.e., assumable hypotheses. We
take a complementary and more general view than these works to NLP semantics by
employing positive hypotheses instead."	ArXiv
1636	POS Tagging and its Applications for Mathematics	['Ulf Schöneberg', 'Wolfram Sperber']	2014-06-11 12:25:26+00:00	http://arxiv.org/abs/1406.2880v1	"Content analysis of scientific publications is a nontrivial task, but a
useful and important one for scientific information services. In the Gutenberg
era it was a domain of human experts; in the digital age many machine-based
methods, e.g., graph analysis tools and machine-learning techniques, have been
developed for it. Natural Language Processing (NLP) is a powerful
machine-learning approach to semiautomatic speech and language processing,
which is also applicable to mathematics. The well established methods of NLP
have to be adjusted for the special needs of mathematics, in particular for
handling mathematical formulae. We demonstrate a mathematics-aware part of
speech tagger and give a short overview about our adaptation of NLP methods for
mathematical publications. We show the use of the tools developed for key
phrase extraction and classification in the database zbMATH."	ArXiv
1637	Visualizing and Understanding Neural Models in NLP	['Jiwei Li', 'Xinlei Chen', 'Eduard Hovy', 'Dan Jurafsky']	2015-06-02 21:17:31+00:00	http://arxiv.org/abs/1506.01066v2	"While neural networks have been successfully applied to many NLP tasks the
resulting vector-based models are very difficult to interpret. For example it's
not clear how they achieve {\em compositionality}, building sentence meaning
from the meanings of words and phrases. In this paper we describe four
strategies for visualizing compositionality in neural models for NLP, inspired
by similar work in computer vision. We first plot unit values to visualize
compositionality of negation, intensification, and concessive clauses, allow us
to see well-known markedness asymmetries in negation. We then introduce three
simple and straightforward methods for visualizing a unit's {\em salience}, the
amount it contributes to the final composed meaning: (1) gradient
back-propagation, (2) the variance of a token from the average word node, (3)
LSTM-style gates that measure information flow. We test our methods on
sentiment using simple recurrent nets and LSTMs. Our general-purpose methods
may have wide applications for understanding compositionality and other
semantic properties of deep networks , and also shed light on why LSTMs
outperform simple recurrent nets,"	ArXiv
1638	"sense2vec - A Fast and Accurate Method for Word Sense Disambiguation In
  Neural Word Embeddings"	['Andrew Trask', 'Phil Michalak', 'John Liu']	2015-11-19 21:22:42+00:00	http://arxiv.org/abs/1511.06388v1	"Neural word representations have proven useful in Natural Language Processing
(NLP) tasks due to their ability to efficiently model complex semantic and
syntactic word relationships. However, most techniques model only one
representation per word, despite the fact that a single word can have multiple
meanings or ""senses"". Some techniques model words by using multiple vectors
that are clustered based on context. However, recent neural approaches rarely
focus on the application to a consuming NLP algorithm. Furthermore, the
training process of recent word-sense models is expensive relative to
single-sense embedding processes. This paper presents a novel approach which
addresses these concerns by modeling multiple embeddings for each word based on
supervised disambiguation, which provides a fast and accurate way for a
consuming NLP model to select a sense-disambiguated embedding. We demonstrate
that these embeddings can disambiguate both contrastive senses such as nominal
and verbal senses as well as nuanced senses such as sarcasm. We further
evaluate Part-of-Speech disambiguated embeddings on neural dependency parsing,
yielding a greater than 8% average error reduction in unlabeled attachment
scores across 6 languages."	ArXiv
1639	How Transferable are Neural Networks in NLP Applications?	['Lili Mou', 'Zhao Meng', 'Rui Yan', 'Ge Li', 'Yan Xu', 'Lu Zhang', 'Zhi Jin']	2016-03-19 16:38:31+00:00	http://arxiv.org/abs/1603.06111v2	"Transfer learning is aimed to make use of valuable knowledge in a source
domain to help model performance in a target domain. It is particularly
important to neural networks, which are very likely to be overfitting. In some
fields like image processing, many studies have shown the effectiveness of
neural network-based transfer learning. For neural NLP, however, existing
studies have only casually applied transfer learning, and conclusions are
inconsistent. In this paper, we conduct systematic case studies and provide an
illuminating picture on the transferability of neural networks in NLP."	ArXiv
1640	"Proceedings of the 2016 Workshop on Semantic Spaces at the Intersection
  of NLP, Physics and Cognitive Science"	['Dimitrios Kartsaklis', 'Martha Lewis', 'Laura Rimell']	2016-08-02 22:28:45+00:00	http://arxiv.org/abs/1608.01018v1	"This volume contains the Proceedings of the 2016 Workshop on Semantic Spaces
at the Intersection of NLP, Physics and Cognitive Science (SLPCS 2016), which
was held on the 11th of June at the University of Strathclyde, Glasgow, and was
co-located with Quantum Physics and Logic (QPL 2016). Exploiting the common
ground provided by the concept of a vector space, the workshop brought together
researchers working at the intersection of Natural Language Processing (NLP),
cognitive science, and physics, offering them an appropriate forum for
presenting their uniquely motivated work and ideas. The interplay between these
three disciplines inspired theoretically motivated approaches to the
understanding of how word meanings interact with each other in sentences and
discourse, how diagrammatic reasoning depicts and simplifies this interaction,
how language models are determined by input from the world, and how word and
sentence meanings interact logically. This first edition of the workshop
consisted of three invited talks from distinguished speakers (Hans Briegel,
Peter G\""ardenfors, Dominic Widdows) and eight presentations of selected
contributed papers. Each submission was refereed by at least three members of
the Programme Committee, who delivered detailed and insightful comments and
suggestions."	ArXiv
1641	"An assessment of orthographic similarity measures for several African
  languages"	['C. Maria Keet']	2016-08-10 07:45:46+00:00	http://arxiv.org/abs/1608.03065v1	"Natural Language Interfaces and tools such as spellcheckers and Web search in
one's own language are known to be useful in ICT-mediated communication. Most
languages in Southern Africa are under-resourced, however. Therefore, it would
be very useful if both the generic and the few language-specific NLP tools
could be reused or easily adapted across languages. This depends on the notion,
and extent, of similarity between the languages. We assess this from the angle
of orthography and corpora. Twelve versions of the Universal Declaration of
Human Rights (UDHR) are examined, showing clusters of languages, and which are
thus more or less amenable to cross-language adaptation of NLP tools, which do
not match with Guthrie zones. To examine the generalisability of these results,
we zoom in on isiZulu both quantitatively and qualitatively with four other
corpora and texts in different genres. The results show that the UDHR is a
typical text document orthographically. The results also provide insight into
usability of typical measures such as lexical diversity and genre, and that the
same statistic may mean different things in different documents. While NLTK for
Python could be used for basic analyses of text, it, and similar NLP tools,
will need considerable customization."	ArXiv
1642	What to do about non-standard (or non-canonical) language in NLP	['Barbara Plank']	2016-08-28 17:51:41+00:00	http://arxiv.org/abs/1608.07836v1	"Real world data differs radically from the benchmark corpora we use in
natural language processing (NLP). As soon as we apply our technologies to the
real world, performance drops. The reason for this problem is obvious: NLP
models are trained on samples from a limited set of canonical varieties that
are considered standard, most prominently English newswire. However, there are
many dimensions, e.g., socio-demographics, language, genre, sentence type, etc.
on which texts can differ from the standard. The solution is not obvious: we
cannot control for all factors, and it is not clear how to best go beyond the
current practice of training on homogeneous data from a single domain and
language.
  In this paper, I review the notion of canonicity, and how it shapes our
community's approach to language. I argue for leveraging what I call fortuitous
data, i.e., non-obvious data that is hitherto neglected, hidden in plain sight,
or raw data that needs to be refined. If we embrace the variety of this
heterogeneous data by combining it with proper algorithms, we will not only
produce more robust models, but will also enable adaptive language technology
capable of addressing natural language variation."	ArXiv
1643	"Universality of next-to-leading power threshold effects for colourless
  final states in hadronic collisions"	['V. Del Duca', 'E. Laenen', 'L. Magnea', 'L. Vernazza', 'C. D. White']	2017-06-13 11:50:29+00:00	http://arxiv.org/abs/1706.04018v1	"We consider the production of an arbitrary number of colour-singlet particles
near partonic threshold, and show that next-to-leading order cross sections for
this class of processes have a simple universal form at next-to-leading power
(NLP) in the energy of the emitted gluon radiation. Our analysis relies on a
recently derived factorisation formula for NLP threshold effects at amplitude
level, and therefore applies both if the leading-order process is tree-level
and if it is loop-induced. It holds for differential distributions as well. The
results can furthermore be seen as applications of recently derived
next-to-soft theorems for gauge theory amplitudes. We use our universal
expression to re-derive known results for the production of up to three Higgs
bosons at NLO in the large top mass limit, and for the hadro-production of a
pair of electroweak gauge bosons. Finally, we present new analytic results for
Higgs boson pair production at NLO and NLP, with exact top-mass dependence."	ArXiv
1644	VnCoreNLP: A Vietnamese Natural Language Processing Toolkit	['Thanh Vu', 'Dat Quoc Nguyen', 'Dai Quoc Nguyen', 'Mark Dras', 'Mark Johnson']	2018-01-04 12:52:43+00:00	http://arxiv.org/abs/1801.01331v2	"We present an easy-to-use and fast toolkit, namely VnCoreNLP---a Java NLP
annotation pipeline for Vietnamese. Our VnCoreNLP supports key natural language
processing (NLP) tasks including word segmentation, part-of-speech (POS)
tagging, named entity recognition (NER) and dependency parsing, and obtains
state-of-the-art (SOTA) results for these tasks. We release VnCoreNLP to
provide rich linguistic annotations to facilitate research work on Vietnamese
NLP. Our VnCoreNLP is open-source and available at:
https://github.com/vncorenlp/VnCoreNLP"	ArXiv
1645	"Modeling Language Variation and Universals: A Survey on Typological
  Linguistics for Natural Language Processing"	"['Edoardo Maria Ponti', ""Helen O'Horan"", 'Yevgeni Berzak', 'Ivan Vulić', 'Roi Reichart', 'Thierry Poibeau', 'Ekaterina Shutova', 'Anna Korhonen']"	2018-07-02 22:09:59+00:00	http://arxiv.org/abs/1807.00914v3	"Linguistic typology aims to capture structural and semantic variation across
the world's languages. A large-scale typology could provide excellent guidance
for multilingual Natural Language Processing (NLP), particularly for languages
that suffer from the lack of human labeled resources. We present an extensive
literature survey on the use of typological information in the development of
NLP techniques. Our survey demonstrates that to date, the use of information in
existing typological databases has resulted in consistent but modest
improvements in system performance. We show that this is due to both intrinsic
limitations of databases (in terms of coverage and feature granularity) and
under-employment of the typological features included in them. We advocate for
a new approach that adapts the broad and discrete nature of typological
categories to the contextual and continuous nature of machine learning
algorithms used in contemporary NLP. In particular, we suggest that such
approach could be facilitated by recent developments in data-driven induction
of typological knowledge."	ArXiv
1646	"Recurrent Neural Networks in Linguistic Theory: Revisiting Pinker and
  Prince (1988) and the Past Tense Debate"	['Christo Kirov', 'Ryan Cotterell']	2018-07-12 18:44:34+00:00	http://arxiv.org/abs/1807.04783v2	"Can advances in NLP help advance cognitive modeling? We examine the role of
artificial neural networks, the current state of the art in many common NLP
tasks, by returning to a classic case study. In 1986, Rumelhart and McClelland
famously introduced a neural architecture that learned to transduce English
verb stems to their past tense forms. Shortly thereafter, Pinker & Prince
(1988) presented a comprehensive rebuttal of many of Rumelhart and McClelland's
claims. Much of the force of their attack centered on the empirical inadequacy
of the Rumelhart and McClelland (1986) model. Today, however, that model is
severely outmoded. We show that the Encoder-Decoder network architectures used
in modern NLP systems obviate most of Pinker and Prince's criticisms without
requiring any simplication of the past tense mapping problem. We suggest that
the empirical performance of modern networks warrants a re-examination of their
utility in linguistic and cognitive modeling."	ArXiv
1647	"Building a Kannada POS Tagger Using Machine Learning and Neural Network
  Models"	['Ketan Kumar Todi', 'Pruthwik Mishra', 'Dipti Misra Sharma']	2018-08-09 14:16:30+00:00	http://arxiv.org/abs/1808.03175v1	"POS Tagging serves as a preliminary task for many NLP applications. Kannada
is a relatively poor Indian language with very limited number of quality NLP
tools available for use. An accurate and reliable POS Tagger is essential for
many NLP tasks like shallow parsing, dependency parsing, sentiment analysis,
named entity recognition. We present a statistical POS tagger for Kannada using
different machine learning and neural network models. Our Kannada POS tagger
outperforms the state-of-the-art Kannada POS tagger by 6%. Our contribution in
this paper is three folds - building a generic POS Tagger, comparing the
performances of different modeling techniques, exploring the use of character
and word embeddings together for Kannada POS Tagging."	ArXiv
1648	Multitask and Multilingual Modelling for Lexical Analysis	['Johannes Bjerva']	2018-09-07 12:07:59+00:00	http://arxiv.org/abs/1809.02428v1	"In Natural Language Processing (NLP), one traditionally considers a single
task (e.g. part-of-speech tagging) for a single language (e.g. English) at a
time. However, recent work has shown that it can be beneficial to take
advantage of relatedness between tasks, as well as between languages. In this
work I examine the concept of relatedness and explore how it can be utilised to
build NLP models that require less manually annotated data. A large selection
of NLP tasks is investigated for a substantial language sample comprising 60
languages. The results show potential for joint multitask and multilingual
modelling, and hints at linguistic insights which can be gained from such
models."	ArXiv
1649	"DreamNLP: Novel NLP System for Clinical Report Metadata Extraction using
  Count Sketch Data Streaming Algorithm: Preliminary Results"	['Sanghyun Choi', 'Nikita Ivkin', 'Vladimir Braverman', 'Michael A. Jacobs']	2018-08-26 01:42:29+00:00	http://arxiv.org/abs/1809.02665v1	"Extracting information from electronic health records (EHR) is a challenging
task since it requires prior knowledge of the reports and some natural language
processing algorithm (NLP). With the growing number of EHR implementations,
such knowledge is increasingly challenging to obtain in an efficient manner. We
address this challenge by proposing a novel methodology to analyze large sets
of EHRs using a modified Count Sketch data streaming algorithm termed DreamNLP.
By using DreamNLP, we generate a dictionary of frequently occurring terms or
heavy hitters in the EHRs using low computational memory compared to
conventional counting approach other NLP programs use. We demonstrate the
extraction of the most important breast diagnosis features from the EHRs in a
set of patients that underwent breast imaging. Based on the analysis,
extraction of these terms would be useful for defining important features for
downstream tasks such as machine learning for precision medicine."	ArXiv
1650	"Does it care what you asked? Understanding Importance of Verbs in Deep
  Learning QA System"	['Barbara Rychalska', 'Dominika Basaj', 'Przemyslaw Biecek', 'Anna Wroblewska']	2018-09-11 08:37:07+00:00	http://arxiv.org/abs/1809.03740v1	"In this paper we present the results of an investigation of the importance of
verbs in a deep learning QA system trained on SQuAD dataset. We show that main
verbs in questions carry little influence on the decisions made by the system -
in over 90% of researched cases swapping verbs for their antonyms did not
change system decision. We track this phenomenon down to the insides of the
net, analyzing the mechanism of self-attention and values contained in hidden
layers of RNN. Finally, we recognize the characteristics of the SQuAD dataset
as the source of the problem. Our work refers to the recently popular topic of
adversarial examples in NLP, combined with investigating deep net structure."	ArXiv
1651	"A Fine-Grained Approach for Automated Conversion of JUnit Assertions to
  English"	['Danielle Gonzalez', 'Suzanne Prentice', 'Mehdi Mirakhorli']	2018-11-12 21:17:03+00:00	http://arxiv.org/abs/1811.05005v1	"Converting source or unit test code to English has been shown to improve the
maintainability, understandability, and analysis of software and tests. Code
summarizers identify important statements in the source/tests and convert them
to easily understood English sentences using static analysis and NLP
techniques. However, current test summarization approaches handle only a subset
of the variation and customization allowed in the JUnit assert API (a critical
component of test cases) which may affect the accuracy of conversions. In this
paper, we present our work towards improving JUnit test summarization with a
detailed process for converting a total of 45 unique JUnit assertions to
English, including 37 previously-unhandled variations of the assertThat method.
This process has also been implemented and released as the AssertConvert tool.
Initial evaluations have shown that this tool generates English conversions
that accurately represent a wide variety of assertion statements which could be
used for code summarization or other NLP analyses."	ArXiv
1652	Few-shot Learning for Named Entity Recognition in Medical Text	['Maximilian Hofer', 'Andrey Kormilitzin', 'Paul Goldberg', 'Alejo Nevado-Holgado']	2018-11-13 13:12:02+00:00	http://arxiv.org/abs/1811.05468v1	"Deep neural network models have recently achieved state-of-the-art
performance gains in a variety of natural language processing (NLP) tasks
(Young, Hazarika, Poria, & Cambria, 2017). However, these gains rely on the
availability of large amounts of annotated examples, without which
state-of-the-art performance is rarely achievable. This is especially
inconvenient for the many NLP fields where annotated examples are scarce, such
as medical text. To improve NLP models in this situation, we evaluate five
improvements on named entity recognition (NER) tasks when only ten annotated
examples are available: (1) layer-wise initialization with pre-trained weights,
(2) hyperparameter tuning, (3) combining pre-training data, (4) custom word
embeddings, and (5) optimizing out-of-vocabulary (OOV) words. Experimental
results show that the F1 score of 69.3% achievable by state-of-the-art models
can be improved to 78.87%."	ArXiv
1653	sCAKE: Semantic Connectivity Aware Keyword Extraction	['Swagata Duari', 'Vasudha Bhatnagar']	2018-11-27 06:22:33+00:00	http://arxiv.org/abs/1811.10831v1	"Keyword Extraction is an important task in several text analysis endeavors.
In this paper, we present a critical discussion of the issues and challenges
ingraph-based keyword extraction methods, along with comprehensive empirical
analysis. We propose a parameterless method for constructing graph of text that
captures the contextual relation between words. A novel word scoring method is
also proposed based on the connection between concepts. We demonstrate that
both proposals are individually superior to those followed by the
state-of-the-art graph-based keyword extraction algorithms. Combination of the
proposed graph construction and scoring methods leads to a novel, parameterless
keyword extraction method (sCAKE) based on semantic connectivity of words in
the document.
  Motivated by limited availability of NLP tools for several languages, we also
design and present a language-agnostic keyword extraction (LAKE) method. We
eliminate the need of NLP tools by using a statistical filter to identify
candidate keywords before constructing the graph. We show that the resulting
method is a competent solution for extracting keywords from documents
oflanguages lacking sophisticated NLP support."	ArXiv
1654	"What Should I Learn First: Introducing LectureBank for NLP Education and
  Prerequisite Chain Learning"	['Irene Li', 'Alexander R. Fabbri', 'Robert R. Tung', 'Dragomir R. Radev']	2018-11-26 21:09:20+00:00	http://arxiv.org/abs/1811.12181v1	"Recent years have witnessed the rising popularity of Natural Language
Processing (NLP) and related fields such as Artificial Intelligence (AI) and
Machine Learning (ML). Many online courses and resources are available even for
those without a strong background in the field. Often the student is curious
about a specific topic but does not quite know where to begin studying. To
answer the question of ""what should one learn first,"" we apply an
embedding-based method to learn prerequisite relations for course concepts in
the domain of NLP. We introduce LectureBank, a dataset containing 1,352 English
lecture files collected from university courses which are each classified
according to an existing taxonomy as well as 208 manually-labeled prerequisite
relation topics, which is publicly available. The dataset will be useful for
educational purposes such as lecture preparation and organization as well as
applications such as reading list generation. Additionally, we experiment with
neural graph-based networks and non-neural classifiers to learn these
prerequisite relations from our dataset."	ArXiv
1655	"Is it Time to Swish? Comparing Deep Learning Activation Functions Across
  NLP tasks"	['Steffen Eger', 'Paul Youssef', 'Iryna Gurevych']	2019-01-09 10:45:20+00:00	http://arxiv.org/abs/1901.02671v1	"Activation functions play a crucial role in neural networks because they are
the nonlinearities which have been attributed to the success story of deep
learning. One of the currently most popular activation functions is ReLU, but
several competitors have recently been proposed or 'discovered', including
LReLU functions and swish. While most works compare newly proposed activation
functions on few tasks (usually from image classification) and against few
competitors (usually ReLU), we perform the first large-scale comparison of 21
activation functions across eight different NLP tasks. We find that a largely
unknown activation function performs most stably across all tasks, the
so-called penalized tanh function. We also show that it can successfully
replace the sigmoid and tanh gates in LSTM cells, leading to a 2 percentage
point (pp) improvement over the standard choices on a challenging NLP task."	ArXiv
1656	"To Tune or Not to Tune? Adapting Pretrained Representations to Diverse
  Tasks"	['Matthew E. Peters', 'Sebastian Ruder', 'Noah A. Smith']	2019-03-14 13:32:31+00:00	http://arxiv.org/abs/1903.05987v2	"While most previous work has focused on different pretraining objectives and
architectures for transfer learning, we ask how to best adapt the pretrained
model to a given target task. We focus on the two most common forms of
adaptation, feature extraction (where the pretrained weights are frozen), and
directly fine-tuning the pretrained model. Our empirical results across diverse
NLP tasks with two state-of-the-art models show that the relative performance
of fine-tuning vs. feature extraction depends on the similarity of the
pretraining and target tasks. We explore possible explanations for this finding
and provide a set of adaptation guidelines for the NLP practitioner."	ArXiv
1657	Does My Rebuttal Matter? Insights from a Major NLP Conference	['Yang Gao', 'Steffen Eger', 'Ilia Kuznetsov', 'Iryna Gurevych', 'Yusuke Miyao']	2019-03-27 12:00:20+00:00	http://arxiv.org/abs/1903.11367v2	"Peer review is a core element of the scientific process, particularly in
conference-centered fields such as ML and NLP. However, only few studies have
evaluated its properties empirically. Aiming to fill this gap, we present a
corpus that contains over 4k reviews and 1.2k author responses from ACL-2018.
We quantitatively and qualitatively assess the corpus. This includes a pilot
study on paper weaknesses given by reviewers and on quality of author
responses. We then focus on the role of the rebuttal phase, and propose a novel
task to predict after-rebuttal (i.e., final) scores from initial reviews and
author responses. Although author responses do have a marginal (and
statistically significant) influence on the final scores, especially for
borderline papers, our results suggest that a reviewer's final score is largely
determined by her initial score and the distance to the other reviewers'
initial scores. In this context, we discuss the conformity bias inherent to
peer reviewing, a bias that has largely been overlooked in previous research.
We hope our analyses will help better assess the usefulness of the rebuttal
phase in NLP conferences."	ArXiv
1658	"JU_KS@SAIL_CodeMixed-2017: Sentiment Analysis for Indian Code Mixed
  Social Media Texts"	['Kamal Sarkar']	2018-02-15 20:02:43+00:00	http://arxiv.org/abs/1802.05737v1	"This paper reports about our work in the NLP Tool Contest @ICON-2017, shared
task on Sentiment Analysis for Indian Languages (SAIL) (code mixed). To
implement our system, we have used a machine learning algo-rithm called
Multinomial Na\""ive Bayes trained using n-gram and SentiWordnet features. We
have also used a small SentiWordnet for English and a small SentiWordnet for
Bengali. But we have not used any SentiWordnet for Hindi language. We have
tested our system on Hindi-English and Bengali-English code mixed social media
data sets released for the contest. The performance of our system is very close
to the best system participated in the contest. For both Bengali-English and
Hindi-English runs, our system was ranked at the 3rd position out of all
submitted runs and awarded the 3rd prize in the contest."	ArXiv
1659	Delta Embedding Learning	['Xiao Zhang', 'Ji Wu', 'Dejing Dou']	2018-12-11 00:19:32+00:00	http://arxiv.org/abs/1812.04160v2	"Unsupervised word embeddings have become a popular approach of word
representation in NLP tasks. However there are limitations to the semantics
represented by unsupervised embeddings, and inadequate fine-tuning of
embeddings can lead to suboptimal performance. We propose a novel learning
technique called Delta Embedding Learning, which can be applied to general NLP
tasks to improve performance by optimized tuning of the word embeddings. A
structured regularization is applied to the embeddings to ensure they are tuned
in an incremental way. As a result, the tuned word embeddings become better
word representations by absorbing semantic information from supervision without
""forgetting."" We apply the method to various NLP tasks and see a consistent
improvement in performance. Evaluation also confirms the tuned word embeddings
have better semantic properties."	ArXiv
1660	"TextKD-GAN: Text Generation using KnowledgeDistillation and Generative
  Adversarial Networks"	['Md. Akmal Haidar', 'Mehdi Rezagholizadeh']	2019-04-23 15:15:12+00:00	http://arxiv.org/abs/1905.01976v1	"Text generation is of particular interest in many NLP applications such as
machine translation, language modeling, and text summarization. Generative
adversarial networks (GANs) achieved a remarkable success in high quality image
generation in computer vision,and recently, GANs have gained lots of interest
from the NLP community as well. However, achieving similar success in NLP would
be more challenging due to the discrete nature of text. In this work, we
introduce a method using knowledge distillation to effectively exploit GAN
setup for text generation. We demonstrate how autoencoders (AEs) can be used
for providing a continuous representation of sentences, which is a smooth
representation that assign non-zero probabilities to more than one word. We
distill this representation to train the generator to synthesize similar smooth
representations. We perform a number of experiments to validate our idea using
different datasets and show that our proposed approach yields better
performance in terms of the BLEU score and Jensen-Shannon distance (JSD)
measure compared to traditional GAN-based text generation approaches without
pre-training."	ArXiv
1661	The Language of Legal and Illegal Activity on the Darknet	['Leshem Choshen', 'Dan Eldad', 'Daniel Hershcovich', 'Elior Sulem', 'Omri Abend']	2019-05-14 12:14:27+00:00	http://arxiv.org/abs/1905.05543v2	"The non-indexed parts of the Internet (the Darknet) have become a haven for
both legal and illegal anonymous activity. Given the magnitude of these
networks, scalably monitoring their activity necessarily relies on automated
tools, and notably on NLP tools. However, little is known about what
characteristics texts communicated through the Darknet have, and how well
off-the-shelf NLP tools do on this domain. This paper tackles this gap and
performs an in-depth investigation of the characteristics of legal and illegal
text in the Darknet, comparing it to a clear net website with similar content
as a control condition. Taking drug-related websites as a test case, we find
that texts for selling legal and illegal drugs have several linguistic
characteristics that distinguish them from one another, as well as from the
control condition, among them the distribution of POS tags, and the coverage of
their named entities in Wikipedia."	ArXiv
1662	BERT Rediscovers the Classical NLP Pipeline	['Ian Tenney', 'Dipanjan Das', 'Ellie Pavlick']	2019-05-15 05:47:23+00:00	http://arxiv.org/abs/1905.05950v2	"Pre-trained text encoders have rapidly advanced the state of the art on many
NLP tasks. We focus on one such model, BERT, and aim to quantify where
linguistic information is captured within the network. We find that the model
represents the steps of the traditional NLP pipeline in an interpretable and
localizable way, and that the regions responsible for each step appear in the
expected sequence: POS tagging, parsing, NER, semantic roles, then coreference.
Qualitative analysis reveals that the model can and often does adjust this
pipeline dynamically, revising lower-level decisions on the basis of
disambiguating information from higher-level representations."	ArXiv
1663	"Towards Automatic Generation of Shareable Synthetic Clinical Notes Using
  Neural Language Models"	['Oren Melamud', 'Chaitanya Shivade']	2019-05-16 19:14:18+00:00	http://arxiv.org/abs/1905.07002v2	"Large-scale clinical data is invaluable to driving many computational
scientific advances today. However, understandable concerns regarding patient
privacy hinder the open dissemination of such data and give rise to suboptimal
siloed research. De-identification methods attempt to address these concerns
but were shown to be susceptible to adversarial attacks. In this work, we focus
on the vast amounts of unstructured natural language data stored in clinical
notes and propose to automatically generate synthetic clinical notes that are
more amenable to sharing using generative models trained on real de-identified
records. To evaluate the merit of such notes, we measure both their privacy
preservation properties as well as utility in training clinical NLP models.
Experiments using neural language models yield notes whose utility is close to
that of the real ones in some clinical NLP tasks, yet leave ample room for
future improvements."	ArXiv
1664	Parsing Thai Social Data: A New Challenge for Thai NLP	['Sattaya Singkul', 'Borirat Khampingyot', 'Nattasit Maharattamalai', 'Supawat Taerungruang', 'Tawunrat Chalothorn']	2020-03-06 08:18:13+00:00	http://arxiv.org/abs/2003.03069v1	"Dependency parsing (DP) is a task that analyzes text for syntactic structure
and relationship between words. DP is widely used to improve natural language
processing (NLP) applications in many languages such as English. Previous works
on DP are generally applicable to formally written languages. However, they do
not apply to informal languages such as the ones used in social networks.
Therefore, DP has to be researched and explored with such social network data.
In this paper, we explore and identify a DP model that is suitable for Thai
social network data. After that, we will identify the appropriate linguistic
unit as an input. The result showed that, the transition based model called,
improve Elkared dependency parser outperform the others at UAS of 81.42%."	ArXiv
1665	Pre-trained Models for Natural Language Processing: A Survey	['Xipeng Qiu', 'Tianxiang Sun', 'Yige Xu', 'Yunfan Shao', 'Ning Dai', 'Xuanjing Huang']	2020-03-18 15:22:51+00:00	http://arxiv.org/abs/2003.08271v4	"Recently, the emergence of pre-trained models (PTMs) has brought natural
language processing (NLP) to a new era. In this survey, we provide a
comprehensive review of PTMs for NLP. We first briefly introduce language
representation learning and its research progress. Then we systematically
categorize existing PTMs based on a taxonomy with four perspectives. Next, we
describe how to adapt the knowledge of PTMs to the downstream tasks. Finally,
we outline some potential directions of PTMs for future research. This survey
is purposed to be a hands-on guide for understanding, using, and developing
PTMs for various NLP tasks."	ArXiv
1666	Meta Fine-Tuning Neural Language Models for Multi-Domain Text Mining	['Chengyu Wang', 'Minghui Qiu', 'Jun Huang', 'Xiaofeng He']	2020-03-29 11:27:10+00:00	http://arxiv.org/abs/2003.13003v2	"Pre-trained neural language models bring significant improvement for various
NLP tasks, by fine-tuning the models on task-specific training sets. During
fine-tuning, the parameters are initialized from pre-trained models directly,
which ignores how the learning process of similar NLP tasks in different
domains is correlated and mutually reinforced. In this paper, we propose an
effective learning procedure named Meta Fine-Tuning (MFT), served as a
meta-learner to solve a group of similar NLP tasks for neural language models.
Instead of simply multi-task training over all the datasets, MFT only learns
from typical instances of various domains to acquire highly transferable
knowledge. It further encourages the language model to encode domain-invariant
representations by optimizing a series of novel domain corruption loss
functions. After MFT, the model can be fine-tuned for each domain with better
parameter initializations and higher generalization ability. We implement MFT
upon BERT to solve several multi-domain text mining tasks. Experimental results
confirm the effectiveness of MFT and its usefulness for few-shot learning."	ArXiv
1667	Exploring and Predicting Transferability across NLP Tasks	['Tu Vu', 'Tong Wang', 'Tsendsuren Munkhdalai', 'Alessandro Sordoni', 'Adam Trischler', 'Andrew Mattarella-Micke', 'Subhransu Maji', 'Mohit Iyyer']	2020-05-02 09:39:36+00:00	http://arxiv.org/abs/2005.00770v2	"Recent advances in NLP demonstrate the effectiveness of training large-scale
language models and transferring them to downstream tasks. Can fine-tuning
these models on tasks other than language modeling further improve performance?
In this paper, we conduct an extensive study of the transferability between 33
NLP tasks across three broad classes of problems (text classification, question
answering, and sequence labeling). Our results show that transfer learning is
more beneficial than previously thought, especially when target task data is
scarce, and can improve performance even when the source task is small or
differs substantially from the target task (e.g., part-of-speech tagging
transfers well to the DROP QA dataset). We also develop task embeddings that
can be used to predict the most transferable source tasks for a given target
task, and we validate their effectiveness in experiments controlled for source
and target data size. Overall, our experiments reveal that factors such as
source data size, task and domain similarity, and task complexity all play a
role in determining transferability."	ArXiv
1668	Social Biases in NLP Models as Barriers for Persons with Disabilities	['Ben Hutchinson', 'Vinodkumar Prabhakaran', 'Emily Denton', 'Kellie Webster', 'Yu Zhong', 'Stephen Denuyl']	2020-05-02 12:16:54+00:00	http://arxiv.org/abs/2005.00813v1	"Building equitable and inclusive NLP technologies demands consideration of
whether and how social attitudes are represented in ML models. In particular,
representations encoded in models often inadvertently perpetuate undesirable
social biases from the data on which they are trained. In this paper, we
present evidence of such undesirable biases towards mentions of disability in
two different English language models: toxicity prediction and sentiment
analysis. Next, we demonstrate that the neural embeddings that are the critical
first step in most NLP pipelines similarly contain undesirable biases towards
mentions of disability. We end by highlighting topical biases in the discourse
about disability which may contribute to the observed model biases; for
instance, gun violence, homelessness, and drug addiction are over-represented
in texts discussing mental illness."	ArXiv
1669	Examining Citations of Natural Language Processing Literature	['Saif M. Mohammad']	2020-05-02 20:01:59+00:00	http://arxiv.org/abs/2005.00912v1	"We extracted information from the ACL Anthology (AA) and Google Scholar (GS)
to examine trends in citations of NLP papers. We explore questions such as: how
well cited are papers of different types (journal articles, conference papers,
demo papers, etc.)? how well cited are papers from different areas of within
NLP? etc. Notably, we show that only about 56\% of the papers in AA are cited
ten or more times. CL Journal has the most cited papers, but its citation
dominance has lessened in recent years. On average, long papers get almost
three times as many citations as short papers; and papers on sentiment
classification, anaphora resolution, and entity recognition have the highest
median citations. The analyses presented here, and the associated dataset of
NLP papers mapped to citations, have a number of uses including: understanding
how the field is growing and quantifying the impact of different types of
papers."	ArXiv
1670	ParsBERT: Transformer-based Model for Persian Language Understanding	['Mehrdad Farahani', 'Mohammad Gharachorloo', 'Marzieh Farahani', 'Mohammad Manthouri']	2020-05-26 05:05:32+00:00	http://arxiv.org/abs/2005.12515v2	"The surge of pre-trained language models has begun a new era in the field of
Natural Language Processing (NLP) by allowing us to build powerful language
models. Among these models, Transformer-based models such as BERT have become
increasingly popular due to their state-of-the-art performance. However, these
models are usually focused on English, leaving other languages to multilingual
models with limited resources. This paper proposes a monolingual BERT for the
Persian language (ParsBERT), which shows its state-of-the-art performance
compared to other architectures and multilingual models. Also, since the amount
of data available for NLP tasks in Persian is very restricted, a massive
dataset for different NLP tasks as well as pre-training the model is composed.
ParsBERT obtains higher scores in all datasets, including existing ones as well
as composed ones and improves the state-of-the-art performance by outperforming
both multilingual BERT and other prior works in Sentiment Analysis, Text
Classification and Named Entity Recognition tasks."	ArXiv
1671	"Give Me Convenience and Give Her Death: Who Should Decide What Uses of
  NLP are Appropriate, and on What Basis?"	['Kobi Leins', 'Jey Han Lau', 'Timothy Baldwin']	2020-05-27 07:31:57+00:00	http://arxiv.org/abs/2005.13213v1	"As part of growing NLP capabilities, coupled with an awareness of the ethical
dimensions of research, questions have been raised about whether particular
datasets and tasks should be deemed off-limits for NLP research. We examine
this question with respect to a paper on automatic legal sentencing from EMNLP
2019 which was a source of some debate, in asking whether the paper should have
been allowed to be published, who should have been charged with making such a
decision, and on what basis. We focus in particular on the role of data
statements in ethically assessing research, but also discuss the topic of dual
use, and examine the outcomes of similar debates in other scientific
disciplines."	ArXiv
1672	Improving Part-of-Speech Tagging for NLP Pipelines	['Vishaal Jatav', 'Ravi Teja', 'Srini Bharadwaj', 'Venkat Srinivasan']	2017-08-01 10:56:17+00:00	http://arxiv.org/abs/1708.00241v1	"This paper outlines the results of sentence level linguistics based rules for
improving part-of-speech tagging. It is well known that the performance of
complex NLP systems is negatively affected if one of the preliminary stages is
less than perfect. Errors in the initial stages in the pipeline have a
snowballing effect on the pipeline's end performance. We have created a set of
linguistics based rules at the sentence level which adjust part-of-speech tags
from state-of-the-art taggers. Comparison with state-of-the-art taggers on
widely used benchmarks demonstrate significant improvements in tagging accuracy
and consequently in the quality and accuracy of NLP systems."	ArXiv
1673	Recent Trends in Deep Learning Based Natural Language Processing	['Tom Young', 'Devamanyu Hazarika', 'Soujanya Poria', 'Erik Cambria']	2017-08-09 04:02:17+00:00	http://arxiv.org/abs/1708.02709v8	"Deep learning methods employ multiple processing layers to learn hierarchical
representations of data and have produced state-of-the-art results in many
domains. Recently, a variety of model designs and methods have blossomed in the
context of natural language processing (NLP). In this paper, we review
significant deep learning related models and methods that have been employed
for numerous NLP tasks and provide a walk-through of their evolution. We also
summarize, compare and contrast the various models and put forward a detailed
understanding of the past, present and future of deep learning in NLP."	ArXiv
1674	Glyph-aware Embedding of Chinese Characters	['Falcon Z. Dai', 'Zheng Cai']	2017-08-31 18:19:08+00:00	http://arxiv.org/abs/1709.00028v1	"Given the advantage and recent success of English character-level and
subword-unit models in several NLP tasks, we consider the equivalent modeling
problem for Chinese. Chinese script is logographic and many Chinese logograms
are composed of common substructures that provide semantic, phonetic and
syntactic hints. In this work, we propose to explicitly incorporate the visual
appearance of a character's glyph in its representation, resulting in a novel
glyph-aware embedding of Chinese characters. Being inspired by the success of
convolutional neural networks in computer vision, we use them to incorporate
the spatio-structural patterns of Chinese glyphs as rendered in raw pixels. In
the context of two basic Chinese NLP tasks of language modeling and word
segmentation, the model learns to represent each character's task-relevant
semantic and syntactic information in the character-level embedding."	ArXiv
1675	A Feature-Rich Vietnamese Named-Entity Recognition Model	['Pham Quang Nhat Minh']	2018-03-12 17:07:40+00:00	http://arxiv.org/abs/1803.04375v1	"In this paper, we present a feature-based named-entity recognition (NER)
model that achieves the start-of-the-art accuracy for Vietnamese language. We
combine word, word-shape features, PoS, chunk, Brown-cluster-based features,
and word-embedding-based features in the Conditional Random Fields (CRF) model.
We also explore the effects of word segmentation, PoS tagging, and chunking
results of many popular Vietnamese NLP toolkits on the accuracy of the proposed
feature-based NER model. Up to now, our work is the first work that
systematically performs an extrinsic evaluation of basic Vietnamese NLP
toolkits on the downstream NER task. Experimental results show that while
automatically-generated word segmentation is useful, PoS and chunking
information generated by Vietnamese NLP tools does not show their benefits for
the proposed feature-based NER model."	ArXiv
1676	"A Natural Language-Inspired Multi-label Video Streaming Traffic
  Classification Method Based on Deep Neural Networks"	['Yan Shi', 'Dezhi Feng', 'Subir Biswas']	2019-06-04 00:21:21+00:00	http://arxiv.org/abs/1906.02679v1	"This paper presents a deep-learning based traffic classification method for
identifying multiple streaming video sources at the same time within an
encrypted tunnel. The work defines a novel feature inspired by Natural Language
Processing (NLP) that allows existing NLP techniques to help the traffic
classification. The feature extraction method is described, and a large dataset
containing video streaming and web traffic is created to verify its
effectiveness. Results are obtained by applying several NLP methods to show
that the proposed method performs well on both binary and multilabel traffic
classification problems. We also show the ability to achieve zero-shot learning
with the proposed method."	ArXiv
1677	"Towards Scalable and Reliable Capsule Networks for Challenging NLP
  Applications"	['Wei Zhao', 'Haiyun Peng', 'Steffen Eger', 'Erik Cambria', 'Min Yang']	2019-06-06 21:53:53+00:00	http://arxiv.org/abs/1906.02829v1	"Obstacles hindering the development of capsule networks for challenging NLP
applications include poor scalability to large output spaces and less reliable
routing processes. In this paper, we introduce: 1) an agreement score to
evaluate the performance of routing processes at instance level; 2) an adaptive
optimizer to enhance the reliability of routing; 3) capsule compression and
partial routing to improve the scalability of capsule networks. We validate our
approach on two NLP tasks, namely: multi-label text classification and question
answering. Experimental results show that our approach considerably improves
over strong competitors on both tasks. In addition, we gain the best results in
low-resource settings with few training instances."	ArXiv
1678	"Lightweight and Efficient Neural Natural Language Processing with
  Quaternion Networks"	['Yi Tay', 'Aston Zhang', 'Luu Anh Tuan', 'Jinfeng Rao', 'Shuai Zhang', 'Shuohang Wang', 'Jie Fu', 'Siu Cheung Hui']	2019-06-11 04:56:17+00:00	http://arxiv.org/abs/1906.04393v1	"Many state-of-the-art neural models for NLP are heavily parameterized and
thus memory inefficient. This paper proposes a series of lightweight and memory
efficient neural architectures for a potpourri of natural language processing
(NLP) tasks. To this end, our models exploit computation using Quaternion
algebra and hypercomplex spaces, enabling not only expressive inter-component
interactions but also significantly ($75\%$) reduced parameter size due to
lesser degrees of freedom in the Hamilton product. We propose Quaternion
variants of models, giving rise to new architectures such as the Quaternion
attention Model and Quaternion Transformer. Extensive experiments on a battery
of NLP tasks demonstrates the utility of proposed Quaternion-inspired models,
enabling up to $75\%$ reduction in parameter size without significant loss in
performance."	ArXiv
1679	"Surf at MEDIQA 2019: Improving Performance of Natural Language Inference
  in the Clinical Domain by Adopting Pre-trained Language Model"	['Jiin Nam', 'Seunghyun Yoon', 'Kyomin Jung']	2019-06-19 00:13:04+00:00	http://arxiv.org/abs/1906.07854v1	"While deep learning techniques have shown promising results in many natural
language processing (NLP) tasks, it has not been widely applied to the clinical
domain. The lack of large datasets and the pervasive use of domain-specific
language (i.e. abbreviations and acronyms) in the clinical domain causes slower
progress in NLP tasks than that of the general NLP tasks. To fill this gap, we
employ word/subword-level based models that adopt large-scale data-driven
methods such as pre-trained language models and transfer learning in analyzing
text for the clinical domain. Empirical results demonstrate the superiority of
the proposed methods by achieving 90.6% accuracy in medical domain natural
language inference task. Furthermore, we inspect the independent strengths of
the proposed approaches in quantitative and qualitative manners. This analysis
will help researchers to select necessary components in building models for the
medical domain."	ArXiv
1680	"Processamento de linguagem natural em Português e aprendizagem
  profunda para o domínio de Óleo e Gás"	['Diogo Gomes', 'Alexandre Evsukoff']	2019-08-05 15:05:48+00:00	http://arxiv.org/abs/1908.01674v2	"Over the last few decades, institutions around the world have been challenged
to deal with the sheer volume of information captured in unstructured formats,
especially in textual documents. The so called Digital Transformation age,
characterized by important technological advances and the advent of disruptive
methods in Artificial Intelligence, offers opportunities to make better use of
this information. Recent techniques in Natural Language Processing (NLP) with
Deep Learning approaches allow to efficiently process a large volume of data in
order to obtain relevant information, to identify patterns, classify text,
among other applications. In this context, the highly technical vocabulary of
Oil and Gas (O&G) domain represents a challenge for these NLP algorithms, in
which terms can assume a very different meaning in relation to common sense
understanding. The search for suitable mathematical representations and
specific models requires a large amount of representative corpora in the O&G
domain. However, public access to this material is scarce in the scientific
literature, especially considering the Portuguese language. This paper presents
a literature review about the main techniques for deep learning NLP and their
major applications for O&G domain in Portuguese."	ArXiv
1681	Self-Knowledge Distillation in Natural Language Processing	['Sangchul Hahn', 'Heeyoul Choi']	2019-08-02 15:17:27+00:00	http://arxiv.org/abs/1908.01851v1	"Since deep learning became a key player in natural language processing (NLP),
many deep learning models have been showing remarkable performances in a
variety of NLP tasks, and in some cases, they are even outperforming humans.
Such high performance can be explained by efficient knowledge representation of
deep learning models. While many methods have been proposed to learn more
efficient representation, knowledge distillation from pretrained deep networks
suggest that we can use more information from the soft target probability to
train other neural networks. In this paper, we propose a new knowledge
distillation method self-knowledge distillation, based on the soft target
probabilities of the training model itself, where multimode information is
distilled from the word embedding space right below the softmax layer. Due to
the time complexity, our method approximates the soft target probabilities. In
experiments, we applied the proposed method to two different and fundamental
NLP tasks: language model and neural machine translation. The experiment
results show that our proposed method improves performance on the tasks."	ArXiv
1682	"On the Effectiveness of Low-Rank Matrix Factorization for LSTM Model
  Compression"	['Genta Indra Winata', 'Andrea Madotto', 'Jamin Shin', 'Elham J. Barezi', 'Pascale Fung']	2019-08-27 01:52:07+00:00	http://arxiv.org/abs/1908.09982v1	"Despite their ubiquity in NLP tasks, Long Short-Term Memory (LSTM) networks
suffer from computational inefficiencies caused by inherent unparallelizable
recurrences, which further aggravates as LSTMs require more parameters for
larger memory capacity. In this paper, we propose to apply low-rank matrix
factorization (MF) algorithms to different recurrences in LSTMs, and explore
the effectiveness on different NLP tasks and model components. We discover that
additive recurrence is more important than multiplicative recurrence, and
explain this by identifying meaningful correlations between matrix norms and
compression performance. We compare our approach across two settings: 1)
compressing core LSTM recurrences in language models, 2) compressing biLSTM
layers of ELMo evaluated in three downstream NLP tasks."	ArXiv
1683	"PidginUNMT: Unsupervised Neural Machine Translation from West African
  Pidgin to English"	['Kelechi Ogueji', 'Orevaoghene Ahia']	2019-12-07 05:30:09+00:00	http://arxiv.org/abs/1912.03444v1	"Over 800 languages are spoken across West Africa. Despite the obvious
diversity among people who speak these languages, one language significantly
unifies them all - West African Pidgin English. There are at least 80 million
speakers of West African Pidgin English. However, there is no known natural
language processing (NLP) work on this language. In this work, we perform the
first NLP work on the most popular variant of the language, providing three
major contributions. First, the provision of a Pidgin corpus of over 56000
sentences, which is the largest we know of. Secondly, the training of the first
ever cross-lingual embedding between Pidgin and English. This aligned embedding
will be helpful in the performance of various downstream tasks between English
and Pidgin. Thirdly, the training of an Unsupervised Neural Machine Translation
model between Pidgin and English which achieves BLEU scores of 7.93 from Pidgin
to English, and 5.18 from English to Pidgin. In all, this work greatly reduces
the barrier of entry for future NLP works on West African Pidgin English."	ArXiv
1684	"Relations between Abs-Normal NLPs and MPCCs. Part 2: Weak Constraint
  Qualifications"	['Lisa C. Hegerhorst-Schultchen', 'Christian Kirches', 'Marc C. Steinbach']	2020-07-29 07:58:52+00:00	http://arxiv.org/abs/2007.14653v4	"This work continues an ongoing effort to compare non-smooth optimization
problems in abs-normal form to Mathematical Programs with Complementarity
Constraints (MPCCs). We study general Nonlinear Programs with equality and
inequality constraints in abs-normal form, so-called Abs-Normal NLPs, and their
relation to equivalent MPCC reformulations. We introduce the concepts of
Abadie's and Guignard's kink qualification and prove relations to MPCC-ACQ and
MPCC-GCQ for the counterpart MPCC formulations. Due to non-uniqueness of a
specific slack reformulation suggested in [10], the relations are non-trivial.
It turns out that constraint qualifications of Abadie type are preserved. We
also prove the weaker result that equivalence of Guginard's (and Abadie's)
constraint qualifications for all branch problems hold, while the question of
GCQ preservation remains open. Finally, we introduce M-stationarity and
B-stationarity concepts for abs-normal NLPs and prove first order optimality
conditions corresponding to MPCC counterpart formulations."	ArXiv
1685	"CLEVR Parser: A Graph Parser Library for Geometric Learning on Language
  Grounded Image Scenes"	['Raeid Saqur', 'Ameet Deshpande']	2020-09-19 03:32:37+00:00	http://arxiv.org/abs/2009.09154v2	"The CLEVR dataset has been used extensively in language grounded visual
reasoning in Machine Learning (ML) and Natural Language Processing (NLP)
domains. We present a graph parser library for CLEVR, that provides
functionalities for object-centric attributes and relationships extraction, and
construction of structural graph representations for dual modalities.
Structural order-invariant representations enable geometric learning and can
aid in downstream tasks like language grounding to vision, robotics,
compositionality, interpretability, and computational grammar construction. We
provide three extensible main components - parser, embedder, and visualizer
that can be tailored to suit specific learning setups. We also provide
out-of-the-box functionality for seamless integration with popular deep graph
neural network (GNN) libraries. Additionally, we discuss downstream usage and
applications of the library, and how it accelerates research for the NLP
research community."	ArXiv
1686	Exponential Decay of Sensitivity in Graph-Structured Nonlinear Programs	['Sungho Shin', 'Mihai Anitescu', 'Victor M. Zavala']	2021-01-08 15:49:11+00:00	http://arxiv.org/abs/2101.03067v2	"We study solution sensitivity for nonlinear programs (NLPs) whose structures
are induced by graphs. These NLPs arise in many applications such as dynamic
optimization, stochastic optimization, optimization with partial differential
equations, and network optimization. We show that for a given pair of nodes,
the sensitivity of the primal-dual solution at one node against a data
perturbation at the other node decays exponentially with respect to the
distance between these two nodes on the graph. In other words, the solution
sensitivity decays as one moves away from the perturbation point. This result,
which we call exponential decay of sensitivity, holds under the strong
second-order sufficiency condition and the linear independence constraint
qualification. We also present conditions under which the decay rate remains
uniformly bounded; this allows us to characterize the sensitivity behavior of
NLPs defined over subgraphs of infinite graphs. The theoretical developments
are illustrated with numerical examples."	ArXiv
1687	"Does Dialog Length matter for Next Response Selection task? An Empirical
  Study"	['Jatin Ganhotra', 'Sachindra Joshi']	2021-01-24 05:39:36+00:00	http://arxiv.org/abs/2101.09647v1	"In the last few years, the release of BERT, a multilingual transformer based
model, has taken the NLP community by storm. BERT-based models have achieved
state-of-the-art results on various NLP tasks, including dialog tasks. One of
the limitation of BERT is the lack of ability to handle long text sequence. By
default, BERT has a maximum wordpiece token sequence length of 512. Recently,
there has been renewed interest to tackle the BERT limitation to handle long
text sequences with the addition of new self-attention based architectures.
However, there has been little to no research on the impact of this limitation
with respect to dialog tasks. Dialog tasks are inherently different from other
NLP tasks due to: a) the presence of multiple utterances from multiple
speakers, which may be interlinked to each other across different turns and b)
longer length of dialogs. In this work, we empirically evaluate the impact of
dialog length on the performance of BERT model for the Next Response Selection
dialog task on four publicly available and one internal multi-turn dialog
datasets. We observe that there is little impact on performance with long
dialogs and even the simplest approach of truncating input works really well."	ArXiv
1688	"Evaluation of BERT and ALBERT Sentence Embedding Performance on
  Downstream NLP Tasks"	['Hyunjin Choi', 'Judong Kim', 'Seongho Joe', 'Youngjune Gwon']	2021-01-26 09:14:06+00:00	http://arxiv.org/abs/2101.10642v1	"Contextualized representations from a pre-trained language model are central
to achieve a high performance on downstream NLP task. The pre-trained BERT and
A Lite BERT (ALBERT) models can be fine-tuned to give state-ofthe-art results
in sentence-pair regressions such as semantic textual similarity (STS) and
natural language inference (NLI). Although BERT-based models yield the [CLS]
token vector as a reasonable sentence embedding, the search for an optimal
sentence embedding scheme remains an active research area in computational
linguistics. This paper explores on sentence embedding models for BERT and
ALBERT. In particular, we take a modified BERT network with siamese and triplet
network structures called Sentence-BERT (SBERT) and replace BERT with ALBERT to
create Sentence-ALBERT (SALBERT). We also experiment with an outer CNN
sentence-embedding network for SBERT and SALBERT. We evaluate performances of
all sentence-embedding models considered using the STS and NLI datasets. The
empirical results indicate that our CNN architecture improves ALBERT models
substantially more than BERT models for STS benchmark. Despite significantly
fewer model parameters, ALBERT sentence embedding is highly competitive to BERT
in downstream NLP evaluations."	ArXiv
1689	CUAD: An Expert-Annotated NLP Dataset for Legal Contract Review	['Dan Hendrycks', 'Collin Burns', 'Anya Chen', 'Spencer Ball']	2021-03-10 18:59:34+00:00	http://arxiv.org/abs/2103.06268v2	"Many specialized domains remain untouched by deep learning, as large labeled
datasets require expensive expert annotators. We address this bottleneck within
the legal domain by introducing the Contract Understanding Atticus Dataset
(CUAD), a new dataset for legal contract review. CUAD was created with dozens
of legal experts from The Atticus Project and consists of over 13,000
annotations. The task is to highlight salient portions of a contract that are
important for a human to review. We find that Transformer models have nascent
performance, but that this performance is strongly influenced by model design
and training dataset size. Despite these promising results, there is still
substantial room for improvement. As one of the only large, specialized NLP
benchmarks annotated by experts, CUAD can serve as a challenging research
benchmark for the broader NLP community."	ArXiv
1690	An Approach to Improve Robustness of NLP Systems against ASR Errors	['Tong Cui', 'Jinghui Xiao', 'Liangyou Li', 'Xin Jiang', 'Qun Liu']	2021-03-25 05:15:43+00:00	http://arxiv.org/abs/2103.13610v1	"Speech-enabled systems typically first convert audio to text through an
automatic speech recognition (ASR) model and then feed the text to downstream
natural language processing (NLP) modules. The errors of the ASR system can
seriously downgrade the performance of the NLP modules. Therefore, it is
essential to make them robust to the ASR errors. Previous work has shown it is
effective to employ data augmentation methods to solve this problem by
injecting ASR noise during the training process. In this paper, we utilize the
prevalent pre-trained language model to generate training samples with
ASR-plausible noise. Compare to the previous methods, our approach generates
ASR noise that better fits the real-world error distribution. Experimental
results on spoken language translation(SLT) and spoken language understanding
(SLU) show that our approach effectively improves the system robustness against
the ASR errors and achieves state-of-the-art results on both tasks."	ArXiv
1691	"An Automated Multiple-Choice Question Generation Using Natural Language
  Processing Techniques"	['Chidinma A. Nwafor', 'Ikechukwu E. Onyenwe']	2021-03-26 22:39:59+00:00	http://arxiv.org/abs/2103.14757v1	"Automatic multiple-choice question generation (MCQG) is a useful yet
challenging task in Natural Language Processing (NLP). It is the task of
automatic generation of correct and relevant questions from textual data.
Despite its usefulness, manually creating sizeable, meaningful and relevant
questions is a time-consuming and challenging task for teachers. In this paper,
we present an NLP-based system for automatic MCQG for Computer-Based Testing
Examination (CBTE).We used NLP technique to extract keywords that are important
words in a given lesson material. To validate that the system is not perverse,
five lesson materials were used to check the effectiveness and efficiency of
the system. The manually extracted keywords by the teacher were compared to the
auto-generated keywords and the result shows that the system was capable of
extracting keywords from lesson materials in setting examinable questions. This
outcome is presented in a user-friendly interface for easy accessibility."	ArXiv
1692	"Be Careful about Poisoned Word Embeddings: Exploring the Vulnerability
  of the Embedding Layers in NLP Models"	['Wenkai Yang', 'Lei Li', 'Zhiyuan Zhang', 'Xuancheng Ren', 'Xu Sun', 'Bin He']	2021-03-29 12:19:45+00:00	http://arxiv.org/abs/2103.15543v1	"Recent studies have revealed a security threat to natural language processing
(NLP) models, called the Backdoor Attack. Victim models can maintain
competitive performance on clean samples while behaving abnormally on samples
with a specific trigger word inserted. Previous backdoor attacking methods
usually assume that attackers have a certain degree of data knowledge, either
the dataset which users would use or proxy datasets for a similar task, for
implementing the data poisoning procedure. However, in this paper, we find that
it is possible to hack the model in a data-free way by modifying one single
word embedding vector, with almost no accuracy sacrificed on clean samples.
Experimental results on sentiment analysis and sentence-pair classification
tasks show that our method is more efficient and stealthier. We hope this work
can raise the awareness of such a critical security risk hidden in the
embedding layers of NLP models. Our code is available at
https://github.com/lancopku/Embedding-Poisoning."	ArXiv
1693	Legal Transformer Models May Not Always Help	['Saibo Geng', 'Rémi Lebret', 'Karl Aberer']	2021-09-14 17:53:55+00:00	http://arxiv.org/abs/2109.06862v2	"Deep learning-based Natural Language Processing methods, especially
transformers, have achieved impressive performance in the last few years.
Applying those state-of-the-art NLP methods to legal activities to automate or
simplify some simple work is of great value. This work investigates the value
of domain adaptive pre-training and language adapters in legal NLP tasks. By
comparing the performance of language models with domain adaptive pre-training
on different tasks and different dataset splits, we show that domain adaptive
pre-training is only helpful with low-resource downstream tasks, thus far from
being a panacea. We also benchmark the performance of adapters in a typical
legal NLP task and show that they can yield similar performance to full model
tuning with much smaller training costs. As an additional result, we release
LegalRoBERTa, a RoBERTa model further pre-trained on legal corpora."	ArXiv
1694	Training Dynamic based data filtering may not work for NLP datasets	['Arka Talukdar', 'Monika Dagar', 'Prachi Gupta', 'Varun Menon']	2021-09-19 18:50:45+00:00	http://arxiv.org/abs/2109.09191v1	"The recent increase in dataset size has brought about significant advances in
natural language understanding. These large datasets are usually collected
through automation (search engines or web crawlers) or crowdsourcing which
inherently introduces incorrectly labeled data. Training on these datasets
leads to memorization and poor generalization. Thus, it is pertinent to develop
techniques that help in the identification and isolation of mislabelled data.
In this paper, we study the applicability of the Area Under the Margin (AUM)
metric to identify and remove/rectify mislabelled examples in NLP datasets. We
find that mislabelled samples can be filtered using the AUM metric in NLP
datasets but it also removes a significant number of correctly labeled points
and leads to the loss of a large amount of relevant language information. We
show that models rely on the distributional information instead of relying on
syntactic and semantic representations."	ArXiv
1695	"Evaluating NLP Systems On a Novel Cloze Task: Judging the Plausibility
  of Possible Fillers in Instructional Texts"	['Zizhao Hu', 'Ravikiran Chanumolu', 'Xingyu Lin', 'Nayela Ayaz', 'Vincent Chi']	2021-12-03 12:02:52+00:00	http://arxiv.org/abs/2112.01867v1	"Cloze task is a widely used task to evaluate an NLP system's language
understanding ability. However, most of the existing cloze tasks only require
NLP systems to give the relative best prediction for each input data sample,
rather than the absolute quality of all possible predictions, in a consistent
way across the input domain. Thus a new task is proposed: predicting if a
filler word in a cloze task is a good, neutral, or bad candidate. Complicated
versions can be extended to predicting more discrete classes or continuous
scores. We focus on subtask A in Semeval 2022 task 7, explored some possible
architectures to solve this new task, provided a detailed comparison of them,
and proposed an ensemble method to improve traditional models in this new task."	ArXiv
1696	JUSTICE: A Benchmark Dataset for Supreme Court's Judgment Prediction	['Mohammad Alali', 'Shaayan Syed', 'Mohammed Alsayed', 'Smit Patel', 'Hemanth Bodala']	2021-12-06 23:19:08+00:00	http://arxiv.org/abs/2112.03414v1	"Artificial intelligence is being utilized in many domains as of late, and the
legal system is no exception. However, as it stands now, the number of
well-annotated datasets pertaining to legal documents from the Supreme Court of
the United States (SCOTUS) is very limited for public use. Even though the
Supreme Court rulings are public domain knowledge, trying to do meaningful work
with them becomes a much greater task due to the need to manually gather and
process that data from scratch each time. Hence, our goal is to create a
high-quality dataset of SCOTUS court cases so that they may be readily used in
natural language processing (NLP) research and other data-driven applications.
Additionally, recent advances in NLP provide us with the tools to build
predictive models that can be used to reveal patterns that influence court
decisions. By using advanced NLP algorithms to analyze previous court cases,
the trained models are able to predict and classify a court's judgment given
the case's facts from the plaintiff and the defendant in textual format; in
other words, the model is emulating a human jury by generating a final verdict."	ArXiv
1697	"Word Embeddings via Causal Inference: Gender Bias Reducing and Semantic
  Information Preserving"	['Lei Ding', 'Dengdeng Yu', 'Jinhan Xie', 'Wenxing Guo', 'Shenggang Hu', 'Meichen Liu', 'Linglong Kong', 'Hongsheng Dai', 'Yanchun Bao', 'Bei Jiang']	2021-12-09 19:57:22+00:00	http://arxiv.org/abs/2112.05194v1	"With widening deployments of natural language processing (NLP) in daily life,
inherited social biases from NLP models have become more severe and
problematic. Previous studies have shown that word embeddings trained on
human-generated corpora have strong gender biases that can produce
discriminative results in downstream tasks. Previous debiasing methods focus
mainly on modeling bias and only implicitly consider semantic information while
completely overlooking the complex underlying causal structure among bias and
semantic components. To address these issues, we propose a novel methodology
that leverages a causal inference framework to effectively remove gender bias.
The proposed method allows us to construct and analyze the complex causal
mechanisms facilitating gender information flow while retaining oracle semantic
information within word embeddings. Our comprehensive experiments show that the
proposed method achieves state-of-the-art results in gender-debiasing tasks. In
addition, our methods yield better performance in word similarity evaluation
and various extrinsic downstream NLP tasks."	ArXiv
1698	"LINDA: Unsupervised Learning to Interpolate in Natural Language
  Processing"	['Yekyung Kim', 'Seohyeong Jeong', 'Kyunghyun Cho']	2021-12-28 02:56:41+00:00	http://arxiv.org/abs/2112.13969v1	"Despite the success of mixup in data augmentation, its applicability to
natural language processing (NLP) tasks has been limited due to the discrete
and variable-length nature of natural languages. Recent studies have thus
relied on domain-specific heuristics and manually crafted resources, such as
dictionaries, in order to apply mixup in NLP. In this paper, we instead propose
an unsupervised learning approach to text interpolation for the purpose of data
augmentation, to which we refer as ""Learning to INterpolate for Data
Augmentation"" (LINDA), that does not require any heuristics nor manually
crafted resources but learns to interpolate between any pair of natural
language sentences over a natural language manifold. After empirically
demonstrating the LINDA's interpolation capability, we show that LINDA indeed
allows us to seamlessly apply mixup in NLP and leads to better generalization
in text classification both in-domain and out-of-domain."	ArXiv
1699	"Beyond modeling: NLP Pipeline for efficient environmental policy
  analysis"	['Jordi Planas', 'Daniel Firebanks-Quevedo', 'Galina Naydenova', 'Ramansh Sharma', 'Cristina Taylor', 'Kathleen Buckingham', 'Rong Fang']	2022-01-08 05:33:04+00:00	http://arxiv.org/abs/2201.07105v1	"As we enter the UN Decade on Ecosystem Restoration, creating effective
incentive structures for forest and landscape restoration has never been more
critical. Policy analysis is necessary for policymakers to understand the
actors and rules involved in restoration in order to shift economic and
financial incentives to the right places. Classical policy analysis is
resource-intensive and complex, lacks comprehensive central information
sources, and is prone to overlapping jurisdictions. We propose a Knowledge
Management Framework based on Natural Language Processing (NLP) techniques that
would tackle these challenges and automate repetitive tasks, reducing the
policy analysis process from weeks to minutes. Our framework was designed in
collaboration with policy analysis experts and made to be platform-, language-
and policy-agnostic. In this paper, we describe the design of the NLP pipeline,
review the state-of-the-art methods for each of its components, and discuss the
challenges that rise when building a framework oriented towards policy
analysis."	ArXiv
1700	Artefact Retrieval: Overview of NLP Models with Knowledge Base Access	['Vilém Zouhar', 'Marius Mosbach', 'Debanjali Biswas', 'Dietrich Klakow']	2022-01-24 13:15:33+00:00	http://arxiv.org/abs/2201.09651v1	"Many NLP models gain performance by having access to a knowledge base. A lot
of research has been devoted to devising and improving the way the knowledge
base is accessed and incorporated into the model, resulting in a number of
mechanisms and pipelines. Despite the diversity of proposed mechanisms, there
are patterns in the designs of such systems. In this paper, we systematically
describe the typology of artefacts (items retrieved from a knowledge base),
retrieval mechanisms and the way these artefacts are fused into the model. This
further allows us to uncover combinations of design decisions that had not yet
been tried. Most of the focus is given to language models, though we also show
how question answering, fact-checking and knowledgable dialogue models fit into
this system as well. Having an abstract model which can describe the
architecture of specific models also helps with transferring these
architectures between multiple NLP tasks."	ArXiv
1701	A Decade of Knowledge Graphs in Natural Language Processing: A Survey	['Phillip Schneider', 'Tim Schopf', 'Juraj Vladika', 'Mikhail Galkin', 'Elena Simperl', 'Florian Matthes']	2022-09-30 21:53:57+00:00	http://arxiv.org/abs/2210.00105v1	"In pace with developments in the research field of artificial intelligence,
knowledge graphs (KGs) have attracted a surge of interest from both academia
and industry. As a representation of semantic relations between entities, KGs
have proven to be particularly relevant for natural language processing (NLP),
experiencing a rapid spread and wide adoption within recent years. Given the
increasing amount of research work in this area, several KG-related approaches
have been surveyed in the NLP research community. However, a comprehensive
study that categorizes established topics and reviews the maturity of
individual research streams remains absent to this day. Contributing to closing
this gap, we systematically analyzed 507 papers from the literature on KGs in
NLP. Our survey encompasses a multifaceted review of tasks, research types, and
contributions. As a result, we present a structured overview of the research
landscape, provide a taxonomy of tasks, summarize our findings, and highlight
directions for future work."	ArXiv
1702	"Factorization at subleading power in deep inelastic scattering in the
  $x\rightarrow 1$ limit"	['Michael Luke', 'Jyotirmoy Roy', 'Aris Spourdalakis']	2022-10-05 19:59:33+00:00	http://arxiv.org/abs/2210.02529v2	"We examine the endpoint region of inclusive deep inelastic scattering at
next-to-leading power (NLP). Using a soft-collinear effective theory approach
with no explicit soft or collinear modes, we discuss the factorization of the
cross section at NLP and show that the overlap subtraction procedure introduced
to eliminate double counting of degrees of freedom at leading power ensures
that spurious endpoint divergences in the rate cancel at NLP at one loop. For
this cancellation to occur at all renormalization scales a nontrivial relation
between the anomalous dimensions of the leading and subleading operators is
required, which is demonstrated to hold at one loop."	ArXiv
1703	TestAug: A Framework for Augmenting Capability-based NLP Tests	['Guanqun Yang', 'Mirazul Haque', 'Qiaochu Song', 'Wei Yang', 'Xueqing Liu']	2022-10-14 20:42:16+00:00	http://arxiv.org/abs/2210.08097v1	"The recently proposed capability-based NLP testing allows model developers to
test the functional capabilities of NLP models, revealing functional failures
that cannot be detected by the traditional heldout mechanism. However, existing
work on capability-based testing requires extensive manual efforts and domain
expertise in creating the test cases. In this paper, we investigate a low-cost
approach for the test case generation by leveraging the GPT-3 engine. We
further propose to use a classifier to remove the invalid outputs from GPT-3
and expand the outputs into templates to generate more test cases. Our
experiments show that TestAug has three advantages over the existing work on
behavioral testing: (1) TestAug can find more bugs than existing work; (2) The
test cases in TestAug are more diverse; and (3) TestAug largely saves the
manual efforts in creating the test suites. The code and data for TestAug can
be found at our project website (https://guanqun-yang.github.io/testaug/) and
GitHub (https://github.com/guanqun-yang/testaug)."	ArXiv
1704	Evidence > Intuition: Transferability Estimation for Encoder Selection	['Elisa Bassignana', 'Max Müller-Eberstein', 'Mike Zhang', 'Barbara Plank']	2022-10-20 13:25:21+00:00	http://arxiv.org/abs/2210.11255v1	"With the increase in availability of large pre-trained language models (LMs)
in Natural Language Processing (NLP), it becomes critical to assess their fit
for a specific target task a priori - as fine-tuning the entire space of
available LMs is computationally prohibitive and unsustainable. However,
encoder transferability estimation has received little to no attention in NLP.
In this paper, we propose to generate quantitative evidence to predict which
LM, out of a pool of models, will perform best on a target task without having
to fine-tune all candidates. We provide a comprehensive study on LM ranking for
10 NLP tasks spanning the two fundamental problem types of classification and
structured prediction. We adopt the state-of-the-art Logarithm of Maximum
Evidence (LogME) measure from Computer Vision (CV) and find that it positively
correlates with final LM performance in 94% of the setups. In the first study
of its kind, we further compare transferability measures with the de facto
standard of human practitioner ranking, finding that evidence from quantitative
metrics is more robust than pure intuition and can help identify unexpected LM
candidates."	ArXiv
1705	Finding Dataset Shortcuts with Grammar Induction	['Dan Friedman', 'Alexander Wettig', 'Danqi Chen']	2022-10-20 19:54:11+00:00	http://arxiv.org/abs/2210.11560v1	"Many NLP datasets have been found to contain shortcuts: simple decision rules
that achieve surprisingly high accuracy. However, it is difficult to discover
shortcuts automatically. Prior work on automatic shortcut detection has focused
on enumerating features like unigrams or bigrams, which can find only low-level
shortcuts, or relied on post-hoc model interpretability methods like saliency
maps, which reveal qualitative patterns without a clear statistical
interpretation. In this work, we propose to use probabilistic grammars to
characterize and discover shortcuts in NLP datasets. Specifically, we use a
context-free grammar to model patterns in sentence classification datasets and
use a synchronous context-free grammar to model datasets involving sentence
pairs. The resulting grammars reveal interesting shortcut features in a number
of datasets, including both simple and high-level features, and automatically
identify groups of test examples on which conventional classifiers fail.
Finally, we show that the features we discover can be used to generate
diagnostic contrast examples and incorporated into standard robust optimization
methods to improve worst-group accuracy."	ArXiv
1706	Learning New Tasks from a Few Examples with Soft-Label Prototypes	['Avyav Kumar Singh', 'Ekaterina Shutova', 'Helen Yannakoudakis']	2022-10-31 16:06:48+00:00	http://arxiv.org/abs/2210.17437v4	"Existing approaches to few-shot learning in NLP rely on large language models
(LLMs) and/or fine-tuning of these to generalise on out-of-distribution data.
In this work, we propose a novel few-shot learning approach based on soft-label
prototypes (SLPs) designed to collectively capture the distribution of
different classes across the input domain space. We focus on learning
previously unseen NLP tasks from very few examples (4, 8, 16) per class and
experimentally demonstrate that our approach achieves superior performance on
the majority of tested tasks in this data-lean setting while being highly
parameter efficient. We also show that our few-shot adaptation method can be
integrated into more generalised learning settings, primarily meta-learning, to
yield superior performance against strong baselines."	ArXiv
1707	Predictive Approaches For Gaussian Process Classifier Model Selection	['Sundararajan Sellamanickam', 'Sathiya Keerthi Selvaraj']	2012-06-26 16:19:51+00:00	http://arxiv.org/abs/1206.6038v1	"In this paper we consider the problem of Gaussian process classifier (GPC)
model selection with different Leave-One-Out (LOO) Cross Validation (CV) based
optimization criteria and provide a practical algorithm using LOO predictive
distributions with such criteria to select hyperparameters. Apart from the
standard average negative logarithm of predictive probability (NLP), we also
consider smoothed versions of criteria such as F-measure and Weighted Error
Rate (WER), which are useful for handling imbalanced data. Unlike the
regression case, LOO predictive distributions for the classifier case are
intractable. We use approximate LOO predictive distributions arrived from
Expectation Propagation (EP) approximation. We conduct experiments on several
real world benchmark datasets. When the NLP criterion is used for optimizing
the hyperparameters, the predictive approaches show better or comparable NLP
generalization performance with existing GPC approaches. On the other hand,
when the F-measure criterion is used, the F-measure generalization performance
improves significantly on several datasets. Overall, the EP-based predictive
algorithm comes out as an excellent choice for GP classifier model selection
with different optimization criteria."	ArXiv
1708	Explaining Predictions of Non-Linear Classifiers in NLP	['Leila Arras', 'Franziska Horn', 'Grégoire Montavon', 'Klaus-Robert Müller', 'Wojciech Samek']	2016-06-23 12:53:31+00:00	http://arxiv.org/abs/1606.07298v1	"Layer-wise relevance propagation (LRP) is a recently proposed technique for
explaining predictions of complex non-linear classifiers in terms of input
variables. In this paper, we apply LRP for the first time to natural language
processing (NLP). More precisely, we use it to explain the predictions of a
convolutional neural network (CNN) trained on a topic categorization task. Our
analysis highlights which words are relevant for a specific prediction of the
CNN. We compare our technique to standard sensitivity analysis, both
qualitatively and quantitatively, using a ""word deleting"" perturbation
experiment, a PCA analysis, and various visualizations. All experiments
validate the suitability of LRP for explaining the CNN predictions, which is
also in line with results reported in recent image classification studies."	ArXiv
1709	Ethical Questions in NLP Research: The (Mis)-Use of Forensic Linguistics	['Anil Kumar Singh', 'Akhilesh Sudhakar']	2017-12-20 15:03:04+00:00	http://arxiv.org/abs/1712.07512v1	"Ideas from forensic linguistics are now being used frequently in Natural
Language Processing (NLP), using machine learning techniques. While the role of
forensic linguistics was more benign earlier, it is now being used for purposes
which are questionable. Certain methods from forensic linguistics are employed,
without considering their scientific limitations and ethical concerns. While we
take the specific case of forensic linguistics as an example of such trends in
NLP and machine learning, the issue is a larger one and present in many other
scientific and data-driven domains. We suggest that such trends indicate that
some of the applied sciences are exceeding their legal and scientific briefs.
We highlight how carelessly implemented practices are serving to short-circuit
the due processes of law as well breach ethical codes."	ArXiv
1710	"High-order convergent Finite-Elements Direct Transcription Method for
  Constrained Optimal Control Problems"	['Martin Peter Neuenhofen']	2017-12-21 01:30:27+00:00	http://arxiv.org/abs/1712.07761v1	"In this paper we present a finite element method for the direct transcription
of constrained non-linear optimal control problems.
  We prove that our method converges of high order under mild assumptions. Our
analysis uses a regularized penalty-barrier functional. The convergence result
is obtained from local strict convexity and Lipschitz-continuity of this
functional in the finite-element space.
  The method is very flexible. Each component of the numerical solution can be
discretized with a different mesh. General differential-algebraic constraints
of arbitrary index can be treated easily with this new method.
  From the discretization results an unconstrained non-linear programming
problem (NLP) with penalty- and barrier-terms. The derivatives of the NLP
functions have a sparsity pattern that can be analysed and tailored in terms of
the chosen finite-element bases in an easy way. We discuss how to treat the
resulting NLP in a practical way with general-purpose software for constrained
non-linear programming."	ArXiv
1711	"Is artificial data useful for biomedical Natural Language Processing
  algorithms?"	['Zixu Wang', 'Julia Ive', 'Sumithra Velupillai', 'Lucia Specia']	2019-07-01 20:17:59+00:00	http://arxiv.org/abs/1907.01055v2	"A major obstacle to the development of Natural Language Processing (NLP)
methods in the biomedical domain is data accessibility. This problem can be
addressed by generating medical data artificially. Most previous studies have
focused on the generation of short clinical text, and evaluation of the data
utility has been limited. We propose a generic methodology to guide the
generation of clinical text with key phrases. We use the artificial data as
additional training data in two key biomedical NLP tasks: text classification
and temporal relation extraction. We show that artificially generated training
data used in conjunction with real training data can lead to performance boosts
for data-greedy neural network algorithms. We also demonstrate the usefulness
of the generated data for NLP setups where it fully replaces real training
data."	ArXiv
1712	"Towards Realistic Practices In Low-Resource Natural Language Processing:
  The Development Set"	['Katharina Kann', 'Kyunghyun Cho', 'Samuel R. Bowman']	2019-09-04 02:20:54+00:00	http://arxiv.org/abs/1909.01522v2	"Development sets are impractical to obtain for real low-resource languages,
since using all available data for training is often more effective. However,
development sets are widely used in research papers that purport to deal with
low-resource natural language processing (NLP). Here, we aim to answer the
following questions: Does using a development set for early stopping in the
low-resource setting influence results as compared to a more realistic
alternative, where the number of training epochs is tuned on development
languages? And does it lead to overestimation or underestimation of
performance? We repeat multiple experiments from recent work on neural models
for low-resource NLP and compare results for models obtained by training with
and without development sets. On average over languages, absolute accuracy
differs by up to 1.4%. However, for some languages and tasks, differences are
as big as 18.0% accuracy. Our results highlight the importance of realistic
experimental setups in the publication of low-resource NLP research results."	ArXiv
1713	AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models	['Eric Wallace', 'Jens Tuyls', 'Junlin Wang', 'Sanjay Subramanian', 'Matt Gardner', 'Sameer Singh']	2019-09-19 22:35:36+00:00	http://arxiv.org/abs/1909.09251v1	"Neural NLP models are increasingly accurate but are imperfect and
opaque---they break in counterintuitive ways and leave end users puzzled at
their behavior. Model interpretation methods ameliorate this opacity by
providing explanations for specific model predictions. Unfortunately, existing
interpretation codebases make it difficult to apply these methods to new models
and tasks, which hinders adoption for practitioners and burdens
interpretability researchers. We introduce AllenNLP Interpret, a flexible
framework for interpreting NLP models. The toolkit provides interpretation
primitives (e.g., input gradients) for any AllenNLP model and task, a suite of
built-in interpretation methods, and a library of front-end visualization
components. We demonstrate the toolkit's flexibility and utility by
implementing live demos for five interpretation methods (e.g., saliency maps
and adversarial attacks) on a variety of models and tasks (e.g., masked
language modeling using BERT and reading comprehension using BiDAF). These
demos, alongside our code and tutorials, are available at
https://allennlp.org/interpret ."	ArXiv
1714	"Does BERT Make Any Sense? Interpretable Word Sense Disambiguation with
  Contextualized Embeddings"	['Gregor Wiedemann', 'Steffen Remus', 'Avi Chawla', 'Chris Biemann']	2019-09-23 15:38:02+00:00	http://arxiv.org/abs/1909.10430v2	"Contextualized word embeddings (CWE) such as provided by ELMo (Peters et al.,
2018), Flair NLP (Akbik et al., 2018), or BERT (Devlin et al., 2019) are a
major recent innovation in NLP. CWEs provide semantic vector representations of
words depending on their respective context. Their advantage over static word
embeddings has been shown for a number of tasks, such as text classification,
sequence tagging, or machine translation. Since vectors of the same word type
can vary depending on the respective context, they implicitly provide a model
for word sense disambiguation (WSD). We introduce a simple but effective
approach to WSD using a nearest neighbor classification on CWEs. We compare the
performance of different CWE models for the task and can report improvements
above the current state of the art for two standard WSD benchmark datasets. We
further show that the pre-trained BERT model is able to place polysemic words
into distinct 'sense' regions of the embedding space, while ELMo and Flair NLP
do not seem to possess this ability."	ArXiv
1715	The State of NLP Literature: A Diachronic Analysis of the ACL Anthology	['Saif M. Mohammad']	2019-11-08 22:15:32+00:00	http://arxiv.org/abs/1911.03562v1	"The ACL Anthology (AA) is a digital repository of tens of thousands of
articles on Natural Language Processing (NLP). This paper examines the
literature as a whole to identify broad trends in productivity, focus, and
impact. It presents the analyses in a sequence of questions and answers. The
goal is to record the state of the AA literature: who and how many of us are
publishing? what are we publishing on? where and in what form are we
publishing? and what is the impact of our publications? The answers are usually
in the form of numbers, graphs, and inter-connected visualizations. Special
emphasis is laid on the demographics and inclusiveness of NLP publishing.
Notably, we find that only about 30% of first authors are female, and that this
percentage has not improved since the year 2000. We also show that, on average,
female first authors are cited less than male first authors, even when
controlling for experience. We hope that recording citation and participation
gaps across demographic groups will encourage more inclusiveness and fairness
in research."	ArXiv
1716	TENER: Adapting Transformer Encoder for Named Entity Recognition	['Hang Yan', 'Bocao Deng', 'Xiaonan Li', 'Xipeng Qiu']	2019-11-10 15:05:48+00:00	http://arxiv.org/abs/1911.04474v3	"The Bidirectional long short-term memory networks (BiLSTM) have been widely
used as an encoder in models solving the named entity recognition (NER) task.
Recently, the Transformer is broadly adopted in various Natural Language
Processing (NLP) tasks owing to its parallelism and advantageous performance.
Nevertheless, the performance of the Transformer in NER is not as good as it is
in other NLP tasks. In this paper, we propose TENER, a NER architecture
adopting adapted Transformer Encoder to model the character-level features and
word-level features. By incorporating the direction and relative distance aware
attention and the un-scaled attention, we prove the Transformer-like encoder is
just as effective for NER as other NLP tasks."	ArXiv
1717	"Performance Comparison of Crowdworkers and NLP Tools on Named-Entity
  Recognition and Sentiment Analysis of Political Tweets"	['Mona Jalal', 'Kate K. Mays', 'Lei Guo', 'Margrit Betke']	2020-02-11 03:03:20+00:00	http://arxiv.org/abs/2002.04181v2	"We report results of a comparison of the accuracy of crowdworkers and seven
Natural Language Processing (NLP) toolkits in solving two important NLP tasks,
named-entity recognition (NER) and entity-level sentiment (ELS) analysis. We
here focus on a challenging dataset, 1,000 political tweets that were collected
during the U.S. presidential primary election in February 2016. Each tweet
refers to at least one of four presidential candidates, i.e., four named
entities. The groundtruth, established by experts in political communication,
has entity-level sentiment information for each candidate mentioned in the
tweet. We tested several commercial and open-source tools. Our experiments show
that, for our dataset of political tweets, the most accurate NER system, Google
Cloud NL, performed almost on par with crowdworkers, but the most accurate ELS
analysis system, TensiStrength, did not match the accuracy of crowdworkers by a
large margin of more than 30 percent points."	ArXiv
1718	"A Nepali Rule Based Stemmer and its performance on different NLP
  applications"	['Pravesh Koirala', 'Aman Shakya']	2020-02-23 13:33:04+00:00	http://arxiv.org/abs/2002.09901v1	"Stemming is an integral part of Natural Language Processing (NLP). It's a
preprocessing step in almost every NLP application. Arguably, the most
important usage of stemming is in Information Retrieval (IR). While there are
lots of work done on stemming in languages like English, Nepali stemming has
only a few works. This study focuses on creating a Rule Based stemmer for
Nepali text. Specifically, it is an affix stripping system that identifies two
different class of suffixes in Nepali grammar and strips them separately. Only
a single negativity prefix (Na) is identified and stripped. This study focuses
on a number of techniques like exception word identification, morphological
normalization and word transformation to increase stemming performance. The
stemmer is tested intrinsically using Paice's method and extrinsically on a
basic tf-idf based IR system and an elementary news topic classifier using
Multinomial Naive Bayes Classifier. The difference in performance of these
systems with and without using the stemmer is analysed."	ArXiv
1719	Igbo-English Machine Translation: An Evaluation Benchmark	['Ignatius Ezeani', 'Paul Rayson', 'Ikechukwu Onyenwe', 'Chinedu Uchechukwu', 'Mark Hepple']	2020-04-01 18:06:21+00:00	http://arxiv.org/abs/2004.00648v1	"Although researchers and practitioners are pushing the boundaries and
enhancing the capacities of NLP tools and methods, works on African languages
are lagging. A lot of focus on well resourced languages such as English,
Japanese, German, French, Russian, Mandarin Chinese etc. Over 97% of the
world's 7000 languages, including African languages, are low resourced for NLP
i.e. they have little or no data, tools, and techniques for NLP research. For
instance, only 5 out of 2965, 0.19% authors of full text papers in the ACL
Anthology extracted from the 5 major conferences in 2018 ACL, NAACL, EMNLP,
COLING and CoNLL, are affiliated to African institutions. In this work, we
discuss our effort toward building a standard machine translation benchmark
dataset for Igbo, one of the 3 major Nigerian languages. Igbo is spoken by more
than 50 million people globally with over 50% of the speakers are in
southeastern Nigeria. Igbo is low resourced although there have been some
efforts toward developing IgboNLP such as part of speech tagging and diacritic
restoration"	ArXiv
1720	Towards Evaluating the Robustness of Chinese BERT Classifiers	['Boxin Wang', 'Boyuan Pan', 'Xin Li', 'Bo Li']	2020-04-07 23:02:37+00:00	http://arxiv.org/abs/2004.03742v1	"Recent advances in large-scale language representation models such as BERT
have improved the state-of-the-art performances in many NLP tasks. Meanwhile,
character-level Chinese NLP models, including BERT for Chinese, have also
demonstrated that they can outperform the existing models. In this paper, we
show that, however, such BERT-based models are vulnerable under character-level
adversarial attacks. We propose a novel Chinese char-level attack method
against BERT-based classifiers. Essentially, we generate ""small"" perturbation
on the character level in the embedding space and guide the character
substitution procedure. Extensive experiments show that the classification
accuracy on a Chinese news dataset drops from 91.8% to 0% by manipulating less
than 2 characters on average based on the proposed attack. Human evaluations
also confirm that our generated Chinese adversarial examples barely affect
human performance on these NLP tasks."	ArXiv
1721	"What's so special about BERT's layers? A closer look at the NLP pipeline
  in monolingual and multilingual models"	['Wietse de Vries', 'Andreas van Cranenburgh', 'Malvina Nissim']	2020-04-14 13:41:48+00:00	http://arxiv.org/abs/2004.06499v2	"Peeking into the inner workings of BERT has shown that its layers resemble
the classical NLP pipeline, with progressively more complex tasks being
concentrated in later layers. To investigate to what extent these results also
hold for a language other than English, we probe a Dutch BERT-based model and
the multilingual BERT model for Dutch NLP tasks. In addition, through a deeper
analysis of part-of-speech tagging, we show that also within a given task,
information is spread over different parts of the network and the pipeline
might not be as neat as it seems. Each layer has different specialisations, so
that it may be more useful to combine information from different layers,
instead of selecting a single one based on the best overall performance."	ArXiv
1722	Coreferential Reasoning Learning for Language Representation	['Deming Ye', 'Yankai Lin', 'Jiaju Du', 'Zhenghao Liu', 'Peng Li', 'Maosong Sun', 'Zhiyuan Liu']	2020-04-15 03:57:45+00:00	http://arxiv.org/abs/2004.06870v2	"Language representation models such as BERT could effectively capture
contextual semantic information from plain text, and have been proved to
achieve promising results in lots of downstream NLP tasks with appropriate
fine-tuning. However, most existing language representation models cannot
explicitly handle coreference, which is essential to the coherent understanding
of the whole discourse. To address this issue, we present CorefBERT, a novel
language representation model that can capture the coreferential relations in
context. The experimental results show that, compared with existing baseline
models, CorefBERT can achieve significant improvements consistently on various
downstream NLP tasks that require coreferential reasoning, while maintaining
comparable performance to previous models on other common NLP tasks. The source
code and experiment details of this paper can be obtained from
https://github.com/thunlp/CorefBERT."	ArXiv
1723	"How Does NLP Benefit Legal System: A Summary of Legal Artificial
  Intelligence"	['Haoxi Zhong', 'Chaojun Xiao', 'Cunchao Tu', 'Tianyang Zhang', 'Zhiyuan Liu', 'Maosong Sun']	2020-04-25 14:45:15+00:00	http://arxiv.org/abs/2004.12158v5	"Legal Artificial Intelligence (LegalAI) focuses on applying the technology of
artificial intelligence, especially natural language processing, to benefit
tasks in the legal domain. In recent years, LegalAI has drawn increasing
attention rapidly from both AI researchers and legal professionals, as LegalAI
is beneficial to the legal system for liberating legal professionals from a
maze of paperwork. Legal professionals often think about how to solve tasks
from rule-based and symbol-based methods, while NLP researchers concentrate
more on data-driven and embedding methods. In this paper, we introduce the
history, the current state, and the future directions of research in LegalAI.
We illustrate the tasks from the perspectives of legal professionals and NLP
researchers and show several representative applications in LegalAI. We conduct
experiments and provide an in-depth analysis of the advantages and
disadvantages of existing works to explore possible future directions. You can
find the implementation of our work from https://github.com/thunlp/CLAIM."	ArXiv
1724	Revisiting Pre-Trained Models for Chinese Natural Language Processing	['Yiming Cui', 'Wanxiang Che', 'Ting Liu', 'Bing Qin', 'Shijin Wang', 'Guoping Hu']	2020-04-29 02:08:30+00:00	http://arxiv.org/abs/2004.13922v2	"Bidirectional Encoder Representations from Transformers (BERT) has shown
marvelous improvements across various NLP tasks, and consecutive variants have
been proposed to further improve the performance of the pre-trained language
models. In this paper, we target on revisiting Chinese pre-trained language
models to examine their effectiveness in a non-English language and release the
Chinese pre-trained language model series to the community. We also propose a
simple but effective model called MacBERT, which improves upon RoBERTa in
several ways, especially the masking strategy that adopts MLM as correction
(Mac). We carried out extensive experiments on eight Chinese NLP tasks to
revisit the existing pre-trained language models as well as the proposed
MacBERT. Experimental results show that MacBERT could achieve state-of-the-art
performances on many NLP tasks, and we also ablate details with several
findings that may help future research. Resources available:
https://github.com/ymcui/MacBERT"	ArXiv
1725	Evaluating Transformer-Based Multilingual Text Classification	['Sophie Groenwold', 'Samhita Honnavalli', 'Lily Ou', 'Aesha Parekh', 'Sharon Levy', 'Diba Mirza', 'William Yang Wang']	2020-04-29 03:34:53+00:00	http://arxiv.org/abs/2004.13939v2	"As NLP tools become ubiquitous in today's technological landscape, they are
increasingly applied to languages with a variety of typological structures.
However, NLP research does not focus primarily on typological differences in
its analysis of state-of-the-art language models. As a result, NLP tools
perform unequally across languages with different syntactic and morphological
structures. Through a detailed discussion of word order typology, morphological
typology, and comparative linguistics, we identify which variables most affect
language modeling efficacy; in addition, we calculate word order and
morphological similarity indices to aid our empirical study. We then use this
background to support our analysis of an experiment we conduct using
multi-class text classification on eight languages and eight models."	ArXiv
1726	"Mind Your Inflections! Improving NLP for Non-Standard Englishes with
  Base-Inflection Encoding"	['Samson Tan', 'Shafiq Joty', 'Lav R. Varshney', 'Min-Yen Kan']	2020-04-30 15:15:40+00:00	http://arxiv.org/abs/2004.14870v4	"Inflectional variation is a common feature of World Englishes such as
Colloquial Singapore English and African American Vernacular English. Although
comprehension by human readers is usually unimpaired by non-standard
inflections, current NLP systems are not yet robust. We propose Base-Inflection
Encoding (BITE), a method to tokenize English text by reducing inflected words
to their base forms before reinjecting the grammatical information as special
symbols. Fine-tuning pretrained NLP models for downstream tasks using our
encoding defends against inflectional adversaries while maintaining performance
on clean data. Models using BITE generalize better to dialects with
non-standard inflections without explicit training and translation models
converge faster when trained with BITE. Finally, we show that our encoding
improves the vocabulary efficiency of popular data-driven subword tokenizers.
Since there has been no prior work on quantitatively evaluating vocabulary
efficiency, we propose metrics to do so."	ArXiv
1727	"NLP Scholar: An Interactive Visual Explorer for Natural Language
  Processing Literature"	['Saif M. Mohammad']	2020-05-31 17:12:37+00:00	http://arxiv.org/abs/2006.01131v1	"As part of the NLP Scholar project, we created a single unified dataset of
NLP papers and their meta-information (including citation numbers), by
extracting and aligning information from the ACL Anthology and Google Scholar.
In this paper, we describe several interconnected interactive visualizations
(dashboards) that present various aspects of the data. Clicking on an item
within a visualization or entering query terms in the search boxes filters the
data in all visualizations in the dashboard. This allows users to search for
papers in the area of their interest, published within specific time periods,
published by specified authors, etc. The interactive visualizations presented
here, and the associated dataset of papers mapped to citations, have additional
uses as well including understanding how the field is growing (both overall and
across sub-areas), as well as quantifying the impact of different types of
papers on subsequent publications."	ArXiv
1728	Human brain activity for machine attention	['Lukas Muttenthaler', 'Nora Hollenstein', 'Maria Barrett']	2020-06-09 08:39:07+00:00	http://arxiv.org/abs/2006.05113v2	"Cognitively inspired NLP leverages human-derived data to teach machines about
language processing mechanisms. Recently, neural networks have been augmented
with behavioral data to solve a range of NLP tasks spanning syntax and
semantics. We are the first to exploit neuroscientific data, namely
electroencephalography (EEG), to inform a neural attention model about language
processing of the human brain. The challenge in working with EEG data is that
features are exceptionally rich and need extensive pre-processing to isolate
signals specific to text processing. We devise a method for finding such EEG
features to supervise machine attention through combining theoretically
motivated cropping with random forest tree splits. After this dimensionality
reduction, the pre-processed EEG features are capable of distinguishing two
reading tasks retrieved from a publicly available EEG corpus. We apply these
features to regularise attention on relation classification and show that EEG
is more informative than strong baselines. This improvement depends on both the
cognitive load of the task and the EEG frequency domain. Hence, informing
neural attention models with EEG signals is beneficial but requires further
investigation to understand which dimensions are the most useful across NLP
tasks."	ArXiv
1729	Through the Twitter Glass: Detecting Questions in Micro-Text	['Kyle Dent', 'Sharoda Paul']	2020-06-13 22:34:01+00:00	http://arxiv.org/abs/2006.07732v1	"In a separate study, we were interested in understanding people's Q&A habits
on Twitter. Finding questions within Twitter turned out to be a difficult
challenge, so we considered applying some traditional NLP approaches to the
problem. On the one hand, Twitter is full of idiosyncrasies, which make
processing it difficult. On the other, it is very restricted in length and
tends to employ simple syntactic constructions, which could help the
performance of NLP processing. In order to find out the viability of NLP and
Twitter, we built a pipeline of tools to work specifically with Twitter input
for the task of finding questions in tweets. This work is still preliminary,
but in this paper we discuss the techniques we used and the lessons we learned."	ArXiv
1730	"Defense against Adversarial Attacks in NLP via Dirichlet Neighborhood
  Ensemble"	['Yi Zhou', 'Xiaoqing Zheng', 'Cho-Jui Hsieh', 'Kai-wei Chang', 'Xuanjing Huang']	2020-06-20 18:01:16+00:00	http://arxiv.org/abs/2006.11627v1	"Despite neural networks have achieved prominent performance on many natural
language processing (NLP) tasks, they are vulnerable to adversarial examples.
In this paper, we propose Dirichlet Neighborhood Ensemble (DNE), a randomized
smoothing method for training a robust model to defense substitution-based
attacks. During training, DNE forms virtual sentences by sampling embedding
vectors for each word in an input sentence from a convex hull spanned by the
word and its synonyms, and it augments them with the training data. In such a
way, the model is robust to adversarial attacks while maintaining the
performance on the original clean data. DNE is agnostic to the network
architectures and scales to large models for NLP applications. We demonstrate
through extensive experimentation that our method consistently outperforms
recently proposed defense methods by a significant margin across different
network architectures and multiple data sets."	ArXiv
1731	Towards Causality Extraction from Requirements	['Jannik Fischbach', 'Benedikt Hauptmann', 'Lukas Konwitschny', 'Dominik Spies', 'Andreas Vogelsang']	2020-06-29 08:35:25+00:00	http://arxiv.org/abs/2006.15871v1	"System behavior is often based on causal relations between certain events
(e.g. If event1, then event2). Consequently, those causal relations are also
textually embedded in requirements. We want to extract this causal knowledge
and utilize it to derive test cases automatically and to reason about
dependencies between requirements. Existing NLP approaches fail to extract
causality from natural language (NL) with reasonable performance. In this
paper, we describe first steps towards building a new approach for causality
extraction and contribute: (1) an NLP architecture based on Tree Recursive
Neural Networks (TRNN) that we will train to identify causal relations in NL
requirements and (2) an annotation scheme and a dataset that is suitable for
training TRNNs. Our dataset contains 212,186 sentences from 463 publicly
available requirement documents and is a first step towards a gold standard
corpus for causality extraction. We encourage fellow researchers to contribute
to our dataset and help us in finalizing the causality annotation process.
Additionally, the dataset can also be annotated further to serve as a benchmark
for other RE-relevant NLP tasks such as requirements classification."	ArXiv
1732	Natural Backdoor Attack on Text Data	['Lichao Sun']	2020-06-29 16:40:14+00:00	http://arxiv.org/abs/2006.16176v4	"Recently, advanced NLP models have seen a surge in the usage of various
applications. This raises the security threats of the released models. In
addition to the clean models' unintentional weaknesses, {\em i.e.,} adversarial
attacks, the poisoned models with malicious intentions are much more dangerous
in real life. However, most existing works currently focus on the adversarial
attacks on NLP models instead of positioning attacks, also named
\textit{backdoor attacks}. In this paper, we first propose the \textit{natural
backdoor attacks} on NLP models. Moreover, we exploit the various attack
strategies to generate trigger on text data and investigate different types of
triggers based on modification scope, human recognition, and special cases.
Last, we evaluate the backdoor attacks, and the results show the excellent
performance of with 100\% backdoor attacks success rate and sacrificing of
0.83\% on the text classification task."	ArXiv
1733	Word meaning in minds and machines	['Brenden M. Lake', 'Gregory L. Murphy']	2020-08-04 18:45:49+00:00	http://arxiv.org/abs/2008.01766v3	"Machines have achieved a broad and growing set of linguistic competencies,
thanks to recent progress in Natural Language Processing (NLP). Psychologists
have shown increasing interest in such models, comparing their output to
psychological judgments such as similarity, association, priming, and
comprehension, raising the question of whether the models could serve as
psychological theories. In this article, we compare how humans and machines
represent the meaning of words. We argue that contemporary NLP systems are
fairly successful models of human word similarity, but they fall short in many
other respects. Current models are too strongly linked to the text-based
patterns in large corpora, and too weakly linked to the desires, goals, and
beliefs that people express through words. Word meanings must also be grounded
in perception and action and be capable of flexible combinations in ways that
current systems are not. We discuss more promising approaches to grounding NLP
systems and argue that they will be more successful with a more human-like,
conceptual basis for word meaning."	ArXiv
1734	Adversarial Attack and Defense of Structured Prediction Models	['Wenjuan Han', 'Liwen Zhang', 'Yong Jiang', 'Kewei Tu']	2020-10-04 15:54:03+00:00	http://arxiv.org/abs/2010.01610v2	"Building an effective adversarial attacker and elaborating on countermeasures
for adversarial attacks for natural language processing (NLP) have attracted a
lot of research in recent years. However, most of the existing approaches focus
on classification problems. In this paper, we investigate attacks and defenses
for structured prediction tasks in NLP. Besides the difficulty of perturbing
discrete words and the sentence fluency problem faced by attackers in any NLP
tasks, there is a specific challenge to attackers of structured prediction
models: the structured output of structured prediction models is sensitive to
small perturbations in the input. To address these problems, we propose a novel
and unified framework that learns to attack a structured prediction model using
a sequence-to-sequence model with feedbacks from multiple reference models of
the same structured prediction task. Based on the proposed attack, we further
reinforce the victim model with adversarial training, making its prediction
more robust and accurate. We evaluate the proposed framework in dependency
parsing and part-of-speech tagging. Automatic and human evaluations show that
our proposed framework succeeds in both attacking state-of-the-art structured
prediction models and boosting them with adversarial training."	ArXiv
1735	Second-Order NLP Adversarial Examples	['John X. Morris']	2020-10-05 04:32:38+00:00	http://arxiv.org/abs/2010.01770v2	"Adversarial example generation methods in NLP rely on models like language
models or sentence encoders to determine if potential adversarial examples are
valid. In these methods, a valid adversarial example fools the model being
attacked, and is determined to be semantically or syntactically valid by a
second model. Research to date has counted all such examples as errors by the
attacked model. We contend that these adversarial examples may not be flaws in
the attacked model, but flaws in the model that determines validity. We term
such invalid inputs second-order adversarial examples. We propose the
constraint robustness curve and associated metric ACCS as tools for evaluating
the robustness of a constraint to second-order adversarial examples. To
generate this curve, we design an adversarial attack to run directly on the
semantic similarity models. We test on two constraints, the Universal Sentence
Encoder (USE) and BERTScore. Our findings indicate that such second-order
examples exist, but are typically less common than first-order adversarial
examples in state-of-the-art models. They also indicate that USE is effective
as constraint on NLP adversarial examples, while BERTScore is nearly
ineffectual. Code for running the experiments in this paper is available at
https://github.com/jxmorris12/second-order-adversarial-examples."	ArXiv
1736	"CAT-Gen: Improving Robustness in NLP Models via Controlled Adversarial
  Text Generation"	['Tianlu Wang', 'Xuezhi Wang', 'Yao Qin', 'Ben Packer', 'Kang Li', 'Jilin Chen', 'Alex Beutel', 'Ed Chi']	2020-10-05 21:07:45+00:00	http://arxiv.org/abs/2010.02338v1	"NLP models are shown to suffer from robustness issues, i.e., a model's
prediction can be easily changed under small perturbations to the input. In
this work, we present a Controlled Adversarial Text Generation (CAT-Gen) model
that, given an input text, generates adversarial texts through controllable
attributes that are known to be invariant to task labels. For example, in order
to attack a model for sentiment classification over product reviews, we can use
the product categories as the controllable attribute which would not change the
sentiment of the reviews. Experiments on real-world NLP datasets demonstrate
that our method can generate more diverse and fluent adversarial texts,
compared to many existing adversarial text generation approaches. We further
use our generated adversarial examples to improve models through adversarial
training, and we demonstrate that our generated attacks are more robust against
model re-training and different model architectures."	ArXiv
1737	Rank and run-time aware compression of NLP Applications	['Urmish Thakker', 'Jesse Beu', 'Dibakar Gope', 'Ganesh Dasika', 'Matthew Mattina']	2020-10-06 16:03:15+00:00	http://arxiv.org/abs/2010.03193v1	"Sequence model based NLP applications can be large. Yet, many applications
that benefit from them run on small devices with very limited compute and
storage capabilities, while still having run-time constraints. As a result,
there is a need for a compression technique that can achieve significant
compression without negatively impacting inference run-time and task accuracy.
This paper proposes a new compression technique called Hybrid Matrix
Factorization that achieves this dual objective. HMF improves low-rank matrix
factorization (LMF) techniques by doubling the rank of the matrix using an
intelligent hybrid-structure leading to better accuracy than LMF. Further, by
preserving dense matrices, it leads to faster inference run-time than pruning
or structure matrix based compression technique. We evaluate the impact of this
technique on 5 NLP benchmarks across multiple tasks (Translation, Intent
Detection, Language Modeling) and show that for similar accuracy values and
compression factors, HMF can achieve more than 2.32x faster inference run-time
than pruning and 16.77% better accuracy than LMF."	ArXiv
1738	"Adversarial Self-Supervised Data-Free Distillation for Text
  Classification"	['Xinyin Ma', 'Yongliang Shen', 'Gongfan Fang', 'Chen Chen', 'Chenghao Jia', 'Weiming Lu']	2020-10-10 02:46:06+00:00	http://arxiv.org/abs/2010.04883v1	"Large pre-trained transformer-based language models have achieved impressive
results on a wide range of NLP tasks. In the past few years, Knowledge
Distillation(KD) has become a popular paradigm to compress a computationally
expensive model to a resource-efficient lightweight model. However, most KD
algorithms, especially in NLP, rely on the accessibility of the original
training dataset, which may be unavailable due to privacy issues. To tackle
this problem, we propose a novel two-stage data-free distillation method, named
Adversarial self-Supervised Data-Free Distillation (AS-DFD), which is designed
for compressing large-scale transformer-based models (e.g., BERT). To avoid
text generation in discrete space, we introduce a Plug & Play Embedding
Guessing method to craft pseudo embeddings from the teacher's hidden knowledge.
Meanwhile, with a self-supervised module to quantify the student's ability, we
adapt the difficulty of pseudo embeddings in an adversarial training manner. To
the best of our knowledge, our framework is the first data-free distillation
framework designed for NLP tasks. We verify the effectiveness of our method on
several text classification datasets."	ArXiv
1739	"What Do Position Embeddings Learn? An Empirical Study of Pre-Trained
  Language Model Positional Encoding"	['Yu-An Wang', 'Yun-Nung Chen']	2020-10-10 05:03:14+00:00	http://arxiv.org/abs/2010.04903v1	"In recent years, pre-trained Transformers have dominated the majority of NLP
benchmark tasks. Many variants of pre-trained Transformers have kept breaking
out, and most focus on designing different pre-training objectives or variants
of self-attention. Embedding the position information in the self-attention
mechanism is also an indispensable factor in Transformers however is often
discussed at will. Therefore, this paper carries out an empirical study on
position embeddings of mainstream pre-trained Transformers, which mainly
focuses on two questions: 1) Do position embeddings really learn the meaning of
positions? 2) How do these different learned position embeddings affect
Transformers for NLP tasks? This paper focuses on providing a new insight of
pre-trained position embeddings through feature-level analysis and empirical
experiments on most of iconic NLP tasks. It is believed that our experimental
results can guide the future work to choose the suitable positional encoding
function for specific tasks given the application property."	ArXiv
1740	Gradient-based Analysis of NLP Models is Manipulable	['Junlin Wang', 'Jens Tuyls', 'Eric Wallace', 'Sameer Singh']	2020-10-12 02:54:22+00:00	http://arxiv.org/abs/2010.05419v1	"Gradient-based analysis methods, such as saliency map visualizations and
adversarial input perturbations, have found widespread use in interpreting
neural NLP models due to their simplicity, flexibility, and most importantly,
their faithfulness. In this paper, however, we demonstrate that the gradients
of a model are easily manipulable, and thus bring into question the reliability
of gradient-based analyses. In particular, we merge the layers of a target
model with a Facade that overwhelms the gradients without affecting the
predictions. This Facade can be trained to have gradients that are misleading
and irrelevant to the task, such as focusing only on the stop words in the
input. On a variety of NLP tasks (text classification, NLI, and QA), we show
that our method can manipulate numerous gradient-based analysis techniques:
saliency maps, input reduction, and adversarial perturbations all identify
unimportant or targeted tokens as being highly important. The code and a
tutorial of this paper is available at http://ucinlp.github.io/facade."	ArXiv
1741	From Hero to Zéroe: A Benchmark of Low-Level Adversarial Attacks	['Steffen Eger', 'Yannik Benz']	2020-10-12 12:35:36+00:00	http://arxiv.org/abs/2010.05648v2	"Adversarial attacks are label-preserving modifications to inputs of machine
learning classifiers designed to fool machines but not humans. Natural Language
Processing (NLP) has mostly focused on high-level attack scenarios such as
paraphrasing input texts. We argue that these are less realistic in typical
application scenarios such as in social media, and instead focus on low-level
attacks on the character-level. Guided by human cognitive abilities and human
robustness, we propose the first large-scale catalogue and benchmark of
low-level adversarial attacks, which we dub Z\'eroe, encompassing nine
different attack modes including visual and phonetic adversaries. We show that
RoBERTa, NLP's current workhorse, fails on our attacks. Our dataset provides a
benchmark for testing robustness of future more human-like NLP models."	ArXiv
1742	SpaML: a Bimodal Ensemble Learning Spam Detector based on NLP Techniques	['Jaouhar Fattahi', 'Mohamed Mejri']	2020-10-15 00:14:44+00:00	http://arxiv.org/abs/2010.07444v2	"In this paper, we put forward a new tool, called SpaML, for spam detection
using a set of supervised and unsupervised classifiers, and two techniques
imbued with Natural Language Processing (NLP), namely Bag of Words (BoW) and
Term Frequency-Inverse Document Frequency (TF-IDF). We first present the NLP
techniques used. Then, we present our classifiers and their performance on each
of these techniques. Then, we present our overall Ensemble Learning classifier
and the strategy we are using to combine them. Finally, we present the
interesting results shown by SpaML in terms of accuracy and precision."	ArXiv
1743	"Improving Natural Language Processing Tasks with Human Gaze-Guided
  Neural Attention"	['Ekta Sood', 'Simon Tannert', 'Philipp Mueller', 'Andreas Bulling']	2020-10-15 17:14:09+00:00	http://arxiv.org/abs/2010.07891v2	"A lack of corpora has so far limited advances in integrating human gaze data
as a supervisory signal in neural attention mechanisms for natural language
processing(NLP). We propose a novel hybrid text saliency model(TSM) that, for
the first time, combines a cognitive model of reading with explicit human gaze
supervision in a single machine learning framework. On four different corpora
we demonstrate that our hybrid TSM duration predictions are highly correlated
with human gaze ground truth. We further propose a novel joint modeling
approach to integrate TSM predictions into the attention layer of a network
designed for a specific upstream NLP task without the need for any
task-specific human gaze data. We demonstrate that our joint model outperforms
the state of the art in paraphrase generation on the Quora Question Pairs
corpus by more than 10% in BLEU-4 and achieves state of the art performance for
sentence compression on the challenging Google Sentence Compression corpus. As
such, our work introduces a practical approach for bridging between data-driven
and cognitive models and demonstrates a new way to integrate human gaze-guided
neural attention into NLP tasks."	ArXiv
1744	Dual Averaging is Surprisingly Effective for Deep Learning Optimization	['Samy Jelassi', 'Aaron Defazio']	2020-10-20 17:55:11+00:00	http://arxiv.org/abs/2010.10502v1	"First-order stochastic optimization methods are currently the most widely
used class of methods for training deep neural networks. However, the choice of
the optimizer has become an ad-hoc rule that can significantly affect the
performance. For instance, SGD with momentum (SGD+M) is typically used in
computer vision (CV) and Adam is used for training transformer models for
Natural Language Processing (NLP). Using the wrong method can lead to
significant performance degradation. Inspired by the dual averaging algorithm,
we propose Modernized Dual Averaging (MDA), an optimizer that is able to
perform as well as SGD+M in CV and as Adam in NLP. Our method is not adaptive
and is significantly simpler than Adam. We show that MDA induces a decaying
uncentered $L_2$-regularization compared to vanilla SGD+M and hypothesize that
this may explain why it works on NLP problems where SGD+M fails."	ArXiv
1745	Interpretation of NLP models through input marginalization	['Siwon Kim', 'Jihun Yi', 'Eunji Kim', 'Sungroh Yoon']	2020-10-27 01:40:41+00:00	http://arxiv.org/abs/2010.13984v1	"To demystify the ""black box"" property of deep neural networks for natural
language processing (NLP), several methods have been proposed to interpret
their predictions by measuring the change in prediction probability after
erasing each token of an input. Since existing methods replace each token with
a predefined value (i.e., zero), the resulting sentence lies out of the
training data distribution, yielding misleading interpretations. In this study,
we raise the out-of-distribution problem induced by the existing interpretation
methods and present a remedy; we propose to marginalize each token out. We
interpret various NLP models trained for sentiment analysis and natural
language inference using the proposed method."	ArXiv
1746	Deconstructing word embedding algorithms	['Kian Kenyon-Dean', 'Edward Newell', 'Jackie Chi Kit Cheung']	2020-11-12 14:23:35+00:00	http://arxiv.org/abs/2011.07013v1	"Word embeddings are reliable feature representations of words used to obtain
high quality results for various NLP applications. Uncontextualized word
embeddings are used in many NLP tasks today, especially in resource-limited
settings where high memory capacity and GPUs are not available. Given the
historical success of word embeddings in NLP, we propose a retrospective on
some of the most well-known word embedding algorithms. In this work, we
deconstruct Word2vec, GloVe, and others, into a common form, unveiling some of
the common conditions that seem to be required for making performant word
embeddings. We believe that the theoretical findings in this paper can provide
a basis for more informed development of future models."	ArXiv
1747	"Don't Patronize Me! An Annotated Dataset with Patronizing and
  Condescending Language towards Vulnerable Communities"	['Carla Pérez-Almendros', 'Luis Espinosa-Anke', 'Steven Schockaert']	2020-11-16 22:45:03+00:00	http://arxiv.org/abs/2011.08320v1	"In this paper, we introduce a new annotated dataset which is aimed at
supporting the development of NLP models to identify and categorize language
that is patronizing or condescending towards vulnerable communities (e.g.
refugees, homeless people, poor families). While the prevalence of such
language in the general media has long been shown to have harmful effects, it
differs from other types of harmful language, in that it is generally used
unconsciously and with good intentions. We furthermore believe that the often
subtle nature of patronizing and condescending language (PCL) presents an
interesting technical challenge for the NLP community. Our analysis of the
proposed dataset shows that identifying PCL is hard for standard NLP models,
with language models such as BERT achieving the best results."	ArXiv
1748	"Inspecting state of the art performance and NLP metrics in image-based
  medical report generation"	['Pablo Pino', 'Denis Parra', 'Pablo Messina', 'Cecilia Besa', 'Sergio Uribe']	2020-11-18 13:09:12+00:00	http://arxiv.org/abs/2011.09257v3	"Several deep learning architectures have been proposed over the last years to
deal with the problem of generating a written report given an imaging exam as
input. Most works evaluate the generated reports using standard Natural
Language Processing (NLP) metrics (e.g. BLEU, ROUGE), reporting significant
progress. In this article, we contrast this progress by comparing state of the
art (SOTA) models against weak baselines. We show that simple and even naive
approaches yield near SOTA performance on most traditional NLP metrics. We
conclude that evaluation methods in this task should be further studied towards
correctly measuring clinical accuracy, ideally involving physicians to
contribute to this end."	ArXiv
1749	Out-of-Task Training for Dialog State Tracking Models	['Michael Heck', 'Carel van Niekerk', 'Nurul Lubis', 'Christian Geishauser', 'Hsien-Chin Lin', 'Marco Moresi', 'Milica Gašić']	2020-11-18 16:23:30+00:00	http://arxiv.org/abs/2011.09379v1	"Dialog state tracking (DST) suffers from severe data sparsity. While many
natural language processing (NLP) tasks benefit from transfer learning and
multi-task learning, in dialog these methods are limited by the amount of
available data and by the specificity of dialog applications. In this work, we
successfully utilize non-dialog data from unrelated NLP tasks to train dialog
state trackers. This opens the door to the abundance of unrelated NLP corpora
to mitigate the data sparsity issue inherent to DST."	ArXiv
1750	"Data-Informed Global Sparseness in Attention Mechanisms for Deep Neural
  Networks"	['Ileana Rugina', 'Rumen Dangovski', 'Li Jing', 'Preslav Nakov', 'Marin Soljačić']	2020-11-20 13:58:21+00:00	http://arxiv.org/abs/2012.02030v3	"Attention mechanisms play a crucial role in the neural revolution of Natural
Language Processing (NLP). With the growth of attention-based models, several
pruning techniques have been developed to identify and exploit sparseness,
making these models more efficient. Most efforts focus on hard-coding attention
patterns or pruning attention weights based on training data. We propose
Attention Pruning (AP), a framework that observes attention patterns in a fixed
dataset and generates a global sparseness mask. AP saves 90% of attention
computation for language modeling and about 50% for machine translation and
GLUE tasks, maintaining result quality. Our method reveals important
distinctions between self- and cross-attention patterns, guiding future NLP
research. Our framework can reduce both latency and memory requirements for any
attention-based model, aiding in the development of improved models for
existing or new NLP applications. We have demonstrated this with encoder and
autoregressive transformer models using Triton GPU kernels and make our code
publicly available at https://github.com/irugina/AP."	ArXiv
1751	"On the Granularity of Explanations in Model Agnostic NLP
  Interpretability"	['Yves Rychener', 'Xavier Renard', 'Djamé Seddah', 'Pascal Frossard', 'Marcin Detyniecki']	2020-12-24 10:32:41+00:00	http://arxiv.org/abs/2012.13189v3	"Current methods for Black-Box NLP interpretability, like LIME or SHAP, are
based on altering the text to interpret by removing words and modeling the
Black-Box response. In this paper, we outline limitations of this approach when
using complex BERT-based classifiers: The word-based sampling produces texts
that are out-of-distribution for the classifier and further gives rise to a
high-dimensional search space, which can't be sufficiently explored when time
or computation power is limited. Both of these challenges can be addressed by
using segments as elementary building blocks for NLP interpretability. As
illustration, we show that the simple choice of sentences greatly improves on
both of these challenges. As a consequence, the resulting explainer attains
much better fidelity on a benchmark classification task."	ArXiv
1752	Explaining NLP Models via Minimal Contrastive Editing (MiCE)	['Alexis Ross', 'Ana Marasović', 'Matthew E. Peters']	2020-12-27 18:06:26+00:00	http://arxiv.org/abs/2012.13985v2	"Humans have been shown to give contrastive explanations, which explain why an
observed event happened rather than some other counterfactual event (the
contrast case). Despite the influential role that contrastivity plays in how
humans explain, this property is largely missing from current methods for
explaining NLP models. We present Minimal Contrastive Editing (MiCE), a method
for producing contrastive explanations of model predictions in the form of
edits to inputs that change model outputs to the contrast case. Our experiments
across three tasks--binary sentiment classification, topic classification, and
multiple-choice question answering--show that MiCE is able to produce edits
that are not only contrastive, but also minimal and fluent, consistent with
human contrastive edits. We demonstrate how MiCE edits can be used for two use
cases in NLP system development--debugging incorrect model outputs and
uncovering dataset artifacts--and thereby illustrate that producing contrastive
explanations is a promising research direction for model interpretability."	ArXiv
1753	"Memorization vs. Generalization: Quantifying Data Leakage in NLP
  Performance Evaluation"	['Aparna Elangovan', 'Jiayuan He', 'Karin Verspoor']	2021-02-03 00:58:45+00:00	http://arxiv.org/abs/2102.01818v1	"Public datasets are often used to evaluate the efficacy and generalizability
of state-of-the-art methods for many tasks in natural language processing
(NLP). However, the presence of overlap between the train and test datasets can
lead to inflated results, inadvertently evaluating the model's ability to
memorize and interpreting it as the ability to generalize. In addition, such
data sets may not provide an effective indicator of the performance of these
methods in real world scenarios. We identify leakage of training data into test
data on several publicly available datasets used to evaluate NLP tasks,
including named entity recognition and relation extraction, and study them to
assess the impact of that leakage on the model's ability to memorize versus
generalize."	ArXiv
1754	"Building Representative Corpora from Illiterate Communities: A Review of
  Challenges and Mitigation Strategies for Developing Countries"	['Stephanie Hirmer', 'Alycia Leonard', 'Josephine Tumwesige', 'Costanza Conforti']	2021-02-04 19:20:35+00:00	http://arxiv.org/abs/2102.02841v1	"Most well-established data collection methods currently adopted in NLP depend
on the assumption of speaker literacy. Consequently, the collected corpora
largely fail to represent swathes of the global population, which tend to be
some of the most vulnerable and marginalised people in society, and often live
in rural developing areas. Such underrepresented groups are thus not only
ignored when making modeling and system design decisions, but also prevented
from benefiting from development outcomes achieved through data-driven NLP.
This paper aims to address the under-representation of illiterate communities
in NLP corpora: we identify potential biases and ethical issues that might
arise when collecting data from rural communities with high illiteracy rates in
Low-Income Countries, and propose a set of practical mitigation strategies to
help future work."	ArXiv
1755	Towards More Fine-grained and Reliable NLP Performance Prediction	['Zihuiwen Ye', 'Pengfei Liu', 'Jinlan Fu', 'Graham Neubig']	2021-02-10 15:23:20+00:00	http://arxiv.org/abs/2102.05486v1	"Performance prediction, the task of estimating a system's performance without
performing experiments, allows us to reduce the experimental burden caused by
the combinatorial explosion of different datasets, languages, tasks, and
models. In this paper, we make two contributions to improving performance
prediction for NLP tasks. First, we examine performance predictors not only for
holistic measures of accuracy like F1 or BLEU but also fine-grained performance
measures such as accuracy over individual classes of examples. Second, we
propose methods to understand the reliability of a performance prediction model
from two angles: confidence intervals and calibration. We perform an analysis
of four types of NLP tasks, and both demonstrate the feasibility of
fine-grained performance prediction and the necessity to perform reliability
analysis for performance prediction methods in the future. We make our code
publicly available: \url{https://github.com/neulab/Reliable-NLPPP}"	ArXiv
1756	"An open access NLP dataset for Arabic dialects : Data collection,
  labeling, and model construction"	['ElMehdi Boujou', 'Hamza Chataoui', 'Abdellah El Mekki', 'Saad Benjelloun', 'Ikram Chairi', 'Ismail Berrada']	2021-02-07 01:39:52+00:00	http://arxiv.org/abs/2102.11000v1	"Natural Language Processing (NLP) is today a very active field of research
and innovation. Many applications need however big sets of data for supervised
learning, suitably labelled for the training purpose. This includes
applications for the Arabic language and its national dialects. However, such
open access labeled data sets in Arabic and its dialects are lacking in the
Data Science ecosystem and this lack can be a burden to innovation and research
in this field. In this work, we present an open data set of social data content
in several Arabic dialects. This data was collected from the Twitter social
network and consists on +50K twits in five (5) national dialects. Furthermore,
this data was labeled for several applications, namely dialect detection, topic
detection and sentiment analysis. We publish this data as an open access data
to encourage innovation and encourage other works in the field of NLP for
Arabic dialects and social media. A selection of models were built using this
data set and are presented in this paper along with their performances."	ArXiv
1757	Highly Fast Text Segmentation With Pairwise Markov Chains	['Elie Azeraf', 'Emmanuel Monfrini', 'Emmanuel Vignon', 'Wojciech Pieczynski']	2021-02-17 20:08:57+00:00	http://arxiv.org/abs/2102.11037v1	"Natural Language Processing (NLP) models' current trend consists of using
increasingly more extra-data to build the best models as possible. It implies
more expensive computational costs and training time, difficulties for
deployment, and worries about these models' carbon footprint reveal a critical
problem in the future. Against this trend, our goal is to develop NLP models
requiring no extra-data and minimizing training time. To do so, in this paper,
we explore Markov chain models, Hidden Markov Chain (HMC) and Pairwise Markov
Chain (PMC), for NLP segmentation tasks. We apply these models for three
classic applications: POS Tagging, Named-Entity-Recognition, and Chunking. We
develop an original method to adapt these models for text segmentation's
specific challenges to obtain relevant performances with very short training
and execution times. PMC achieves equivalent results to those obtained by
Conditional Random Fields (CRF), one of the most applied models for these tasks
when no extra-data are used. Moreover, PMC has training times 30 times shorter
than the CRF ones, which validates this model given our objectives."	ArXiv
1758	"AlephBERT:A Hebrew Large Pre-Trained Language Model to Start-off your
  Hebrew NLP Application With"	['Amit Seker', 'Elron Bandel', 'Dan Bareket', 'Idan Brusilovsky', 'Refael Shaked Greenfeld', 'Reut Tsarfaty']	2021-04-08 20:51:29+00:00	http://arxiv.org/abs/2104.04052v1	"Large Pre-trained Language Models (PLMs) have become ubiquitous in the
development of language understanding technology and lie at the heart of many
artificial intelligence advances. While advances reported for English using
PLMs are unprecedented, reported advances using PLMs in Hebrew are few and far
between. The problem is twofold. First, Hebrew resources available for training
NLP models are not at the same order of magnitude as their English
counterparts. Second, there are no accepted tasks and benchmarks to evaluate
the progress of Hebrew PLMs on. In this work we aim to remedy both aspects.
First, we present AlephBERT, a large pre-trained language model for Modern
Hebrew, which is trained on larger vocabulary and a larger dataset than any
Hebrew PLM before. Second, using AlephBERT we present new state-of-the-art
results on multiple Hebrew tasks and benchmarks, including: Segmentation,
Part-of-Speech Tagging, full Morphological Tagging, Named-Entity Recognition
and Sentiment Analysis. We make our AlephBERT model publicly available,
providing a single point of entry for the development of Hebrew NLP
applications."	ArXiv
1759	"ELECTRAMed: a new pre-trained language representation model for
  biomedical NLP"	['Giacomo Miolo', 'Giulio Mantoan', 'Carlotta Orsenigo']	2021-04-19 19:38:34+00:00	http://arxiv.org/abs/2104.09585v1	"The overwhelming amount of biomedical scientific texts calls for the
development of effective language models able to tackle a wide range of
biomedical natural language processing (NLP) tasks. The most recent dominant
approaches are domain-specific models, initialized with general-domain textual
data and then trained on a variety of scientific corpora. However, it has been
observed that for specialized domains in which large corpora exist, training a
model from scratch with just in-domain knowledge may yield better results.
Moreover, the increasing focus on the compute costs for pre-training recently
led to the design of more efficient architectures, such as ELECTRA. In this
paper, we propose a pre-trained domain-specific language model, called
ELECTRAMed, suited for the biomedical field. The novel approach inherits the
learning framework of the general-domain ELECTRA architecture, as well as its
computational advantages. Experiments performed on benchmark datasets for
several biomedical NLP tasks support the usefulness of ELECTRAMed, which sets
the novel state-of-the-art result on the BC5CDR corpus for named entity
recognition, and provides the best outcome in 2 over the 5 runs of the 7th
BioASQ-factoid Challange for the question answering task."	ArXiv
1760	"RECKONition: a NLP-based system for Industrial Accidents at Work
  Prevention"	['Patrizia Agnello', 'Silvia M. Ansaldi', 'Emilia Lenzi', 'Alessio Mongelluzzo', 'Manuel Roveri']	2021-04-29 07:13:07+00:00	http://arxiv.org/abs/2104.14150v1	"Extracting patterns and useful information from Natural Language datasets is
a challenging task, especially when dealing with data written in a language
different from English, like Italian. Machine and Deep Learning, together with
Natural Language Processing (NLP) techniques have widely spread and improved
lately, providing a plethora of useful methods to address both Supervised and
Unsupervised problems on textual information. We propose RECKONition, a
NLP-based system for Industrial Accidents at Work Prevention. RECKONition,
which is meant to provide Natural Language Understanding, Clustering and
Inference, is the result of a joint partnership with the Italian National
Institute for Insurance against Accidents at Work (INAIL). The obtained results
showed the ability to process textual data written in Italian describing
industrial accidents dynamics and consequences."	ArXiv
1761	Including Signed Languages in Natural Language Processing	['Kayo Yin', 'Amit Moryossef', 'Julie Hochgesang', 'Yoav Goldberg', 'Malihe Alikhani']	2021-05-11 17:37:55+00:00	http://arxiv.org/abs/2105.05222v2	"Signed languages are the primary means of communication for many deaf and
hard of hearing individuals. Since signed languages exhibit all the fundamental
linguistic properties of natural language, we believe that tools and theories
of Natural Language Processing (NLP) are crucial towards its modeling. However,
existing research in Sign Language Processing (SLP) seldom attempt to explore
and leverage the linguistic organization of signed languages. This position
paper calls on the NLP community to include signed languages as a research area
with high social and scientific impact. We first discuss the linguistic
properties of signed languages to consider during their modeling. Then, we
review the limitations of current SLP models and identify the open challenges
to extend NLP to signed languages. Finally, we urge (1) the adoption of an
efficient tokenization method; (2) the development of linguistically-informed
models; (3) the collection of real-world signed language data; (4) the
inclusion of local signed language communities as an active and leading voice
in the direction of research."	ArXiv
1762	"UIUC_BioNLP at SemEval-2021 Task 11: A Cascade of Neural Models for
  Structuring Scholarly NLP Contributions"	['Haoyang Liu', 'M. Janina Sarol', 'Halil Kilicoglu']	2021-05-12 05:24:35+00:00	http://arxiv.org/abs/2105.05435v1	"We propose a cascade of neural models that performs sentence classification,
phrase recognition, and triple extraction to automatically structure the
scholarly contributions of NLP publications. To identify the most important
contribution sentences in a paper, we used a BERT-based classifier with
positional features (Subtask 1). A BERT-CRF model was used to recognize and
characterize relevant phrases in contribution sentences (Subtask 2). We
categorized the triples into several types based on whether and how their
elements were expressed in text, and addressed each type using separate
BERT-based classifiers as well as rules (Subtask 3). Our system was officially
ranked second in Phase 1 evaluation and first in both parts of Phase 2
evaluation. After fixing a submission error in Pharse 1, our approach yields
the best results overall. In this paper, in addition to a system description,
we also provide further analysis of our results, highlighting its strengths and
limitations. We make our code publicly available at
https://github.com/Liu-Hy/nlp-contrib-graph."	ArXiv
1763	Analysing The Impact Of Linguistic Features On Cross-Lingual Transfer	['Błażej Dolicki', 'Gerasimos Spanakis']	2021-05-12 21:22:58+00:00	http://arxiv.org/abs/2105.05975v1	"There is an increasing amount of evidence that in cases with little or no
data in a target language, training on a different language can yield
surprisingly good results. However, currently there are no established
guidelines for choosing the training (source) language. In attempt to solve
this issue we thoroughly analyze a state-of-the-art multilingual model and try
to determine what impacts good transfer between languages. As opposed to the
majority of multilingual NLP literature, we don't only train on English, but on
a group of almost 30 languages. We show that looking at particular syntactic
features is 2-4 times more helpful in predicting the performance than an
aggregated syntactic similarity. We find out that the importance of syntactic
features strongly differs depending on the downstream task - no single feature
is a good performance predictor for all NLP tasks. As a result, one should not
expect that for a target language $L_1$ there is a single language $L_2$ that
is the best choice for any NLP task (for instance, for Bulgarian, the best
source language is French on POS tagging, Russian on NER and Thai on NLI). We
discuss the most important linguistic features affecting the transfer quality
using statistical and machine learning methods."	ArXiv
1764	Designing Multimodal Datasets for NLP Challenges	['James Pustejovsky', 'Eben Holderness', 'Jingxuan Tu', 'Parker Glenn', 'Kyeongmin Rim', 'Kelley Lynch', 'Richard Brutti']	2021-05-12 23:02:46+00:00	http://arxiv.org/abs/2105.05999v1	"In this paper, we argue that the design and development of multimodal
datasets for natural language processing (NLP) challenges should be enhanced in
two significant respects: to more broadly represent commonsense semantic
inferences; and to better reflect the dynamics of actions and events, through a
substantive alignment of textual and visual information. We identify challenges
and tasks that are reflective of linguistic and cognitive competencies that
humans have when speaking and reasoning, rather than merely the performance of
systems on isolated tasks. We introduce the distinction between challenge-based
tasks and competence-based performance, and describe a diagnostic dataset,
Recipe-to-Video Questions (R2VQ), designed for testing competence-based
comprehension over a multimodal recipe collection (http://r2vq.org/). The
corpus contains detailed annotation supporting such inferencing tasks and
facilitating a rich set of question families that we use to evaluate NLP
systems."	ArXiv
1765	"Bidirectional LSTM-CRF Attention-based Model for Chinese Word
  Segmentation"	['Chen Jin', 'Zhuangwei Shi', 'Weihua Li', 'Yanbu Guo']	2021-05-20 11:46:53+00:00	http://arxiv.org/abs/2105.09681v1	"Chinese word segmentation (CWS) is the basic of Chinese natural language
processing (NLP). The quality of word segmentation will directly affect the
rest of NLP tasks. Recently, with the artificial intelligence tide rising
again, Long Short-Term Memory (LSTM) neural network, as one of easily modeling
in sequence, has been widely utilized in various kinds of NLP tasks, and
functions well. Attention mechanism is an ingenious method to solve the memory
compression problem on LSTM. Furthermore, inspired by the powerful abilities of
bidirectional LSTM models for modeling sequence and CRF model for decoding, we
propose a Bidirectional LSTM-CRF Attention-based Model in this paper.
Experiments on PKU and MSRA benchmark datasets show that our model performs
better than the baseline methods modeling by other neural networks."	ArXiv
1766	IrEne: Interpretable Energy Prediction for Transformers	['Qingqing Cao', 'Yash Kumar Lal', 'Harsh Trivedi', 'Aruna Balasubramanian', 'Niranjan Balasubramanian']	2021-06-02 14:43:51+00:00	http://arxiv.org/abs/2106.01199v1	"Existing software-based energy measurements of NLP models are not accurate
because they do not consider the complex interactions between energy
consumption and model execution. We present IrEne, an interpretable and
extensible energy prediction system that accurately predicts the inference
energy consumption of a wide range of Transformer-based NLP models. IrEne
constructs a model tree graph that breaks down the NLP model into modules that
are further broken down into low-level machine learning (ML) primitives. IrEne
predicts the inference energy consumption of the ML primitives as a function of
generalizable features and fine-grained runtime resource usage. IrEne then
aggregates these low-level predictions recursively to predict the energy of
each module and finally of the entire model. Experiments across multiple
Transformer models show IrEne predicts inference energy consumption of
transformer models with an error of under 7% compared to the ground truth. In
contrast, existing energy models see an error of over 50%. We also show how
IrEne can be used to conduct energy bottleneck analysis and to easily evaluate
the energy impact of different architectural choices. We release the code and
data at https://github.com/StonyBrookNLP/irene."	ArXiv
1767	CodemixedNLP: An Extensible and Open NLP Toolkit for Code-Mixing	['Sai Muralidhar Jayanthi', 'Kavya Nerella', 'Khyathi Raghavi Chandu', 'Alan W Black']	2021-06-10 18:49:29+00:00	http://arxiv.org/abs/2106.06004v1	"The NLP community has witnessed steep progress in a variety of tasks across
the realms of monolingual and multilingual language processing recently. These
successes, in conjunction with the proliferating mixed language interactions on
social media have boosted interest in modeling code-mixed texts. In this work,
we present CodemixedNLP, an open-source library with the goals of bringing
together the advances in code-mixed NLP and opening it up to a wider machine
learning community. The library consists of tools to develop and benchmark
versatile model architectures that are tailored for mixed texts, methods to
expand training sets, techniques to quantify mixing styles, and fine-tuned
state-of-the-art models for 7 tasks in Hinglish. We believe this work has a
potential to foster a distributed yet collaborative and sustainable ecosystem
in an otherwise dispersed space of code-mixing research. The toolkit is
designed to be simple, easily extensible, and resourceful to both researchers
as well as practitioners."	ArXiv
1768	"Dynaboard: An Evaluation-As-A-Service Platform for Holistic
  Next-Generation Benchmarking"	['Zhiyi Ma', 'Kawin Ethayarajh', 'Tristan Thrush', 'Somya Jain', 'Ledell Wu', 'Robin Jia', 'Christopher Potts', 'Adina Williams', 'Douwe Kiela']	2021-05-21 01:17:52+00:00	http://arxiv.org/abs/2106.06052v1	"We introduce Dynaboard, an evaluation-as-a-service framework for hosting
benchmarks and conducting holistic model comparison, integrated with the
Dynabench platform. Our platform evaluates NLP models directly instead of
relying on self-reported metrics or predictions on a single dataset. Under this
paradigm, models are submitted to be evaluated in the cloud, circumventing the
issues of reproducibility, accessibility, and backwards compatibility that
often hinder benchmarking in NLP. This allows users to interact with uploaded
models in real time to assess their quality, and permits the collection of
additional metrics such as memory use, throughput, and robustness, which --
despite their importance to practitioners -- have traditionally been absent
from leaderboards. On each task, models are ranked according to the Dynascore,
a novel utility-based aggregation of these statistics, which users can
customize to better reflect their preferences, placing more/less weight on a
particular axis of evaluation or dataset. As state-of-the-art NLP models push
the limits of traditional benchmarks, Dynaboard offers a standardized solution
for a more diverse and comprehensive evaluation of model quality."	ArXiv
1769	"FedNLP: An interpretable NLP System to Decode Federal Reserve
  Communications"	['Jean Lee', 'Hoyoul Luis Youn', 'Nicholas Stevens', 'Josiah Poon', 'Soyeon Caren Han']	2021-06-11 08:58:36+00:00	http://arxiv.org/abs/2106.06247v1	"The Federal Reserve System (the Fed) plays a significant role in affecting
monetary policy and financial conditions worldwide. Although it is important to
analyse the Fed's communications to extract useful information, it is generally
long-form and complex due to the ambiguous and esoteric nature of content. In
this paper, we present FedNLP, an interpretable multi-component Natural
Language Processing system to decode Federal Reserve communications. This
system is designed for end-users to explore how NLP techniques can assist their
holistic understanding of the Fed's communications with NO coding. Behind the
scenes, FedNLP uses multiple NLP models from traditional machine learning
algorithms to deep neural network architectures in each downstream task. The
demonstration shows multiple results at once including sentiment analysis,
summary of the document, prediction of the Federal Funds Rate movement and
visualization for interpreting the prediction model's result."	ArXiv
1770	"A Discussion on Building Practical NLP Leaderboards: The Case of Machine
  Translation"	['Sebastin Santy', 'Prasanta Bhattacharya']	2021-06-11 10:24:35+00:00	http://arxiv.org/abs/2106.06292v2	"Recent advances in AI and ML applications have benefited from rapid progress
in NLP research. Leaderboards have emerged as a popular mechanism to track and
accelerate progress in NLP through competitive model development. While this
has increased interest and participation, the over-reliance on single, and
accuracy-based metrics have shifted focus from other important metrics that
might be equally pertinent to consider in real-world contexts. In this paper,
we offer a preliminary discussion of the risks associated with focusing
exclusively on accuracy metrics and draw on recent discussions to highlight
prescriptive suggestions on how to develop more practical and effective
leaderboards that can better reflect the real-world utility of models."	ArXiv
1771	"Turn the Combination Lock: Learnable Textual Backdoor Attacks via Word
  Substitution"	['Fanchao Qi', 'Yuan Yao', 'Sophia Xu', 'Zhiyuan Liu', 'Maosong Sun']	2021-06-11 13:03:17+00:00	http://arxiv.org/abs/2106.06361v1	"Recent studies show that neural natural language processing (NLP) models are
vulnerable to backdoor attacks. Injected with backdoors, models perform
normally on benign examples but produce attacker-specified predictions when the
backdoor is activated, presenting serious security threats to real-world
applications. Since existing textual backdoor attacks pay little attention to
the invisibility of backdoors, they can be easily detected and blocked. In this
work, we present invisible backdoors that are activated by a learnable
combination of word substitution. We show that NLP models can be injected with
backdoors that lead to a nearly 100% attack success rate, whereas being highly
invisible to existing defense strategies and even human inspections. The
results raise a serious alarm to the security of NLP models, which requires
further research to be resolved. All the data and code of this paper are
released at https://github.com/thunlp/BkdAtk-LWS."	ArXiv
1772	"Challenges and Considerations with Code-Mixed NLP for Multilingual
  Societies"	['Vivek Srivastava', 'Mayank Singh']	2021-06-15 00:53:55+00:00	http://arxiv.org/abs/2106.07823v1	"Multilingualism refers to the high degree of proficiency in two or more
languages in the written and oral communication modes. It often results in
language mixing, a.k.a. code-mixing, when a multilingual speaker switches
between multiple languages in a single utterance of a text or speech. This
paper discusses the current state of the NLP research, limitations, and
foreseeable pitfalls in addressing five real-world applications for social good
crisis management, healthcare, political campaigning, fake news, and hate
speech for multilingual societies. We also propose futuristic datasets, models,
and tools that can significantly advance the current research in multilingual
NLP applications for the societal good. As a representative example, we
consider English-Hindi code-mixing but draw similar inferences for other
language pairs"	ArXiv
1773	On the Diversity and Limits of Human Explanations	['Chenhao Tan']	2021-06-22 18:00:07+00:00	http://arxiv.org/abs/2106.11988v2	"A growing effort in NLP aims to build datasets of human explanations.
However, the term explanation encompasses a broad range of notions, each with
different properties and ramifications. Our goal is to provide an overview of
diverse types of explanations and human limitations, and discuss implications
for collecting and using explanations in NLP. Inspired by prior work in
psychology and cognitive sciences, we group existing human explanations in NLP
into three categories: proximal mechanism, evidence, and procedure. These three
types differ in nature and have implications for the resultant explanations.
For instance, procedure is not considered explanations in psychology and
connects with a rich body of work on learning from instructions. The diversity
of explanations is further evidenced by proxy questions that are needed for
annotators to interpret and answer open-ended why questions. Finally,
explanations may require different, often deeper, understandings than
predictions, which casts doubt on whether humans can provide useful
explanations in some tasks."	ArXiv
1774	"Draw Me a Flower: Processing and Grounding Abstraction in Natural
  Language"	['Royi Lachmy', 'Valentina Pyatkin', 'Avshalom Manevich', 'Reut Tsarfaty']	2021-06-27 21:11:16+00:00	http://arxiv.org/abs/2106.14321v2	"Abstraction is a core tenet of human cognition and communication. When
composing natural language instructions, humans naturally evoke abstraction to
convey complex procedures in an efficient and concise way. Yet, interpreting
and grounding abstraction expressed in NL has not yet been systematically
studied in NLP, with no accepted benchmarks specifically eliciting abstraction
in NL. In this work, we set the foundation for a systematic study of processing
and grounding abstraction in NLP. First, we deliver a novel abstraction
elicitation method and present Hexagons, a 2D instruction-following game. Using
Hexagons we collected over 4k naturally-occurring visually-grounded
instructions rich with diverse types of abstractions. From these data, we
derive an instruction-to-execution task and assess different types of neural
models. Our results show that contemporary models and modeling practices are
substantially inferior to human performance, and that models' performance is
inversely correlated with the level of abstraction, showing less satisfying
performance on higher levels of abstraction. These findings are consistent
across models and setups, confirming that abstraction is a challenging
phenomenon deserving further attention and study in NLP/AI research."	ArXiv
1775	"Quantifying Social Biases in NLP: A Generalization and Empirical
  Comparison of Extrinsic Fairness Metrics"	['Paula Czarnowska', 'Yogarshi Vyas', 'Kashif Shah']	2021-06-28 11:02:33+00:00	http://arxiv.org/abs/2106.14574v1	"Measuring bias is key for better understanding and addressing unfairness in
NLP/ML models. This is often done via fairness metrics which quantify the
differences in a model's behaviour across a range of demographic groups. In
this work, we shed more light on the differences and similarities between the
fairness metrics used in NLP. First, we unify a broad range of existing metrics
under three generalized fairness metrics, revealing the connections between
them. Next, we carry out an extensive empirical comparison of existing metrics
and demonstrate that the observed differences in bias measurement can be
systematically explained via differences in parameter choices for our
generalized metrics."	ArXiv
1776	Deep Natural Language Processing for LinkedIn Search Systems	['Weiwei Guo', 'Xiaowei Liu', 'Sida Wang', 'Michaeel Kazi', 'Zhoutong Fu', 'Huiji Gao', 'Jun Jia', 'Liang Zhang', 'Bo Long']	2021-07-30 17:40:36+00:00	http://arxiv.org/abs/2108.08252v1	"Many search systems work with large amounts of natural language data, e.g.,
search queries, user profiles and documents, where deep learning based natural
language processing techniques (deep NLP) can be of great help. In this paper,
we introduce a comprehensive study of applying deep NLP techniques to five
representative tasks in search engines. Through the model design and
experiments of the five tasks, readers can find answers to three important
questions: (1) When is deep NLP helpful/not helpful in search systems? (2) How
to address latency challenges? (3) How to ensure model robustness? This work
builds on existing efforts of LinkedIn search, and is tested at scale on a
commercial search engine. We believe our experiences can provide useful
insights for the industry and research communities."	ArXiv
1777	Semantic Communication with Adaptive Universal Transformer	['Qingyang Zhou', 'Rongpeng Li', 'Zhifeng Zhao', 'Chenghui Peng', 'Honggang Zhang']	2021-08-20 11:36:24+00:00	http://arxiv.org/abs/2108.09119v3	"With the development of deep learning (DL), natural language processing (NLP)
makes it possible for us to analyze and understand a large amount of language
texts. Accordingly, we can achieve a semantic communication in terms of joint
semantic source and channel coding over a noisy channel with the help of NLP.
However, the existing method to realize this goal is to use a fixed transformer
of NLP while ignoring the difference of semantic information contained in each
sentence. To solve this problem, we propose a new semantic communication system
based on Universal Transformer. Compared with the traditional transformer, an
adaptive circulation mechanism is introduced in the Universal Transformer.
Through the introduction of the circulation mechanism, the new semantic
communication system can be more flexible to transmit sentences with different
semantic information, and achieve better end-to-end performance under various
channel conditions."	ArXiv
1778	"Ensuring the Inclusive Use of Natural Language Processing in the Global
  Response to COVID-19"	['Alexandra Sasha Luccioni', 'Katherine Hoffmann Pham', 'Cynthia Sin Nga Lam', 'Joseph Aylett-Bullock', 'Miguel Luengo-Oroz']	2021-08-11 12:54:26+00:00	http://arxiv.org/abs/2108.10791v1	"Natural language processing (NLP) plays a significant role in tools for the
COVID-19 pandemic response, from detecting misinformation on social media to
helping to provide accurate clinical information or summarizing scientific
research. However, the approaches developed thus far have not benefited all
populations, regions or languages equally. We discuss ways in which current and
future NLP approaches can be made more inclusive by covering low-resource
languages, including alternative modalities, leveraging out-of-the-box tools
and forming meaningful partnerships. We suggest several future directions for
researchers interested in maximizing the positive societal impacts of NLP."	ArXiv
1779	A Survey On Neural Word Embeddings	['Erhan Sezerer', 'Selma Tekir']	2021-10-05 03:37:57+00:00	http://arxiv.org/abs/2110.01804v1	"Understanding human language has been a sub-challenge on the way of
intelligent machines. The study of meaning in natural language processing (NLP)
relies on the distributional hypothesis where language elements get meaning
from the words that co-occur within contexts. The revolutionary idea of
distributed representation for a concept is close to the working of a human
mind in that the meaning of a word is spread across several neurons, and a loss
of activation will only slightly affect the memory retrieval process.
  Neural word embeddings transformed the whole field of NLP by introducing
substantial improvements in all NLP tasks. In this survey, we provide a
comprehensive literature review on neural word embeddings. We give theoretical
foundations and describe existing work by an interplay between word embeddings
and language modelling. We provide broad coverage on neural word embeddings,
including early word embeddings, embeddings targeting specific semantic
relations, sense embeddings, morpheme embeddings, and finally, contextual
representations. Finally, we describe benchmark datasets in word embeddings'
performance evaluation and downstream tasks along with the performance results
of/due to word embeddings."	ArXiv
1780	Structured Prediction in NLP -- A survey	['Chauhan Dev', 'Naman Biyani', 'Nirmal P. Suthar', 'Prashant Kumar', 'Priyanshu Agarwal']	2021-08-31 07:01:09+00:00	http://arxiv.org/abs/2110.02057v1	"Over the last several years, the field of Structured prediction in NLP has
had seen huge advancements with sophisticated probabilistic graphical models,
energy-based networks, and its combination with deep learning-based approaches.
This survey provides a brief of major techniques in structured prediction and
its applications in the NLP domains like parsing, sequence labeling, text
generation, and sequence to sequence tasks. We also deep-dived into
energy-based and attention-based techniques in structured prediction,
identified some relevant open issues and gaps in the current state-of-the-art
research, and have come up with some detailed ideas for future research in
these fields."	ArXiv
1781	"We Need to Talk About Data: The Importance of Data Readiness in Natural
  Language Processing"	['Fredrik Olsson', 'Magnus Sahlgren']	2021-10-11 17:55:07+00:00	http://arxiv.org/abs/2110.05464v1	"In this paper, we identify the state of data as being an important reason for
failure in applied Natural Language Processing (NLP) projects. We argue that
there is a gap between academic research in NLP and its application to problems
outside academia, and that this gap is rooted in poor mutual understanding
between academic researchers and their non-academic peers who seek to apply
research results to their operations. To foster transfer of research results
from academia to non-academic settings, and the corresponding influx of
requirements back to academia, we propose a method for improving the
communication between researchers and external stakeholders regarding the
accessibility, validity, and utility of data based on Data Readiness Levels
\cite{lawrence2017data}. While still in its infancy, the method has been
iterated on and applied in multiple innovation and research projects carried
out with stakeholders in both the private and public sectors. Finally, we
invite researchers and practitioners to share their experiences, and thus
contributing to a body of work aimed at raising awareness of the importance of
data readiness for NLP."	ArXiv
1782	Masader: Metadata Sourcing for Arabic Text and Speech Data Resources	['Zaid Alyafeai', 'Maraim Masoud', 'Mustafa Ghaleb', 'Maged S. Al-shaibani']	2021-10-13 14:25:21+00:00	http://arxiv.org/abs/2110.06744v1	"The NLP pipeline has evolved dramatically in the last few years. The first
step in the pipeline is to find suitable annotated datasets to evaluate the
tasks we are trying to solve. Unfortunately, most of the published datasets
lack metadata annotations that describe their attributes. Not to mention, the
absence of a public catalogue that indexes all the publicly available datasets
related to specific regions or languages. When we consider low-resource
dialectical languages, for example, this issue becomes more prominent. In this
paper we create \textit{Masader}, the largest public catalogue for Arabic NLP
datasets, which consists of 200 datasets annotated with 25 attributes.
Furthermore, We develop a metadata annotation strategy that could be extended
to other languages. We also make remarks and highlight some issues about the
current status of Arabic NLP datasets and suggest recommendations to address
them."	ArXiv
1783	"Interpreting the Robustness of Neural NLP Models to Textual
  Perturbations"	['Yunxiang Zhang', 'Liangming Pan', 'Samson Tan', 'Min-Yen Kan']	2021-10-14 05:26:08+00:00	http://arxiv.org/abs/2110.07159v2	"Modern Natural Language Processing (NLP) models are known to be sensitive to
input perturbations and their performance can decrease when applied to
real-world, noisy data. However, it is still unclear why models are less robust
to some perturbations than others. In this work, we test the hypothesis that
the extent to which a model is affected by an unseen textual perturbation
(robustness) can be explained by the learnability of the perturbation (defined
as how well the model learns to identify the perturbation with a small amount
of evidence). We further give a causal justification for the learnability
metric. We conduct extensive experiments with four prominent NLP models --
TextRNN, BERT, RoBERTa and XLNet -- over eight types of textual perturbations
on three datasets. We show that a model which is better at identifying a
perturbation (higher learnability) becomes worse at ignoring such a
perturbation at test time (lower robustness), providing empirical support for
our hypothesis."	ArXiv
1784	Understanding Model Robustness to User-generated Noisy Texts	['Jakub Náplava', 'Martin Popel', 'Milan Straka', 'Jana Straková']	2021-10-14 14:54:52+00:00	http://arxiv.org/abs/2110.07428v2	"Sensitivity of deep-neural models to input noise is known to be a challenging
problem. In NLP, model performance often deteriorates with naturally occurring
noise, such as spelling errors. To mitigate this issue, models may leverage
artificially noised data. However, the amount and type of generated noise has
so far been determined arbitrarily. We therefore propose to model the errors
statistically from grammatical-error-correction corpora. We present a thorough
evaluation of several state-of-the-art NLP systems' robustness in multiple
languages, with tasks including morpho-syntactic analysis, named entity
recognition, neural machine translation, a subset of the GLUE benchmark and
reading comprehension. We also compare two approaches to address the
performance drop: a) training the NLP models with noised data generated by our
framework; and b) reducing the input noise with external system for natural
language correction. The code is released at https://github.com/ufal/kazitext."	ArXiv
1785	"Identifying and Mitigating Spurious Correlations for Improving
  Robustness in NLP Models"	['Tianlu Wang', 'Rohit Sridhar', 'Diyi Yang', 'Xuezhi Wang']	2021-10-14 21:40:03+00:00	http://arxiv.org/abs/2110.07736v2	"Recently, NLP models have achieved remarkable progress across a variety of
tasks; however, they have also been criticized for being not robust. Many
robustness problems can be attributed to models exploiting spurious
correlations, or shortcuts between the training data and the task labels. Most
existing work identifies a limited set of task-specific shortcuts via human
priors or error analyses, which requires extensive expertise and efforts. In
this paper, we aim to automatically identify such spurious correlations in NLP
models at scale. We first leverage existing interpretability methods to extract
tokens that significantly affect model's decision process from the input text.
We then distinguish ""genuine"" tokens and ""spurious"" tokens by analyzing model
predictions across multiple corpora and further verify them through
knowledge-aware perturbations. We show that our proposed method can effectively
and efficiently identify a scalable set of ""shortcuts"", and mitigating these
leads to more robust models in multiple applications."	ArXiv
1786	"Can Character-based Language Models Improve Downstream Task Performance
  in Low-Resource and Noisy Language Scenarios?"	['Arij Riabi', 'Benoît Sagot', 'Djamé Seddah']	2021-10-26 14:59:16+00:00	http://arxiv.org/abs/2110.13658v1	"Recent impressive improvements in NLP, largely based on the success of
contextual neural language models, have been mostly demonstrated on at most a
couple dozen high-resource languages. Building language models and, more
generally, NLP systems for non-standardized and low-resource languages remains
a challenging task. In this work, we focus on North-African colloquial
dialectal Arabic written using an extension of the Latin script, called
NArabizi, found mostly on social media and messaging communication. In this
low-resource scenario with data displaying a high level of variability, we
compare the downstream performance of a character-based language model on
part-of-speech tagging and dependency parsing to that of monolingual and
multilingual models. We show that a character-based model trained on only 99k
sentences of NArabizi and fined-tuned on a small treebank of this language
leads to performance close to those obtained with the same architecture
pre-trained on large multilingual and monolingual models. Confirming these
results a on much larger data set of noisy French user-generated content, we
argue that such character-based language models can be an asset for NLP in
low-resource and high language variability set-tings."	ArXiv
1787	"NLP From Scratch Without Large-Scale Pretraining: A Simple and Efficient
  Framework"	['Xingcheng Yao', 'Yanan Zheng', 'Xiaocong Yang', 'Zhilin Yang']	2021-11-07 17:13:59+00:00	http://arxiv.org/abs/2111.04130v2	"Pretrained language models have become the standard approach for many NLP
tasks due to strong performance, but they are very expensive to train. We
propose a simple and efficient learning framework, TLM, that does not rely on
large-scale pretraining. Given some labeled task data and a large general
corpus, TLM uses task data as queries to retrieve a tiny subset of the general
corpus and jointly optimizes the task objective and the language modeling
objective from scratch. On eight classification datasets in four domains, TLM
achieves results better than or similar to pretrained language models (e.g.,
RoBERTa-Large) while reducing the training FLOPs by two orders of magnitude.
With high accuracy and efficiency, we hope TLM will contribute to democratizing
NLP and expediting its development."	ArXiv
1788	Time Waits for No One! Analysis and Challenges of Temporal Misalignment	['Kelvin Luu', 'Daniel Khashabi', 'Suchin Gururangan', 'Karishma Mandyam', 'Noah A. Smith']	2021-11-14 18:29:19+00:00	http://arxiv.org/abs/2111.07408v2	"When an NLP model is trained on text data from one time period and tested or
deployed on data from another, the resulting temporal misalignment can degrade
end-task performance. In this work, we establish a suite of eight diverse tasks
across different domains (social media, science papers, news, and reviews) and
periods of time (spanning five years or more) to quantify the effects of
temporal misalignment. Our study is focused on the ubiquitous setting where a
pretrained model is optionally adapted through continued domain-specific
pretraining, followed by task-specific finetuning. We establish a suite of
tasks across multiple domains to study temporal misalignment in modern NLP
systems. We find stronger effects of temporal misalignment on task performance
than have been previously reported. We also find that, while temporal
adaptation through continued pretraining can help, these gains are small
compared to task-specific finetuning on data from the target time period. Our
findings motivate continued research to improve temporal robustness of NLP
models."	ArXiv
1789	DataCLUE: A Benchmark Suite for Data-centric NLP	['Liang Xu', 'Jiacheng Liu', 'Xiang Pan', 'Xiaojing Lu', 'Xiaofeng Hou']	2021-11-16 17:30:56+00:00	http://arxiv.org/abs/2111.08647v2	"Data-centric AI has recently proven to be more effective and
high-performance, while traditional model-centric AI delivers fewer and fewer
benefits. It emphasizes improving the quality of datasets to achieve better
model performance. This field has significant potential because of its great
practicability and getting more and more attention. However, we have not seen
significant research progress in this field, especially in NLP. We propose
DataCLUE, which is the first Data-Centric benchmark applied in NLP field. We
also provide three simple but effective baselines to foster research in this
field (improve Macro-F1 up to 5.7% point). In addition, we conduct
comprehensive experiments with human annotators and show the hardness of
DataCLUE. We also try an advanced method: the forgetting informed bootstrapping
label correction method. All the resources related to DataCLUE, including
datasets, toolkit, leaderboard, and baselines, is available online at
https://github.com/CLUEbenchmark/DataCLUE"	ArXiv
1790	A Comparative Study of Transformers on Word Sense Disambiguation	['Avi Chawla', 'Nidhi Mulay', 'Vikas Bishnoi', 'Gaurav Dhama', 'Anil Kumar Singh']	2021-11-30 14:10:22+00:00	http://arxiv.org/abs/2111.15417v1	"Recent years of research in Natural Language Processing (NLP) have witnessed
dramatic growth in training large models for generating context-aware language
representations. In this regard, numerous NLP systems have leveraged the power
of neural network-based architectures to incorporate sense information in
embeddings, resulting in Contextualized Word Embeddings (CWEs). Despite this
progress, the NLP community has not witnessed any significant work performing a
comparative study on the contextualization power of such architectures. This
paper presents a comparative study and an extensive analysis of nine widely
adopted Transformer models. These models are BERT, CTRL, DistilBERT,
OpenAI-GPT, OpenAI-GPT2, Transformer-XL, XLNet, ELECTRA, and ALBERT. We
evaluate their contextualization power using two lexical sample Word Sense
Disambiguation (WSD) tasks, SensEval-2 and SensEval-3. We adopt a simple yet
effective approach to WSD that uses a k-Nearest Neighbor (kNN) classification
on CWEs. Experimental results show that the proposed techniques also achieve
superior results over the current state-of-the-art on both the WSD tasks"	ArXiv
1791	"Measuring and Reducing Model Update Regression in Structured Prediction
  for NLP"	['Deng Cai', 'Elman Mansimov', 'Yi-An Lai', 'Yixuan Su', 'Lei Shu', 'Yi Zhang']	2022-02-07 07:04:54+00:00	http://arxiv.org/abs/2202.02976v2	"Recent advance in deep learning has led to the rapid adoption of machine
learning-based NLP models in a wide range of applications. Despite the
continuous gain in accuracy, backward compatibility is also an important aspect
for industrial applications, yet it received little research attention.
Backward compatibility requires that the new model does not regress on cases
that were correctly handled by its predecessor. This work studies model update
regression in structured prediction tasks. We choose syntactic dependency
parsing and conversational semantic parsing as representative examples of
structured prediction tasks in NLP. First, we measure and analyze model update
regression in different model update settings. Next, we explore and benchmark
existing techniques for reducing model update regression including model
ensemble and knowledge distillation. We further propose a simple and effective
method, Backward-Congruent Re-ranking (BCR), by taking into account the
characteristics of structured prediction. Experiments show that BCR can better
mitigate model update regression than model ensemble and knowledge distillation
approaches."	ArXiv
1792	pNLP-Mixer: an Efficient all-MLP Architecture for Language	['Francesco Fusco', 'Damian Pascual', 'Peter Staar', 'Diego Antognini']	2022-02-09 09:01:29+00:00	http://arxiv.org/abs/2202.04350v2	"Large pre-trained language models based on transformer architecture have
drastically changed the natural language processing (NLP) landscape. However,
deploying those models for on-device applications in constrained devices such
as smart watches is completely impractical due to their size and inference
cost. As an alternative to transformer-based architectures, recent work on
efficient NLP has shown that weight-efficient models can attain competitive
performance for simple tasks, such as slot filling and intent classification,
with model sizes in the order of the megabyte. This work introduces the
pNLP-Mixer architecture, an embedding-free MLP-Mixer model for on-device NLP
that achieves high weight-efficiency thanks to a novel projection layer. We
evaluate a pNLP-Mixer model of only one megabyte in size on two multi-lingual
semantic parsing datasets, MTOP and multiATIS. Our quantized model achieves
99.4% and 97.8% the performance of mBERT on MTOP and multi-ATIS, while using
170x fewer parameters. Our model consistently beats the state-of-the-art of
tiny models (pQRNN), which is twice as large, by a margin up to 7.8% on MTOP."	ArXiv
1793	"Natural Language in Requirements Engineering for Structure Inference --
  An Integrative Review"	['Maximilian Vierlboeck', 'Carlo Lipizzi', 'Roshanak Nilchiani']	2022-02-10 14:46:09+00:00	http://arxiv.org/abs/2202.05065v1	"The automatic extraction of structure from text can be difficult for
machines. Yet, the elicitation of this information can provide many benefits
and opportunities for various applications. Benefits have also been identified
for the area of Requirements Engineering. To evaluate what work has been done
and is currently available, the paper at hand provides an integrative review
regarding Natural Language Processing (NLP) tools for Requirements Engineering.
This assessment was conducted to provide a foundation for future work as well
as deduce insights from the stats quo. To conduct the review, the history of
Requirements Engineering and NLP are described as well as an evaluation of over
136 NLP tools. To assess these tools, a set of criteria was defined. The
results are that currently no open source approach exists that allows for the
direct/primary extraction of information structure and even closed source
solutions show limitations such as supervision or input limitations, which
eliminates the possibility for fully automatic and universal application. As a
results, the authors deduce that the current approaches are not applicable and
a different methodology is necessary. An approach that allows for individual
management of the algorithm, knowledge base, and text corpus is a possibility
being pursued."	ArXiv
1794	MuLD: The Multitask Long Document Benchmark	['G Thomas Hudson', 'Noura Al Moubayed']	2022-02-15 12:42:55+00:00	http://arxiv.org/abs/2202.07362v1	"The impressive progress in NLP techniques has been driven by the development
of multi-task benchmarks such as GLUE and SuperGLUE. While these benchmarks
focus on tasks for one or two input sentences, there has been exciting work in
designing efficient techniques for processing much longer inputs. In this
paper, we present MuLD: a new long document benchmark consisting of only
documents over 10,000 tokens. By modifying existing NLP tasks, we create a
diverse benchmark which requires models to successfully model long-term
dependencies in the text. We evaluate how existing models perform, and find
that our benchmark is much more challenging than their `short document'
equivalents. Furthermore, by evaluating both regular and efficient
transformers, we show that models with increased context length are better able
to solve the tasks presented, suggesting that future improvements in these
models are vital for solving similar long document problems. We release the
data and code for baselines to encourage further research on efficient NLP
models."	ArXiv
1795	The NLP Task Effectiveness of Long-Range Transformers	['Guanghui Qin', 'Yukun Feng', 'Benjamin Van Durme']	2022-02-16 04:39:35+00:00	http://arxiv.org/abs/2202.07856v2	"Transformer models cannot easily scale to long sequences due to their O(N^2)
time and space complexity. This has led to Transformer variants seeking to
lower computational complexity, such as Longformer and Performer. While such
models have theoretically greater efficiency, their effectiveness on real NLP
tasks has not been well studied. We benchmark 7 variants of Transformer models
on 5 difficult NLP tasks and 7 datasets. We design experiments to isolate the
effect of pretraining and hyperparameter settings, to focus on their capacity
for long-range attention. Moreover, we present various methods to investigate
attention behaviors to illuminate model details beyond metric scores. We find
that the modified attention in long-range transformers has advantages on
content selection and query-guided decoding, but they come with previously
unrecognized drawbacks such as insufficient attention to distant tokens and
accumulated approximation error."	ArXiv
1796	"Welcome to the Modern World of Pronouns: Identity-Inclusive Natural
  Language Processing beyond Gender"	['Anne Lauscher', 'Archie Crowley', 'Dirk Hovy']	2022-02-24 06:42:11+00:00	http://arxiv.org/abs/2202.11923v1	"The world of pronouns is changing. From a closed class of words with few
members to a much more open set of terms to reflect identities. However,
Natural Language Processing (NLP) is barely reflecting this linguistic shift,
even though recent work outlined the harms of gender-exclusive language
technology. Particularly problematic is the current modeling 3rd person
pronouns, as it largely ignores various phenomena like neopronouns, i.e.,
pronoun sets that are novel and not (yet) widely established. This omission
contributes to the discrimination of marginalized and underrepresented groups,
e.g., non-binary individuals. However, other identity-expression phenomena
beyond gender are also ignored by current NLP technology. In this paper, we
provide an overview of 3rd person pronoun issues for NLP. Based on our
observations and ethical considerations, we define a series of desiderata for
modeling pronouns in language technology. We evaluate existing and novel
modeling approaches w.r.t. these desiderata qualitatively, and quantify the
impact of a more discrimination-free approach on established benchmark data."	ArXiv
1797	"How reparametrization trick broke differentially-private text
  representation learning"	['Ivan Habernal']	2022-02-24 15:02:42+00:00	http://arxiv.org/abs/2202.12138v2	"As privacy gains traction in the NLP community, researchers have started
adopting various approaches to privacy-preserving methods. One of the favorite
privacy frameworks, differential privacy (DP), is perhaps the most compelling
thanks to its fundamental theoretical guarantees. Despite the apparent
simplicity of the general concept of differential privacy, it seems non-trivial
to get it right when applying it to NLP. In this short paper, we formally
analyze several recent NLP papers proposing text representation learning using
DPText (Beigi et al., 2019a,b; Alnasser et al., 2021; Beigi et al., 2021) and
reveal their false claims of being differentially private. Furthermore, we also
show a simple yet general empirical sanity check to determine whether a given
implementation of a DP mechanism almost certainly violates the privacy loss
guarantees. Our main goal is to raise awareness and help the community
understand potential pitfalls of applying differential privacy to text
representation learning."	ArXiv
1798	"A Unified Framework of Medical Information Annotation and Extraction for
  Chinese Clinical Text"	['Enwei Zhu', 'Qilin Sheng', 'Huanwan Yang', 'Jinpeng Li']	2022-03-08 03:19:16+00:00	http://arxiv.org/abs/2203.03823v1	"Medical information extraction consists of a group of natural language
processing (NLP) tasks, which collaboratively convert clinical text to
pre-defined structured formats. Current state-of-the-art (SOTA) NLP models are
highly integrated with deep learning techniques and thus require massive
annotated linguistic data. This study presents an engineering framework of
medical entity recognition, relation extraction and attribute extraction, which
are unified in annotation, modeling and evaluation. Specifically, the
annotation scheme is comprehensive, and compatible between tasks, especially
for the medical relations. The resulted annotated corpus includes 1,200 full
medical records (or 18,039 broken-down documents), and achieves inter-annotator
agreements (IAAs) of 94.53%, 73.73% and 91.98% F 1 scores for the three tasks.
Three task-specific neural network models are developed within a shared
structure, and enhanced by SOTA NLP techniques, i.e., pre-trained language
models. Experimental results show that the system can retrieve medical
entities, relations and attributes with F 1 scores of 93.47%, 67.14% and
90.89%, respectively. This study, in addition to our publicly released
annotation scheme and code, provides solid and practical engineering experience
of developing an integrated medical information extraction system."	ArXiv
1799	iSEA: An Interactive Pipeline for Semantic Error Analysis of NLP Models	['Jun Yuan', 'Jesse Vig', 'Nazneen Rajani']	2022-03-08 21:31:15+00:00	http://arxiv.org/abs/2203.04408v1	"Error analysis in NLP models is essential to successful model development and
deployment. One common approach for diagnosing errors is to identify
subpopulations in the dataset where the model produces the most errors.
However, existing approaches typically define subpopulations based on
pre-defined features, which requires users to form hypotheses of errors in
advance. To complement these approaches, we propose iSEA, an Interactive
Pipeline for Semantic Error Analysis in NLP Models, which automatically
discovers semantically-grounded subpopulations with high error rates in the
context of a human-in-the-loop interactive system. iSEA enables model
developers to learn more about their model errors through discovered
subpopulations, validate the sources of errors through interactive analysis on
the discovered subpopulations, and test hypotheses about model errors by
defining custom subpopulations. The tool supports semantic descriptions of
error-prone subpopulations at the token and concept level, as well as
pre-defined higher-level features. Through use cases and expert interviews, we
demonstrate how iSEA can assist error understanding and analysis."	ArXiv
1800	"HealthPrompt: A Zero-shot Learning Paradigm for Clinical Natural
  Language Processing"	['Sonish Sivarajkumar', 'Yanshan Wang']	2022-03-09 21:44:28+00:00	http://arxiv.org/abs/2203.05061v1	"Deep learning algorithms are dependent on the availability of large-scale
annotated clinical text datasets. The lack of such publicly available datasets
is the biggest bottleneck for the development of clinical Natural Language
Processing(NLP) systems. Zero-Shot Learning(ZSL) refers to the use of deep
learning models to classify instances from new classes of which no training
data have been seen before. Prompt-based learning is an emerging ZSL technique
where we define task-based templates for NLP tasks. We developed a novel
prompt-based clinical NLP framework called HealthPrompt and applied the
paradigm of prompt-based learning on clinical texts. In this technique, rather
than fine-tuning a Pre-trained Language Model(PLM), the task definitions are
tuned by defining a prompt template. We performed an in-depth analysis of
HealthPrompt on six different PLMs in a no-data setting. Our experiments prove
that prompts effectively capture the context of clinical texts and perform
remarkably well without any training data."	ArXiv
1801	"Expanding Pretrained Models to Thousands More Languages via
  Lexicon-based Adaptation"	['Xinyi Wang', 'Sebastian Ruder', 'Graham Neubig']	2022-03-17 16:48:22+00:00	http://arxiv.org/abs/2203.09435v2	"The performance of multilingual pretrained models is highly dependent on the
availability of monolingual or parallel text present in a target language.
Thus, the majority of the world's languages cannot benefit from recent progress
in NLP as they have no or limited textual data. To expand possibilities of
using NLP technology in these under-represented languages, we systematically
study strategies that relax the reliance on conventional language resources
through the use of bilingual lexicons, an alternative resource with much better
language coverage. We analyze different strategies to synthesize textual or
labeled data using lexicons, and how this data can be combined with monolingual
or parallel text when available. For 19 under-represented languages across 3
tasks, our methods lead to consistent improvements of up to 5 and 15 points
with and without extra monolingual text respectively. Overall, our study
highlights how NLP methods can be adapted to thousands more languages that are
under-served by current technology"	ArXiv
1802	Understanding COVID-19 News Coverage using Medical NLP	['Ali Emre Varol', 'Veysel Kocaman', 'Hasham Ul Haq', 'David Talby']	2022-03-19 15:07:46+00:00	http://arxiv.org/abs/2203.10338v1	"Being a global pandemic, the COVID-19 outbreak received global media
attention. In this study, we analyze news publications from CNN and The
Guardian - two of the world's most influential media organizations. The dataset
includes more than 36,000 articles, analyzed using the clinical and biomedical
Natural Language Processing (NLP) models from the Spark NLP for Healthcare
library, which enables a deeper analysis of medical concepts than previously
achieved. The analysis covers key entities and phrases, observed biases, and
change over time in news coverage by correlating mined medical symptoms,
procedures, drugs, and guidance with commonly mentioned demographic and
occupational groups. Another analysis is of extracted Adverse Drug Events about
drug and vaccine manufacturers, which when reported by major news outlets has
an impact on vaccine hesitancy."	ArXiv
1803	An Empirical Study of Memorization in NLP	['Xiaosen Zheng', 'Jing Jiang']	2022-03-23 03:27:56+00:00	http://arxiv.org/abs/2203.12171v1	"A recent study by Feldman (2020) proposed a long-tail theory to explain the
memorization behavior of deep learning models. However, memorization has not
been empirically verified in the context of NLP, a gap addressed by this work.
In this paper, we use three different NLP tasks to check if the long-tail
theory holds. Our experiments demonstrate that top-ranked memorized training
instances are likely atypical, and removing the top-memorized training
instances leads to a more serious drop in test accuracy compared with removing
training instances randomly. Furthermore, we develop an attribution method to
better understand why a training instance is memorized. We empirically show
that our memorization attribution method is faithful, and share our interesting
finding that the top-memorized parts of a training instance tend to be features
negatively correlated with the class label."	ArXiv
1804	"EnCBP: A New Benchmark Dataset for Finer-Grained Cultural Background
  Prediction in English"	['Weicheng Ma', 'Samiha Datta', 'Lili Wang', 'Soroush Vosoughi']	2022-03-28 04:57:17+00:00	http://arxiv.org/abs/2203.14498v1	"While cultural backgrounds have been shown to affect linguistic expressions,
existing natural language processing (NLP) research on culture modeling is
overly coarse-grained and does not examine cultural differences among speakers
of the same language. To address this problem and augment NLP models with
cultural background features, we collect, annotate, manually validate, and
benchmark EnCBP, a finer-grained news-based cultural background prediction
dataset in English. Through language modeling (LM) evaluations and manual
analyses, we confirm that there are noticeable differences in linguistic
expressions among five English-speaking countries and across four states in the
US. Additionally, our evaluations on nine syntactic (CoNLL-2003), semantic
(PAWS-Wiki, QNLI, STS-B, and RTE), and psycholinguistic tasks (SST-5, SST-2,
Emotion, and Go-Emotions) show that, while introducing cultural background
information does not benefit the Go-Emotions task due to text domain conflicts,
it noticeably improves deep learning (DL) model performance on other tasks. Our
findings strongly support the importance of cultural background modeling to a
wide variety of NLP tasks and demonstrate the applicability of EnCBP in
culture-related research."	ArXiv
1805	"An Inverse Optimal Control Approach for Trajectory Prediction of
  Autonomous Race Cars"	['Rudolf Reiter', 'Florian Messerer', 'Markus Schratter', 'Daniel Watzenig', 'Moritz Diehl']	2022-04-04 13:48:24+00:00	http://arxiv.org/abs/2204.01494v1	"This paper proposes an optimization-based approach to predict trajectories of
autonomous race cars. We assume that the observed trajectory is the result of
an optimization problem that trades off path progress against acceleration and
jerk smoothness, and which is restricted by constraints. The algorithm predicts
a trajectory by solving a parameterized nonlinear program (NLP) which contains
path progress and smoothness in cost terms. By observing the actual motion of a
vehicle, the parameters of prediction are updated by means of solving an
inverse optimal control problem that contains the parameters of the predicting
NLP as optimization variables. The algorithm therefore learns to predict the
observed vehicle trajectory in a least-squares relation to measurement data and
to the presumed structure of the predicting NLP. This work contributes with an
algorithm that allows for accurate and interpretable predictions with sparse
data. The algorithm is implemented on embedded hardware in an autonomous
real-world race car that is competing in the challenge Roborace and analyzed
with respect to recorded data."	ArXiv
1806	"Design considerations for a hierarchical semantic compositional
  framework for medical natural language understanding"	['Ricky K. Taira', 'Anders O. Garlid', 'William Speier']	2022-04-05 09:04:34+00:00	http://arxiv.org/abs/2204.02067v1	"Medical natural language processing (NLP) systems are a key enabling
technology for transforming Big Data from clinical report repositories to
information used to support disease models and validate intervention methods.
However, current medical NLP systems fall considerably short when faced with
the task of logically interpreting clinical text. In this paper, we describe a
framework inspired by mechanisms of human cognition in an attempt to jump the
NLP performance curve. The design centers about a hierarchical semantic
compositional model (HSCM) which provides an internal substrate for guiding the
interpretation process. The paper describes insights from four key cognitive
aspects including semantic memory, semantic composition, semantic activation,
and hierarchical predictive coding. We discuss the design of a generative
semantic model and an associated semantic parser used to transform a free-text
sentence into a logical representation of its meaning. The paper discusses
supportive and antagonistic arguments for the key features of the architecture
as a long-term foundational framework."	ArXiv
1807	"A Survey of Multi-task Learning in Natural Language Processing:
  Regarding Task Relatedness and Training Methods"	['Zhihan Zhang', 'Wenhao Yu', 'Mengxia Yu', 'Zhichun Guo', 'Meng Jiang']	2022-04-07 15:22:19+00:00	http://arxiv.org/abs/2204.03508v2	"Multi-task learning (MTL) has become increasingly popular in natural language
processing (NLP) because it improves the performance of related tasks by
exploiting their commonalities and differences. Nevertheless, it is still not
understood very well how multi-task learning can be implemented based on the
relatedness of training tasks. In this survey, we review recent advances of
multi-task learning methods in NLP, with the aim of summarizing them into two
general multi-task training methods based on their task relatedness: (i) joint
training and (ii) multi-step training. We present examples in various NLP
downstream applications, summarize the task relationships and discuss future
directions of this promising topic."	ArXiv
1808	Re-Examining Human Annotations for Interpretable NLP	['Cheng-Han Chiang', 'Hung-yi Lee']	2022-04-10 02:27:30+00:00	http://arxiv.org/abs/2204.04580v1	"Explanation methods in Interpretable NLP often explain the model's decision
by extracting evidence (rationale) from the input texts supporting the
decision. Benchmark datasets for rationales have been released to evaluate how
good the rationale is. The ground truth rationales in these datasets are often
human annotations obtained via crowd-sourced websites. Valuable as these
datasets are, the details on how those human annotations are obtained are often
not clearly specified. We conduct comprehensive controlled experiments using
crowd-sourced websites on two widely used datasets in Interpretable NLP to
understand how those unsaid details can affect the annotation results.
Specifically, we compare the annotation results obtained from recruiting
workers satisfying different levels of qualification. We also provide
high-quality workers with different instructions for completing the same
underlying tasks. Our results reveal that the annotation quality is highly
subject to the workers' qualification, and workers can be guided to provide
certain annotations by the instructions. We further show that specific
explanation methods perform better when evaluated using the ground truth
rationales obtained by particular instructions. Based on these observations, we
highlight the importance of providing complete details of the annotation
process and call for careful interpretation of any experiment results obtained
using those annotations."	ArXiv
1809	"A Survey on Legal Judgment Prediction: Datasets, Metrics, Models and
  Challenges"	['Junyun Cui', 'Xiaoyu Shen', 'Feiping Nie', 'Zheng Wang', 'Jinglong Wang', 'Yulong Chen']	2022-04-11 04:06:28+00:00	http://arxiv.org/abs/2204.04859v1	"Legal judgment prediction (LJP) applies Natural Language Processing (NLP)
techniques to predict judgment results based on fact descriptions
automatically. Recently, large-scale public datasets and advances in NLP
research have led to increasing interest in LJP. Despite a clear gap between
machine and human performance, impressive results have been achieved in various
benchmark datasets. In this paper, to address the current lack of comprehensive
survey of existing LJP tasks, datasets, models and evaluations, (1) we analyze
31 LJP datasets in 6 languages, present their construction process and define a
classification method of LJP with 3 different attributes; (2) we summarize 14
evaluation metrics under four categories for different outputs of LJP tasks;
(3) we review 12 legal-domain pretrained models in 3 languages and highlight 3
major research directions for LJP; (4) we show the state-of-art results for 8
representative datasets from different court cases and discuss the open
challenges. This paper can provide up-to-date and comprehensive reviews to help
readers understand the status of LJP. We hope to facilitate both NLP
researchers and legal professionals for further joint efforts in this problem."	ArXiv
1810	"How Gender Debiasing Affects Internal Model Representations, and Why It
  Matters"	['Hadas Orgad', 'Seraphina Goldfarb-Tarrant', 'Yonatan Belinkov']	2022-04-14 08:54:15+00:00	http://arxiv.org/abs/2204.06827v2	"Common studies of gender bias in NLP focus either on extrinsic bias measured
by model performance on a downstream task or on intrinsic bias found in models'
internal representations. However, the relationship between extrinsic and
intrinsic bias is relatively unknown. In this work, we illuminate this
relationship by measuring both quantities together: we debias a model during
downstream fine-tuning, which reduces extrinsic bias, and measure the effect on
intrinsic bias, which is operationalized as bias extractability with
information-theoretic probing. Through experiments on two tasks and multiple
bias metrics, we show that our intrinsic bias metric is a better indicator of
debiasing than (a contextual adaptation of) the standard WEAT metric, and can
also expose cases of superficial debiasing. Our framework provides a
comprehensive perspective on bias in NLP models, which can be applied to deploy
NLP systems in a more informed manner. Our code and model checkpoints are
publicly available."	ArXiv
1811	"Locally Aggregated Feature Attribution on Natural Language Model
  Understanding"	['Sheng Zhang', 'Jin Wang', 'Haitao Jiang', 'Rui Song']	2022-04-22 18:59:27+00:00	http://arxiv.org/abs/2204.10893v2	"With the growing popularity of deep-learning models, model understanding
becomes more important. Much effort has been devoted to demystify deep neural
networks for better interpretability. Some feature attribution methods have
shown promising results in computer vision, especially the gradient-based
methods where effectively smoothing the gradients with reference data is key to
a robust and faithful result. However, direct application of these
gradient-based methods to NLP tasks is not trivial due to the fact that the
input consists of discrete tokens and the ""reference"" tokens are not explicitly
defined. In this work, we propose Locally Aggregated Feature Attribution
(LAFA), a novel gradient-based feature attribution method for NLP models.
Instead of relying on obscure reference tokens, it smooths gradients by
aggregating similar reference texts derived from language model embeddings. For
evaluation purpose, we also design experiments on different NLP tasks including
Entity Recognition and Sentiment Analysis on public datasets as well as key
feature detection on a constructed Amazon catalogue dataset. The superior
performance of the proposed method is demonstrated through experiments."	ArXiv
1812	"Systematicity, Compositionality and Transitivity of Deep NLP Models: a
  Metamorphic Testing Perspective"	['Edoardo Manino', 'Julia Rozanova', 'Danilo Carvalho', 'Andre Freitas', 'Lucas Cordeiro']	2022-04-26 13:50:07+00:00	http://arxiv.org/abs/2204.12316v1	"Metamorphic testing has recently been used to check the safety of neural NLP
models. Its main advantage is that it does not rely on a ground truth to
generate test cases. However, existing studies are mostly concerned with
robustness-like metamorphic relations, limiting the scope of linguistic
properties they can test. We propose three new classes of metamorphic
relations, which address the properties of systematicity, compositionality and
transitivity. Unlike robustness, our relations are defined over multiple source
inputs, thus increasing the number of test cases that we can produce by a
polynomial factor. With them, we test the internal consistency of
state-of-the-art NLP models, and show that they do not always behave according
to their expected linguistic properties. Lastly, we introduce a novel graphical
notation that efficiently summarises the inner structure of metamorphic
relations."	ArXiv
1813	"EasyNLP: A Comprehensive and Easy-to-use Toolkit for Natural Language
  Processing"	['Chengyu Wang', 'Minghui Qiu', 'Chen Shi', 'Taolin Zhang', 'Tingting Liu', 'Lei Li', 'Jianing Wang', 'Ming Wang', 'Jun Huang', 'Wei Lin']	2022-04-30 13:03:53+00:00	http://arxiv.org/abs/2205.00258v2	"The success of Pre-Trained Models (PTMs) has reshaped the development of
Natural Language Processing (NLP). Yet, it is not easy to obtain
high-performing models and deploy them online for industrial practitioners. To
bridge this gap, EasyNLP is designed to make it easy to build NLP applications,
which supports a comprehensive suite of NLP algorithms. It further features
knowledge-enhanced pre-training, knowledge distillation and few-shot learning
functionalities for large-scale PTMs, and provides a unified framework of model
training, inference and deployment for real-world applications. Currently,
EasyNLP has powered over ten business units within Alibaba Group and is
seamlessly integrated to the Platform of AI (PAI) products on Alibaba Cloud.
The source code of our EasyNLP toolkit is released at GitHub
(https://github.com/alibaba/EasyNLP)."	ArXiv
1814	"Neural language models for network configuration: Opportunities and
  reality check"	['Zied Ben Houidi', 'Dario Rossi']	2022-05-03 10:08:04+00:00	http://arxiv.org/abs/2205.01398v3	"Boosted by deep learning, natural language processing (NLP) techniques have
recently seen spectacular progress, mainly fueled by breakthroughs both in
representation learning with word embeddings (e.g. word2vec) as well as novel
architectures (e.g. transformers). This success quickly invited researchers to
explore the use of NLP techniques to other fields, such as computer programming
languages, with the promise to automate tasks in software programming (bug
detection, code synthesis, code repair, cross language translation etc.). By
extension, NLP has potential for application to network configuration languages
as well, for instance considering tasks such as network configuration
verification, synthesis, and cross-vendor translation. In this paper, we survey
recent advances in deep learning applied to programming languages, for the
purpose of code verification, synthesis and translation: in particularly, we
review their training requirements and expected performance, and qualitatively
assess whether similar techniques can benefit corresponding use-cases in
networking."	ArXiv
1815	"Challenges and Opportunities in Information Manipulation Detection: An
  Examination of Wartime Russian Media"	['Chan Young Park', 'Julia Mendelsohn', 'Anjalie Field', 'Yulia Tsvetkov']	2022-05-24 21:59:10+00:00	http://arxiv.org/abs/2205.12382v2	"NLP research on public opinion manipulation campaigns has primarily focused
on detecting overt strategies such as fake news and disinformation. However,
information manipulation in the ongoing Russia-Ukraine war exemplifies how
governments and media also employ more nuanced strategies. We release a new
dataset, VoynaSlov, containing 38M+ posts from Russian media outlets on Twitter
and VKontakte, as well as public activity and responses, immediately preceding
and during the 2022 Russia-Ukraine war. We apply standard and
recently-developed NLP models on VoynaSlov to examine agenda setting, framing,
and priming, several strategies underlying information manipulation, and reveal
variation across media outlet control, social media platform, and time. Our
examination of these media effects and extensive discussion of current
approaches' limitations encourage further development of NLP models for
understanding information manipulation in emerging crises, as well as other
real-world and interdisciplinary tasks."	ArXiv
1816	Perturbation Augmentation for Fairer NLP	['Rebecca Qian', 'Candace Ross', 'Jude Fernandes', 'Eric Smith', 'Douwe Kiela', 'Adina Williams']	2022-05-25 09:00:29+00:00	http://arxiv.org/abs/2205.12586v2	"Unwanted and often harmful social biases are becoming ever more salient in
NLP research, affecting both models and datasets. In this work, we ask whether
training on demographically perturbed data leads to fairer language models. We
collect a large dataset of human annotated text perturbations and train a
neural perturbation model, which we show outperforms heuristic alternatives. We
find that (i) language models (LMs) pre-trained on demographically perturbed
corpora are typically more fair, and (ii) LMs finetuned on perturbed GLUE
datasets exhibit less demographic bias on downstream tasks, and (iii) fairness
improvements do not come at the expense of performance on downstream tasks.
Lastly, we discuss outstanding questions about how best to evaluate the
(un)fairness of large language models. We hope that this exploration of neural
demographic perturbation will help drive more improvement towards fairer NLP."	ArXiv
1817	"State Supervised Steering Function for Sampling-based Kinodynamic
  Planning"	['Pranav Atreya', 'Joydeep Biswas']	2022-06-15 01:05:30+00:00	http://arxiv.org/abs/2206.07227v1	"Sampling-based motion planners such as RRT* and BIT*, when applied to
kinodynamic motion planning, rely on steering functions to generate
time-optimal solutions connecting sampled states. Implementing exact steering
functions requires either analytical solutions to the time-optimal control
problem, or nonlinear programming (NLP) solvers to solve the boundary value
problem given the system's kinodynamic equations. Unfortunately, analytical
solutions are unavailable for many real-world domains, and NLP solvers are
prohibitively computationally expensive, hence fast and optimal kinodynamic
motion planning remains an open problem. We provide a solution to this problem
by introducing State Supervised Steering Function (S3F), a novel approach to
learn time-optimal steering functions. S3F is able to produce near-optimal
solutions to the steering function orders of magnitude faster than its NLP
counterpart. Experiments conducted on three challenging robot domains show that
RRT* using S3F significantly outperforms state-of-the-art planning approaches
on both solution cost and runtime. We further provide a proof of probabilistic
completeness of RRT* modified to use S3F."	ArXiv
1818	Enhancing Networking Cipher Algorithms with Natural Language	['John E. Ortega']	2022-06-22 09:05:52+00:00	http://arxiv.org/abs/2206.10924v1	"This work provides a survey of several networking cipher algorithms and
proposes a method for integrating natural language processing (NLP) as a
protective agent for them. Two main proposals are covered for the use of NLP in
networking. First, NLP is considered as the weakest link in a networking
encryption model; and, second, as a hefty deterrent when combined as an extra
layer over what could be considered a strong type of encryption -- the stream
cipher. This paper summarizes how languages can be integrated into symmetric
encryption as a way to assist in the encryption of vulnerable streams that may
be found under attack due to the natural frequency distribution of letters or
words in a local language stream."	ArXiv
1819	Self-Supervised Learning of Brain Dynamics from Broad Neuroimaging Data	['Armin W. Thomas', 'Christopher Ré', 'Russell A. Poldrack']	2022-06-22 23:22:17+00:00	http://arxiv.org/abs/2206.11417v3	"Self-supervised learning techniques are celebrating immense success in
natural language processing (NLP) by enabling models to learn from broad
language data at unprecedented scales. Here, we aim to leverage the success of
these techniques for mental state decoding, where researchers aim to identify
specific mental states (e.g., the experience of anger or joy) from brain
activity. To this end, we devise a set of novel self-supervised learning
frameworks for neuroimaging data inspired by prominent learning frameworks in
NLP. At their core, these frameworks learn the dynamics of brain activity by
modeling sequences of activity akin to how sequences of text are modeled in
NLP. We evaluate the frameworks by pre-training models on a broad neuroimaging
dataset spanning functional Magnetic Resonance Imaging data from 11,980
experimental runs of 1,726 individuals across 34 datasets, and subsequently
adapting the pre-trained models to benchmark mental state decoding datasets.
The pre-trained models transfer well, generally outperforming baseline models
trained from scratch, while models trained in a learning framework based on
causal language modeling clearly outperform the others."	ArXiv
1820	"The Topological BERT: Transforming Attention into Topology for Natural
  Language Processing"	['Ilan Perez', 'Raphael Reinauer']	2022-06-30 11:25:31+00:00	http://arxiv.org/abs/2206.15195v1	"In recent years, the introduction of the Transformer models sparked a
revolution in natural language processing (NLP). BERT was one of the first text
encoders using only the attention mechanism without any recurrent parts to
achieve state-of-the-art results on many NLP tasks.
  This paper introduces a text classifier using topological data analysis. We
use BERT's attention maps transformed into attention graphs as the only input
to that classifier. The model can solve tasks such as distinguishing spam from
ham messages, recognizing whether a sentence is grammatically correct, or
evaluating a movie review as negative or positive. It performs comparably to
the BERT baseline and outperforms it on some tasks.
  Additionally, we propose a new method to reduce the number of BERT's
attention heads considered by the topological classifier, which allows us to
prune the number of heads from 144 down to as few as ten with no reduction in
performance. Our work also shows that the topological model displays higher
robustness against adversarial attacks than the original BERT model, which is
maintained during the pruning process. To the best of our knowledge, this work
is the first to confront topological-based models with adversarial attacks in
the context of NLP."	ArXiv
1821	Efficient NLP Model Finetuning via Multistage Data Filtering	['Xu Ouyang', 'Shahina Mohd Azam Ansari', 'Felix Xiaozhu Lin', 'Yangfeng Ji']	2022-07-28 21:43:31+00:00	http://arxiv.org/abs/2207.14386v2	"As model finetuning is central to the modern NLP, we set to maximize its
efficiency. Motivated by redundancy in training examples and the sheer sizes of
pretrained models, we exploit a key opportunity: training only on important
data. To this end, we set to filter training examples in a streaming fashion,
in tandem with training the target model. Our key techniques are two: (1)
automatically determine a training loss threshold for skipping backward
training passes; (2) run a meta predictor for further skipping forward training
passes. We integrate the above techniques in a holistic, three-stage training
process. On a diverse set of benchmarks, our method reduces the required
training examples by up to 5.3$\times$ and training time by up to 6.8$\times$,
while only seeing minor accuracy degradation. Our method is effective even when
training one epoch, where each training example is encountered only once. It is
simple to implement and is compatible with the existing finetuning techniques.
Code is available at: https://github.com/xo28/efficient-
NLP-multistage-training"	ArXiv
1822	"A Survey on Masked Autoencoder for Self-supervised Learning in Vision
  and Beyond"	['Chaoning Zhang', 'Chenshuang Zhang', 'Junha Song', 'John Seon Keun Yi', 'Kang Zhang', 'In So Kweon']	2022-07-30 09:59:28+00:00	http://arxiv.org/abs/2208.00173v1	"Masked autoencoders are scalable vision learners, as the title of MAE
\cite{he2022masked}, which suggests that self-supervised learning (SSL) in
vision might undertake a similar trajectory as in NLP. Specifically, generative
pretext tasks with the masked prediction (e.g., BERT) have become a de facto
standard SSL practice in NLP. By contrast, early attempts at generative methods
in vision have been buried by their discriminative counterparts (like
contrastive learning); however, the success of mask image modeling has revived
the masking autoencoder (often termed denoising autoencoder in the past). As a
milestone to bridge the gap with BERT in NLP, masked autoencoder has attracted
unprecedented attention for SSL in vision and beyond. This work conducts a
comprehensive survey of masked autoencoders to shed insight on a promising
direction of SSL. As the first to review SSL with masked autoencoders, this
work focuses on its application in vision by discussing its historical
developments, recent progress, and implications for diverse applications."	ArXiv
1823	On the Limitations of Sociodemographic Adaptation with Transformers	['Chia-Chien Hung', 'Anne Lauscher', 'Dirk Hovy', 'Simone Paolo Ponzetto', 'Goran Glavaš']	2022-08-01 17:58:02+00:00	http://arxiv.org/abs/2208.01029v1	"Sociodemographic factors (e.g., gender or age) shape our language. Previous
work showed that incorporating specific sociodemographic factors can
consistently improve performance for various NLP tasks in traditional NLP
models. We investigate whether these previous findings still hold with
state-of-the-art pretrained Transformers. We use three common specialization
methods proven effective for incorporating external knowledge into pretrained
Transformers (e.g., domain-specific or geographic knowledge). We adapt the
language representations for the sociodemographic dimensions of gender and age,
using continuous language modeling and dynamic multi-task learning for
adaptation, where we couple language modeling with the prediction of a
sociodemographic class. Our results when employing a multilingual model show
substantial performance gains across four languages (English, German, French,
and Danish). These findings are in line with the results of previous work and
hold promise for successful sociodemographic specialization. However,
controlling for confounding factors like domain and language shows that, while
sociodemographic adaptation does improve downstream performance, the gains do
not always solely stem from sociodemographic knowledge. Our results indicate
that sociodemographic specialization, while very important, is still an
unresolved problem in NLP."	ArXiv
1824	"Threshold resummation of quark-gluon partonic channels at
  next-to-leading power"	['Leonardo Vernazza']	2022-08-03 13:56:34+00:00	http://arxiv.org/abs/2208.02076v1	"We discuss recent progress concerning the resummation of large logarithms at
next-to-leading power (NLP) in scattering processes near threshold. We begin by
briefly reviewing the diagrammatic and SCET approach, which are used to derive
factorization theorems for physical observables in this kinematic limit. Then,
we focus on the quark-gluon channel in deep inelastic scattering and Drell-Yan.
We show that the use of consistency conditions for the cancellation of leading
poles in the hadronic cross section can be used to achieve the resummation of
large leading logarithms (LLs) at NLP, both within diagrammatic and SCET
methods. In this context it is also possible to investigate the problem of
endpoint divergences appearing at NLP in SCET, and relate its solution to the
concept of re-factorization."	ArXiv
1825	"Searching for chromate replacements using natural language processing
  and machine learning algorithms"	['Shujing Zhao', 'Nick Birbilis']	2022-08-11 07:21:18+00:00	http://arxiv.org/abs/2208.05672v1	"The past few years has seen the application of machine learning utilised in
the exploration of new materials. As in many fields of research - the vast
majority of knowledge is published as text, which poses challenges in either a
consolidated or statistical analysis across studies and reports. Such
challenges include the inability to extract quantitative information, and in
accessing the breadth of non-numerical information. To address this issue, the
application of natural language processing (NLP) has been explored in several
studies to date. In NLP, assignment of high-dimensional vectors, known as
embeddings, to passages of text preserves the syntactic and semantic
relationship between words. Embeddings rely on machine learning algorithms and
in the present work, we have employed the Word2Vec model, previously explored
by others, and the BERT model - applying them towards a unique challenge in
materials engineering. That challenge is the search for chromate replacements
in the field of corrosion protection. From a database of over 80 million
records, a down-selection of 5990 papers focused on the topic of corrosion
protection were examined using NLP. This study demonstrates it is possible to
extract knowledge from the automated interpretation of the scientific
literature and achieve expert human level insights."	ArXiv
1826	Transformer Vs. MLP-Mixer: Exponential Expressive Gap For NLP Problems	['Dan Navon', 'Alex M. Bronstein']	2022-08-17 09:59:22+00:00	http://arxiv.org/abs/2208.08191v3	"Vision-Transformers are widely used in various vision tasks. Meanwhile, there
is another line of works starting with the MLP-mixer trying to achieve similar
performance using mlp-based architectures. Interestingly, until now those
mlp-based architectures have not been adapted for NLP tasks. Additionally,
until now, mlp-based architectures have failed to achieve state-of-the-art
performance in vision tasks. In this paper, we analyze the expressive power of
mlp-based architectures in modeling dependencies between multiple different
inputs simultaneously, and show an exponential gap between the attention and
the mlp-based mechanisms. Our results suggest a theoretical explanation for the
mlp inability to compete with attention-based mechanisms in NLP problems, they
also suggest that the performance gap in vision tasks may be due to the mlp
relative weakness in modeling dependencies between multiple different
locations, and that combining smart input permutations with mlp architectures
may not be enough to close the performance gap alone."	ArXiv
1827	naab: A ready-to-use plug-and-play corpus for Farsi	['Sadra Sabouri', 'Elnaz Rahmati', 'Soroush Gooran', 'Hossein Sameti']	2022-08-29 10:40:58+00:00	http://arxiv.org/abs/2208.13486v2	"The rise of large language models (LLMs) has transformed numerous natural
language processing (NLP) tasks, yet their performance in low and mid-resource
languages, such as Farsi, still lags behind resource-rich languages like
English. To address this gap, we introduce naab, the largest publicly
available, cleaned, and ready-to-use Farsi textual corpus. naab consists of
130GB of data, comprising over 250 million paragraphs and 15 billion words.
Named after the Farsi word NAAB (meaning ""pure"" or ""high-grade""), this corpus
is openly accessible via Hugging Face, offering researchers a valuable resource
for Farsi NLP tasks. In addition to naab, we provide naab-raw, an unprocessed
version of the dataset, along with a pre-processing toolkit that allows users
to clean their custom corpora. These resources empower NLP researchers and
practitioners, particularly those focusing on low-resource languages, to
improve the performance of LLMs in their respective domains and bridge the gap
between resource-rich and resource-poor languages."	ArXiv
1828	Efficient Methods for Natural Language Processing: A Survey	['Marcos Treviso', 'Ji-Ung Lee', 'Tianchu Ji', 'Betty van Aken', 'Qingqing Cao', 'Manuel R. Ciosici', 'Michael Hassid', 'Kenneth Heafield', 'Sara Hooker', 'Colin Raffel', 'Pedro H. Martins', 'André F. T. Martins', 'Jessica Zosa Forde', 'Peter Milder', 'Edwin Simpson', 'Noam Slonim', 'Jesse Dodge', 'Emma Strubell', 'Niranjan Balasubramanian', 'Leon Derczynski', 'Iryna Gurevych', 'Roy Schwartz']	2022-08-31 20:32:35+00:00	http://arxiv.org/abs/2209.00099v2	"Recent work in natural language processing (NLP) has yielded appealing
results from scaling model parameters and training data; however, using only
scale to improve performance means that resource consumption also grows. Such
resources include data, time, storage, or energy, all of which are naturally
limited and unevenly distributed. This motivates research into efficient
methods that require fewer resources to achieve similar results. This survey
synthesizes and relates current methods and findings in efficient NLP. We aim
to provide both guidance for conducting NLP under limited resources, and point
towards promising research directions for developing more efficient methods."	ArXiv
1829	Domain Adaptation from Scratch	['Eyal Ben-David', 'Yftah Ziser', 'Roi Reichart']	2022-09-02 05:55:09+00:00	http://arxiv.org/abs/2209.00830v1	"Natural language processing (NLP) algorithms are rapidly improving but often
struggle when applied to out-of-distribution examples. A prominent approach to
mitigate the domain gap is domain adaptation, where a model trained on a source
domain is adapted to a new target domain. We present a new learning setup,
``domain adaptation from scratch'', which we believe to be crucial for
extending the reach of NLP to sensitive domains in a privacy-preserving manner.
In this setup, we aim to efficiently annotate data from a set of source domains
such that the trained model performs well on a sensitive target domain from
which data is unavailable for annotation. Our study compares several approaches
for this challenging setup, ranging from data selection and domain adaptation
algorithms to active learning paradigms, on two NLP tasks: sentiment analysis
and Named Entity Recognition. Our results suggest that using the abovementioned
approaches eases the domain gap, and combining them further improves the
results."	ArXiv
1830	Language Varieties of Italy: Technology Challenges and Opportunities	['Alan Ramponi']	2022-09-20 14:39:12+00:00	http://arxiv.org/abs/2209.09757v2	"Italy is characterized by a one-of-a-kind linguistic diversity landscape in
Europe, which implicitly encodes local knowledge, cultural traditions, artistic
expressions and history of its speakers. However, most local languages and
dialects in Italy are at risk of disappearing within few generations. The NLP
community has recently begun to engage with endangered languages, including
those of Italy. Yet, most efforts assume that these varieties are
under-resourced language monoliths with an established written form and
homogeneous functions and needs, and thus highly interchangeable with each
other and with high-resource, standardized languages. In this paper, we
introduce the linguistic context of Italy and challenge the default
machine-centric assumptions of NLP for Italy's language varieties. We advocate
for a shift in the paradigm from machine-centric to speaker-centric NLP, and
provide recommendations and opportunities for work that prioritizes languages
and their speakers over technological advances. To facilitate the process, we
finally propose building a local community towards responsible, participatory
efforts aimed at supporting vitality of languages and dialects of Italy."	ArXiv
1831	"A Case Report On The ""A.I. Locked-In Problem"": social concerns with
  modern NLP"	['Yoshija Walter']	2022-09-22 16:39:35+00:00	http://arxiv.org/abs/2209.12687v1	"Modern NLP models are becoming better conversational agents than their
predecessors. Recurrent Neural Networks (RNNs) and especially Long-Short Term
Memory (LSTM) features allow the agent to better store and use information
about semantic content, a trend that has become even more pronounced with the
Transformer Models. Large Language Models (LLMs) such as GPT-3 by OpenAI have
become known to be able to construct and follow a narrative, which enables the
system to adopt personas on the go, adapt them and play along in conversational
stories. However, practical experimentation with GPT-3 shows that there is a
recurring problem with these modern NLP systems, namely that they can ""get
stuck"" in the narrative so that further conversations, prompt executions or
commands become futile. This is here referred to as the ""Locked-In Problem"" and
is exemplified with an experimental case report, followed by practical and
social concerns that are accompanied with this problem."	ArXiv
1832	"Discover, Explanation, Improvement: An Automatic Slice Detection
  Framework for Natural Language Processing"	['Wenyue Hua', 'Lifeng Jin', 'Linfeng Song', 'Haitao Mi', 'Yongfeng Zhang', 'Dong Yu']	2022-11-08 19:00:00+00:00	http://arxiv.org/abs/2211.04476v2	"Pretrained natural language processing (NLP) models have achieved high
overall performance, but they still make systematic errors. Instead of manual
error analysis, research on slice detection models (SDM), which automatically
identify underperforming groups of datapoints, has caught escalated attention
in Computer Vision for both understanding model behaviors and providing
insights for future model training and designing. However, little research on
SDM and quantitative evaluation of their effectiveness have been conducted on
NLP tasks. Our paper fills the gap by proposing a benchmark named ""Discover,
Explain, Improve (DEIM)"" for classification NLP tasks along with a new SDM
Edisa. Edisa discovers coherent and underperforming groups of datapoints; DEIM
then unites them under human-understandable concepts and provides comprehensive
evaluation tasks and corresponding quantitative metrics. The evaluation in DEIM
shows that Edisa can accurately select error-prone datapoints with informative
semantic features that summarize error patterns. Detecting difficult datapoints
directly boosts model performance without tuning any original model parameters,
showing that discovered slices are actionable for users."	ArXiv
1833	Factorization for quasi-TMD distributions of sub-leading power	['Simone Rodini', 'Alexey Vladimirov']	2022-11-08 19:00:18+00:00	http://arxiv.org/abs/2211.04494v2	"The quasi-transverse-momentum dependent (qTMD) distributions are equal-time
correlators that can be computed within the lattice QCD approach. In the regime
of large hadron's momentum, qTMD distributions are expressed in terms of
standard TMD distributions via the factorization theorem. We derive the
corresponding factorization theorem at the next-leading power (NLP), and, for
the first time, we present the factorized expressions for a large class of qTMD
distributions of sub-leading power. The NLP expression contains TMD
distributions of twist-two, twist-three, and a new lattice-specific
nonperturbative function. We point out that some of the qTMD distributions
considered in this work can be employed to extract the Collins-Soper kernel
using the standard techniques of different-momenta-ratio. We provide NLO
expressions for all the elements of the factorization theorem. Also, for the
first time, we explicitly demonstrate the restoration of boost invariance in
NLP TMD factorization."	ArXiv
1834	On the Security Vulnerabilities of Text-to-SQL Models	['Xutan Peng', 'Yipeng Zhang', 'Jingfeng Yang', 'Mark Stevenson']	2022-11-28 14:38:45+00:00	http://arxiv.org/abs/2211.15363v4	"Although it has been demonstrated that Natural Language Processing (NLP)
algorithms are vulnerable to deliberate attacks, the question of whether such
weaknesses can lead to software security threats is under-explored. To bridge
this gap, we conducted vulnerability tests on Text-to-SQL systems that are
commonly used to create natural language interfaces to databases. We showed
that the Text-to-SQL modules within six commercial applications can be
manipulated to produce malicious code, potentially leading to data breaches and
Denial of Service attacks. This is the first demonstration that NLP models can
be exploited as attack vectors in the wild. In addition, experiments using four
open-source language models verified that straightforward backdoor attacks on
Text-to-SQL systems achieve a 100% success rate without affecting their
performance. The aim of this work is to draw the community's attention to
potential software security issues associated with NLP algorithms and encourage
exploration of methods to mitigate against them."	ArXiv
1835	"Improving Precancerous Case Characterization via Transformer-based
  Ensemble Learning"	['Yizhen Zhong', 'Jiajie Xiao', 'Thomas Vetterli', 'Mahan Matin', 'Ellen Loo', 'Jimmy Lin', 'Richard Bourgon', 'Ofer Shapira']	2022-12-10 00:06:28+00:00	http://arxiv.org/abs/2212.05150v1	"The application of natural language processing (NLP) to cancer pathology
reports has been focused on detecting cancer cases, largely ignoring
precancerous cases. Improving the characterization of precancerous adenomas
assists in developing diagnostic tests for early cancer detection and
prevention, especially for colorectal cancer (CRC). Here we developed
transformer-based deep neural network NLP models to perform the CRC
phenotyping, with the goal of extracting precancerous lesion attributes and
distinguishing cancer and precancerous cases. We achieved 0.914 macro-F1 scores
for classifying patients into negative, non-advanced adenoma, advanced adenoma
and CRC. We further improved the performance to 0.923 using an ensemble of
classifiers for cancer status classification and lesion size named entity
recognition (NER). Our results demonstrated the potential of using NLP to
leverage real-world health record data to facilitate the development of
diagnostic tests for early cancer prevention."	ArXiv
1836	Is GPT-3 a Good Data Annotator?	['Bosheng Ding', 'Chengwei Qin', 'Linlin Liu', 'Yew Ken Chia', 'Shafiq Joty', 'Boyang Li', 'Lidong Bing']	2022-12-20 17:28:41+00:00	http://arxiv.org/abs/2212.10450v2	"Data annotation is the process of labeling data that could be used to train
machine learning models. Having high-quality annotation is crucial, as it
allows the model to learn the relationship between the input data and the
desired output. GPT-3, a large-scale language model developed by OpenAI, has
demonstrated impressive zero- and few-shot performance on a wide range of NLP
tasks. It is therefore natural to wonder whether it can be used to effectively
annotate data for NLP tasks. In this paper, we evaluate the performance of
GPT-3 as a data annotator by comparing it with traditional data annotation
methods and analyzing its output on a range of tasks. Through this analysis, we
aim to provide insight into the potential of GPT-3 as a general-purpose data
annotator in NLP."	ArXiv
1837	DMOps: Data Management Operation and Recipes	['Eujeong Choi', 'Chanjun Park']	2023-01-02 09:46:53+00:00	http://arxiv.org/abs/2301.01228v3	"Data-centric AI has shed light on the significance of data within the machine
learning (ML) pipeline. Recognizing its significance, academia, industry, and
government departments have suggested various NLP data research initiatives.
While the ability to utilize existing data is essential, the ability to build a
dataset has become more critical than ever, especially in the industry. In
consideration of this trend, we propose a ""Data Management Operations and
Recipes"" to guide the industry in optimizing the building of datasets for NLP
products. This paper presents the concept of DMOps which is derived from
real-world experiences with NLP data management and aims to streamline data
operations by offering a baseline."	ArXiv
1838	Traditional Readability Formulas Compared for English	['Bruce W. Lee', 'Jason Hyung-Jong Lee']	2023-01-08 04:33:43+00:00	http://arxiv.org/abs/2301.02975v3	"Traditional English readability formulas, or equations, were largely
developed in the 20th century. Nonetheless, many researchers still rely on them
for various NLP applications. This phenomenon is presumably due to the
convenience and straightforwardness of readability formulas. In this work, we
contribute to the NLP community by 1. introducing New English Readability
Formula (NERF), 2. recalibrating the coefficients of old readability formulas
(Flesch-Kincaid Grade Level, Fog Index, SMOG Index, Coleman-Liau Index, and
Automated Readability Index), 3. evaluating the readability formulas, for use
in text simplification studies and medical texts, and 4. developing a
Python-based program for the wide application to various NLP projects."	ArXiv
1839	MEGAnno: Exploratory Labeling for NLP in Computational Notebooks	['Dan Zhang', 'Hannah Kim', 'Rafael Li Chen', 'Eser Kandogan', 'Estevam Hruschka']	2023-01-08 19:16:22+00:00	http://arxiv.org/abs/2301.03095v1	"We present MEGAnno, a novel exploratory annotation framework designed for NLP
researchers and practitioners. Unlike existing labeling tools that focus on
data labeling only, our framework aims to support a broader, iterative ML
workflow including data exploration and model development. With MEGAnno's API,
users can programmatically explore the data through sophisticated search and
automated suggestion functions and incrementally update task schema as their
project evolve. Combined with our widget, the users can interactively sort,
filter, and assign labels to multiple items simultaneously in the same notebook
where the rest of the NLP project resides. We demonstrate MEGAnno's flexible,
exploratory, efficient, and seamless labeling experience through a sentiment
analysis use case."	ArXiv
1840	"Towards Answering Climate Questionnaires from Unstructured Climate
  Reports"	['Daniel Spokoyny', 'Tanmay Laud', 'Tom Corringham', 'Taylor Berg-Kirkpatrick']	2023-01-11 00:22:56+00:00	http://arxiv.org/abs/2301.04253v2	"The topic of Climate Change (CC) has received limited attention in NLP
despite its urgency. Activists and policymakers need NLP tools to effectively
process the vast and rapidly growing unstructured textual climate reports into
structured form. To tackle this challenge we introduce two new large-scale
climate questionnaire datasets and use their existing structure to train
self-supervised models. We conduct experiments to show that these models can
learn to generalize to climate disclosures of different organizations types
than seen during training. We then use these models to help align texts from
unstructured climate documents to the semi-structured questionnaires in a human
pilot study. Finally, to support further NLP research in the climate domain we
introduce a benchmark of existing climate text classification datasets to
better evaluate and compare existing models."	ArXiv
1841	"A Dataset of Kurdish (Sorani) Named Entities -- An Amendment to
  Kurdish-BLARK Named Entities"	['Sazan Salar', 'Hossein Hassani']	2023-01-12 12:13:44+00:00	http://arxiv.org/abs/2301.04962v1	"Named Entity Recognition (NER) is one of the essential applications of
Natural Language Processing (NLP). It is also an instrument that plays a
significant role in many other NLP applications, such as Machine Translation
(MT), Information Retrieval (IR), and Part of Speech Tagging (POST). Kurdish is
an under-resourced language from the NLP perspective. Particularly, in all the
categories, the lack of NER resources hinders other aspects of Kurdish
processing. In this work, we present a data set that covers several categories
of NEs in Kurdish (Sorani). The dataset is a significant amendment to a
previously developed dataset in the Kurdish BLARK (Basic Language Resource
Kit). It covers 11 categories and 33261 entries in total. The dataset is
publicly available for non-commercial use under CC BY-NC-SA 4.0 license at
https://kurdishblark.github.io/."	ArXiv
1842	LEXTREME: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain	['Joel Niklaus', 'Veton Matoshi', 'Pooja Rani', 'Andrea Galassi', 'Matthias Stürmer', 'Ilias Chalkidis']	2023-01-30 18:05:08+00:00	http://arxiv.org/abs/2301.13126v3	"Lately, propelled by the phenomenal advances around the transformer
architecture, the legal NLP field has enjoyed spectacular growth. To measure
progress, well curated and challenging benchmarks are crucial. However, most
benchmarks are English only and in legal NLP specifically there is no
multilingual benchmark available yet. Additionally, many benchmarks are
saturated, with the best models clearly outperforming the best humans and
achieving near perfect scores. We survey the legal NLP literature and select 11
datasets covering 24 languages, creating LEXTREME. To provide a fair
comparison, we propose two aggregate scores, one based on the datasets and one
on the languages. The best baseline (XLM-R large) achieves both a dataset
aggregate score a language aggregate score of 61.3. This indicates that
LEXTREME is still very challenging and leaves ample room for improvement. To
make it easy for researchers and practitioners to use, we release LEXTREME on
huggingface together with all the code required to evaluate models and a public
Weights and Biases project with all the runs."	ArXiv
1843	"Towards Few-Shot Identification of Morality Frames using In-Context
  Learning"	['Shamik Roy', 'Nishanth Sridhar Nakshatri', 'Dan Goldwasser']	2023-02-03 23:26:59+00:00	http://arxiv.org/abs/2302.02029v1	"Data scarcity is a common problem in NLP, especially when the annotation
pertains to nuanced socio-linguistic concepts that require specialized
knowledge. As a result, few-shot identification of these concepts is desirable.
Few-shot in-context learning using pre-trained Large Language Models (LLMs) has
been recently applied successfully in many NLP tasks. In this paper, we study
few-shot identification of a psycho-linguistic concept, Morality Frames (Roy et
al., 2021), using LLMs. Morality frames are a representation framework that
provides a holistic view of the moral sentiment expressed in text, identifying
the relevant moral foundation (Haidt and Graham, 2007) and at a finer level of
granularity, the moral sentiment expressed towards the entities mentioned in
the text. Previous studies relied on human annotation to identify morality
frames in text which is expensive. In this paper, we propose prompting-based
approaches using pretrained Large Language Models for identification of
morality frames, relying only on few-shot exemplars. We compare our models'
performance with few-shot RoBERTa and found promising results."	ArXiv
1844	Natural Language Processing for Policymaking	['Zhijing Jin', 'Rada Mihalcea']	2023-02-07 14:34:39+00:00	http://arxiv.org/abs/2302.03490v1	"Language is the medium for many political activities, from campaigns to news
reports. Natural language processing (NLP) uses computational tools to parse
text into key information that is needed for policymaking. In this chapter, we
introduce common methods of NLP, including text classification, topic modeling,
event extraction, and text scaling. We then overview how these methods can be
used for policymaking through four major applications including data collection
for evidence-based policymaking, interpretation of political decisions, policy
communication, and investigation of policy effects. Finally, we highlight some
potential limitations and ethical concerns when using NLP for policymaking.
  This text is from Chapter 7 (pages 141-162) of the Handbook of Computational
Social Science for Policy (2023). Open Access on Springer:
https://doi.org/10.1007/978-3-031-16624-2"	ArXiv
1845	Augmenting NLP data to counter Annotation Artifacts for NLI Tasks	['Armaan Singh Bhullar']	2023-02-09 15:34:53+00:00	http://arxiv.org/abs/2302.04700v1	"In this paper, we explore Annotation Artifacts - the phenomena wherein large
pre-trained NLP models achieve high performance on benchmark datasets but do
not actually ""solve"" the underlying task and instead rely on some dataset
artifacts (same across train, validation, and test sets) to figure out the
right answer. We explore this phenomenon on the well-known Natural Language
Inference task by first using contrast and adversarial examples to understand
limitations to the model's performance and show one of the biases arising from
annotation artifacts (the way training data was constructed by the annotators).
We then propose a data augmentation technique to fix this bias and measure its
effectiveness."	ArXiv
1846	RobustNLP: A Technique to Defend NLP Models Against Backdoor Attacks	['Marwan Omar']	2023-02-18 20:52:08+00:00	http://arxiv.org/abs/2302.09420v1	"As machine learning (ML) systems are being increasingly employed in the real
world to handle sensitive tasks and make decisions in various fields, the
security and privacy of those models have also become increasingly critical. In
particular, Deep Neural Networks (DNN) have been shown to be vulnerable to
backdoor attacks whereby adversaries have access to the training data and the
opportunity to manipulate such data by inserting carefully developed samples
into the training dataset. Although the NLP community has produced several
studies on generating backdoor attacks proving the vulnerable state of language
modes, to the best of our knowledge, there does not exist any work to combat
such attacks. To bridge this gap, we present RobustEncoder: a novel
clustering-based technique for detecting and removing backdoor attacks in the
text domain. Extensive empirical results demonstrate the effectiveness of our
technique in detecting and removing backdoor triggers. Our code is available at
https://github.com/marwanomar1/Backdoor-Learning-for-NLP"	ArXiv
1847	"BBT-Fin: Comprehensive Construction of Chinese Financial Domain
  Pre-trained Language Model, Corpus and Benchmark"	['Dakuan Lu', 'Hengkui Wu', 'Jiaqing Liang', 'Yipei Xu', 'Qianyu He', 'Yipeng Geng', 'Mengkun Han', 'Yingsi Xin', 'Yanghua Xiao']	2023-02-18 22:20:37+00:00	http://arxiv.org/abs/2302.09432v2	"To advance Chinese financial natural language processing (NLP), we introduce
BBT-FinT5, a new Chinese financial pre-training language model based on the T5
model. To support this effort, we have built BBT-FinCorpus, a large-scale
financial corpus with approximately 300GB of raw text from four different
sources. In general domain NLP, comprehensive benchmarks like GLUE and
SuperGLUE have driven significant advancements in language model pre-training
by enabling head-to-head comparisons among models. Drawing inspiration from
these benchmarks, we propose BBT-CFLEB, a Chinese Financial Language
understanding and generation Evaluation Benchmark, which includes six datasets
covering both understanding and generation tasks. Our aim is to facilitate
research in the development of NLP within the Chinese financial domain. Our
model, corpus and benchmark are released at
https://github.com/ssymmetry/BBT-FinCUGE-Applications. Our work belongs to the
Big Bang Transformer (BBT), a large-scale pre-trained language model project."	ArXiv
1848	CARE: Collaborative AI-Assisted Reading Environment	['Dennis Zyska', 'Nils Dycke', 'Jan Buchmann', 'Ilia Kuznetsov', 'Iryna Gurevych']	2023-02-24 12:55:31+00:00	http://arxiv.org/abs/2302.12611v1	"Recent years have seen impressive progress in AI-assisted writing, yet the
developments in AI-assisted reading are lacking. We propose inline commentary
as a natural vehicle for AI-based reading assistance, and present CARE: the
first open integrated platform for the study of inline commentary and reading.
CARE facilitates data collection for inline commentaries in a commonplace
collaborative reading environment, and provides a framework for enhancing
reading with NLP-based assistance, such as text classification, generation or
question answering. The extensible behavioral logging allows unique insights
into the reading and commenting behavior, and flexible configuration makes the
platform easy to deploy in new scenarios. To evaluate CARE in action, we apply
the platform in a user study dedicated to scholarly peer review. CARE
facilitates the data collection and study of inline commentary in NLP,
extrinsic evaluation of NLP assistance, and application prototyping. We invite
the community to explore and build upon the open source implementation of CARE."	ArXiv
1849	"IFAN: An Explainability-Focused Interaction Framework for Humans and NLP
  Models"	['Edoardo Mosca', 'Daryna Dementieva', 'Tohid Ebrahim Ajdari', 'Maximilian Kummeth', 'Kirill Gringauz', 'Yutong Zhou', 'Georg Groh']	2023-03-06 13:37:59+00:00	http://arxiv.org/abs/2303.03124v2	"Interpretability and human oversight are fundamental pillars of deploying
complex NLP models into real-world applications. However, applying
explainability and human-in-the-loop methods requires technical proficiency.
Despite existing toolkits for model understanding and analysis, options to
integrate human feedback are still limited. We propose IFAN, a framework for
real-time explanation-based interaction with NLP models. Through IFAN's
interface, users can provide feedback to selected model explanations, which is
then integrated through adapter layers to align the model with human rationale.
We show the system to be effective in debiasing a hate speech classifier with
minimal impact on performance. IFAN also offers a visual admin system and API
to manage models (and datasets) as well as control access rights. A demo is
live at https://ifan.ml."	ArXiv
1850	Context-faithful Prompting for Large Language Models	['Wenxuan Zhou', 'Sheng Zhang', 'Hoifung Poon', 'Muhao Chen']	2023-03-20 17:54:58+00:00	http://arxiv.org/abs/2303.11315v2	"Large language models (LLMs) encode parametric knowledge about world facts
and have shown remarkable performance in knowledge-driven NLP tasks. However,
their reliance on parametric knowledge may cause them to overlook contextual
cues, leading to incorrect predictions in context-sensitive NLP tasks (e.g.,
knowledge acquisition tasks). In this paper, we seek to assess and enhance
LLMs' contextual faithfulness in two aspects: knowledge conflict and prediction
with abstention. We demonstrate that LLMs' faithfulness can be significantly
improved using carefully designed prompting strategies. In particular, we
identify opinion-based prompts and counterfactual demonstrations as the most
effective methods. Opinion-based prompts reframe the context as a narrator's
statement and inquire about the narrator's opinions, while counterfactual
demonstrations use instances containing false facts to improve faithfulness in
knowledge conflict situations. Neither technique requires additional training.
We conduct experiments on three datasets of two standard NLP tasks, machine
reading comprehension and relation extraction, and the results demonstrate
significant improvement in faithfulness to contexts. Code and data are released
at https://github.com/wzhouad/context-faithful-llm."	ArXiv
1851	"Difficulty in chirality recognition for Transformer architectures
  learning chemical structures from string"	['Yasuhiro Yoshikai', 'Tadahaya Mizuno', 'Shumpei Nemoto', 'Hiroyuki Kusuhara']	2023-03-21 04:47:45+00:00	http://arxiv.org/abs/2303.11593v4	"Recent years have seen rapid development of descriptor generation based on
representation learning of extremely diverse molecules, especially those that
apply natural language processing (NLP) models to SMILES, a literal
representation of molecular structure. However, little research has been done
on how these models understand chemical structure. To address this black box,
we investigated the relationship between the learning progress of SMILES and
chemical structure using a representative NLP model, the Transformer. We show
that while the Transformer learns partial structures of molecules quickly, it
requires extended training to understand overall structures. Consistently, the
accuracy of molecular property predictions using descriptors generated from
models at different learning steps was similar from the beginning to the end of
training. Furthermore, we found that the Transformer requires particularly long
training to learn chirality and sometimes stagnates with low performance due to
misunderstanding of enantiomers. These findings are expected to deepen the
understanding of NLP models in chemistry."	ArXiv
1852	Towards Countering Essentialism through Social Bias Reasoning	['Emily Allaway', 'Nina Taneja', 'Sarah-Jane Leslie', 'Maarten Sap']	2023-03-28 17:34:59+00:00	http://arxiv.org/abs/2303.16173v1	"Essentialist beliefs (i.e., believing that members of the same group are
fundamentally alike) play a central role in social stereotypes and can lead to
harm when left unchallenged. In our work, we conduct exploratory studies into
the task of countering essentialist beliefs (e.g., ``liberals are stupid'').
Drawing on prior work from psychology and NLP, we construct five types of
counterstatements and conduct human studies on the effectiveness of these
different strategies. Our studies also investigate the role in choosing a
counterstatement of the level of explicitness with which an essentialist belief
is conveyed. We find that statements that broaden the scope of a stereotype
(e.g., to other groups, as in ``conservatives can also be stupid'') are the
most popular countering strategy. We conclude with a discussion of challenges
and open questions for future work in this area (e.g., improving factuality,
studying community-specific variation) and we emphasize the importance of work
at the intersection of NLP and psychology."	ArXiv
1853	Writing Tools: Looking Back to Look Ahead	['Cerstin Mahlow']	2023-03-31 08:55:19+00:00	http://arxiv.org/abs/2303.17894v1	"Research on writing tools started with the increased availability of
computers in the 1970s. After a first phase addressing the needs of programmers
and data scientists, research in the late 1980s started to focus on
writing-specific needs. Several projects aimed at supporting writers and
letting them concentrate on the creative aspects of writing by having the
writing tool take care of the mundane aspects using NLP techniques. Due to
technical limitations at that time the projects failed and research in this
area stopped. However, today's computing power and NLP resources make the ideas
from these projects technically feasible; in fact, we see projects explicitly
continuing from where abandoned projects stopped, and we see new applications
integrating NLP resources without making references to those old projects. To
design intelligent writing assistants with the possibilities offered by today's
technology, we should re-examine the goals and lessons learned from previous
projects to define the important dimensions to be considered."	ArXiv
1854	"Automatic ICD-10 Code Association: A Challenging Task on French Clinical
  Texts"	['Yakini Tchouka', 'Jean-François Couchot', 'David Laiymani', 'Philippe Selles', 'Azzedine Rahmani']	2023-04-06 06:31:54+00:00	http://arxiv.org/abs/2304.02886v1	"Automatically associating ICD codes with electronic health data is a
well-known NLP task in medical research. NLP has evolved significantly in
recent years with the emergence of pre-trained language models based on
Transformers architecture, mainly in the English language. This paper adapts
these models to automatically associate the ICD codes. Several neural network
architectures have been experimented with to address the challenges of dealing
with a large set of both input tokens and labels to be guessed. In this paper,
we propose a model that combines the latest advances in NLP and multi-label
classification for ICD-10 code association. Fair experiments on a Clinical
dataset in the French language show that our approach increases the $F_1$-score
metric by more than 55\% compared to state-of-the-art results."	ArXiv
1855	Locate: Low-Power Viterbi Decoder Exploration using Approximate Adders	['Rajat Bhattacharjya', 'Biswadip Maity', 'Nikil Dutt']	2023-04-06 17:44:01+00:00	http://arxiv.org/abs/2304.03257v1	"Viterbi decoders are widely used in communication systems, natural language
processing (NLP), and other domains. While Viterbi decoders are
compute-intensive and power-hungry, we can exploit approximations for early
design space exploration (DSE) of trade-offs between accuracy, power, and area.
We present Locate, a DSE framework that uses approximate adders in the
critically compute and power-intensive Add-Compare-Select Unit (ACSU) of the
Viterbi decoder. We demonstrate the utility of Locate for early DSE of
accuracy-power-area trade-offs for two applications: communication systems and
NLP, showing a range of pareto-optimal design configurations. For instance, in
the communication system, using an approximate adder, we observe savings of
21.5% area and 31.02% power with only 0.142% loss in accuracy averaged across
three modulation schemes. Similarly, for a Parts-of-Speech Tagger in an NLP
setting, out of 15 approximate adders, 7 report 100% accuracy while saving
22.75% area and 28.79% power on average when compared to using a
Carry-Lookahead Adder in the ACSU. These results show that Locate can be used
synergistically with other optimization techniques to improve the end-to-end
efficiency of Viterbi decoders for various application domains."	ArXiv
1856	On Evaluation of Bangla Word Analogies	['Mousumi Akter', 'Souvika Sarkar', 'Shubhra Kanti Karmaker Santu']	2023-04-10 14:27:35+00:00	http://arxiv.org/abs/2304.04613v1	"This paper presents a high-quality dataset for evaluating the quality of
Bangla word embeddings, which is a fundamental task in the field of Natural
Language Processing (NLP). Despite being the 7th most-spoken language in the
world, Bangla is a low-resource language and popular NLP models fail to perform
well. Developing a reliable evaluation test set for Bangla word embeddings are
crucial for benchmarking and guiding future research. We provide a
Mikolov-style word analogy evaluation set specifically for Bangla, with a
sample size of 16678, as well as a translated and curated version of the
Mikolov dataset, which contains 10594 samples for cross-lingual research. Our
experiments with different state-of-the-art embedding models reveal that Bangla
has its own unique characteristics, and current embeddings for Bangla still
struggle to achieve high accuracy on both datasets. We suggest that future
research should focus on training models with larger datasets and considering
the unique morphological characteristics of Bangla. This study represents the
first step towards building a reliable NLP system for the Bangla language1."	ArXiv
1857	"Use of social media and Natural Language Processing (NLP) in natural
  hazard research"	['José Augusto Proença Maia Devienne']	2023-04-17 15:03:05+00:00	http://arxiv.org/abs/2304.08341v1	"Twitter is a microblogging service for sending short, public text messages
(tweets) that has recently received more attention in scientific comunity. In
the works of Sasaki et al. (2010) and Earle et al., (2011) the authors explored
the real-time interaction on Twitter for detecting natural hazards (e.g.,
earthquakes, typhoons) baed on users' tweets. An inherent challenge for such an
application is the natural language processing (NLP), which basically consists
in converting the words in number (vectors and tensors) in order to
(mathematically/ computationally) make predictions and classifications.
Recently advanced computational tools have been made available for dealing with
text computationally. In this report we implement a NLP machine learning with
TensorFlow, an end-to-end open source plataform for machine learning
applications, to process and classify evenct based on files containing only
text."	ArXiv
1858	Improving Autoregressive NLP Tasks via Modular Linearized Attention	['Victor Agostinelli', 'Lizhong Chen']	2023-04-17 17:25:48+00:00	http://arxiv.org/abs/2304.08453v3	"Various natural language processing (NLP) tasks necessitate models that are
efficient and small based on their ultimate application at the edge or in other
resource-constrained environments. While prior research has reduced the size of
these models, increasing computational efficiency without considerable
performance impacts remains difficult, especially for autoregressive tasks.
This paper proposes modular linearized attention (MLA), which combines multiple
efficient attention mechanisms, including cosFormer, to maximize inference
quality while achieving notable speedups. We validate this approach on several
autoregressive NLP tasks, including speech-to-text neural machine translation
(S2T NMT), speech-to-text simultaneous translation (SimulST), and
autoregressive text-to-spectrogram, noting efficiency gains on TTS and
competitive performance for NMT and SimulST during training and inference."	ArXiv
1859	A Survey of Corpora for Germanic Low-Resource Languages and Dialects	['Verena Blaschke', 'Hinrich Schütze', 'Barbara Plank']	2023-04-19 16:45:16+00:00	http://arxiv.org/abs/2304.09805v1	"Despite much progress in recent years, the vast majority of work in natural
language processing (NLP) is on standard languages with many speakers. In this
work, we instead focus on low-resource languages and in particular
non-standardized low-resource languages. Even within branches of major language
families, often considered well-researched, little is known about the extent
and type of available resources and what the major NLP challenges are for these
language varieties. The first step to address this situation is a systematic
survey of available corpora (most importantly, annotated corpora, which are
particularly valuable for NLP research). Focusing on Germanic low-resource
language varieties, we provide such a survey in this paper. Except for
geolocation (origin of speaker or document), we find that manually annotated
linguistic resources are sparse and, if they exist, mostly cover morphosyntax.
Despite this lack of resources, we observe that interest in this area is
increasing: there is active development and a growing research community. To
facilitate research, we make our overview of over 80 corpora publicly
available. We share a companion website of this overview at
https://github.com/mainlp/germanic-lrl-corpora ."	ArXiv
1860	The LBK theorem to all orders	['Tim Engel']	2023-04-23 15:43:10+00:00	http://arxiv.org/abs/2304.11689v3	"We study the soft limit of one-photon radiation at next-to-leading power
(NLP) in the framework of heavy-quark effective theory (HQET) to all orders in
perturbation theory. We establish the soft theorem that for unpolarised
scattering the radiative contribution up to NLP is entirely determined by the
non-radiative amplitude. This generalises the Low-Burnett-Kroll (LBK) theorem
for QED to all orders. All hard matching corrections can be calculated by
applying the LBK differential operator to the non-radiative amplitude. The
virtual corrections in the effective theory vanish beyond one loop, resulting
in a one-loop exact soft function. As a first, non-trivial application we
calculate the real-virtual-virtual electron-line corrections to muon-electron
scattering at NLP in the soft limit."	ArXiv
1861	Semantic Tokenizer for Enhanced Natural Language Processing	['Sandeep Mehta', 'Darpan Shah', 'Ravindra Kulkarni', 'Cornelia Caragea']	2023-04-24 19:33:41+00:00	http://arxiv.org/abs/2304.12404v1	"Traditionally, NLP performance improvement has been focused on improving
models and increasing the number of model parameters. NLP vocabulary
construction has remained focused on maximizing the number of words represented
through subword regularization. We present a novel tokenizer that uses
semantics to drive vocabulary construction. The tokenizer includes a trainer
that uses stemming to enhance subword formation. Further optimizations and
adaptations are implemented to minimize the number of words that cannot be
encoded. The encoder is updated to integrate with the trainer. The tokenizer is
implemented as a drop-in replacement for the SentencePiece tokenizer. The new
tokenizer more than doubles the number of wordforms represented in the
vocabulary. The enhanced vocabulary significantly improves NLP model
convergence, and improves quality of word and sentence embeddings. Our
experimental results show top performance on two Glue tasks using BERT-base,
improving on models more than 50X in size."	ArXiv
1862	"Transcending the ""Male Code"": Implicit Masculine Biases in NLP Contexts"	['Katie Seaborn', 'Shruti Chandra', 'Thibault Fabre']	2023-04-22 03:53:24+00:00	http://arxiv.org/abs/2304.12810v1	"Critical scholarship has elevated the problem of gender bias in data sets
used to train virtual assistants (VAs). Most work has focused on explicit
biases in language, especially against women, girls, femme-identifying people,
and genderqueer folk; implicit associations through word embeddings; and
limited models of gender and masculinities, especially toxic masculinities,
conflation of sex and gender, and a sex/gender binary framing of the masculine
as diametric to the feminine. Yet, we must also interrogate how masculinities
are ""coded"" into language and the assumption of ""male"" as the linguistic
default: implicit masculine biases. To this end, we examined two natural
language processing (NLP) data sets. We found that when gendered language was
present, so were gender biases and especially masculine biases. Moreover, these
biases related in nuanced ways to the NLP context. We offer a new dictionary
called AVA that covers ambiguous associations between gendered language and the
language of VAs."	ArXiv
1863	"Lessons Learned from a Citizen Science Project for Natural Language
  Processing"	['Jan-Christoph Klie', 'Ji-Ung Lee', 'Kevin Stowe', 'Gözde Gül Şahin', 'Nafise Sadat Moosavi', 'Luke Bates', 'Dominic Petrak', 'Richard Eckart de Castilho', 'Iryna Gurevych']	2023-04-25 14:08:53+00:00	http://arxiv.org/abs/2304.12836v1	"Many Natural Language Processing (NLP) systems use annotated corpora for
training and evaluation. However, labeled data is often costly to obtain and
scaling annotation projects is difficult, which is why annotation tasks are
often outsourced to paid crowdworkers. Citizen Science is an alternative to
crowdsourcing that is relatively unexplored in the context of NLP. To
investigate whether and how well Citizen Science can be applied in this
setting, we conduct an exploratory study into engaging different groups of
volunteers in Citizen Science for NLP by re-annotating parts of a pre-existing
crowdsourced dataset. Our results show that this can yield high-quality
annotations and attract motivated volunteers, but also requires considering
factors such as scalability, participation over time, and legal and ethical
issues. We summarize lessons learned in the form of guidelines and provide our
code and data to aid future work on Citizen Science."	ArXiv
1864	"KGA: A General Machine Unlearning Framework Based on Knowledge Gap
  Alignment"	['Lingzhi Wang', 'Tong Chen', 'Wei Yuan', 'Xingshan Zeng', 'Kam-Fai Wong', 'Hongzhi Yin']	2023-05-11 02:44:29+00:00	http://arxiv.org/abs/2305.06535v1	"Recent legislation of the ""right to be forgotten"" has led to the interest in
machine unlearning, where the learned models are endowed with the function to
forget information about specific training instances as if they have never
existed in the training set. Previous work mainly focuses on computer vision
scenarios and largely ignores the essentials of unlearning in NLP field, where
text data contains more explicit and sensitive personal information than
images. In this paper, we propose a general unlearning framework called KGA to
induce forgetfulness. Different from previous work that tries to recover
gradients or forces models to perform close to one specific distribution, KGA
maintains distribution differences (i.e., knowledge gap). This relaxes the
distribution assumption. Furthermore, we first apply the unlearning method to
various NLP tasks (i.e., classification, translation, response generation) and
propose several unlearning evaluation metrics with pertinence. Experiments on
large-scale datasets show that KGA yields comprehensive improvements over
baselines, where extensive analyses further validate the effectiveness of KGA
and provide insight into unlearning for NLP tasks."	ArXiv
1865	Asymmetric feature interaction for interpreting model predictions	['Xiaolei Lu', 'Jianghong Ma', 'Haode Zhang']	2023-05-12 03:31:24+00:00	http://arxiv.org/abs/2305.07224v4	"In natural language processing (NLP), deep neural networks (DNNs) could model
complex interactions between context and have achieved impressive results on a
range of NLP tasks. Prior works on feature interaction attribution mainly focus
on studying symmetric interaction that only explains the additional influence
of a set of words in combination, which fails to capture asymmetric influence
that contributes to model prediction. In this work, we propose an asymmetric
feature interaction attribution explanation model that aims to explore
asymmetric higher-order feature interactions in the inference of deep neural
NLP models. By representing our explanation with an directed interaction graph,
we experimentally demonstrate interpretability of the graph to discover
asymmetric feature interactions. Experimental results on two sentiment
classification datasets show the superiority of our model against the
state-of-the-art feature interaction attribution methods in identifying
influential features for model predictions. Our code is available at
https://github.com/StillLu/ASIV."	ArXiv
1866	"From Pretraining Data to Language Models to Downstream Tasks: Tracking
  the Trails of Political Biases Leading to Unfair NLP Models"	['Shangbin Feng', 'Chan Young Park', 'Yuhan Liu', 'Yulia Tsvetkov']	2023-05-15 00:06:30+00:00	http://arxiv.org/abs/2305.08283v3	"Language models (LMs) are pretrained on diverse data sources, including news,
discussion forums, books, and online encyclopedias. A significant portion of
this data includes opinions and perspectives which, on one hand, celebrate
democracy and diversity of ideas, and on the other hand are inherently socially
biased. Our work develops new methods to (1) measure political biases in LMs
trained on such corpora, along social and economic axes, and (2) measure the
fairness of downstream NLP models trained on top of politically biased LMs. We
focus on hate speech and misinformation detection, aiming to empirically
quantify the effects of political (social, economic) biases in pretraining data
on the fairness of high-stakes social-oriented tasks. Our findings reveal that
pretrained LMs do have political leanings that reinforce the polarization
present in pretraining corpora, propagating social biases into hate speech
predictions and misinformation detectors. We discuss the implications of our
findings for NLP research and propose future directions to mitigate unfairness."	ArXiv
1867	"It Takes Two to Tango: Navigating Conceptualizations of NLP Tasks and
  Measurements of Performance"	['Arjun Subramonian', 'Xingdi Yuan', 'Hal Daumé III', 'Su Lin Blodgett']	2023-05-15 21:12:07+00:00	http://arxiv.org/abs/2305.09022v1	"Progress in NLP is increasingly measured through benchmarks; hence,
contextualizing progress requires understanding when and why practitioners may
disagree about the validity of benchmarks. We develop a taxonomy of
disagreement, drawing on tools from measurement modeling, and distinguish
between two types of disagreement: 1) how tasks are conceptualized and 2) how
measurements of model performance are operationalized. To provide evidence for
our taxonomy, we conduct a meta-analysis of relevant literature to understand
how NLP tasks are conceptualized, as well as a survey of practitioners about
their impressions of different factors that affect benchmark validity. Our
meta-analysis and survey across eight tasks, ranging from coreference
resolution to question answering, uncover that tasks are generally not clearly
and consistently conceptualized and benchmarks suffer from operationalization
disagreements. These findings support our proposed taxonomy of disagreement.
Finally, based on our taxonomy, we present a framework for constructing
benchmarks and documenting their limitations."	ArXiv
1868	"Towards More Robust NLP System Evaluation: Handling Missing Scores in
  Benchmarks"	['Anas Himmi', 'Ekhine Irurozki', 'Nathan Noiry', 'Stephan Clemencon', 'Pierre Colombo']	2023-05-17 15:20:31+00:00	http://arxiv.org/abs/2305.10284v1	"The evaluation of natural language processing (NLP) systems is crucial for
advancing the field, but current benchmarking approaches often assume that all
systems have scores available for all tasks, which is not always practical. In
reality, several factors such as the cost of running baseline, private systems,
computational limitations, or incomplete data may prevent some systems from
being evaluated on entire tasks. This paper formalize an existing problem in
NLP research: benchmarking when some systems scores are missing on the task,
and proposes a novel approach to address it. Our method utilizes a compatible
partial ranking approach to impute missing data, which is then aggregated using
the Borda count method. It includes two refinements designed specifically for
scenarios where either task-level or instance-level scores are available. We
also introduce an extended benchmark, which contains over 131 million scores,
an order of magnitude larger than existing benchmarks. We validate our methods
and demonstrate their effectiveness in addressing the challenge of missing
system evaluation on an entire task. This work highlights the need for more
comprehensive benchmarking approaches that can handle real-world scenarios
where not all systems are evaluated on the entire task."	ArXiv
1869	Collaborative Development of NLP models	['Fereshte Khani', 'Marco Tulio Ribeiro']	2023-05-20 15:55:39+00:00	http://arxiv.org/abs/2305.12219v2	"Despite substantial advancements, Natural Language Processing (NLP) models
often require post-training adjustments to enforce business rules, rectify
undesired behavior, and align with user values. These adjustments involve
operationalizing ""concepts""--dictating desired model responses to certain
inputs. However, it's difficult for a single entity to enumerate and define all
possible concepts, indicating a need for a multi-user, collaborative model
alignment framework. Moreover, the exhaustive delineation of a concept is
challenging, and an improper approach can create shortcuts or interfere with
original data or other concepts.
  To address these challenges, we introduce CoDev, a framework that enables
multi-user interaction with the model, thereby mitigating individual
limitations. CoDev aids users in operationalizing their concepts using Large
Language Models, and relying on the principle that NLP models exhibit simpler
behaviors in local regions. Our main insight is learning a \emph{local} model
for each concept, and a \emph{global} model to integrate the original data with
all concepts. We then steer a large language model to generate instances within
concept boundaries where local and global disagree. Our experiments show CoDev
is effective at helping multiple users operationalize concepts and avoid
interference for a variety of scenarios, tasks, and models."	ArXiv
1870	TaskWeb: Selecting Better Source Tasks for Multi-task NLP	['Joongwon Kim', 'Akari Asai', 'Gabriel Ilharco', 'Hannaneh Hajishirzi']	2023-05-22 17:27:57+00:00	http://arxiv.org/abs/2305.13256v2	"Recent work in NLP has shown promising results in training models on large
amounts of tasks to achieve better generalization. However, it is not
well-understood how tasks are related, and how helpful training tasks can be
chosen for a new task. In this work, we investigate whether knowing task
relationships via pairwise task transfer improves choosing one or more source
tasks that help to learn a new target task. We provide TaskWeb, a large-scale
benchmark of pairwise task transfers for 22 NLP tasks using three different
model types, sizes, and adaptation methods, spanning about 25,000 experiments.
Then, we design a new method TaskShop based on our analysis of TaskWeb.
TaskShop uses TaskWeb to estimate the benefit of using a source task for
learning a new target task, and to choose a subset of helpful training tasks
for multi-task training. Our method improves overall rankings and top-k
precision of source tasks by 10% and 38%, respectively. We also use TaskShop to
build much smaller multi-task training sets that improve zero-shot performances
across 11 different target tasks by at least 4.3%."	ArXiv
1871	"When Does Aggregating Multiple Skills with Multi-Task Learning Work? A
  Case Study in Financial NLP"	['Jingwei Ni', 'Zhijing Jin', 'Qian Wang', 'Mrinmaya Sachan', 'Markus Leippold']	2023-05-23 12:37:14+00:00	http://arxiv.org/abs/2305.14007v1	"Multi-task learning (MTL) aims at achieving a better model by leveraging data
and knowledge from multiple tasks. However, MTL does not always work --
sometimes negative transfer occurs between tasks, especially when aggregating
loosely related skills, leaving it an open question when MTL works. Previous
studies show that MTL performance can be improved by algorithmic tricks.
However, what tasks and skills should be included is less well explored. In
this work, we conduct a case study in Financial NLP where multiple datasets
exist for skills relevant to the domain, such as numeric reasoning and
sentiment analysis. Due to the task difficulty and data scarcity in the
Financial NLP domain, we explore when aggregating such diverse skills from
multiple datasets with MTL can work. Our findings suggest that the key to MTL
success lies in skill diversity, relatedness between tasks, and choice of
aggregation size and shared capacity. Specifically, MTL works well when tasks
are diverse but related, and when the size of the task aggregation and the
shared capacity of the model are balanced to avoid overwhelming certain tasks."	ArXiv
1872	"How do humans perceive adversarial text? A reality check on the validity
  and naturalness of word-based adversarial attacks"	['Salijona Dyrmishi', 'Salah Ghamizi', 'Maxime Cordy']	2023-05-24 21:52:13+00:00	http://arxiv.org/abs/2305.15587v1	"Natural Language Processing (NLP) models based on Machine Learning (ML) are
susceptible to adversarial attacks -- malicious algorithms that imperceptibly
modify input text to force models into making incorrect predictions. However,
evaluations of these attacks ignore the property of imperceptibility or study
it under limited settings. This entails that adversarial perturbations would
not pass any human quality gate and do not represent real threats to
human-checked NLP systems. To bypass this limitation and enable proper
assessment (and later, improvement) of NLP model robustness, we have surveyed
378 human participants about the perceptibility of text adversarial examples
produced by state-of-the-art methods. Our results underline that existing text
attacks are impractical in real-world scenarios where humans are involved. This
contrasts with previous smaller-scale human studies, which reported overly
optimistic conclusions regarding attack success. Through our work, we hope to
position human perceptibility as a first-class success criterion for text
attacks, and provide guidance for research to build effective attack algorithms
and, in turn, design appropriate defence mechanisms."	ArXiv
1873	"ParaAMR: A Large-Scale Syntactically Diverse Paraphrase Dataset by AMR
  Back-Translation"	['Kuan-Hao Huang', 'Varun Iyer', 'I-Hung Hsu', 'Anoop Kumar', 'Kai-Wei Chang', 'Aram Galstyan']	2023-05-26 02:27:33+00:00	http://arxiv.org/abs/2305.16585v1	"Paraphrase generation is a long-standing task in natural language processing
(NLP). Supervised paraphrase generation models, which rely on human-annotated
paraphrase pairs, are cost-inefficient and hard to scale up. On the other hand,
automatically annotated paraphrase pairs (e.g., by machine back-translation),
usually suffer from the lack of syntactic diversity -- the generated paraphrase
sentences are very similar to the source sentences in terms of syntax. In this
work, we present ParaAMR, a large-scale syntactically diverse paraphrase
dataset created by abstract meaning representation back-translation. Our
quantitative analysis, qualitative examples, and human evaluation demonstrate
that the paraphrases of ParaAMR are syntactically more diverse compared to
existing large-scale paraphrase datasets while preserving good semantic
similarity. In addition, we show that ParaAMR can be used to improve on three
NLP tasks: learning sentence embeddings, syntactically controlled paraphrase
generation, and data augmentation for few-shot learning. Our results thus
showcase the potential of ParaAMR for improving various NLP applications."	ArXiv
1874	"Enhancing Translation for Indigenous Languages: Experiments with
  Multilingual Models"	['Atnafu Lambebo Tonja', 'Hellina Hailu Nigatu', 'Olga Kolesnikova', 'Grigori Sidorov', 'Alexander Gelbukh', 'Jugal Kalita']	2023-05-27 08:10:40+00:00	http://arxiv.org/abs/2305.17406v1	"This paper describes CIC NLP's submission to the AmericasNLP 2023 Shared Task
on machine translation systems for indigenous languages of the Americas. We
present the system descriptions for three methods. We used two multilingual
models, namely M2M-100 and mBART50, and one bilingual (one-to-one) -- Helsinki
NLP Spanish-English translation model, and experimented with different transfer
learning setups. We experimented with 11 languages from America and report the
setups we used as well as the results we achieved. Overall, the mBART setup was
able to improve upon the baseline for three out of the eleven languages."	ArXiv
1875	UKP-SQuARE: An Interactive Tool for Teaching Question Answering	['Haishuo Fang', 'Haritz Puerto', 'Iryna Gurevych']	2023-05-31 11:29:04+00:00	http://arxiv.org/abs/2305.19748v2	"The exponential growth of question answering (QA) has made it an
indispensable topic in any Natural Language Processing (NLP) course.
Additionally, the breadth of QA derived from this exponential growth makes it
an ideal scenario for teaching related NLP topics such as information
retrieval, explainability, and adversarial attacks among others. In this paper,
we introduce UKP-SQuARE as a platform for QA education. This platform provides
an interactive environment where students can run, compare, and analyze various
QA models from different perspectives, such as general behavior,
explainability, and robustness. Therefore, students can get a first-hand
experience in different QA techniques during the class. Thanks to this, we
propose a learner-centered approach for QA education in which students
proactively learn theoretical concepts and acquire problem-solving skills
through interactive exploration, experimentation, and practical assignments,
rather than solely relying on traditional lectures. To evaluate the
effectiveness of UKP-SQuARE in teaching scenarios, we adopted it in a
postgraduate NLP course and surveyed the students after the course. Their
positive feedback shows the platform's effectiveness in their course and
invites a wider adoption."	ArXiv
1876	Systematic Evaluation of GPT-3 for Zero-Shot Personality Estimation	['Adithya V Ganesan', 'Yash Kumar Lal', 'August Håkan Nilsson', 'H. Andrew Schwartz']	2023-06-01 22:43:37+00:00	http://arxiv.org/abs/2306.01183v1	"Very large language models (LLMs) perform extremely well on a spectrum of NLP
tasks in a zero-shot setting. However, little is known about their performance
on human-level NLP problems which rely on understanding psychological concepts,
such as assessing personality traits. In this work, we investigate the
zero-shot ability of GPT-3 to estimate the Big 5 personality traits from users'
social media posts. Through a set of systematic experiments, we find that
zero-shot GPT-3 performance is somewhat close to an existing pre-trained SotA
for broad classification upon injecting knowledge about the trait in the
prompts. However, when prompted to provide fine-grained classification, its
performance drops to close to a simple most frequent class (MFC) baseline. We
further analyze where GPT-3 performs better, as well as worse, than a
pretrained lexical model, illustrating systematic errors that suggest ways to
improve LLMs on human-level NLP tasks."	ArXiv
1877	Word Embeddings for Banking Industry	['Avnish Patel']	2023-06-02 01:00:44+00:00	http://arxiv.org/abs/2306.01807v1	"Applications of Natural Language Processing (NLP) are plentiful, from
sentiment analysis to text classification. Practitioners rely on static word
embeddings (e.g. Word2Vec or GloVe) or static word representation from
contextual models (e.g. BERT or ELMo) to perform many of these NLP tasks. These
widely available word embeddings are built from large amount of text, so they
are likely to have captured most of the vocabulary in different context.
However, how well would they capture domain-specific semantics and word
relatedness? This paper explores this idea by creating a bank-specific word
embeddings and evaluates them against other sources of word embeddings such as
GloVe and BERT. Not surprising that embeddings built from bank-specific corpora
does a better job of capturing the bank-specific semantics and word
relatedness. This finding suggests that bank-specific word embeddings could be
a good stand-alone source or a complement to other widely available embeddings
when performing NLP tasks specific to the banking industry."	ArXiv
1878	RoBERTweet: A BERT Language Model for Romanian Tweets	['Iulian-Marius Tăiatu', 'Andrei-Marius Avram', 'Dumitru-Clementin Cercel', 'Florin Pop']	2023-06-11 06:11:56+00:00	http://arxiv.org/abs/2306.06598v1	"Developing natural language processing (NLP) systems for social media
analysis remains an important topic in artificial intelligence research. This
article introduces RoBERTweet, the first Transformer architecture trained on
Romanian tweets. Our RoBERTweet comes in two versions, following the base and
large architectures of BERT. The corpus used for pre-training the models
represents a novelty for the Romanian NLP community and consists of all tweets
collected from 2008 to 2022. Experiments show that RoBERTweet models outperform
the previous general-domain Romanian and multilingual language models on three
NLP tasks with tweet inputs: emotion detection, sexist language identification,
and named entity recognition. We make our models and the newly created corpus
of Romanian tweets freely available."	ArXiv
1879	"Adversarial Capsule Networks for Romanian Satire Detection and Sentiment
  Analysis"	['Sebastian-Vasile Echim', 'Răzvan-Alexandru Smădu', 'Andrei-Marius Avram', 'Dumitru-Clementin Cercel', 'Florin Pop']	2023-06-13 15:23:44+00:00	http://arxiv.org/abs/2306.07845v1	"Satire detection and sentiment analysis are intensively explored natural
language processing (NLP) tasks that study the identification of the satirical
tone from texts and extracting sentiments in relationship with their targets.
In languages with fewer research resources, an alternative is to produce
artificial examples based on character-level adversarial processes to overcome
dataset size limitations. Such samples are proven to act as a regularization
method, thus improving the robustness of models. In this work, we improve the
well-known NLP models (i.e., Convolutional Neural Networks, Long Short-Term
Memory (LSTM), Bidirectional LSTM, Gated Recurrent Units (GRUs), and
Bidirectional GRUs) with adversarial training and capsule networks. The
fine-tuned models are used for satire detection and sentiment analysis tasks in
the Romanian language. The proposed framework outperforms the existing methods
for the two tasks, achieving up to 99.08% accuracy, thus confirming the
improvements added by the capsule layers and the adversarial training in NLP
approaches."	ArXiv
1880	The Double Helix inside the NLP Transformer	['Jason H. J. Lu', 'Qingzhen Guo']	2023-06-23 23:53:49+00:00	http://arxiv.org/abs/2306.13817v1	"We introduce a framework for analyzing various types of information in an NLP
Transformer. In this approach, we distinguish four layers of information:
positional, syntactic, semantic, and contextual. We also argue that the common
practice of adding positional information to semantic embedding is sub-optimal
and propose instead a Linear-and-Add approach. Our analysis reveals an
autogenetic separation of positional information through the deep layers. We
show that the distilled positional components of the embedding vectors follow
the path of a helix, both on the encoder side and on the decoder side. We
additionally show that on the encoder side, the conceptual dimensions generate
Part-of-Speech (PoS) clusters. On the decoder side, we show that a di-gram
approach helps to reveal the PoS clusters of the next token. Our approach paves
a way to elucidate the processing of information through the deep layers of an
NLP Transformer."	ArXiv
1881	"SCAT: Robust Self-supervised Contrastive Learning via Adversarial
  Training for Text Classification"	['Junjie Wu', 'Dit-Yan Yeung']	2023-07-04 05:41:31+00:00	http://arxiv.org/abs/2307.01488v1	"Despite their promising performance across various natural language
processing (NLP) tasks, current NLP systems are vulnerable to textual
adversarial attacks. To defend against these attacks, most existing methods
apply adversarial training by incorporating adversarial examples. However,
these methods have to rely on ground-truth labels to generate adversarial
examples, rendering it impractical for large-scale model pre-training which is
commonly used nowadays for NLP and many other tasks. In this paper, we propose
a novel learning framework called SCAT (Self-supervised Contrastive Learning
via Adversarial Training), which can learn robust representations without
requiring labeled data. Specifically, SCAT modifies random augmentations of the
data in a fully labelfree manner to generate adversarial examples. Adversarial
training is achieved by minimizing the contrastive loss between the
augmentations and their adversarial counterparts. We evaluate SCAT on two text
classification datasets using two state-of-the-art attack schemes proposed
recently. Our results show that SCAT can not only train robust language models
from scratch, but it can also significantly improve the robustness of existing
pre-trained language models. Moreover, to demonstrate its flexibility, we show
that SCAT can also be combined with supervised adversarial training to further
enhance model robustness."	ArXiv
1882	"Natural Language Generation and Understanding of Big Code for
  AI-Assisted Programming: A Review"	['Man Fai Wong', 'Shangxin Guo', 'Ching Nam Hang', 'Siu Wai Ho', 'Chee Wei Tan']	2023-07-04 21:26:51+00:00	http://arxiv.org/abs/2307.02503v1	"This paper provides a comprehensive review of the literature concerning the
utilization of Natural Language Processing (NLP) techniques, with a particular
focus on transformer-based large language models (LLMs) trained using Big Code,
within the domain of AI-assisted programming tasks. LLMs, augmented with
software naturalness, have played a crucial role in facilitating AI-assisted
programming applications, including code generation, code completion, code
translation, code refinement, code summarization, defect detection, and clone
detection. Notable examples of such applications include the GitHub Copilot
powered by OpenAI's Codex and DeepMind AlphaCode. This paper presents an
overview of the major LLMs and their applications in downstream tasks related
to AI-assisted programming. Furthermore, it explores the challenges and
opportunities associated with incorporating NLP techniques with software
naturalness in these applications, with a discussion on extending AI-assisted
programming capabilities to Apple's Xcode for mobile software development. This
paper also presents the challenges of and opportunities for incorporating NLP
techniques with software naturalness, empowering developers with advanced
coding assistance and streamlining the software development process."	ArXiv
1883	Can ChatGPT's Responses Boost Traditional Natural Language Processing?	['Mostafa M. Amin', 'Erik Cambria', 'Björn W. Schuller']	2023-07-06 15:42:05+00:00	http://arxiv.org/abs/2307.04648v1	"The employment of foundation models is steadily expanding, especially with
the launch of ChatGPT and the release of other foundation models. These models
have shown the potential of emerging capabilities to solve problems, without
being particularly trained to solve. A previous work demonstrated these
emerging capabilities in affective computing tasks; the performance quality was
similar to traditional Natural Language Processing (NLP) techniques, but
falling short of specialised trained models, like fine-tuning of the RoBERTa
language model. In this work, we extend this by exploring if ChatGPT has novel
knowledge that would enhance existing specialised models when they are fused
together. We achieve this by investigating the utility of verbose responses
from ChatGPT about solving a downstream task, in addition to studying the
utility of fusing that with existing NLP methods. The study is conducted on
three affective computing problems, namely sentiment analysis, suicide tendency
detection, and big-five personality assessment. The results conclude that
ChatGPT has indeed novel knowledge that can improve existing NLP techniques by
way of fusion, be it early or late fusion."	ArXiv
1884	"Empowering Cross-lingual Behavioral Testing of NLP Models with
  Typological Features"	['Ester Hlavnova', 'Sebastian Ruder']	2023-07-11 17:33:03+00:00	http://arxiv.org/abs/2307.05454v1	"A challenge towards developing NLP systems for the world's languages is
understanding how they generalize to typological differences relevant for
real-world applications. To this end, we propose M2C, a morphologically-aware
framework for behavioral testing of NLP models. We use M2C to generate tests
that probe models' behavior in light of specific linguistic features in 12
typologically diverse languages. We evaluate state-of-the-art language models
on the generated tests. While models excel at most tests in English, we
highlight generalization failures to specific typological characteristics such
as temporal expressions in Swahili and compounding possessives in Finish. Our
findings motivate the development of models that address these blind spots."	ArXiv
1885	"To share or not to share: What risks would laypeople accept to give
  sensitive data to differentially-private NLP systems?"	['Christopher Weiss', 'Frauke Kreuter', 'Ivan Habernal']	2023-07-13 12:06:48+00:00	http://arxiv.org/abs/2307.06708v2	"Although the NLP community has adopted central differential privacy as a
go-to framework for privacy-preserving model training or data sharing, the
choice and interpretation of the key parameter, privacy budget $\varepsilon$
that governs the strength of privacy protection, remains largely arbitrary. We
argue that determining the $\varepsilon$ value should not be solely in the
hands of researchers or system developers, but must also take into account the
actual people who share their potentially sensitive data. In other words: Would
you share your instant messages for $\varepsilon$ of 10? We address this
research gap by designing, implementing, and conducting a behavioral experiment
(311 lay participants) to study the behavior of people in uncertain
decision-making situations with respect to privacy-threatening situations.
Framing the risk perception in terms of two realistic NLP scenarios and using a
vignette behavioral study help us determine what $\varepsilon$ thresholds would
lead lay people to be willing to share sensitive textual data - to our
knowledge, the first study of its kind."	ArXiv
1886	Does Correction Remain A Problem For Large Language Models?	['Xiaowu Zhang', 'Xiaotian Zhang', 'Cheng Yang', 'Hang Yan', 'Xipeng Qiu']	2023-08-03 14:09:31+00:00	http://arxiv.org/abs/2308.01776v2	"As large language models, such as GPT, continue to advance the capabilities
of natural language processing (NLP), the question arises: does the problem of
correction still persist? This paper investigates the role of correction in the
context of large language models by conducting two experiments. The first
experiment focuses on correction as a standalone task, employing few-shot
learning techniques with GPT-like models for error correction. The second
experiment explores the notion of correction as a preparatory task for other
NLP tasks, examining whether large language models can tolerate and perform
adequately on texts containing certain levels of noise or errors. By addressing
these experiments, we aim to shed light on the significance of correction in
the era of large language models and its implications for various NLP
applications."	ArXiv
1887	LASIGE and UNICAGE solution to the NASA LitCoin NLP Competition	['Pedro Ruas', 'Diana F. Sousa', 'André Neves', 'Carlos Cruz', 'Francisco M. Couto']	2023-08-10 14:41:17+00:00	http://arxiv.org/abs/2308.05609v1	"Biomedical Natural Language Processing (NLP) tends to become cumbersome for
most researchers, frequently due to the amount and heterogeneity of text to be
processed. To address this challenge, the industry is continuously developing
highly efficient tools and creating more flexible engineering solutions. This
work presents the integration between industry data engineering solutions for
efficient data processing and academic systems developed for Named Entity
Recognition (LasigeUnicage\_NER) and Relation Extraction (BiOnt). Our design
reflects an integration of those components with external knowledge in the form
of additional training data from other datasets and biomedical ontologies. We
used this pipeline in the 2022 LitCoin NLP Challenge, where our team
LasigeUnicage was awarded the 7th Prize out of approximately 200 participating
teams, reflecting a successful collaboration between the academia (LASIGE) and
the industry (Unicage). The software supporting this work is available at
\url{https://github.com/lasigeBioTM/Litcoin-Lasige_Unicage}."	ArXiv
1888	"A Fast Smoothing Newton Method for Bilevel Hyperparameter Optimization
  for SVC with Logistic Loss"	['Yixin Wang', 'Qingna Li']	2023-08-15 12:23:06+00:00	http://arxiv.org/abs/2308.07734v2	"Support vector classification (SVC) with logistic loss has excellent
theoretical properties in classification problems where the label values are
not continuous. In this paper, we reformulate the hyperparameter selection for
SVC with logistic loss as a bilevel optimization problem in which the
upper-level problem and the lower-level problem are both based on logistic
loss. The resulting bilevel optimization model is converted to a single-level
nonlinear programming (NLP) problem based on the KKT conditions of the
lower-level problem. Such NLP contains a set of nonlinear equality constraints
and a simple lower bound constraint. The second-order sufficient condition is
characterized, which guarantees that the strict local optimizers are obtained.
To solve such NLP, we apply the smoothing Newton method proposed in
\cite{Liang} to solve the KKT conditions, which contain one pair of
complementarity constraints. We show that the smoothing Newton method has a
superlinear convergence rate. Extensive numerical results verify the efficiency
of the proposed approach and strict local minimizers can be achieved both
numerically and theoretically. In particular, compared with other methods, our
algorithm can achieve competitive results while consuming less time than other
methods."	ArXiv
1889	"Debunking Disinformation: Revolutionizing Truth with NLP in Fake News
  Detection"	['Li He', 'Siyi Hu', 'Ailun Pei']	2023-08-30 21:25:31+00:00	http://arxiv.org/abs/2308.16328v2	"The Internet and social media have altered how individuals access news in the
age of instantaneous information distribution. While this development has
increased access to information, it has also created a significant problem: the
spread of fake news and information. Fake news is rapidly spreading on digital
platforms, which has a negative impact on the media ecosystem, public opinion,
decision-making, and social cohesion. Natural Language Processing(NLP), which
offers a variety of approaches to identify content as authentic, has emerged as
a potent weapon in the growing war against disinformation. This paper takes an
in-depth look at how NLP technology can be used to detect fake news and reveals
the challenges and opportunities it presents."	ArXiv
1890	Addressing the Blind Spots in Spoken Language Processing	['Amit Moryossef']	2023-09-06 10:29:25+00:00	http://arxiv.org/abs/2309.06572v1	"This paper explores the critical but often overlooked role of non-verbal
cues, including co-speech gestures and facial expressions, in human
communication and their implications for Natural Language Processing (NLP). We
argue that understanding human communication requires a more holistic approach
that goes beyond textual or spoken words to include non-verbal elements.
Borrowing from advances in sign language processing, we propose the development
of universal automatic gesture segmentation and transcription models to
transcribe these non-verbal cues into textual form. Such a methodology aims to
bridge the blind spots in spoken language understanding, enhancing the scope
and applicability of NLP models. Through motivating examples, we demonstrate
the limitations of relying solely on text-based models. We propose a
computationally efficient and flexible approach for incorporating non-verbal
cues, which can seamlessly integrate with existing NLP pipelines. We conclude
by calling upon the research community to contribute to the development of
universal transcription methods and to validate their effectiveness in
capturing the complexities of real-world, multi-modal interactions."	ArXiv
1891	"Connecting the Dots in News Analysis: Bridging the Cross-Disciplinary
  Disparities in Media Bias and Framing"	['Gisela Vallejo', 'Timothy Baldwin', 'Lea Frermann']	2023-09-14 23:57:55+00:00	http://arxiv.org/abs/2309.08069v2	"The manifestation and effect of bias in news reporting have been central
topics in the social sciences for decades, and have received increasing
attention in the NLP community recently. While NLP can help to scale up
analyses or contribute automatic procedures to investigate the impact of biased
news in society, we argue that methodologies that are currently dominant fall
short of addressing the complex questions and effects addressed in theoretical
media studies. In this survey paper, we review social science approaches and
draw a comparison with typical task formulations, methods, and evaluation
metrics used in the analysis of media bias in NLP. We discuss open questions
and suggest possible directions to close identified gaps between theory and
predictive models, and their evaluation. These include model transparency,
considering document-external information, and cross-document reasoning rather
than single-label assignment."	ArXiv
1892	"Mixed-Distil-BERT: Code-mixed Language Modeling for Bangla, English, and
  Hindi"	['Md Nishat Raihan', 'Dhiman Goswami', 'Antara Mahmud']	2023-09-19 02:59:41+00:00	http://arxiv.org/abs/2309.10272v2	"One of the most popular downstream tasks in the field of Natural Language
Processing is text classification. Text classification tasks have become more
daunting when the texts are code-mixed. Though they are not exposed to such
text during pre-training, different BERT models have demonstrated success in
tackling Code-Mixed NLP challenges. Again, in order to enhance their
performance, Code-Mixed NLP models have depended on combining synthetic data
with real-world data. It is crucial to understand how the BERT models'
performance is impacted when they are pretrained using corresponding code-mixed
languages. In this paper, we introduce Tri-Distil-BERT, a multilingual model
pre-trained on Bangla, English, and Hindi, and Mixed-Distil-BERT, a model
fine-tuned on code-mixed data. Both models are evaluated across multiple NLP
tasks and demonstrate competitive performance against larger models like mBERT
and XLM-R. Our two-tiered pre-training approach offers efficient alternatives
for multilingual and code-mixed language understanding, contributing to
advancements in the field."	ArXiv
1893	"Making Small Language Models Better Multi-task Learners with
  Mixture-of-Task-Adapters"	['Yukang Xie', 'Chengyu Wang', 'Junbing Yan', 'Jiyong Zhou', 'Feiqi Deng', 'Jun Huang']	2023-09-20 03:39:56+00:00	http://arxiv.org/abs/2309.11042v1	"Recently, Large Language Models (LLMs) have achieved amazing zero-shot
learning performance over a variety of Natural Language Processing (NLP) tasks,
especially for text generative tasks. Yet, the large size of LLMs often leads
to the high computational cost of model training and online deployment. In our
work, we present ALTER, a system that effectively builds the multi-tAsk
Learners with mixTure-of-task-adaptERs upon small language models (with <1B
parameters) to address multiple NLP tasks simultaneously, capturing the
commonalities and differences between tasks, in order to support
domain-specific applications. Specifically, in ALTER, we propose the
Mixture-of-Task-Adapters (MTA) module as an extension to the transformer
architecture for the underlying model to capture the intra-task and inter-task
knowledge. A two-stage training method is further proposed to optimize the
collaboration between adapters at a small computational cost. Experimental
results over a mixture of NLP tasks show that our proposed MTA architecture and
the two-stage training method achieve good performance. Based on ALTER, we have
also produced MTA-equipped language models for various domains."	ArXiv
1894	Efficient Social Choice via NLP and Sampling	['Lior Ashkenazy', 'Nimrod Talmon']	2023-09-04 13:30:31+00:00	http://arxiv.org/abs/2309.12360v1	"Attention-Aware Social Choice tackles the fundamental conflict faced by some
agent communities between their desire to include all members in the decision
making processes and the limited time and attention that are at the disposal of
the community members. Here, we investigate a combination of two techniques for
attention-aware social choice, namely Natural Language Processing (NLP) and
Sampling. Essentially, we propose a system in which each governance proposal to
change the status quo is first sent to a trained NLP model that estimates the
probability that the proposal would pass if all community members directly vote
on it; then, based on such an estimation, a population sample of a certain size
is being selected and the proposal is decided upon by taking the sample
majority. We develop several concrete algorithms following the scheme described
above and evaluate them using various data, including such from several
Decentralized Autonomous Organizations (DAOs)."	ArXiv
1895	Weakly Supervised Reasoning by Neuro-Symbolic Approaches	['Xianggen Liu', 'Zhengdong Lu', 'Lili Mou']	2023-09-19 06:10:51+00:00	http://arxiv.org/abs/2309.13072v1	"Deep learning has largely improved the performance of various natural
language processing (NLP) tasks. However, most deep learning models are
black-box machinery, and lack explicit interpretation. In this chapter, we will
introduce our recent progress on neuro-symbolic approaches to NLP, which
combines different schools of AI, namely, symbolism and connectionism.
Generally, we will design a neural system with symbolic latent structures for
an NLP task, and apply reinforcement learning or its relaxation to perform
weakly supervised reasoning in the downstream task. Our framework has been
successfully applied to various tasks, including table query reasoning,
syntactic structure reasoning, information extraction reasoning, and rule
reasoning. For each application, we will introduce the background, our
approach, and experimental results."	ArXiv
1896	A Practical Survey on Zero-shot Prompt Design for In-context Learning	['Yinheng Li']	2023-09-22 23:00:34+00:00	http://arxiv.org/abs/2309.13205v1	"The remarkable advancements in large language models (LLMs) have brought
about significant improvements in Natural Language Processing(NLP) tasks. This
paper presents a comprehensive review of in-context learning techniques,
focusing on different types of prompts, including discrete, continuous,
few-shot, and zero-shot, and their impact on LLM performance. We explore
various approaches to prompt design, such as manual design, optimization
algorithms, and evaluation methods, to optimize LLM performance across diverse
tasks. Our review covers key research studies in prompt engineering, discussing
their methodologies and contributions to the field. We also delve into the
challenges faced in evaluating prompt performance, given the absence of a
single ""best"" prompt and the importance of considering multiple metrics. In
conclusion, the paper highlights the critical role of prompt design in
harnessing the full potential of LLMs and provides insights into the
combination of manual design, optimization techniques, and rigorous evaluation
for more effective and efficient use of LLMs in various NLP tasks."	ArXiv
1897	CCAE: A Corpus of Chinese-based Asian Englishes	['Yang Liu', 'Melissa Xiaohui Qin', 'Long Wang', 'Chao Huang']	2023-10-09 03:34:15+00:00	http://arxiv.org/abs/2310.05381v1	"Language models have been foundations in various scenarios of NLP
applications, but it has not been well applied in language variety studies,
even for the most popular language like English. This paper represents one of
the few initial efforts to utilize the NLP technology in the paradigm of World
Englishes, specifically in creating a multi-variety corpus for studying Asian
Englishes. We present an overview of the CCAE -- Corpus of Chinese-based Asian
English, a suite of corpora comprising six Chinese-based Asian English
varieties. It is based on 340 million tokens in 448 thousand web documents from
six regions. The ontology of data would make the corpus a helpful resource with
enormous research potential for Asian Englishes (especially for Chinese
Englishes for which there has not been a publicly accessible corpus yet so far)
and an ideal source for variety-specific language modeling and downstream
tasks, thus setting the stage for NLP-based World Englishes studies. And
preliminary experiments on this corpus reveal the practical value of CCAE.
Finally, we make CCAE available at
\href{https://huggingface.co/datasets/CCAE/CCAE-Corpus}{this https URL}."	ArXiv
1898	Does Synthetic Data Make Large Language Models More Efficient?	['Sia Gholami', 'Marwan Omar']	2023-10-11 19:16:09+00:00	http://arxiv.org/abs/2310.07830v1	"Natural Language Processing (NLP) has undergone transformative changes with
the advent of deep learning methodologies. One challenge persistently
confronting researchers is the scarcity of high-quality, annotated datasets
that drive these models. This paper explores the nuances of synthetic data
generation in NLP, with a focal point on template-based question generation. By
assessing its advantages, including data augmentation potential and the
introduction of structured variety, we juxtapose these benefits against
inherent limitations, such as the risk of overfitting and the constraints posed
by pre-defined templates. Drawing from empirical evaluations, we demonstrate
the impact of template-based synthetic data on the performance of modern
transformer models. We conclude by emphasizing the delicate balance required
between synthetic and real-world data, and the future trajectories of
integrating synthetic data in model training pipelines. The findings aim to
guide NLP practitioners in harnessing synthetic data's potential, ensuring
optimal model performance in diverse applications."	ArXiv
1899	"PuoBERTa: Training and evaluation of a curated language model for
  Setswana"	"['Vukosi Marivate', ""Moseli Mots'Oehli"", 'Valencia Wagner', 'Richard Lastrucci', 'Isheanesu Dzingirai']"	2023-10-13 14:33:02+00:00	http://arxiv.org/abs/2310.09141v2	"Natural language processing (NLP) has made significant progress for
well-resourced languages such as English but lagged behind for low-resource
languages like Setswana. This paper addresses this gap by presenting PuoBERTa,
a customised masked language model trained specifically for Setswana. We cover
how we collected, curated, and prepared diverse monolingual texts to generate a
high-quality corpus for PuoBERTa's training. Building upon previous efforts in
creating monolingual resources for Setswana, we evaluated PuoBERTa across
several NLP tasks, including part-of-speech (POS) tagging, named entity
recognition (NER), and news categorisation. Additionally, we introduced a new
Setswana news categorisation dataset and provided the initial benchmarks using
PuoBERTa. Our work demonstrates the efficacy of PuoBERTa in fostering NLP
capabilities for understudied languages like Setswana and paves the way for
future research directions."	ArXiv
1900	BufferSearch: Generating Black-Box Adversarial Texts With Lower Queries	['Wenjie Lv', 'Zhen Wang', 'Yitao Zheng', 'Zhehua Zhong', 'Qi Xuan', 'Tianyi Chen']	2023-10-14 19:49:02+00:00	http://arxiv.org/abs/2310.09652v1	"Machine learning security has recently become a prominent topic in the
natural language processing (NLP) area. The existing black-box adversarial
attack suffers prohibitively from the high model querying complexity, resulting
in easily being captured by anti-attack monitors. Meanwhile, how to eliminate
redundant model queries is rarely explored. In this paper, we propose a
query-efficient approach BufferSearch to effectively attack general intelligent
NLP systems with the minimal number of querying requests. In general,
BufferSearch makes use of historical information and conducts statistical test
to avoid incurring model queries frequently. Numerically, we demonstrate the
effectiveness of BufferSearch on various benchmark text-classification
experiments by achieving the competitive attacking performance but with a
significant reduction of query quantity. Furthermore, BufferSearch performs
multiple times better than competitors within restricted query budget. Our work
establishes a strong benchmark for the future study of query-efficiency in NLP
adversarial attacks."	ArXiv
1901	"Domain-Specific Language Model Post-Training for Indonesian Financial
  NLP"	['Ni Putu Intan Maharani', 'Yoga Yustiawan', 'Fauzy Caesar Rochim', 'Ayu Purwarianti']	2023-10-15 05:07:08+00:00	http://arxiv.org/abs/2310.09736v1	"BERT and IndoBERT have achieved impressive performance in several NLP tasks.
There has been several investigation on its adaption in specialized domains
especially for English language. We focus on financial domain and Indonesian
language, where we perform post-training on pre-trained IndoBERT for financial
domain using a small scale of Indonesian financial corpus. In this paper, we
construct an Indonesian self-supervised financial corpus, Indonesian financial
sentiment analysis dataset, Indonesian financial topic classification dataset,
and release a family of BERT models for financial NLP. We also evaluate the
effectiveness of domain-specific post-training on sentiment analysis and topic
classification tasks. Our findings indicate that the post-training increases
the effectiveness of a language model when it is fine-tuned to domain-specific
downstream tasks."	ArXiv
1902	"Reformulating NLP tasks to Capture Longitudinal Manifestation of
  Language Disorders in People with Dementia"	['Dimitris Gkoumas', 'Matthew Purver', 'Maria Liakata']	2023-10-15 17:58:47+00:00	http://arxiv.org/abs/2310.09897v1	"Dementia is associated with language disorders which impede communication.
Here, we automatically learn linguistic disorder patterns by making use of a
moderately-sized pre-trained language model and forcing it to focus on
reformulated natural language processing (NLP) tasks and associated linguistic
patterns. Our experiments show that NLP tasks that encapsulate contextual
information and enhance the gradient signal with linguistic patterns benefit
performance. We then use the probability estimates from the best model to
construct digital linguistic markers measuring the overall quality in
communication and the intensity of a variety of language disorders. We
investigate how the digital markers characterize dementia speech from a
longitudinal perspective. We find that our proposed communication marker is
able to robustly and reliably characterize the language of people with
dementia, outperforming existing linguistic approaches; and shows external
validity via significant correlation with clinical markers of behaviour.
Finally, our proposed linguistic disorder markers provide useful insights into
gradual language impairment associated with disease progression."	ArXiv
1903	Legal NLP Meets MiCAR: Advancing the Analysis of Crypto White Papers	['Carolina Camassa']	2023-10-16 12:17:11+00:00	http://arxiv.org/abs/2310.10333v3	"In the rapidly evolving field of crypto assets, white papers are essential
documents for investor guidance, and are now subject to unprecedented content
requirements under the European Union's Markets in Crypto-Assets Regulation
(MiCAR). Natural Language Processing (NLP) can serve as a powerful tool for
both analyzing these documents and assisting in regulatory compliance. This
paper delivers two contributions to the topic. First, we survey existing
applications of textual analysis to unregulated crypto asset white papers,
uncovering a research gap that could be bridged with interdisciplinary
collaboration. We then conduct an analysis of the changes introduced by MiCAR,
highlighting the opportunities and challenges of integrating NLP within the new
regulatory framework. The findings set the stage for further research, with the
potential to benefit regulators, crypto asset issuers, and investors."	ArXiv
1904	The Past, Present, and Future of Typological Databases in NLP	['Emi Baylor', 'Esther Ploeger', 'Johannes Bjerva']	2023-10-20 12:01:42+00:00	http://arxiv.org/abs/2310.13440v1	"Typological information has the potential to be beneficial in the development
of NLP models, particularly for low-resource languages. Unfortunately, current
large-scale typological databases, notably WALS and Grambank, are inconsistent
both with each other and with other sources of typological information, such as
linguistic grammars. Some of these inconsistencies stem from coding errors or
linguistic variation, but many of the disagreements are due to the discrete
categorical nature of these databases. We shed light on this issue by
systematically exploring disagreements across typological databases and
resources, and their uses in NLP, covering the past and present. We next
investigate the future of such work, offering an argument that a continuous
view of typological features is clearly beneficial, echoing recommendations
from linguistics. We propose that such a view of typology has significant
potential in the future, including in language modeling in low-resource
scenarios."	ArXiv
1905	"SuperTweetEval: A Challenging, Unified and Heterogeneous Benchmark for
  Social Media NLP Research"	['Dimosthenis Antypas', 'Asahi Ushio', 'Francesco Barbieri', 'Leonardo Neves', 'Kiamehr Rezaee', 'Luis Espinosa-Anke', 'Jiaxin Pei', 'Jose Camacho-Collados']	2023-10-23 09:48:25+00:00	http://arxiv.org/abs/2310.14757v1	"Despite its relevance, the maturity of NLP for social media pales in
comparison with general-purpose models, metrics and benchmarks. This fragmented
landscape makes it hard for the community to know, for instance, given a task,
which is the best performing model and how it compares with others. To
alleviate this issue, we introduce a unified benchmark for NLP evaluation in
social media, SuperTweetEval, which includes a heterogeneous set of tasks and
datasets combined, adapted and constructed from scratch. We benchmarked the
performance of a wide range of models on SuperTweetEval and our results suggest
that, despite the recent advances in language modelling, social media remains
challenging."	ArXiv
1906	DALE: Generative Data Augmentation for Low-Resource Legal NLP	['Sreyan Ghosh', 'Chandra Kiran Evuru', 'Sonal Kumar', 'S Ramaneswaran', 'S Sakshi', 'Utkarsh Tyagi', 'Dinesh Manocha']	2023-10-24 12:50:28+00:00	http://arxiv.org/abs/2310.15799v1	"We present DALE, a novel and effective generative Data Augmentation framework
for low-resource LEgal NLP. DALE addresses the challenges existing frameworks
pose in generating effective data augmentations of legal documents - legal
language, with its specialized vocabulary and complex semantics, morphology,
and syntax, does not benefit from data augmentations that merely rephrase the
source sentence. To address this, DALE, built on an Encoder-Decoder Language
Model, is pre-trained on a novel unsupervised text denoising objective based on
selective masking - our masking strategy exploits the domain-specific language
characteristics of templatized legal documents to mask collocated spans of
text. Denoising these spans helps DALE acquire knowledge about legal concepts,
principles, and language usage. Consequently, it develops the ability to
generate coherent and diverse augmentations with novel contexts. Finally, DALE
performs conditional generation to generate synthetic augmentations for
low-resource Legal NLP tasks. We demonstrate the effectiveness of DALE on 13
datasets spanning 6 tasks and 4 low-resource settings. DALE outperforms all our
baselines, including LLMs, qualitatively and quantitatively, with improvements
of 1%-50%."	ArXiv
1907	"torchdistill Meets Hugging Face Libraries for Reproducible, Coding-Free
  Deep Learning Studies: A Case Study on NLP"	['Yoshitomo Matsubara']	2023-10-26 17:57:15+00:00	http://arxiv.org/abs/2310.17644v1	"Reproducibility in scientific work has been becoming increasingly important
in research communities such as machine learning, natural language processing,
and computer vision communities due to the rapid development of the research
domains supported by recent advances in deep learning. In this work, we present
a significantly upgraded version of torchdistill, a modular-driven coding-free
deep learning framework significantly upgraded from the initial release, which
supports only image classification and object detection tasks for reproducible
knowledge distillation experiments. To demonstrate that the upgraded framework
can support more tasks with third-party libraries, we reproduce the GLUE
benchmark results of BERT models using a script based on the upgraded
torchdistill, harmonizing with various Hugging Face libraries. All the 27
fine-tuned BERT models and configurations to reproduce the results are
published at Hugging Face, and the model weights have already been widely used
in research communities. We also reimplement popular small-sized models and new
knowledge distillation methods and perform additional experiments for computer
vision tasks."	ArXiv
1908	"TeacherLM: Teaching to Fish Rather Than Giving the Fish, Language
  Modeling Likewise"	['Nan He', 'Hanyu Lai', 'Chenyang Zhao', 'Zirui Cheng', 'Junting Pan', 'Ruoyu Qin', 'Ruofan Lu', 'Rui Lu', 'Yunchen Zhang', 'Gangming Zhao', 'Zhaohui Hou', 'Zhiyuan Huang', 'Shaoqing Lu', 'Ding Liang', 'Mingjie Zhan']	2023-10-29 14:16:54+00:00	http://arxiv.org/abs/2310.19019v3	"Large Language Models (LLMs) exhibit impressive reasoning and data
augmentation capabilities in various NLP tasks. However, what about small
models? In this work, we propose TeacherLM-7.1B, capable of annotating relevant
fundamentals, chain of thought, and common mistakes for most NLP samples, which
makes annotation more than just an answer, thus allowing other models to learn
""why"" instead of just ""what"". The TeacherLM-7.1B model achieved a zero-shot
score of 52.3 on MMLU, surpassing most models with over 100B parameters. Even
more remarkable is its data augmentation ability. Based on TeacherLM-7.1B, we
augmented 58 NLP datasets and taught various student models with different
parameters from OPT and BLOOM series in a multi-task setting. The experimental
results indicate that the data augmentation provided by TeacherLM has brought
significant benefits. We will release the TeacherLM series of models and
augmented datasets as open-source."	ArXiv
1909	"Formulating and Heuristic Solving of Contact Problems in Hybrid
  Data-Driven Computational Mechanics"	['Cristian Guillermo Gebhardt', 'Senta Lange', 'Marc Christian Steinbach']	2023-11-07 15:48:31+00:00	http://arxiv.org/abs/2311.04083v1	"In this work we consider the hybrid Data-Driven Computational Mechanics
(DDCM) approach, in which a smooth constitutive manifold is reconstructed to
obtain a well-behaved nonlinear optimization problem (NLP) rather than the much
harder discrete-continous NLP (DCNLP) of the direct DDCM approach. The key
focus is on the addition of geometric inequality constraints to the hybrid DDCM
formulation. Therein, the required constraint force leads to a contact problem
in the form of a mathematical program with complementarity constraints (MPCC),
a problem class that is still less complex than the DCNLP. For this MPCC we
propose a heuristic quick-shot solution approach, which can produce verifiable
solutions by solving up to four NLPs. We perform various numerical experiments
on three different contact problems of increasing difficulty to demonstrate the
potential and limitations of this approach."	ArXiv
1910	"ChatGPT Prompting Cannot Estimate Predictive Uncertainty in
  High-Resource Languages"	['Martino Pelucchi', 'Matias Valdenegro-Toro']	2023-11-10 23:25:34+00:00	http://arxiv.org/abs/2311.06427v1	"ChatGPT took the world by storm for its impressive abilities. Due to its
release without documentation, scientists immediately attempted to identify its
limits, mainly through its performance in natural language processing (NLP)
tasks. This paper aims to join the growing literature regarding ChatGPT's
abilities by focusing on its performance in high-resource languages and on its
capacity to predict its answers' accuracy by giving a confidence level. The
analysis of high-resource languages is of interest as studies have shown that
low-resource languages perform worse than English in NLP tasks, but no study so
far has analysed whether high-resource languages perform as well as English.
The analysis of ChatGPT's confidence calibration has not been carried out
before either and is critical to learn about ChatGPT's trustworthiness. In
order to study these two aspects, five high-resource languages and two NLP
tasks were chosen. ChatGPT was asked to perform both tasks in the five
languages and to give a numerical confidence value for each answer. The results
show that all the selected high-resource languages perform similarly and that
ChatGPT does not have a good confidence calibration, often being overconfident
and never giving low confidence values."	ArXiv
1911	"Selecting Shots for Demographic Fairness in Few-Shot Learning with Large
  Language Models"	['Carlos Aguirre', 'Kuleen Sasse', 'Isabel Cachola', 'Mark Dredze']	2023-11-14 19:02:03+00:00	http://arxiv.org/abs/2311.08472v1	"Recently, work in NLP has shifted to few-shot (in-context) learning, with
large language models (LLMs) performing well across a range of tasks. However,
while fairness evaluations have become a standard for supervised methods,
little is known about the fairness of LLMs as prediction systems. Further,
common standard methods for fairness involve access to models weights or are
applied during finetuning, which are not applicable in few-shot learning. Do
LLMs exhibit prediction biases when used for standard NLP tasks? In this work,
we explore the effect of shots, which directly affect the performance of
models, on the fairness of LLMs as NLP classification systems. We consider how
different shot selection strategies, both existing and new demographically
sensitive methods, affect model fairness across three standard fairness
datasets. We discuss how future work can include LLM fairness evaluations."	ArXiv
1912	Subtle Misogyny Detection and Mitigation: An Expert-Annotated Dataset	['Brooklyn Sheppard', 'Anna Richter', 'Allison Cohen', 'Elizabeth Allyn Smith', 'Tamara Kneese', 'Carolyne Pelletier', 'Ioana Baldini', 'Yue Dong']	2023-11-15 23:27:19+00:00	http://arxiv.org/abs/2311.09443v1	"Using novel approaches to dataset development, the Biasly dataset captures
the nuance and subtlety of misogyny in ways that are unique within the
literature. Built in collaboration with multi-disciplinary experts and
annotators themselves, the dataset contains annotations of movie subtitles,
capturing colloquial expressions of misogyny in North American film. The
dataset can be used for a range of NLP tasks, including classification,
severity score regression, and text generation for rewrites. In this paper, we
discuss the methodology used, analyze the annotations obtained, and provide
baselines using common NLP algorithms in the context of misogyny detection and
mitigation. We hope this work will promote AI for social good in NLP for bias
detection, explanation, and removal."	ArXiv
1913	Whispers of Doubt Amidst Echoes of Triumph in NLP Robustness	['Ashim Gupta', 'Rishanth Rajendhran', 'Nathan Stringham', 'Vivek Srikumar', 'Ana Marasović']	2023-11-16 09:09:32+00:00	http://arxiv.org/abs/2311.09694v2	"Do larger and more performant models resolve NLP's longstanding robustness
issues? We investigate this question using over 20 models of different sizes
spanning different architectural choices and pretraining objectives. We conduct
evaluations using (a) out-of-domain and challenge test sets, (b) behavioral
testing with CheckLists, (c) contrast sets, and (d) adversarial inputs. Our
analysis reveals that not all out-of-domain tests provide insight into
robustness. Evaluating with CheckLists and contrast sets shows significant gaps
in model performance; merely scaling models does not make them adequately
robust. Finally, we point out that current approaches for adversarial
evaluations of models are themselves problematic: they can be easily thwarted,
and in their current forms, do not represent a sufficiently deep probe of model
robustness. We conclude that not only is the question of robustness in NLP as
yet unresolved, but even some of the approaches to measure robustness need to
be reassessed."	ArXiv
1914	"Understanding and Mitigating Classification Errors Through Interpretable
  Token Patterns"	['Michael A. Hedderich', 'Jonas Fischer', 'Dietrich Klakow', 'Jilles Vreeken']	2023-11-18 00:24:26+00:00	http://arxiv.org/abs/2311.10920v1	"State-of-the-art NLP methods achieve human-like performance on many tasks,
but make errors nevertheless. Characterizing these errors in easily
interpretable terms gives insight into whether a classifier is prone to making
systematic errors, but also gives a way to act and improve the classifier. We
propose to discover those patterns of tokens that distinguish correct and
erroneous predictions as to obtain global and interpretable descriptions for
arbitrary NLP classifiers. We formulate the problem of finding a succinct and
non-redundant set of such patterns in terms of the Minimum Description Length
principle. Through an extensive set of experiments, we show that our method,
Premise, performs well in practice. Unlike existing solutions, it recovers
ground truth, even on highly imbalanced data over large vocabularies. In VQA
and NER case studies, we confirm that it gives clear and actionable insight
into the systematic errors made by NLP classifiers."	ArXiv
1915	"Probabilistic Transformer: A Probabilistic Dependency Model for
  Contextual Word Representation"	['Haoyi Wu', 'Kewei Tu']	2023-11-26 06:56:02+00:00	http://arxiv.org/abs/2311.15211v1	"Syntactic structures used to play a vital role in natural language processing
(NLP), but since the deep learning revolution, NLP has been gradually dominated
by neural models that do not consider syntactic structures in their design. One
vastly successful class of neural models is transformers. When used as an
encoder, a transformer produces contextual representation of words in the input
sentence. In this work, we propose a new model of contextual word
representation, not from a neural perspective, but from a purely syntactic and
probabilistic perspective. Specifically, we design a conditional random field
that models discrete latent representations of all words in a sentence as well
as dependency arcs between them; and we use mean field variational inference
for approximate inference. Strikingly, we find that the computation graph of
our model resembles transformers, with correspondences between dependencies and
self-attention and between distributions over latent representations and
contextual embeddings of words. Experiments show that our model performs
competitively to transformers on small to medium sized datasets. We hope that
our work could help bridge the gap between traditional syntactic and
probabilistic approaches and cutting-edge neural approaches to NLP, and inspire
more linguistically-principled neural approaches in the future."	ArXiv
1916	A Pipeline For Discourse Circuits From CCG	['Jonathon Liu', 'Razin A. Shaikh', 'Benjamin Rodatz', 'Richie Yeung', 'Bob Coecke']	2023-11-29 18:46:29+00:00	http://arxiv.org/abs/2311.17892v1	"There is a significant disconnect between linguistic theory and modern NLP
practice, which relies heavily on inscrutable black-box architectures.
DisCoCirc is a newly proposed model for meaning that aims to bridge this
divide, by providing neuro-symbolic models that incorporate linguistic
structure. DisCoCirc represents natural language text as a `circuit' that
captures the core semantic information of the text. These circuits can then be
interpreted as modular machine learning models. Additionally, DisCoCirc fulfils
another major aim of providing an NLP model that can be implemented on
near-term quantum computers.
  In this paper we describe a software pipeline that converts English text to
its DisCoCirc representation. The pipeline achieves coverage over a large
fragment of the English language. It relies on Combinatory Categorial Grammar
(CCG) parses of the input text as well as coreference resolution information.
This semantic and syntactic information is used in several steps to convert the
text into a simply-typed $\lambda$-calculus term, and then into a circuit
diagram. This pipeline will enable the application of the DisCoCirc framework
to NLP tasks, using both classical and quantum approaches."	ArXiv
1917	The Ethics of Automating Legal Actors	['Josef Valvoda', 'Alec Thompson', 'Ryan Cotterell', 'Simone Teufel']	2023-12-01 13:48:46+00:00	http://arxiv.org/abs/2312.00584v1	"The introduction of large public legal datasets has brought about a
renaissance in legal NLP. Many of these datasets are comprised of legal
judgements - the product of judges deciding cases. This fact, together with the
way machine learning works, means that several legal NLP models are models of
judges. While some have argued for the automation of judges, in this position
piece, we argue that automating the role of the judge raises difficult ethical
challenges, in particular for common law legal systems. Our argument follows
from the social role of the judge in actively shaping the law, rather than
merely applying it. Since current NLP models come nowhere close to having the
facilities necessary for this task, they should not be used to automate judges.
Furthermore, even in the case the models could achieve human-level
capabilities, there would still be remaining ethical concerns inherent in the
automation of the legal process."	ArXiv
1918	"A Review of Hybrid and Ensemble in Deep Learning for Natural Language
  Processing"	['Jianguo Jia', 'Wen Liang', 'Youzhi Liang']	2023-12-09 14:49:34+00:00	http://arxiv.org/abs/2312.05589v2	"This review presents a comprehensive exploration of hybrid and ensemble deep
learning models within Natural Language Processing (NLP), shedding light on
their transformative potential across diverse tasks such as Sentiment Analysis,
Named Entity Recognition, Machine Translation, Question Answering, Text
Classification, Generation, Speech Recognition, Summarization, and Language
Modeling. The paper systematically introduces each task, delineates key
architectures from Recurrent Neural Networks (RNNs) to Transformer-based models
like BERT, and evaluates their performance, challenges, and computational
demands. The adaptability of ensemble techniques is emphasized, highlighting
their capacity to enhance various NLP applications. Challenges in
implementation, including computational overhead, overfitting, and model
interpretation complexities, are addressed alongside the trade-off between
interpretability and performance. Serving as a concise yet invaluable guide,
this review synthesizes insights into tasks, architectures, and challenges,
offering a holistic perspective for researchers and practitioners aiming to
advance language-driven applications through ensemble deep learning in NLP."	ArXiv
1919	News Signals: An NLP Library for Text and Time Series	['Chris Hokamp', 'Demian Gholipour Ghalandari', 'Parsa Ghaffari']	2023-12-18 18:02:41+00:00	http://arxiv.org/abs/2312.11399v1	"We present an open-source Python library for building and using datasets
where inputs are clusters of textual data, and outputs are sequences of real
values representing one or more time series signals. The news-signals library
supports diverse data science and NLP problem settings related to the
prediction of time series behaviour using textual data feeds. For example, in
the news domain, inputs are document clusters corresponding to daily news
articles about a particular entity, and targets are explicitly associated
real-valued time series: the volume of news about a particular person or
company, or the number of pageviews of specific Wikimedia pages. Despite many
industry and research use cases for this class of problem settings, to the best
of our knowledge, News Signals is the only open-source library designed
specifically to facilitate data science and research settings with natural
language inputs and time series targets. In addition to the core codebase for
building and interacting with datasets, we also conduct a suite of experiments
using several popular Machine Learning libraries, which are used to establish
baselines for time series anomaly prediction using textual inputs."	ArXiv
1920	"A Natural Language Processing-Based Classification and Mode-Based
  Ranking of Musculoskeletal Disorder Risk Factors"	['Md Abrar Jahin', 'Subrata Talapatra']	2023-12-12 19:34:23+00:00	http://arxiv.org/abs/2312.11517v4	"This research delves into Musculoskeletal Disorder (MSD) risk factors, using
a blend of Natural Language Processing (NLP) and mode-based ranking. The aim is
to refine understanding, classification, and prioritization for focused
prevention and treatment. Eight NLP models are evaluated, combining pre-trained
transformers, cosine similarity, and distance metrics to categorize factors
into personal, biomechanical, workplace, psychological, and organizational
classes. BERT with cosine similarity achieves 28% accuracy; sentence
transformer with Euclidean, Bray-Curtis, and Minkowski distances scores 100%.
With 10-fold cross-validation, statistical tests ensure robust results. Survey
data and mode-based ranking determine severity hierarchy, aligning with the
literature. ""Working posture"" is the most severe, highlighting posture's role.
Survey insights emphasize ""Job insecurity,"" ""Effort reward imbalance,"" and
""Poor employee facility"" as significant contributors. Rankings offer actionable
insights for MSD prevention. The study suggests targeted interventions,
workplace improvements, and future research directions. This integrated NLP and
ranking approach enhances MSD comprehension and informs occupational health
strategies."	ArXiv
1921	"Advancing SQL Injection Detection for High-Speed Data Centers: A Novel
  Approach Using Cascaded NLP"	['Kasim Tasdemir', 'Rafiullah Khan', 'Fahad Siddiqui', 'Sakir Sezer', 'Fatih Kurugollu', 'Sena Busra Yengec-Tasdemir', 'Alperen Bolat']	2023-12-20 14:09:13+00:00	http://arxiv.org/abs/2312.13041v1	"Detecting SQL Injection (SQLi) attacks is crucial for web-based data center
security, but it is challenging to balance accuracy and computational
efficiency, especially in high-speed networks. Traditional methods struggle
with this balance, while NLP-based approaches, although accurate, are
computationally intensive.
  We introduce a novel cascade SQLi detection method, blending classical and
transformer-based NLP models, achieving a 99.86% detection accuracy with
significantly lower computational demands-20 times faster than using
transformer-based models alone. Our approach is tested in a realistic setting
and compared with 35 other methods, including Machine Learning-based and
transformer models like BERT, on a dataset of over 30,000 SQL sentences.
  Our results show that this hybrid method effectively detects SQLi in
high-traffic environments, offering efficient and accurate protection against
SQLi vulnerabilities with computational efficiency. The code is available at
https://github.com/gdrlab/cascaded-sqli-detection ."	ArXiv
1922	Imperio: Language-Guided Backdoor Attacks for Arbitrary Model Control	['Ka-Ho Chow', 'Wenqi Wei', 'Lei Yu']	2024-01-02 07:57:04+00:00	http://arxiv.org/abs/2401.01085v2	"Natural language processing (NLP) has received unprecedented attention. While
advancements in NLP models have led to extensive research into their backdoor
vulnerabilities, the potential for these advancements to introduce new backdoor
threats remains unexplored. This paper proposes Imperio, which harnesses the
language understanding capabilities of NLP models to enrich backdoor attacks.
Imperio provides a new model control experience. Demonstrated through
controlling image classifiers, it empowers the adversary to manipulate the
victim model with arbitrary output through language-guided instructions. This
is achieved using a language model to fuel a conditional trigger generator,
with optimizations designed to extend its language understanding capabilities
to backdoor instruction interpretation and execution. Our experiments across
three datasets, five attacks, and nine defenses confirm Imperio's
effectiveness. It can produce contextually adaptive triggers from text
descriptions and control the victim model with desired outputs, even in
scenarios not encountered during training. The attack reaches a high success
rate across complex datasets without compromising the accuracy of clean inputs
and exhibits resilience against representative defenses."	ArXiv
1923	"Maintaining Journalistic Integrity in the Digital Age: A Comprehensive
  NLP Framework for Evaluating Online News Content"	['Ljubisa Bojic', 'Nikola Prodanovic', 'Agariadne Dwinggo Samala']	2024-01-07 12:27:14+00:00	http://arxiv.org/abs/2401.03467v1	"The rapid growth of online news platforms has led to an increased need for
reliable methods to evaluate the quality and credibility of news articles. This
paper proposes a comprehensive framework to analyze online news texts using
natural language processing (NLP) techniques, particularly a language model
specifically trained for this purpose, alongside other well-established NLP
methods. The framework incorporates ten journalism standards-objectivity,
balance and fairness, readability and clarity, sensationalism and clickbait,
ethical considerations, public interest and value, source credibility,
relevance and timeliness, factual accuracy, and attribution and transparency-to
assess the quality of news articles. By establishing these standards,
researchers, media organizations, and readers can better evaluate and
understand the content they consume and produce. The proposed method has some
limitations, such as potential difficulty in detecting subtle biases and the
need for continuous updating of the language model to keep pace with evolving
language patterns."	ArXiv
1924	Finding Challenging Metaphors that Confuse Pretrained Language Models	['Yucheng Li', 'Frank Guerin', 'Chenghua Lin']	2024-01-29 10:00:54+00:00	http://arxiv.org/abs/2401.16012v1	"Metaphors are considered to pose challenges for a wide spectrum of NLP tasks.
This gives rise to the area of computational metaphor processing. However, it
remains unclear what types of metaphors challenge current state-of-the-art
models. In this paper, we test various NLP models on the VUA metaphor dataset
and quantify to what extent metaphors affect models' performance on various
downstream tasks. Analysis reveals that VUA includes a large number of
metaphors that pose little difficulty to downstream tasks. We would like to
shift the attention of researchers away from these metaphors to instead focus
on challenging metaphors. To identify hard metaphors, we propose an automatic
pipeline that identifies metaphors that challenge a particular model. Our
analysis demonstrates that our detected hard metaphors contrast significantly
with VUA and reduce the accuracy of machine translation by 16\%, QA performance
by 4\%, NLI by 7\%, and metaphor identification recall by over 14\% for various
popular NLP systems."	ArXiv
1925	"ViLexNorm: A Lexical Normalization Corpus for Vietnamese Social Media
  Text"	['Thanh-Nhi Nguyen', 'Thanh-Phong Le', 'Kiet Van Nguyen']	2024-01-29 18:41:39+00:00	http://arxiv.org/abs/2401.16403v2	"Lexical normalization, a fundamental task in Natural Language Processing
(NLP), involves the transformation of words into their canonical forms. This
process has been proven to benefit various downstream NLP tasks greatly. In
this work, we introduce Vietnamese Lexical Normalization (ViLexNorm), the
first-ever corpus developed for the Vietnamese lexical normalization task. The
corpus comprises over 10,000 pairs of sentences meticulously annotated by human
annotators, sourced from public comments on Vietnam's most popular social media
platforms. Various methods were used to evaluate our corpus, and the
best-performing system achieved a result of 57.74% using the Error Reduction
Rate (ERR) metric (van der Goot, 2019a) with the Leave-As-Is (LAI) baseline.
For extrinsic evaluation, employing the model trained on ViLexNorm demonstrates
the positive impact of the Vietnamese lexical normalization task on other NLP
tasks. Our corpus is publicly available exclusively for research purposes."	ArXiv
1926	"Gazetteer-Enhanced Bangla Named Entity Recognition with BanglaBERT
  Semantic Embeddings K-Means-Infused CRF Model"	['Niloy Farhan', 'Saman Sarker Joy', 'Tafseer Binte Mannan', 'Farig Sadeque']	2024-01-30 17:47:07+00:00	http://arxiv.org/abs/2401.17206v1	"Named Entity Recognition (NER) is a sub-task of Natural Language Processing
(NLP) that distinguishes entities from unorganized text into predefined
categorization. In recent years, a lot of Bangla NLP subtasks have received
quite a lot of attention; but Named Entity Recognition in Bangla still lags
behind. In this research, we explored the existing state of research in Bangla
Named Entity Recognition. We tried to figure out the limitations that current
techniques and datasets face, and we would like to address these limitations in
our research. Additionally, We developed a Gazetteer that has the ability to
significantly boost the performance of NER. We also proposed a new NER solution
by taking advantage of state-of-the-art NLP tools that outperform conventional
techniques."	ArXiv
1927	Document Structure in Long Document Transformers	['Jan Buchmann', 'Max Eichler', 'Jan-Micha Bodensohn', 'Ilia Kuznetsov', 'Iryna Gurevych']	2024-01-31 08:28:06+00:00	http://arxiv.org/abs/2401.17658v1	"Long documents often exhibit structure with hierarchically organized elements
of different functions, such as section headers and paragraphs. Despite the
omnipresence of document structure, its role in natural language processing
(NLP) remains opaque. Do long-document Transformer models acquire an internal
representation of document structure during pre-training? How can structural
information be communicated to a model after pre-training, and how does it
influence downstream performance? To answer these questions, we develop a novel
suite of probing tasks to assess structure-awareness of long-document
Transformers, propose general-purpose structure infusion methods, and evaluate
the effects of structure infusion on QASPER and Evidence Inference, two
challenging long-document NLP tasks. Results on LED and LongT5 suggest that
they acquire implicit understanding of document structure during pre-training,
which can be further enhanced by structure infusion, leading to improved
end-task performance. To foster research on the role of document structure in
NLP modeling, we make our data and code publicly available."	ArXiv
1928	An Information-Theoretic Approach to Analyze NLP Classification Tasks	['Luran Wang', 'Mark Gales', 'Vatsal Raina']	2024-02-01 19:49:44+00:00	http://arxiv.org/abs/2402.00978v1	"Understanding the importance of the inputs on the output is useful across
many tasks. This work provides an information-theoretic framework to analyse
the influence of inputs for text classification tasks. Natural language
processing (NLP) tasks take either a single element input or multiple element
inputs to predict an output variable, where an element is a block of text. Each
text element has two components: an associated semantic meaning and a
linguistic realization. Multiple-choice reading comprehension (MCRC) and
sentiment classification (SC) are selected to showcase the framework. For MCRC,
it is found that the context influence on the output compared to the question
influence reduces on more challenging datasets. In particular, more challenging
contexts allow a greater variation in complexity of questions. Hence, test
creators need to carefully consider the choice of the context when designing
multiple-choice questions for assessment. For SC, it is found the semantic
meaning of the input text dominates (above 80\% for all datasets considered)
compared to its linguistic realisation when determining the sentiment. The
framework is made available at:
https://github.com/WangLuran/nlp-element-influence"	ArXiv
1929	"Partially Recentralization Softmax Loss for Vision-Language Models
  Robustness"	['Hao Wang', 'Jinzhe Jiang', 'Xin Zhang', 'Chen Li']	2024-02-06 01:44:38+00:00	http://arxiv.org/abs/2402.03627v2	"As Large Language Models make a breakthrough in natural language processing
tasks (NLP), multimodal technique becomes extremely popular. However, it has
been shown that multimodal NLP are vulnerable to adversarial attacks, where the
outputs of a model can be dramatically changed by a perturbation to the input.
While several defense techniques have been proposed both in computer vision and
NLP models, the multimodal robustness of models have not been fully explored.
In this paper, we study the adversarial robustness provided by modifying loss
function of pre-trained multimodal models, by restricting top K softmax
outputs. Based on the evaluation and scoring, our experiments show that after a
fine-tuning, adversarial robustness of pre-trained models can be significantly
improved, against popular attacks. Further research should be studying, such as
output diversity, generalization and the robustness-performance trade-off of
this kind of loss functions. Our code will be available after this paper is
accepted"	ArXiv
1930	AraSpider: Democratizing Arabic-to-SQL	['Ahmed Heakl', 'Youssef Mohamed', 'Ahmed B. Zaky']	2024-02-12 07:11:13+00:00	http://arxiv.org/abs/2402.07448v1	"This study presents AraSpider, the first Arabic version of the Spider
dataset, aimed at improving natural language processing (NLP) in the
Arabic-speaking community. Four multilingual translation models were tested for
their effectiveness in translating English to Arabic. Additionally, two models
were assessed for their ability to generate SQL queries from Arabic text. The
results showed that using back translation significantly improved the
performance of both ChatGPT 3.5 and SQLCoder models, which are considered top
performers on the Spider dataset. Notably, ChatGPT 3.5 demonstrated
high-quality translation, while SQLCoder excelled in text-to-SQL tasks. The
study underscores the importance of incorporating contextual schema and
employing back translation strategies to enhance model performance in Arabic
NLP tasks. Moreover, the provision of detailed methodologies for
reproducibility and translation of the dataset into other languages highlights
the research's commitment to promoting transparency and collaborative knowledge
sharing in the field. Overall, these contributions advance NLP research,
empower Arabic-speaking researchers, and enrich the global discourse on
language comprehension and database interrogation."	ArXiv
1931	"What Do Dialect Speakers Want? A Survey of Attitudes Towards Language
  Technology for German Dialects"	['Verena Blaschke', 'Christoph Purschke', 'Hinrich Schütze', 'Barbara Plank']	2024-02-19 09:15:28+00:00	http://arxiv.org/abs/2402.11968v2	"Natural language processing (NLP) has largely focused on modelling
standardized languages. More recently, attention has increasingly shifted to
local, non-standardized languages and dialects. However, the relevant speaker
populations' needs and wishes with respect to NLP tools are largely unknown. In
this paper, we focus on dialects and regional languages related to German -- a
group of varieties that is heterogeneous in terms of prestige and
standardization. We survey speakers of these varieties (N=327) and present
their opinions on hypothetical language technologies for their dialects.
Although attitudes vary among subgroups of our respondents, we find that
respondents are especially in favour of potential NLP tools that work with
dialectal input (especially audio input) such as virtual assistants, and less
so for applications that produce dialectal output such as machine translation
or spellcheckers."	ArXiv
1932	"How Important is Domain Specificity in Language Models and Instruction
  Finetuning for Biomedical Relation Extraction?"	['Aviv Brokman', 'Ramakanth Kavuluru']	2024-02-21 01:57:58+00:00	http://arxiv.org/abs/2402.13470v1	"Cutting edge techniques developed in the general NLP domain are often
subsequently applied to the high-value, data-rich biomedical domain. The past
few years have seen generative language models (LMs), instruction finetuning,
and few-shot learning become foci of NLP research. As such, generative LMs
pretrained on biomedical corpora have proliferated and biomedical instruction
finetuning has been attempted as well, all with the hope that domain
specificity improves performance on downstream tasks. Given the nontrivial
effort in training such models, we investigate what, if any, benefits they have
in the key biomedical NLP task of relation extraction. Specifically, we address
two questions: (1) Do LMs trained on biomedical corpora outperform those
trained on general domain corpora? (2) Do models instruction finetuned on
biomedical datasets outperform those finetuned on assorted datasets or those
simply pretrained? We tackle these questions using existing LMs, testing across
four datasets. In a surprising result, general-domain models typically
outperformed biomedical-domain models. However, biomedical instruction
finetuning improved performance to a similar degree as general instruction
finetuning, despite having orders of magnitude fewer instructions. Our findings
suggest it may be more fruitful to focus research effort on larger-scale
biomedical instruction finetuning of general LMs over building domain-specific
biomedical LMs"	ArXiv
1933	"Leveraging Large Language Models for Concept Graph Recovery and Question
  Answering in NLP Education"	['Rui Yang', 'Boming Yang', 'Sixun Ouyang', 'Tianwei She', 'Aosong Feng', 'Yuang Jiang', 'Freddy Lecue', 'Jinghui Lu', 'Irene Li']	2024-02-22 05:15:27+00:00	http://arxiv.org/abs/2402.14293v1	"In the domain of Natural Language Processing (NLP), Large Language Models
(LLMs) have demonstrated promise in text-generation tasks. However, their
educational applications, particularly for domain-specific queries, remain
underexplored. This study investigates LLMs' capabilities in educational
scenarios, focusing on concept graph recovery and question-answering (QA). We
assess LLMs' zero-shot performance in creating domain-specific concept graphs
and introduce TutorQA, a new expert-verified NLP-focused benchmark for
scientific graph reasoning and QA. TutorQA consists of five tasks with 500 QA
pairs. To tackle TutorQA queries, we present CGLLM, a pipeline integrating
concept graphs with LLMs for answering diverse questions. Our results indicate
that LLMs' zero-shot concept graph recovery is competitive with supervised
methods, showing an average 3% F1 score improvement. In TutorQA tasks, LLMs
achieve up to 26% F1 score enhancement. Moreover, human evaluation and analysis
show that CGLLM generates answers with more fine-grained concepts."	ArXiv
1934	HOP to the Next Tasks and Domains for Continual Learning in NLP	['Umberto Michieli', 'Mete Ozay']	2024-02-28 16:21:02+00:00	http://arxiv.org/abs/2402.18449v1	"Continual Learning (CL) aims to learn a sequence of problems (i.e., tasks and
domains) by transferring knowledge acquired on previous problems, whilst
avoiding forgetting of past ones. Different from previous approaches which
focused on CL for one NLP task or domain in a specific use-case, in this paper,
we address a more general CL setting to learn from a sequence of problems in a
unique framework. Our method, HOP, permits to hop across tasks and domains by
addressing the CL problem along three directions: (i) we employ a set of
adapters to generalize a large pre-trained model to unseen problems, (ii) we
compute high-order moments over the distribution of embedded representations to
distinguish independent and correlated statistics across different tasks and
domains, (iii) we process this enriched information with auxiliary heads
specialized for each end problem. Extensive experimental campaign on 4 NLP
applications, 5 benchmarks and 2 CL setups demonstrates the effectiveness of
our HOP."	ArXiv
1935	Improving Legal Judgement Prediction in Romanian with Long Text Encoders	['Mihai Masala', 'Traian Rebedea', 'Horia Velicu']	2024-02-29 13:52:33+00:00	http://arxiv.org/abs/2402.19170v2	"In recent years,the entire field of Natural Language Processing (NLP) has
enjoyed amazing novel results achieving almost human-like performance on a
variety of tasks. Legal NLP domain has also been part of this process, as it
has seen an impressive growth. However, general-purpose models are not readily
applicable for legal domain. Due to the nature of the domain (e.g. specialized
vocabulary, long documents) specific models and methods are often needed for
Legal NLP. In this work we investigate both specialized and general models for
predicting the final ruling of a legal case, task known as Legal Judgment
Prediction (LJP). We particularly focus on methods to extend to sequence length
of Transformer-based models to better understand the long documents present in
legal corpora. Extensive experiments on 4 LJP datasets in Romanian, originating
from 2 sources with significantly different sizes and document lengths, show
that specialized models and handling long texts are critical for a good
performance."	ArXiv
1936	"The Impact of Quantization on the Robustness of Transformer-based Text
  Classifiers"	['Seyed Parsa Neshaei', 'Yasaman Boreshban', 'Gholamreza Ghassem-Sani', 'Seyed Abolghasem Mirroshandel']	2024-03-08 14:55:05+00:00	http://arxiv.org/abs/2403.05365v1	"Transformer-based models have made remarkable advancements in various NLP
areas. Nevertheless, these models often exhibit vulnerabilities when confronted
with adversarial attacks. In this paper, we explore the effect of quantization
on the robustness of Transformer-based models. Quantization usually involves
mapping a high-precision real number to a lower-precision value, aiming at
reducing the size of the model at hand. To the best of our knowledge, this work
is the first application of quantization on the robustness of NLP models. In
our experiments, we evaluate the impact of quantization on BERT and DistilBERT
models in text classification using SST-2, Emotion, and MR datasets. We also
evaluate the performance of these models against TextFooler, PWWS, and PSO
adversarial attacks. Our findings show that quantization significantly improves
(by an average of 18.68%) the adversarial accuracy of the models. Furthermore,
we compare the effect of quantization versus that of the adversarial training
approach on robustness. Our experiments indicate that quantization increases
the robustness of the model by 18.80% on average compared to adversarial
training without imposing any extra computational overhead during training.
Therefore, our results highlight the effectiveness of quantization in improving
the robustness of NLP models."	ArXiv
1937	"Identifying Health Risks from Family History: A Survey of Natural
  Language Processing Techniques"	"['Xiang Dai', 'Sarvnaz Karimi', ""Nathan O'Callaghan""]"	2024-03-15 03:43:07+00:00	http://arxiv.org/abs/2403.09997v1	"Electronic health records include information on patients' status and medical
history, which could cover the history of diseases and disorders that could be
hereditary. One important use of family history information is in precision
health, where the goal is to keep the population healthy with preventative
measures. Natural Language Processing (NLP) and machine learning techniques can
assist with identifying information that could assist health professionals in
identifying health risks before a condition is developed in their later years,
saving lives and reducing healthcare costs.
  We survey the literature on the techniques from the NLP field that have been
developed to utilise digital health records to identify risks of familial
diseases. We highlight that rule-based methods are heavily investigated and are
still actively used for family history extraction. Still, more recent efforts
have been put into building neural models based on large-scale pre-trained
language models. In addition to the areas where NLP has successfully been
utilised, we also identify the areas where more research is needed to unlock
the value of patients' records regarding data collection, task formulation and
downstream applications."	ArXiv
1938	"Is Translation All You Need? A Study on Solving Multilingual Tasks with
  Large Language Models"	['Chaoqun Liu', 'Wenxuan Zhang', 'Yiran Zhao', 'Anh Tuan Luu', 'Lidong Bing']	2024-03-15 12:47:39+00:00	http://arxiv.org/abs/2403.10258v2	"Large language models (LLMs) have demonstrated multilingual capabilities;
yet, they are mostly English-centric due to the imbalanced training corpora.
Existing works leverage this phenomenon to improve their multilingual
performances through translation, primarily on natural language processing
(NLP) tasks. This work extends the evaluation from NLP tasks to real user
queries and from English-centric LLMs to non-English-centric LLMs. While
translation into English can help improve the performance of multilingual NLP
tasks for English-centric LLMs, it may not be optimal for all scenarios. For
culture-related tasks that need deep language understanding, prompting in the
native language tends to be more promising as it better captures the nuances of
culture and language. Our experiments reveal varied behaviors among different
LLMs and tasks in the multilingual context. Therefore, we advocate for more
comprehensive multilingual evaluation and more efforts toward developing
multilingual LLMs beyond English-centric ones."	ArXiv
1939	NSINA: A News Corpus for Sinhala	['Hansi Hettiarachchi', 'Damith Premasiri', 'Lasitha Uyangodage', 'Tharindu Ranasinghe']	2024-03-25 09:36:51+00:00	http://arxiv.org/abs/2403.16571v1	"The introduction of large language models (LLMs) has advanced natural
language processing (NLP), but their effectiveness is largely dependent on
pre-training resources. This is especially evident in low-resource languages,
such as Sinhala, which face two primary challenges: the lack of substantial
training data and limited benchmarking datasets. In response, this study
introduces NSINA, a comprehensive news corpus of over 500,000 articles from
popular Sinhala news websites, along with three NLP tasks: news media
identification, news category prediction, and news headline generation. The
release of NSINA aims to provide a solution to challenges in adapting LLMs to
Sinhala, offering valuable resources and benchmarks for improving NLP in the
Sinhala language. NSINA is the largest news corpus for Sinhala, available up to
date."	ArXiv
1940	ArabicaQA: A Comprehensive Dataset for Arabic Question Answering	['Abdelrahman Abdallah', 'Mahmoud Kasem', 'Mahmoud Abdalla', 'Mohamed Mahmoud', 'Mohamed Elkasaby', 'Yasser Elbendary', 'Adam Jatowt']	2024-03-26 16:37:54+00:00	http://arxiv.org/abs/2403.17848v1	"In this paper, we address the significant gap in Arabic natural language
processing (NLP) resources by introducing ArabicaQA, the first large-scale
dataset for machine reading comprehension and open-domain question answering in
Arabic. This comprehensive dataset, consisting of 89,095 answerable and 3,701
unanswerable questions created by crowdworkers to look similar to answerable
ones, along with additional labels of open-domain questions marks a crucial
advancement in Arabic NLP resources. We also present AraDPR, the first dense
passage retrieval model trained on the Arabic Wikipedia corpus, specifically
designed to tackle the unique challenges of Arabic text retrieval. Furthermore,
our study includes extensive benchmarking of large language models (LLMs) for
Arabic question answering, critically evaluating their performance in the
Arabic language context. In conclusion, ArabicaQA, AraDPR, and the benchmarking
of LLMs in Arabic question answering offer significant advancements in the
field of Arabic NLP. The dataset and code are publicly accessible for further
research https://github.com/DataScienceUIBK/ArabicaQA."	ArXiv
1941	EthioMT: Parallel Corpus for Low-resource Ethiopian Languages	['Atnafu Lambebo Tonja', 'Olga Kolesnikova', 'Alexander Gelbukh', 'Jugal Kalita']	2024-03-28 12:26:45+00:00	http://arxiv.org/abs/2403.19365v1	"Recent research in natural language processing (NLP) has achieved impressive
performance in tasks such as machine translation (MT), news classification, and
question-answering in high-resource languages. However, the performance of MT
leaves much to be desired for low-resource languages. This is due to the
smaller size of available parallel corpora in these languages, if such corpora
are available at all. NLP in Ethiopian languages suffers from the same issues
due to the unavailability of publicly accessible datasets for NLP tasks,
including MT. To help the research community and foster research for Ethiopian
languages, we introduce EthioMT -- a new parallel corpus for 15 languages. We
also create a new benchmark by collecting a dataset for better-researched
languages in Ethiopia. We evaluate the newly collected corpus and the benchmark
dataset for 23 Ethiopian languages using transformer and fine-tuning
approaches."	ArXiv
1942	LayerNorm: A key component in parameter-efficient fine-tuning	['Taha ValizadehAslani', 'Hualou Liang']	2024-03-29 16:53:11+00:00	http://arxiv.org/abs/2403.20284v1	"Fine-tuning a pre-trained model, such as Bidirectional Encoder
Representations from Transformers (BERT), has been proven to be an effective
method for solving many natural language processing (NLP) tasks. However, due
to the large number of parameters in many state-of-the-art NLP models,
including BERT, the process of fine-tuning is computationally expensive. One
attractive solution to this issue is parameter-efficient fine-tuning, which
involves modifying only a minimal segment of the model while keeping the
remainder unchanged. Yet, it remains unclear which segment of the BERT model is
crucial for fine-tuning. In this paper, we first analyze different components
in the BERT model to pinpoint which one undergoes the most significant changes
after fine-tuning. We find that output LayerNorm changes more than any other
components when fine-tuned for different General Language Understanding
Evaluation (GLUE) tasks. Then we show that only fine-tuning the LayerNorm can
reach comparable, or in some cases better, performance to full fine-tuning and
other parameter-efficient fine-tuning methods. Moreover, we use Fisher
information to determine the most critical subset of LayerNorm and demonstrate
that many NLP tasks in the GLUE benchmark can be solved by fine-tuning only a
small portion of LayerNorm with negligible performance degradation."	ArXiv
1943	Addressing Both Statistical and Causal Gender Fairness in NLP Models	['Hannah Chen', 'Yangfeng Ji', 'David Evans']	2024-03-30 20:05:41+00:00	http://arxiv.org/abs/2404.00463v1	"Statistical fairness stipulates equivalent outcomes for every protected
group, whereas causal fairness prescribes that a model makes the same
prediction for an individual regardless of their protected characteristics.
Counterfactual data augmentation (CDA) is effective for reducing bias in NLP
models, yet models trained with CDA are often evaluated only on metrics that
are closely tied to the causal fairness notion; similarly, sampling-based
methods designed to promote statistical fairness are rarely evaluated for
causal fairness. In this work, we evaluate both statistical and causal
debiasing methods for gender bias in NLP models, and find that while such
methods are effective at reducing bias as measured by the targeted metric, they
do not necessarily improve results on other bias metrics. We demonstrate that
combinations of statistical and causal debiasing techniques are able to reduce
bias measured through both types of metrics."	ArXiv
1944	"Constructing and Expanding Low-Resource and Underrepresented Parallel
  Datasets for Indonesian Local Languages"	['Joanito Agili Lopo', 'Radius Tanone']	2024-04-01 09:24:06+00:00	http://arxiv.org/abs/2404.01009v1	"In Indonesia, local languages play an integral role in the culture. However,
the available Indonesian language resources still fall into the category of
limited data in the Natural Language Processing (NLP) field. This is become
problematic when build NLP model for these languages. To address this gap, we
introduce Bhinneka Korpus, a multilingual parallel corpus featuring five
Indonesian local languages. Our goal is to enhance access and utilization of
these resources, extending their reach within the country. We explained in a
detail the dataset collection process and associated challenges. Additionally,
we experimented with translation task using the IBM Model 1 due to data
constraints. The result showed that the performance of each language already
shows good indications for further development. Challenges such as lexical
variation, smoothing effects, and cross-linguistic variability are discussed.
We intend to evaluate the corpus using advanced NLP techniques for low-resource
languages, paving the way for multilingual translation models."	ArXiv
1945	"CMULAB: An Open-Source Framework for Training and Deployment of Natural
  Language Processing Models"	['Zaid Sheikh', 'Antonios Anastasopoulos', 'Shruti Rijhwani', 'Lindia Tjuatja', 'Robbie Jimerson', 'Graham Neubig']	2024-04-03 02:21:46+00:00	http://arxiv.org/abs/2404.02408v1	"Effectively using Natural Language Processing (NLP) tools in under-resourced
languages requires a thorough understanding of the language itself, familiarity
with the latest models and training methodologies, and technical expertise to
deploy these models. This could present a significant obstacle for language
community members and linguists to use NLP tools. This paper introduces the CMU
Linguistic Annotation Backend, an open-source framework that simplifies model
deployment and continuous human-in-the-loop fine-tuning of NLP models. CMULAB
enables users to leverage the power of multilingual models to quickly adapt and
extend existing tools for speech recognition, OCR, translation, and syntactic
analysis to new languages, even with limited training data. We describe various
tools and APIs that are currently available and how developers can easily add
new models/functionality to the framework. Code is available at
https://github.com/neulab/cmulab along with a live demo at https://cmulab.dev"	ArXiv
1946	"A Comparative Analysis of Word-Level Metric Differential Privacy:
  Benchmarking The Privacy-Utility Trade-off"	['Stephen Meisenbacher', 'Nihildev Nandakumar', 'Alexandra Klymenko', 'Florian Matthes']	2024-04-04 09:48:14+00:00	http://arxiv.org/abs/2404.03324v1	"The application of Differential Privacy to Natural Language Processing
techniques has emerged in relevance in recent years, with an increasing number
of studies published in established NLP outlets. In particular, the adaptation
of Differential Privacy for use in NLP tasks has first focused on the
$\textit{word-level}$, where calibrated noise is added to word embedding
vectors to achieve ""noisy"" representations. To this end, several
implementations have appeared in the literature, each presenting an alternative
method of achieving word-level Differential Privacy. Although each of these
includes its own evaluation, no comparative analysis has been performed to
investigate the performance of such methods relative to each other. In this
work, we conduct such an analysis, comparing seven different algorithms on two
NLP tasks with varying hyperparameters, including the $\textit{epsilon
($\varepsilon$)}$ parameter, or privacy budget. In addition, we provide an
in-depth analysis of the results with a focus on the privacy-utility trade-off,
as well as open-source our implementation code for further reproduction. As a
result of our analysis, we give insight into the benefits and challenges of
word-level Differential Privacy, and accordingly, we suggest concrete steps
forward for the research field."	ArXiv
1947	Interpreting Themes from Educational Stories	['Yigeng Zhang', 'Fabio A. González', 'Thamar Solorio']	2024-04-08 07:26:27+00:00	http://arxiv.org/abs/2404.05250v1	"Reading comprehension continues to be a crucial research focus in the NLP
community. Recent advances in Machine Reading Comprehension (MRC) have mostly
centered on literal comprehension, referring to the surface-level understanding
of content. In this work, we focus on the next level - interpretive
comprehension, with a particular emphasis on inferring the themes of a
narrative text. We introduce the first dataset specifically designed for
interpretive comprehension of educational narratives, providing corresponding
well-edited theme texts. The dataset spans a variety of genres and cultural
origins and includes human-annotated theme keywords with varying levels of
granularity. We further formulate NLP tasks under different abstractions of
interpretive comprehension toward the main idea of a story. After conducting
extensive experiments with state-of-the-art methods, we found the task to be
both challenging and significant for NLP research. The dataset and source code
have been made publicly available to the research community at
https://github.com/RiTUAL-UH/EduStory."	ArXiv
1948	Multilingual Evaluation of Semantic Textual Relatedness	['Sharvi Endait', 'Srushti Sonavane', 'Ridhima Sinare', 'Pritika Rohera', 'Advait Naik', 'Dipali Kadam']	2024-04-13 17:16:03+00:00	http://arxiv.org/abs/2404.09047v1	"The explosive growth of online content demands robust Natural Language
Processing (NLP) techniques that can capture nuanced meanings and cultural
context across diverse languages. Semantic Textual Relatedness (STR) goes
beyond superficial word overlap, considering linguistic elements and
non-linguistic factors like topic, sentiment, and perspective. Despite its
pivotal role, prior NLP research has predominantly focused on English, limiting
its applicability across languages. Addressing this gap, our paper dives into
capturing deeper connections between sentences beyond simple word overlap.
Going beyond English-centric NLP research, we explore STR in Marathi, Hindi,
Spanish, and English, unlocking the potential for information retrieval,
machine translation, and more. Leveraging the SemEval-2024 shared task, we
explore various language models across three learning paradigms: supervised,
unsupervised, and cross-lingual. Our comprehensive methodology gains promising
results, demonstrating the effectiveness of our approach. This work aims to not
only showcase our achievements but also inspire further research in
multilingual STR, particularly for low-resourced languages."	ArXiv
1949	"From Bytes to Borsch: Fine-Tuning Gemma and Mistral for the Ukrainian
  Language Representation"	['Artur Kiulian', 'Anton Polishko', 'Mykola Khandoga', 'Oryna Chubych', 'Jack Connor', 'Raghav Ravishankar', 'Adarsh Shirawalmath']	2024-04-14 04:25:41+00:00	http://arxiv.org/abs/2404.09138v1	"In the rapidly advancing field of AI and NLP, generative large language
models (LLMs) stand at the forefront of innovation, showcasing unparalleled
abilities in text understanding and generation. However, the limited
representation of low-resource languages like Ukrainian poses a notable
challenge, restricting the reach and relevance of this technology. Our paper
addresses this by fine-tuning the open-source Gemma and Mistral LLMs with
Ukrainian datasets, aiming to improve their linguistic proficiency and
benchmarking them against other existing models capable of processing Ukrainian
language. This endeavor not only aims to mitigate language bias in technology
but also promotes inclusivity in the digital realm. Our transparent and
reproducible approach encourages further NLP research and development.
Additionally, we present the Ukrainian Knowledge and Instruction Dataset (UKID)
to aid future efforts in language model fine-tuning. Our research not only
advances the field of NLP but also highlights the importance of linguistic
diversity in AI, which is crucial for cultural preservation, education, and
expanding AI's global utility. Ultimately, we advocate for a future where
technology is inclusive, enabling AI to communicate effectively across all
languages, especially those currently underrepresented."	ArXiv
1950	"D3CODE: Disentangling Disagreements in Data across Cultures on
  Offensiveness Detection and Evaluation"	['Aida Mostafazadeh Davani', 'Mark Díaz', 'Dylan Baker', 'Vinodkumar Prabhakaran']	2024-04-16 19:12:03+00:00	http://arxiv.org/abs/2404.10857v1	"While human annotations play a crucial role in language technologies,
annotator subjectivity has long been overlooked in data collection. Recent
studies that have critically examined this issue are often situated in the
Western context, and solely document differences across age, gender, or racial
groups. As a result, NLP research on subjectivity have overlooked the fact that
individuals within demographic groups may hold diverse values, which can
influence their perceptions beyond their group norms. To effectively
incorporate these considerations into NLP pipelines, we need datasets with
extensive parallel annotations from various social and cultural groups. In this
paper we introduce the \dataset dataset: a large-scale cross-cultural dataset
of parallel annotations for offensive language in over 4.5K sentences annotated
by a pool of over 4k annotators, balanced across gender and age, from across 21
countries, representing eight geo-cultural regions. The dataset contains
annotators' moral values captured along six moral foundations: care, equality,
proportionality, authority, loyalty, and purity. Our analyses reveal
substantial regional variations in annotators' perceptions that are shaped by
individual moral values, offering crucial insights for building pluralistic,
culturally sensitive NLP models."	ArXiv
1951	Annotator-Centric Active Learning for Subjective NLP Tasks	['Michiel van der Meer', 'Neele Falk', 'Pradeep K. Murukannaiah', 'Enrico Liscio']	2024-04-24 08:13:02+00:00	http://arxiv.org/abs/2404.15720v4	"Active Learning (AL) addresses the high costs of collecting human annotations
by strategically annotating the most informative samples. However, for
subjective NLP tasks, incorporating a wide range of perspectives in the
annotation process is crucial to capture the variability in human judgments. We
introduce Annotator-Centric Active Learning (ACAL), which incorporates an
annotator selection strategy following data sampling. Our objective is
two-fold: 1) to efficiently approximate the full diversity of human judgments,
and 2) to assess model performance using annotator-centric metrics, which value
minority and majority perspectives equally. We experiment with multiple
annotator selection strategies across seven subjective NLP tasks, employing
both traditional and novel, human-centered evaluation metrics. Our findings
indicate that ACAL improves data efficiency and excels in annotator-centric
performance evaluations. However, its success depends on the availability of a
sufficiently large and diverse pool of annotators to sample from."	ArXiv
1952	"Comparing LLM prompting with Cross-lingual transfer performance on
  Indigenous and Low-resource Brazilian Languages"	['David Ifeoluwa Adelani', 'A. Seza Doğruöz', 'André Coneglian', 'Atul Kr. Ojha']	2024-04-28 19:24:28+00:00	http://arxiv.org/abs/2404.18286v2	"Large Language Models are transforming NLP for a variety of tasks. However,
how LLMs perform NLP tasks for low-resource languages (LRLs) is less explored.
In line with the goals of the AmericasNLP workshop, we focus on 12 LRLs from
Brazil, 2 LRLs from Africa and 2 high-resource languages (HRLs) (e.g., English
and Brazilian Portuguese). Our results indicate that the LLMs perform worse for
the part of speech (POS) labeling of LRLs in comparison to HRLs. We explain the
reasons behind this failure and provide an error analysis through examples
observed in our data set."	ArXiv
1953	Conformal Prediction for Natural Language Processing: A Survey	['Margarida M. Campos', 'António Farinhas', 'Chrysoula Zerva', 'Mário A. T. Figueiredo', 'André F. T. Martins']	2024-05-03 10:00:45+00:00	http://arxiv.org/abs/2405.01976v1	"The rapid proliferation of large language models and natural language
processing (NLP) applications creates a crucial need for uncertainty
quantification to mitigate risks such as hallucinations and to enhance
decision-making reliability in critical applications. Conformal prediction is
emerging as a theoretically sound and practically useful framework, combining
flexibility with strong statistical guarantees. Its model-agnostic and
distribution-free nature makes it particularly promising to address the current
shortcomings of NLP systems that stem from the absence of uncertainty
quantification. This paper provides a comprehensive survey of conformal
prediction techniques, their guarantees, and existing applications in NLP,
pointing to directions for future research and open challenges."	ArXiv
1954	Guylingo: The Republic of Guyana Creole Corpora	['Christopher Clarke', 'Roland Daynauth', 'Charlene Wilkinson', 'Hubert Devonish', 'Jason Mars']	2024-05-06 20:30:14+00:00	http://arxiv.org/abs/2405.03832v3	"While major languages often enjoy substantial attention and resources, the
linguistic diversity across the globe encompasses a multitude of smaller,
indigenous, and regional languages that lack the same level of computational
support. One such region is the Caribbean. While commonly labeled as ""English
speaking"", the ex-British Caribbean region consists of a myriad of Creole
languages thriving alongside English. In this paper, we present Guylingo: a
comprehensive corpus designed for advancing NLP research in the domain of
Creolese (Guyanese English-lexicon Creole), the most widely spoken language in
the culturally rich nation of Guyana. We first outline our framework for
gathering and digitizing this diverse corpus, inclusive of colloquial
expressions, idioms, and regional variations in a low-resource language. We
then demonstrate the challenges of training and evaluating NLP models for
machine translation in Creole. Lastly, we discuss the unique opportunities
presented by recent NLP advancements for accelerating the formal adoption of
Creole languages as official languages in the Caribbean."	ArXiv
1955	Natural Language Processing RELIES on Linguistics	['Juri Opitz', 'Shira Wein', 'Nathan Schneider']	2024-05-09 17:59:32+00:00	http://arxiv.org/abs/2405.05966v3	"Large Language Models (LLMs) have become capable of generating highly fluent
text in certain languages, without modules specially designed to capture
grammar or semantic coherence. What does this mean for the future of linguistic
expertise in NLP? We highlight several aspects in which NLP (still) relies on
linguistics, or where linguistic thinking can illuminate new directions. We
argue our case around the acronym RELIES that encapsulates six major facets
where linguistics contributes to NLP: Resources, Evaluation, Low-resource
settings, Interpretability, Explanation, and the Study of language. This list
is not exhaustive, nor is linguistics the main point of reference for every
effort under these themes; but at a macro level, these facets highlight the
enduring importance of studying machine systems vis-\`a-vis systems of human
language."	ArXiv
1956	Challenges and Opportunities in Text Generation Explainability	['Kenza Amara', 'Rita Sevastjanova', 'Mennatallah El-Assady']	2024-05-14 09:44:52+00:00	http://arxiv.org/abs/2405.08468v1	"The necessity for interpretability in natural language processing (NLP) has
risen alongside the growing prominence of large language models. Among the
myriad tasks within NLP, text generation stands out as a primary objective of
autoregressive models. The NLP community has begun to take a keen interest in
gaining a deeper understanding of text generation, leading to the development
of model-agnostic explainable artificial intelligence (xAI) methods tailored to
this task. The design and evaluation of explainability methods are non-trivial
since they depend on many factors involved in the text generation process,
e.g., the autoregressive model and its stochastic nature. This paper outlines
17 challenges categorized into three groups that arise during the development
and assessment of attribution-based explainability methods. These challenges
encompass issues concerning tokenization, defining explanation similarity,
determining token importance and prediction change metrics, the level of human
intervention required, and the creation of suitable test datasets. The paper
illustrates how these challenges can be intertwined, showcasing new
opportunities for the community. These include developing probabilistic
word-level explainability methods and engaging humans in the explainability
pipeline, from the data design to the final evaluation, to draw robust
conclusions on xAI methods."	ArXiv
1957	Optimization Techniques for Sentiment Analysis Based on LLM (GPT-3)	['Tong Zhan', 'Chenxi Shi', 'Yadong Shi', 'Huixiang Li', 'Yiyu Lin']	2024-05-16 02:21:13+00:00	http://arxiv.org/abs/2405.09770v1	"With the rapid development of natural language processing (NLP) technology,
large-scale pre-trained language models such as GPT-3 have become a popular
research object in NLP field. This paper aims to explore sentiment analysis
optimization techniques based on large pre-trained language models such as
GPT-3 to improve model performance and effect and further promote the
development of natural language processing (NLP). By introducing the importance
of sentiment analysis and the limitations of traditional methods, GPT-3 and
Fine-tuning techniques are introduced in this paper, and their applications in
sentiment analysis are explained in detail. The experimental results show that
the Fine-tuning technique can optimize GPT-3 model and obtain good performance
in sentiment analysis task. This study provides an important reference for
future sentiment analysis using large-scale language models."	ArXiv
1958	CNER: A tool Classifier of Named-Entity Relationships	['Jefferson A. Peña Torres', 'Raúl E. Gutiérrez De Piñerez']	2024-05-17 01:16:58+00:00	http://arxiv.org/abs/2405.10485v1	"We introduce CNER, an ensemble of capable tools for extraction of semantic
relationships between named entities in Spanish language. Built upon a
container-based architecture, CNER integrates different Named entity
recognition and relation extraction tools with a user-friendly interface that
allows users to input free text or files effortlessly, facilitating streamlined
analysis. Developed as a prototype version for the Natural Language Processing
(NLP) Group at Universidad del Valle, CNER serves as a practical educational
resource, illustrating how machine learning techniques can effectively tackle
diverse NLP tasks in Spanish. Our preliminary results reveal the promising
potential of CNER in advancing the understanding and development of NLP tools,
particularly within Spanish-language contexts."	ArXiv
1959	"Scalable Multi-Period AC Optimal Power Flow Utilizing GPUs with High
  Memory Capacities"	['Sungho Shin', 'Vishwas Rao', 'Michel Schanen', 'D. Adrian Maldonado', 'Mihai Anitescu']	2024-05-22 22:07:42+00:00	http://arxiv.org/abs/2405.14032v1	"This paper demonstrates the scalability of open-source GPU-accelerated
nonlinear programming (NLP) frameworks -- ExaModels.jl and MadNLP.jl -- for
solving multi-period alternating current (AC) optimal power flow (OPF) problems
on GPUs with high memory capacities (e.g., NVIDIA GH200 with 480 GB of unified
memory). There has been a growing interest in solving multi-period AC OPF
problems, as the increasingly fluctuating electricity market requires operation
planning over multiple periods. These problems, formerly deemed intractable,
are now becoming technologically feasible to solve thanks to the advent of
high-memory GPU hardware and accelerated NLP tools. This study evaluates the
capability of these tools to tackle previously unsolvable multi-period AC OPF
instances. Our numerical experiments, run on an NVIDIA GH200, demonstrate that
we can solve a multi-period OPF instance with more than 10 million variables up
to $10^{-4}$ precision in less than 10 minutes. These results demonstrate the
efficacy of the GPU-accelerated NLP frameworks for the solution of
extreme-scale multi-period OPF. We provide ExaModelsPower.jl, an open-source
modeling tool for multi-period AC OPF models for GPUs."	ArXiv
1960	"Detection and Positive Reconstruction of Cognitive Distortion sentences:
  Mandarin Dataset and Evaluation"	['Shuya Lin', 'Yuxiong Wang', 'Jonathan Dong', 'Shiguang Ni']	2024-05-24 08:17:20+00:00	http://arxiv.org/abs/2405.15334v1	"This research introduces a Positive Reconstruction Framework based on
positive psychology theory. Overcoming negative thoughts can be challenging,
our objective is to address and reframe them through a positive
reinterpretation. To tackle this challenge, a two-fold approach is necessary:
identifying cognitive distortions and suggesting a positively reframed
alternative while preserving the original thought's meaning. Recent studies
have investigated the application of Natural Language Processing (NLP) models
in English for each stage of this process. In this study, we emphasize the
theoretical foundation for the Positive Reconstruction Framework, grounded in
broaden-and-build theory. We provide a shared corpus containing 4001 instances
for detecting cognitive distortions and 1900 instances for positive
reconstruction in Mandarin. Leveraging recent NLP techniques, including
transfer learning, fine-tuning pretrained networks, and prompt engineering, we
demonstrate the effectiveness of automated tools for both tasks. In summary,
our study contributes to multilingual positive reconstruction, highlighting the
effectiveness of NLP in cognitive distortion detection and positive
reconstruction."	ArXiv
1961	"An NLP Crosswalk Between the Common Core State Standards and NAEP Item
  Specifications"	['Gregory Camilli']	2024-05-27 15:47:46+00:00	http://arxiv.org/abs/2405.17284v2	"Natural language processing (NLP) is rapidly developing for applications in
educational assessment. In this paper, I describe an NLP-based procedure that
can be used to support subject matter experts in establishing a crosswalk
between item specifications and content standards. This paper extends recent
work by proposing and demonstrating the use of multivariate similarity based on
embedding vectors for sentences or texts. In particular, a hybrid regression
procedure is demonstrated for establishing the match of each content standard
to multiple item specifications. The procedure is used to evaluate the match of
the Common Core State Standards (CCSS) for mathematics at grade 4 to the
corresponding item specifications for the 2026 National Assessment of
Educational Progress (NAEP)."	ArXiv
1962	Formality Style Transfer in Persian	['Parastoo Falakaflaki', 'Mehrnoush Shamsfard']	2024-06-02 20:57:27+00:00	http://arxiv.org/abs/2406.00867v1	"This study explores the formality style transfer in Persian, particularly
relevant in the face of the increasing prevalence of informal language on
digital platforms, which poses challenges for existing Natural Language
Processing (NLP) tools. The aim is to transform informal text into formal while
retaining the original meaning, addressing both lexical and syntactic
differences. We introduce a novel model, Fa-BERT2BERT, based on the Fa-BERT
architecture, incorporating consistency learning and gradient-based dynamic
weighting. This approach improves the model's understanding of syntactic
variations, balancing loss components effectively during training. Our
evaluation of Fa-BERT2BERT against existing methods employs new metrics
designed to accurately measure syntactic and stylistic changes. Results
demonstrate our model's superior performance over traditional techniques across
various metrics, including BLEU, BERT score, Rouge-l, and proposed metrics
underscoring its ability to adeptly navigate the complexities of Persian
language style transfer. This study significantly contributes to Persian
language processing by enhancing the accuracy and functionality of NLP models
and thereby supports the development of more efficient and reliable NLP
applications, capable of handling language style transformation effectively,
thereby streamlining content moderation, enhancing data mining results, and
facilitating cross-cultural communication."	ArXiv
1963	ThaiCoref: Thai Coreference Resolution Dataset	['Pontakorn Trakuekul', 'Wei Qi Leong', 'Charin Polpanumas', 'Jitkapat Sawatphol', 'William Chandra Tjhi', 'Attapol T. Rutherford']	2024-06-10 03:47:24+00:00	http://arxiv.org/abs/2406.06000v1	"While coreference resolution is a well-established research area in Natural
Language Processing (NLP), research focusing on Thai language remains limited
due to the lack of large annotated corpora. In this work, we introduce
ThaiCoref, a dataset for Thai coreference resolution. Our dataset comprises
777,271 tokens, 44,082 mentions and 10,429 entities across four text genres:
university essays, newspapers, speeches, and Wikipedia. Our annotation scheme
is built upon the OntoNotes benchmark with adjustments to address Thai-specific
phenomena. Utilizing ThaiCoref, we train models employing a multilingual
encoder and cross-lingual transfer techniques, achieving a best F1 score of
67.88\% on the test set. Error analysis reveals challenges posed by Thai's
unique linguistic features. To benefit the NLP community, we make the dataset
and the model publicly available at http://www.github.com/nlp-chula/thai-coref ."	ArXiv
1964	Prompt-based vs. Fine-tuned LLMs Toward Causal Graph Verification	['Yuni Susanti', 'Nina Holsmoelle']	2024-05-29 09:06:18+00:00	http://arxiv.org/abs/2406.16899v1	"This work aims toward an application of natural language processing (NLP)
technology for automatic verification of causal graphs using text sources. A
causal graph is often derived from unsupervised causal discovery methods and
requires manual evaluation from human experts. NLP technologies, i.e., Large
Language Models (LLMs) such as BERT and ChatGPT, can potentially be used to
verify the resulted causal graph by predicting if causal relation can be
observed between node pairs based on the textual context. In this work, we
compare the performance of two types of NLP models: (1) Pre-trained language
models fine-tuned for causal relation classification task and, (2) prompt-based
LLMs. Contrasted to previous studies where prompt-based LLMs work relatively
well over a set of diverse tasks, preliminary experiments on biomedical and
open-domain datasets suggest that the fine-tuned models far outperform the
prompt-based LLMs, up to 20.5 points improvement of F1 score. We shared the
code and the pre-processed datasets in our repository."	ArXiv
1965	Toucan: Many-to-Many Translation for 150 African Language Pairs	['AbdelRahim Elmadany', 'Ife Adebara', 'Muhammad Abdul-Mageed']	2024-07-05 18:12:19+00:00	http://arxiv.org/abs/2407.04796v2	"We address a notable gap in Natural Language Processing (NLP) by introducing
a collection of resources designed to improve Machine Translation (MT) for
low-resource languages, with a specific focus on African languages. First, we
introduce two language models (LMs), Cheetah-1.2B and Cheetah-3.7B, with 1.2
billion and 3.7 billion parameters respectively. Next, we finetune the
aforementioned models to create toucan, an Afrocentric machine translation
model designed to support 156 African language pairs. To evaluate Toucan, we
carefully develop an extensive machine translation benchmark, dubbed
AfroLingu-MT, tailored for evaluating machine translation. Toucan significantly
outperforms other models, showcasing its remarkable performance on MT for
African languages. Finally, we train a new model, spBLEU-1K, to enhance
translation evaluation metrics, covering 1K languages, including 614 African
languages. This work aims to advance the field of NLP, fostering cross-cultural
understanding and knowledge exchange, particularly in regions with limited
language resources such as Africa. The GitHub repository for the Toucan project
is available at https://github.com/UBC-NLP/Toucan."	ArXiv
1966	A Principled Framework for Evaluating on Typologically Diverse Languages	['Esther Ploeger', 'Wessel Poelman', 'Andreas Holck Høeg-Petersen', 'Anders Schlichtkrull', 'Miryam de Lhoneux', 'Johannes Bjerva']	2024-07-06 09:31:02+00:00	http://arxiv.org/abs/2407.05022v1	"Beyond individual languages, multilingual natural language processing (NLP)
research increasingly aims to develop models that perform well across languages
generally. However, evaluating these systems on all the world's languages is
practically infeasible. To attain generalizability, representative language
sampling is essential. Previous work argues that generalizable multilingual
evaluation sets should contain languages with diverse typological properties.
However, 'typologically diverse' language samples have been found to vary
considerably in this regard, and popular sampling methods are flawed and
inconsistent. We present a language sampling framework for selecting highly
typologically diverse languages given a sampling frame, informed by language
typology. We compare sampling methods with a range of metrics and find that our
systematic methods consistently retrieve more typologically diverse language
selections than previous methods in NLP. Moreover, we provide evidence that
this affects generalizability in multilingual model evaluation, emphasizing the
importance of diverse language sampling in NLP evaluation."	ArXiv
1967	"A Comparison of Language Modeling and Translation as Multilingual
  Pretraining Objectives"	['Zihao Li', 'Shaoxiong Ji', 'Timothee Mickus', 'Vincent Segonne', 'Jörg Tiedemann']	2024-07-22 09:16:30+00:00	http://arxiv.org/abs/2407.15489v2	"Pretrained language models (PLMs) display impressive performances and have
captured the attention of the NLP community. Establishing best practices in
pretraining has, therefore, become a major focus of NLP research, especially
since insights gained from monolingual English models may not necessarily apply
to more complex multilingual models. One significant caveat of the current
state of the art is that different works are rarely comparable: they often
discuss different parameter counts, training data, and evaluation methodology.
  This paper proposes a comparison of multilingual pretraining objectives in a
controlled methodological environment. We ensure that training data and model
architectures are comparable, and discuss the downstream performances across 6
languages that we observe in probing and fine-tuning scenarios. We make two key
observations: (1) the architecture dictates which pretraining objective is
optimal; (2) multilingual translation is a very effective pretraining objective
under the right conditions. We make our code, data, and model weights available
at \texttt{\url{https://github.com/Helsinki-NLP/lm-vs-mt}}."	ArXiv
1968	"Improving ICD coding using Chapter based Named Entities and Attentional
  Models"	['Abhijith R. Beeravolu', 'Mirjam Jonkman', 'Sami Azam', 'Friso De Boer']	2024-07-24 12:34:23+00:00	http://arxiv.org/abs/2407.17230v1	"Recent advancements in natural language processing (NLP) have led to
automation in various domains. However, clinical NLP often relies on benchmark
datasets that may not reflect real-world scenarios accurately. Automatic ICD
coding, a vital NLP task, typically uses outdated and imbalanced datasets like
MIMIC-III, with existing methods yielding micro-averaged F1 scores between 0.4
and 0.7 due to many false positives. Our research introduces an enhanced
approach to ICD coding that improves F1 scores by using chapter-based named
entities and attentional models. This method categorizes discharge summaries
into ICD-9 Chapters and develops attentional models with chapter-specific data,
eliminating the need to consider external data for code identification. For
categorization, we use Chapter-IV to de-bias and influence key entities and
weights without neural networks, creating accurate thresholds and providing
interpretability for human validation. Post-validation, we develop attentional
models for three frequent and three non-frequent codes from Chapter-IV using
Bidirectional-Gated Recurrent Units (GRUs) with Attention and Transformer with
Multi-head Attention architectures. The average Micro-F1 scores of 0.79 and
0.81 from these models demonstrate significant performance improvements in ICD
coding."	ArXiv
1969	"Enhancing Semantic Similarity Understanding in Arabic NLP with Nested
  Embedding Learning"	['Omer Nacar', 'Anis Koubaa']	2024-07-30 19:03:03+00:00	http://arxiv.org/abs/2407.21139v2	"This work presents a novel framework for training Arabic nested embedding
models through Matryoshka Embedding Learning, leveraging multilingual,
Arabic-specific, and English-based models, to highlight the power of nested
embeddings models in various Arabic NLP downstream tasks. Our innovative
contribution includes the translation of various sentence similarity datasets
into Arabic, enabling a comprehensive evaluation framework to compare these
models across different dimensions. We trained several nested embedding models
on the Arabic Natural Language Inference triplet dataset and assessed their
performance using multiple evaluation metrics, including Pearson and Spearman
correlations for cosine similarity, Manhattan distance, Euclidean distance, and
dot product similarity. The results demonstrate the superior performance of the
Matryoshka embedding models, particularly in capturing semantic nuances unique
to the Arabic language. Results demonstrated that Arabic Matryoshka embedding
models have superior performance in capturing semantic nuances unique to the
Arabic language, significantly outperforming traditional models by up to
20-25\% across various similarity metrics. These results underscore the
effectiveness of language-specific training and highlight the potential of
Matryoshka models in enhancing semantic textual similarity tasks for Arabic
NLP."	ArXiv
1970	"AttackER: Towards Enhancing Cyber-Attack Attribution with a Named Entity
  Recognition Dataset"	['Pritam Deka', 'Sampath Rajapaksha', 'Ruby Rani', 'Amirah Almutairi', 'Erisa Karafili']	2024-08-09 16:10:35+00:00	http://arxiv.org/abs/2408.05149v1	"Cyber-attack attribution is an important process that allows experts to put
in place attacker-oriented countermeasures and legal actions. The analysts
mainly perform attribution manually, given the complex nature of this task. AI
and, more specifically, Natural Language Processing (NLP) techniques can be
leveraged to support cybersecurity analysts during the attribution process.
However powerful these techniques are, they need to deal with the lack of
datasets in the attack attribution domain. In this work, we will fill this gap
and will provide, to the best of our knowledge, the first dataset on
cyber-attack attribution. We designed our dataset with the primary goal of
extracting attack attribution information from cybersecurity texts, utilizing
named entity recognition (NER) methodologies from the field of NLP. Unlike
other cybersecurity NER datasets, ours offers a rich set of annotations with
contextual details, including some that span phrases and sentences. We
conducted extensive experiments and applied NLP techniques to demonstrate the
dataset's effectiveness for attack attribution. These experiments highlight the
potential of Large Language Models (LLMs) capabilities to improve the NER tasks
in cybersecurity datasets for cyber-attack attribution."	ArXiv
1971	"How Well Do LLMs Handle Cantonese? Benchmarking Cantonese Capabilities
  of Large Language Models"	['Jiyue Jiang', 'Pengan Chen', 'Liheng Chen', 'Sheng Wang', 'Qinghang Bao', 'Lingpeng Kong', 'Yu Li', 'Chuan Wu']	2024-08-29 17:54:14+00:00	http://arxiv.org/abs/2408.16756v2	"The rapid evolution of large language models (LLMs) has transformed the
competitive landscape in natural language processing (NLP), particularly for
English and other data-rich languages. However, underrepresented languages like
Cantonese, spoken by over 85 million people, face significant development gaps,
which is particularly concerning given the economic significance of the
Guangdong-Hong Kong-Macau Greater Bay Area, and in substantial
Cantonese-speaking populations in places like Singapore and North America.
Despite its wide use, Cantonese has scant representation in NLP research,
especially compared to other languages from similarly developed regions. To
bridge these gaps, we outline current Cantonese NLP methods and introduce new
benchmarks designed to evaluate LLM performance in factual generation,
mathematical logic, complex reasoning, and general knowledge in Cantonese,
which aim to advance open-source Cantonese LLM technology. We also propose
future research directions and recommended models to enhance Cantonese LLM
development."	ArXiv
1972	Pre-Trained Language Models for Keyphrase Prediction: A Review	['Muhammad Umair', 'Tangina Sultana', 'Young-Koo Lee']	2024-09-02 09:15:44+00:00	http://arxiv.org/abs/2409.01087v1	"Keyphrase Prediction (KP) is essential for identifying keyphrases in a
document that can summarize its content. However, recent Natural Language
Processing (NLP) advances have developed more efficient KP models using deep
learning techniques. The limitation of a comprehensive exploration jointly both
keyphrase extraction and generation using pre-trained language models
spotlights a critical gap in the literature, compelling our survey paper to
bridge this deficiency and offer a unified and in-depth analysis to address
limitations in previous surveys. This paper extensively examines the topic of
pre-trained language models for keyphrase prediction (PLM-KP), which are
trained on large text corpora via different learning (supervisor, unsupervised,
semi-supervised, and self-supervised) techniques, to provide respective
insights into these two types of tasks in NLP, precisely, Keyphrase Extraction
(KPE) and Keyphrase Generation (KPG). We introduce appropriate taxonomies for
PLM-KPE and KPG to highlight these two main tasks of NLP. Moreover, we point
out some promising future directions for predicting keyphrases."	ArXiv
1973	"CortexCompile: Harnessing Cortical-Inspired Architectures for Enhanced
  Multi-Agent NLP Code Synthesis"	['Gautham Ramachandran', 'Rick Yang']	2024-08-23 18:36:20+00:00	http://arxiv.org/abs/2409.02938v1	"Current approaches to automated code generation often rely on monolithic
models that lack real-time adaptability and scalability. This limitation is
particularly evident in complex programming tasks that require dynamic
adjustment and efficiency. The integration of neuroscience principles into
Natural Language Processing (NLP) has the potential to revolutionize automated
code generation. This paper presents CortexCompile, a novel modular system
inspired by the specialized functions of the human brain's cortical regions. By
emulating the distinct roles of the Prefrontal Cortex, Parietal Cortex,
Temporal Lobe, and Motor Cortex, CortexCompile achieves significant
advancements in scalability, efficiency, and adaptability compared to
traditional monolithic models like GPT-4o. The system's architecture features a
Task Orchestration Agent that manages dynamic task delegation and parallel
processing, facilitating the generation of highly accurate and optimized code
across increasingly complex programming tasks. Experimental evaluations
demonstrate that CortexCompile consistently outperforms GPT-4o in development
time, accuracy, and user satisfaction, particularly in tasks involving
real-time strategy games and first-person shooters. These findings underscore
the viability of neuroscience-inspired architectures in addressing the
limitations of current NLP models, paving the way for more efficient and
human-like AI systems."	ArXiv
1974	"HyPA-RAG: A Hybrid Parameter Adaptive Retrieval-Augmented Generation
  System for AI Legal and Policy Applications"	['Rishi Kalra', 'Zekun Wu', 'Ayesha Gulley', 'Airlie Hilliard', 'Xin Guan', 'Adriano Koshiyama', 'Philip Treleaven']	2024-08-29 16:11:20+00:00	http://arxiv.org/abs/2409.09046v1	"While Large Language Models (LLMs) excel in text generation and
question-answering, their effectiveness in AI legal and policy is limited by
outdated knowledge, hallucinations, and inadequate reasoning in complex
contexts. Retrieval-Augmented Generation (RAG) systems improve response
accuracy by integrating external knowledge but struggle with retrieval errors,
poor context integration, and high costs, particularly in interpreting
qualitative and quantitative AI legal texts. This paper introduces a Hybrid
Parameter-Adaptive RAG (HyPA-RAG) system tailored for AI legal and policy,
exemplified by NYC Local Law 144 (LL144). HyPA-RAG uses a query complexity
classifier for adaptive parameter tuning, a hybrid retrieval strategy combining
dense, sparse, and knowledge graph methods, and an evaluation framework with
specific question types and metrics. By dynamically adjusting parameters,
HyPA-RAG significantly improves retrieval accuracy and response fidelity.
Testing on LL144 shows enhanced correctness, faithfulness, and contextual
precision, addressing the need for adaptable NLP systems in complex,
high-stakes AI legal and policy applications."	ArXiv
1975	"Analyzing Correlations Between Intrinsic and Extrinsic Bias Metrics of
  Static Word Embeddings With Their Measuring Biases Aligned"	['Taisei Katô', 'Yusuke Miyao']	2024-09-14 02:13:56+00:00	http://arxiv.org/abs/2409.09260v1	"We examine the abilities of intrinsic bias metrics of static word embeddings
to predict whether Natural Language Processing (NLP) systems exhibit biased
behavior. A word embedding is one of the fundamental NLP technologies that
represents the meanings of words through real vectors, and problematically, it
also learns social biases such as stereotypes. An intrinsic bias metric
measures bias by examining a characteristic of vectors, while an extrinsic bias
metric checks whether an NLP system trained with a word embedding is biased. A
previous study found that a common intrinsic bias metric usually does not
correlate with extrinsic bias metrics. However, the intrinsic and extrinsic
bias metrics did not measure the same bias in most cases, which makes us
question whether the lack of correlation is genuine. In this paper, we extract
characteristic words from datasets of extrinsic bias metrics and analyze
correlations with intrinsic bias metrics with those words to ensure both
metrics measure the same bias. We observed moderate to high correlations with
some extrinsic bias metrics but little to no correlations with the others. This
result suggests that intrinsic bias metrics can predict biased behavior in
particular settings but not in others. Experiment codes are available at
GitHub."	ArXiv
1976	"Natural Language Processing Methods for the Study of Protein-Ligand
  Interactions"	['James Michels', 'Ramya Bandarupalli', 'Amin Ahangar Akbari', 'Thai Le', 'Hong Xiao', 'Jing Li', 'Erik F. Y. Hom']	2024-09-19 19:14:50+00:00	http://arxiv.org/abs/2409.13057v2	"Recent advances in Natural Language Processing (NLP) have ignited interest in
developing effective methods for predicting protein-ligand interactions (PLIs)
given their relevance to drug discovery and protein engineering efforts and the
ever-growing volume of biochemical sequence and structural data available. The
parallels between human languages and the ""languages"" used to represent
proteins and ligands have enabled the use of NLP machine learning approaches to
advance PLI studies. In this review, we explain where and how such approaches
have been applied in the recent literature and discuss useful mechanisms such
as long short-term memory, transformers, and attention. We conclude with a
discussion of the current limitations of NLP methods for the study of PLIs as
well as key challenges that need to be addressed in future work."	ArXiv
1977	"LLM for Everyone: Representing the Underrepresented in Large Language
  Models"	['Samuel Cahyawijaya']	2024-09-20 20:53:22+00:00	http://arxiv.org/abs/2409.13897v1	"Natural language processing (NLP) has witnessed a profound impact of large
language models (LLMs) that excel in a multitude of tasks. However, the
limitation of LLMs in multilingual settings, particularly in underrepresented
languages, remains a significant hurdle. This thesis aims to bridge the gap in
NLP research and development by focusing on underrepresented languages. A
comprehensive evaluation of LLMs is conducted to assess their capabilities in
these languages, revealing the challenges of multilingual and multicultural
generalization. Addressing the multilingual generalization gap, this thesis
proposes data-and-compute-efficient methods to mitigate the disparity in LLM
ability in underrepresented languages, allowing better generalization on
underrepresented languages without the loss of task generalization ability. The
proposed solutions cover cross-lingual continual instruction tuning,
retrieval-based cross-lingual in-context learning, and in-context query
alignment. Furthermore, a novel method to measure cultural values alignment
between LLMs operating in different languages is proposed, ensuring cultural
sensitivity and inclusivity. These contributions aim to enhance the
multilingual and multicultural alignment of LLMs in underrepresented languages,
ultimately advancing the NLP field toward greater equality and inclusiveness."	ArXiv
1978	"SDBA: A Stealthy and Long-Lasting Durable Backdoor Attack in Federated
  Learning"	['Minyeong Choe', 'Cheolhee Park', 'Changho Seo', 'Hyunil Kim']	2024-09-23 08:30:57+00:00	http://arxiv.org/abs/2409.14805v1	"Federated Learning is a promising approach for training machine learning
models while preserving data privacy, but its distributed nature makes it
vulnerable to backdoor attacks, particularly in NLP tasks while related
research remains limited. This paper introduces SDBA, a novel backdoor attack
mechanism designed for NLP tasks in FL environments. Our systematic analysis
across LSTM and GPT-2 models identifies the most vulnerable layers for backdoor
injection and achieves both stealth and long-lasting durability through
layer-wise gradient masking and top-k% gradient masking within these layers.
Experiments on next token prediction and sentiment analysis tasks show that
SDBA outperforms existing backdoors in durability and effectively bypasses
representative defense mechanisms, with notable performance in LLM such as
GPT-2. These results underscore the need for robust defense strategies in
NLP-based FL systems."	ArXiv
1979	"Faithfulness and the Notion of Adversarial Sensitivity in NLP
  Explanations"	['Supriya Manna', 'Niladri Sett']	2024-09-26 12:11:28+00:00	http://arxiv.org/abs/2409.17774v2	"Faithfulness is arguably the most critical metric to assess the reliability
of explainable AI. In NLP, current methods for faithfulness evaluation are
fraught with discrepancies and biases, often failing to capture the true
reasoning of models. We introduce Adversarial Sensitivity as a novel approach
to faithfulness evaluation, focusing on the explainer's response when the model
is under adversarial attack. Our method accounts for the faithfulness of
explainers by capturing sensitivity to adversarial input changes. This work
addresses significant limitations in existing evaluation techniques, and
furthermore, quantifies faithfulness from a crucial yet underexplored paradigm."	ArXiv
1980	"Enhancing Romanian Offensive Language Detection through Knowledge
  Distillation, Multi-Task Learning, and Data Augmentation"	['Vlad-Cristian Matei', 'Iulian-Marius Tăiatu', 'Răzvan-Alexandru Smădu', 'Dumitru-Clementin Cercel']	2024-09-30 16:59:48+00:00	http://arxiv.org/abs/2409.20498v1	"This paper highlights the significance of natural language processing (NLP)
within artificial intelligence, underscoring its pivotal role in comprehending
and modeling human language. Recent advancements in NLP, particularly in
conversational bots, have garnered substantial attention and adoption among
developers. This paper explores advanced methodologies for attaining smaller
and more efficient NLP models. Specifically, we employ three key approaches:
(1) training a Transformer-based neural network to detect offensive language,
(2) employing data augmentation and knowledge distillation techniques to
increase performance, and (3) incorporating multi-task learning with knowledge
distillation and teacher annealing using diverse datasets to enhance
efficiency. The culmination of these methods has yielded demonstrably improved
outcomes."	ArXiv
1981	"Thinking Outside of the Differential Privacy Box: A Case Study in Text
  Privatization with Language Model Prompting"	['Stephen Meisenbacher', 'Florian Matthes']	2024-10-01 14:46:15+00:00	http://arxiv.org/abs/2410.00751v1	"The field of privacy-preserving Natural Language Processing has risen in
popularity, particularly at a time when concerns about privacy grow with the
proliferation of Large Language Models. One solution consistently appearing in
recent literature has been the integration of Differential Privacy (DP) into
NLP techniques. In this paper, we take these approaches into critical view,
discussing the restrictions that DP integration imposes, as well as bring to
light the challenges that such restrictions entail. To accomplish this, we
focus on $\textbf{DP-Prompt}$, a recent method for text privatization
leveraging language models to rewrite texts. In particular, we explore this
rewriting task in multiple scenarios, both with DP and without DP. To drive the
discussion on the merits of DP in NLP, we conduct empirical utility and privacy
experiments. Our results demonstrate the need for more discussion on the
usability of DP in NLP and its benefits over non-DP approaches."	ArXiv
1982	"NLP Case Study on Predicting the Before and After of the Ukraine-Russia
  and Hamas-Israel Conflicts"	['Jordan Miner', 'John E. Ortega']	2024-10-08 23:46:56+00:00	http://arxiv.org/abs/2410.06427v1	"We propose a method to predict toxicity and other textual attributes through
the use of natural language processing (NLP) techniques for two recent events:
the Ukraine-Russia and Hamas-Israel conflicts. This article provides a basis
for exploration in future conflicts with hopes to mitigate risk through the
analysis of social media before and after a conflict begins. Our work compiles
several datasets from Twitter and Reddit for both conflicts in a before and
after separation with an aim of predicting a future state of social media for
avoidance. More specifically, we show that: (1) there is a noticeable
difference in social media discussion leading up to and following a conflict
and (2) social media discourse on platforms like Twitter and Reddit is useful
in identifying future conflicts before they arise. Our results show that
through the use of advanced NLP techniques (both supervised and unsupervised)
toxicity and other attributes about language before and after a conflict is
predictable with a low error of nearly 1.2 percent for both conflicts."	ArXiv
1983	"Wikimedia data for AI: a review of Wikimedia datasets for NLP tasks and
  AI-assisted editing"	['Isaac Johnson', 'Lucie-Aimée Kaffee', 'Miriam Redi']	2024-10-11 15:46:09+00:00	http://arxiv.org/abs/2410.08918v1	"Wikimedia content is used extensively by the AI community and within the
language modeling community in particular. In this paper, we provide a review
of the different ways in which Wikimedia data is curated to use in NLP tasks
across pre-training, post-training, and model evaluations. We point to
opportunities for greater use of Wikimedia content but also identify ways in
which the language modeling community could better center the needs of
Wikimedia editors. In particular, we call for incorporating additional sources
of Wikimedia data, a greater focus on benchmarks for LLMs that encode Wikimedia
principles, and greater multilingualism in Wikimedia-derived datasets."	ArXiv
1984	Long Range Named Entity Recognition for Marathi Documents	['Pranita Deshmukh', 'Nikita Kulkarni', 'Sanhita Kulkarni', 'Kareena Manghani', 'Geetanjali Kale', 'Raviraj Joshi']	2024-10-11 18:48:20+00:00	http://arxiv.org/abs/2410.09192v1	"The demand for sophisticated natural language processing (NLP) methods,
particularly Named Entity Recognition (NER), has increased due to the
exponential growth of Marathi-language digital content. In particular, NER is
essential for recognizing distant entities and for arranging and understanding
unstructured Marathi text data. With an emphasis on managing long-range
entities, this paper offers a comprehensive analysis of current NER techniques
designed for Marathi documents. It dives into current practices and
investigates the BERT transformer model's potential for long-range Marathi NER.
Along with analyzing the effectiveness of earlier methods, the report draws
comparisons between NER in English literature and suggests adaptation
strategies for Marathi literature. The paper discusses the difficulties caused
by Marathi's particular linguistic traits and contextual subtleties while
acknowledging NER's critical role in NLP. To conclude, this project is a major
step forward in improving Marathi NER techniques, with potential wider
applications across a range of NLP tasks and domains."	ArXiv
1985	"ERAS: Evaluating the Robustness of Chinese NLP Models to Morphological
  Garden Path Errors"	['Qinchan Li', 'Sophie Hao']	2024-10-16 21:35:20+00:00	http://arxiv.org/abs/2410.13057v1	"In languages without orthographic word boundaries, NLP models perform word
segmentation, either as an explicit preprocessing step or as an implicit step
in an end-to-end computation. This paper shows that Chinese NLP models are
vulnerable to morphological garden path errors: errors caused by a failure to
resolve local word segmentation ambiguities using sentence-level
morphosyntactic context. We propose a benchmark, ERAS, that tests a model's
vulnerability to morphological garden path errors by comparing its behavior on
sentences with and without local segmentation ambiguities. Using ERAS, we show
that word segmentation models make garden path errors on locally ambiguous
sentences, but do not make equivalent errors on unambiguous sentences. We
further show that sentiment analysis models with character-level tokenization
make implicit garden path errors, even without an explicit word segmentation
step in the pipeline. Our results indicate that models' segmentation of Chinese
text often fails to account for morphosyntactic context."	ArXiv
1986	"A Systematic Survey on Instructional Text: From Representation Formats
  to Downstream NLP Tasks"	['Abdulfattah Safa', 'Tamta Kapanadze', 'Arda Uzunoğlu', 'Gözde Gül Şahin']	2024-10-24 08:22:59+00:00	http://arxiv.org/abs/2410.18529v2	"Recent advances in large language models have demonstrated promising
capabilities in following simple instructions through instruction tuning.
However, real-world tasks often involve complex, multi-step instructions that
remain challenging for current NLP systems. Despite growing interest in this
area, there lacks a comprehensive survey that systematically analyzes the
landscape of complex instruction understanding and processing. Through a
systematic review of the literature, we analyze available resources,
representation schemes, and downstream tasks related to instructional text. Our
study examines 177 papers, identifying trends, challenges, and opportunities in
this emerging field. We provide AI/NLP researchers with essential background
knowledge and a unified view of various approaches to complex instruction
understanding, bridging gaps between different research directions and
highlighting future research opportunities."	ArXiv
1987	"Magnitude Pruning of Large Pretrained Transformer Models with a Mixture
  Gaussian Prior"	['Mingxuan Zhang', 'Yan Sun', 'Faming Liang']	2024-11-01 18:39:38+00:00	http://arxiv.org/abs/2411.00969v1	"Large pretrained transformer models have revolutionized modern AI
applications with their state-of-the-art performance in natural language
processing (NLP). However, their substantial parameter count poses challenges
for real-world deployment. To address this, researchers often reduce model size
by pruning parameters based on their magnitude or sensitivity. Previous
research has demonstrated the limitations of magnitude pruning, especially in
the context of transfer learning for modern NLP tasks. In this paper, we
introduce a new magnitude-based pruning algorithm called mixture Gaussian prior
pruning (MGPP), which employs a mixture Gaussian prior for regularization. MGPP
prunes non-expressive weights under the guidance of the mixture Gaussian prior,
aiming to retain the model's expressive capability. Extensive evaluations
across various NLP tasks, including natural language understanding, question
answering, and natural language generation, demonstrate the superiority of MGPP
over existing pruning methods, particularly in high sparsity settings.
Additionally, we provide a theoretical justification for the consistency of the
sparse transformer, shedding light on the effectiveness of the proposed pruning
method."	ArXiv
1988	TinyML NLP Approach for Semantic Wireless Sentiment Classification	['Ahmed Y. Radwan', 'Mohammad Shehab', 'Mohamed-Slim Alouini']	2024-11-09 21:26:59+00:00	http://arxiv.org/abs/2411.06291v1	"Natural Language Processing (NLP) operations, such as semantic sentiment
analysis and text synthesis, may often impair users' privacy and demand
significant on device computational resources. Centralized learning (CL) on the
edge offers an alternative energy-efficient approach, yet requires the
collection of raw information, which affects the user's privacy. While
Federated learning (FL) preserves privacy, it requires high computational
energy on board tiny user devices. We introduce split learning (SL) as an
energy-efficient alternative, privacy-preserving tiny machine learning (TinyML)
scheme and compare it to FL and CL in the presence of Rayleigh fading and
additive noise. Our results show that SL reduces processing power and CO2
emissions while maintaining high accuracy, whereas FL offers a balanced
compromise between efficiency and privacy. Hence, this study provides insights
into deploying energy-efficient, privacy-preserving NLP models on edge devices."	ArXiv
1989	"MetaphorShare: A Dynamic Collaborative Repository of Open Metaphor
  Datasets"	['Joanne Boisson', 'Arif Mehmood', 'Jose Camacho-Collados']	2024-11-27 11:58:34+00:00	http://arxiv.org/abs/2411.18260v2	"The metaphor studies community has developed numerous valuable labelled
corpora in various languages over the years. Many of these resources are not
only unknown to the NLP community, but are also often not easily shared among
the researchers. Both in human sciences and in NLP, researchers could benefit
from a centralised database of labelled resources, easily accessible and
unified under an identical format. To facilitate this, we present
MetaphorShare, a website to integrate metaphor datasets making them open and
accessible. With this effort, our aim is to encourage researchers to share and
upload more datasets in any language in order to facilitate metaphor studies
and the development of future metaphor processing NLP systems. The website has
four main functionalities: upload, download, search and label metaphor
datasets. It is accessible at www.metaphorshare.com."	ArXiv
1990	"Consolidating and Developing Benchmarking Datasets for the Nepali
  Natural Language Understanding Tasks"	['Jinu Nyachhyon', 'Mridul Sharma', 'Prajwal Thapa', 'Bal Krishna Bal']	2024-11-28 16:32:02+00:00	http://arxiv.org/abs/2411.19244v1	"The Nepali language has distinct linguistic features, especially its complex
script (Devanagari script), morphology, and various dialects, which pose a
unique challenge for natural language processing (NLP) evaluation. While the
Nepali Language Understanding Evaluation (Nep-gLUE) benchmark provides a
foundation for evaluating models, it remains limited in scope, covering four
tasks. This restricts their utility for comprehensive assessments of NLP
models. To address this limitation, we introduce eight new datasets, creating a
new benchmark, the Nepali Language Understanding Evaluation (NLUE) benchmark,
which covers a total of 12 tasks for evaluating the performance of models
across a diverse set of Natural Language Understanding (NLU) tasks. The added
tasks include single-sentence classification, similarity and paraphrase tasks,
and Natural Language Inference (NLI) tasks. On evaluating the models using
added tasks, we observe that the existing models fall short in handling complex
NLU tasks effectively. This expanded benchmark sets a new standard for
evaluating, comparing, and advancing models, contributing significantly to the
broader goal of advancing NLP research for low-resource languages."	ArXiv
1991	Yankari: A Monolingual Yoruba Dataset	['Maro Akpobi']	2024-12-04 14:05:18+00:00	http://arxiv.org/abs/2412.03334v1	"This paper presents Yankari, a large-scale monolingual dataset for the Yoruba
language, aimed at addressing the critical gap in Natural Language Processing
(NLP) resources for this important West African language. Despite being spoken
by over 30 million people, Yoruba has been severely underrepresented in NLP
research and applications. We detail our methodology for creating this dataset,
which includes careful source selection, automated quality control, and
rigorous data cleaning processes. The Yankari dataset comprises 51,407
documents from 13 diverse sources, totaling over 30 million tokens. Our
approach focuses on ethical data collection practices, avoiding problematic
sources and addressing issues prevalent in existing datasets. We provide
thorough automated evaluations of the dataset, demonstrating its quality
compared to existing resources. The Yankari dataset represents a significant
advancement in Yoruba language resources, providing a foundation for developing
more accurate NLP models, supporting comparative linguistic studies, and
contributing to the digital accessibility of the Yoruba language."	ArXiv
1992	"NLP Cluster Analysis of Common Core State Standards and NAEP Item
  Specifications"	['Gregory Camilli', 'Larry Suter']	2024-11-20 15:44:58+00:00	http://arxiv.org/abs/2412.04482v2	"Camilli (2024) proposed a methodology using natural language processing (NLP)
to map the relationship of a set of content standards to item specifications.
This study provided evidence that NLP can be used to improve the mapping
process. As part of this investigation, the nominal classifications of
standards and items specifications were used to examine construct equivalence.
In the current paper, we determine the strength of empirical support for the
semantic distinctiveness of these classifications, which are known as ""domains""
for Common Core standards, and ""strands"" for National Assessment of Educational
Progress (NAEP) item specifications. This is accomplished by separate k-means
clustering for standards and specifications of their corresponding embedding
vectors. We then briefly illustrate an application of these findings."	ArXiv
1993	Hype-Adjusted Probability Measure for NLP Stock Return Forecasting	['Zheng Cao', 'Helyette Geman']	2024-12-10 15:23:31+00:00	http://arxiv.org/abs/2412.07587v2	"This manuscript introduces the Hype-Adjusted Probability Measure developed in
the context of a new Natural Language Processing (NLP) approach for stock
return and volatility forecasting. A novel sentiment score equation is
presented to capture component and memory effects and assign dynamic
parameters, enhancing the impact of intraday news data on forecasting
next-period volatility for selected U.S. semiconductor tickers. This approach
integrates machine learning techniques to analyze and improve the predictive
value of news. Building on the research of Geman et al [6], this work improves
forecast accuracy by addressing news bias, memory, and weight, and
incorporating shifts in senti-ment direction. Finally, we propose the
Hype-Adjusted Probability Measure, proving its existence and uniqueness, and
discuss its theoretical applications in finance for NLP-based stock return
forecasting, outlining future research pathways inspired by its concepts."	ArXiv
1994	"Continual Learning for Encoder-only Language Models via a Discrete
  Key-Value Bottleneck"	['Andor Diera', 'Lukas Galke', 'Fabian Karl', 'Ansgar Scherp']	2024-12-11 16:38:34+00:00	http://arxiv.org/abs/2412.08528v1	"Continual learning remains challenging across various natural language
understanding tasks. When models are updated with new training data, they risk
catastrophic forgetting of prior knowledge. In the present work, we introduce a
discrete key-value bottleneck for encoder-only language models, allowing for
efficient continual learning by requiring only localized updates. Inspired by
the success of a discrete key-value bottleneck in vision, we address new and
NLP-specific challenges. We experiment with different bottleneck architectures
to find the most suitable variants regarding language, and present a generic
discrete key initialization technique for NLP that is task independent. We
evaluate the discrete key-value bottleneck in four continual learning NLP
scenarios and demonstrate that it alleviates catastrophic forgetting. We
showcase that it offers competitive performance to other popular continual
learning methods, with lower computational costs."	ArXiv
1995	"SusGen-GPT: A Data-Centric LLM for Financial NLP and Sustainability
  Report Generation"	['Qilong Wu', 'Xiaoneng Xiang', 'Hejia Huang', 'Xuan Wang', 'Yeo Wei Jie', 'Ranjan Satapathy', 'Ricardo Shirota Filho', 'Bharadwaj Veeravalli']	2024-12-14 17:30:33+00:00	http://arxiv.org/abs/2412.10906v1	"The rapid growth of the financial sector and the rising focus on
Environmental, Social, and Governance (ESG) considerations highlight the need
for advanced NLP tools. However, open-source LLMs proficient in both finance
and ESG domains remain scarce. To address this gap, we introduce SusGen-30K, a
category-balanced dataset comprising seven financial NLP tasks and ESG report
generation, and propose TCFD-Bench, a benchmark for evaluating sustainability
report generation. Leveraging this dataset, we developed SusGen-GPT, a suite of
models achieving state-of-the-art performance across six adapted and two
off-the-shelf tasks, trailing GPT-4 by only 2% despite using 7-8B parameters
compared to GPT-4's 1,700B. Based on this, we propose the SusGen system,
integrated with Retrieval-Augmented Generation (RAG), to assist in
sustainability report generation. This work demonstrates the efficiency of our
approach, advancing research in finance and ESG."	ArXiv
1996	"Multilabel Classification for Lung Disease Detection: Integrating Deep
  Learning and Natural Language Processing"	['Maria Efimovich', 'Jayden Lim', 'Vedant Mehta', 'Ethan Poon']	2024-12-16 05:14:08+00:00	http://arxiv.org/abs/2412.11452v1	"Classifying chest radiographs is a time-consuming and challenging task, even
for experienced radiologists. This provides an area for improvement due to the
difficulty in precisely distinguishing between conditions such as pleural
effusion, pneumothorax, and pneumonia. We propose a novel transfer learning
model for multi-label lung disease classification, utilizing the CheXpert
dataset with over 12,617 images of frontal radiographs being analyzed. By
integrating RadGraph parsing for efficient annotation extraction, we enhance
the model's ability to accurately classify multiple lung diseases from complex
medical images. The proposed model achieved an F1 score of 0.69 and an AUROC of
0.86, demonstrating its potential for clinical applications. Also explored was
the use of Natural Language Processing (NLP) to parse report metadata and
address uncertainties in disease classification. By comparing uncertain reports
with more certain cases, the NLP-enhanced model improves its ability to
conclusively classify conditions. This research highlights the connection
between deep learning and NLP, underscoring their potential to enhance
radiological diagnostics and aid in the efficient analysis of chest
radiographs."	ArXiv
1997	"The Role of Natural Language Processing Tasks in Automatic Literary
  Character Network Construction"	['Arthur Amalvy', 'Vincent Labatut', 'Richard Dufour']	2024-12-16 08:46:53+00:00	http://arxiv.org/abs/2412.11560v1	"The automatic extraction of character networks from literary texts is
generally carried out using natural language processing (NLP) cascading
pipelines. While this approach is widespread, no study exists on the impact of
low-level NLP tasks on their performance. In this article, we conduct such a
study on a literary dataset, focusing on the role of named entity recognition
(NER) and coreference resolution when extracting co-occurrence networks. To
highlight the impact of these tasks' performance, we start with gold-standard
annotations, progressively add uniformly distributed errors, and observe their
impact in terms of character network quality. We demonstrate that NER
performance depends on the tested novel and strongly affects character
detection. We also show that NER-detected mentions alone miss a lot of
character co-occurrences, and that coreference resolution is needed to prevent
this. Finally, we present comparison points with 2 methods based on large
language models (LLMs), including a fully end-to-end one, and show that these
models are outperformed by traditional NLP pipelines in terms of recall."	ArXiv
1998	"Survey of Pseudonymization, Abstractive Summarization & Spell Checker
  for Hindi and Marathi"	['Rasika Ransing', 'Mohammed Amaan Dhamaskar', 'Ayush Rajpurohit', 'Amey Dhoke', 'Sanket Dalvi']	2024-12-24 04:51:32+00:00	http://arxiv.org/abs/2412.18163v1	"India's vast linguistic diversity presents unique challenges and
opportunities for technological advancement, especially in the realm of Natural
Language Processing (NLP). While there has been significant progress in NLP
applications for widely spoken languages, the regional languages of India, such
as Marathi and Hindi, remain underserved. Research in the field of NLP for
Indian regional languages is at a formative stage and holds immense
significance. The paper aims to build a platform which enables the user to use
various features like text anonymization, abstractive text summarization and
spell checking in English, Hindi and Marathi language. The aim of these tools
is to serve enterprise and consumer clients who predominantly use Indian
Regional Languages."	ArXiv
1999	Cross-Demographic Portability of Deep NLP-Based Depression Models	['Tomek Rutowski', 'Elizabeth Shriberg', 'Amir Harati', 'Yang Lu', 'Ricardo Oliveira', 'Piotr Chlebek']	2024-12-26 05:54:24+00:00	http://arxiv.org/abs/2412.19070v1	"Deep learning models are rapidly gaining interest for real-world applications
in behavioral health. An important gap in current literature is how well such
models generalize over different populations. We study Natural Language
Processing (NLP) based models to explore portability over two different corpora
highly mismatched in age. The first and larger corpus contains younger
speakers. It is used to train an NLP model to predict depression. When testing
on unseen speakers from the same age distribution, this model performs at
AUC=0.82. We then test this model on the second corpus, which comprises seniors
from a retirement community. Despite the large demographic differences in the
two corpora, we saw only modest degradation in performance for the
senior-corpus data, achieving AUC=0.76. Interestingly, in the senior
population, we find AUC=0.81 for the subset of patients whose health state is
consistent over time. Implications for demographic portability of speech-based
applications are discussed."	ArXiv
2000	"Analyzing Bias in Swiss Federal Supreme Court Judgments Using Facebook's
  Holistic Bias Dataset: Implications for Language Model Training"	['Sabine Wehnert', 'Muhammet Ertas', 'Ernesto William De Luca']	2025-01-06 19:00:09+00:00	http://arxiv.org/abs/2501.03324v1	"Natural Language Processing (NLP) is vital for computers to process and
respond accurately to human language. However, biases in training data can
introduce unfairness, especially in predicting legal judgment. This study
focuses on analyzing biases within the Swiss Judgment Prediction Dataset
(SJP-Dataset). Our aim is to ensure unbiased factual descriptions essential for
fair decision making by NLP models in legal contexts. We analyze the dataset
using social bias descriptors from the Holistic Bias dataset and employ
advanced NLP techniques, including attention visualization, to explore the
impact of dispreferred descriptors on model predictions. The study identifies
biases and examines their influence on model behavior. Challenges include
dataset imbalance and token limits affecting model performance."	ArXiv
2001	"Bootstrapping Method for Developing Part-of-Speech Tagged Corpus in Low
  Resource Languages Tagset - A Focus on an African Igbo"	['Onyenwe Ikechukwu E', 'Onyedinma Ebele G', 'Aniegwu Godwin E', 'Ezeani Ignatius M']	2019-03-12 21:24:25+00:00	http://arxiv.org/abs/1903.05225v1	"Most languages, especially in Africa, have fewer or no established
part-of-speech (POS) tagged corpus. However, POS tagged corpus is essential for
natural language processing (NLP) to support advanced researches such as
machine translation, speech recognition, etc. Even in cases where there is no
POS tagged corpus, there are some languages for which parallel texts are
available online. The task of POS tagging a new language corpus with a new
tagset usually face a bootstrapping problem at the initial stages of the
annotation process. The unavailability of automatic taggers to help the human
annotator makes the annotation process to appear infeasible to quickly produce
adequate amounts of POS tagged corpus for advanced NLP research and training
the taggers. In this paper, we demonstrate the efficacy of a POS annotation
method that employed the services of two automatic approaches to assist POS
tagged corpus creation for a novel language in NLP. The two approaches are
cross-lingual and monolingual POS tags projection. We used cross-lingual to
automatically create an initial 'errorful' tagged corpus for a target language
via word-alignment. The resources for creating this are derived from a source
language rich in NLP resources. A monolingual method is applied to clean the
induce noise via an alignment process and to transform the source language tags
to the target language tags. We used English and Igbo as our case study. This
is possible because there are parallel texts that exist between English and
Igbo, and the source language English has available NLP resources. The results
of the experiment show a steady improvement in accuracy and rate of tags
transformation with score ranges of 6.13% to 83.79% and 8.67% to 98.37%
respectively. The rate of tags transformation evaluates the rate at which
source language tags are translated to target language tags."	ArXiv
2002	"Natural language processing to identify lupus nephritis phenotype in
  electronic health records"	['Yu Deng', 'Jennifer A. Pacheco', 'Anh Chung', 'Chengsheng Mao', 'Joshua C. Smith', 'Juan Zhao', 'Wei-Qi Wei', 'April Barnado', 'Chunhua Weng', 'Cong Liu', 'Adam Cordon', 'Jingzhi Yu', 'Yacob Tedla', 'Abel Kho', 'Rosalind Ramsey-Goldman', 'Theresa Walunas', 'Yuan Luo']	2021-12-20 19:33:50+00:00	http://arxiv.org/abs/2112.10821v1	"Systemic lupus erythematosus (SLE) is a rare autoimmune disorder
characterized by an unpredictable course of flares and remission with diverse
manifestations. Lupus nephritis, one of the major disease manifestations of SLE
for organ damage and mortality, is a key component of lupus classification
criteria. Accurately identifying lupus nephritis in electronic health records
(EHRs) would therefore benefit large cohort observational studies and clinical
trials where characterization of the patient population is critical for
recruitment, study design, and analysis. Lupus nephritis can be recognized
through procedure codes and structured data, such as laboratory tests. However,
other critical information documenting lupus nephritis, such as histologic
reports from kidney biopsies and prior medical history narratives, require
sophisticated text processing to mine information from pathology reports and
clinical notes. In this study, we developed algorithms to identify lupus
nephritis with and without natural language processing (NLP) using EHR data. We
developed four algorithms: a rule-based algorithm using only structured data
(baseline algorithm) and three algorithms using different NLP models. The three
NLP models are based on regularized logistic regression and use different sets
of features including positive mention of concept unique identifiers (CUIs),
number of appearances of CUIs, and a mixture of three components respectively.
The baseline algorithm and the best performed NLP algorithm were external
validated on a dataset from Vanderbilt University Medical Center (VUMC). Our
best performing NLP model incorporating features from both structured data,
regular expression concepts, and mapped CUIs improved F measure in both the
NMEDW (0.41 vs 0.79) and VUMC (0.62 vs 0.96) datasets compared to the baseline
lupus nephritis algorithm."	ArXiv
2003	Extractive Question Answering on Queries in Hindi and Tamil	['Adhitya Thirumala', 'Elisa Ferracane']	2022-09-27 00:40:21+00:00	http://arxiv.org/abs/2210.06356v1	"Indic languages like Hindi and Tamil are underrepresented in the natural
language processing (NLP) field compared to languages like English. Due to this
underrepresentation, performance on NLP tasks (such as search algorithms) in
Indic languages are inferior to their English counterparts. This difference
disproportionately affects those who come from lower socioeconomic statuses
because they consume the most Internet content in local languages. The goal of
this project is to build an NLP model that performs better than pre-existing
models for the task of extractive question-answering (QA) on a public dataset
in Hindi and Tamil. Extractive QA is an NLP task where answers to questions are
extracted from a corresponding body of text. To build the best solution, we
used three different models. The first model is an unmodified cross-lingual
version of the NLP model RoBERTa, known as XLM-RoBERTa, that is pretrained on
100 languages. The second model is based on the pretrained RoBERTa model with
an extra classification head for the question answering, but we used a custom
Indic tokenizer, then optimized hyperparameters and fine tuned on the Indic
dataset. The third model is based on XLM-RoBERTa, but with extra finetuning and
training on the Indic dataset. We hypothesize the third model will perform best
because of the variety of languages the XLM-RoBERTa model has been pretrained
on and the additional finetuning on the Indic dataset. This hypothesis was
proven wrong because the paired RoBERTa models performed the best as the
training data used was most specific to the task performed as opposed to the
XLM-RoBERTa models which had much data that was not in either Hindi or Tamil."	ArXiv
2004	"NLPContributions: An Annotation Scheme for Machine Reading of Scholarly
  Contributions in Natural Language Processing Literature"	"[""Jennifer D'Souza"", 'Sören Auer']"	2020-06-23 10:04:39+00:00	http://arxiv.org/abs/2006.12870v3	"We describe an annotation initiative to capture the scholarly contributions
in natural language processing (NLP) articles, particularly, for the articles
that discuss machine learning (ML) approaches for various information
extraction tasks. We develop the annotation task based on a pilot annotation
exercise on 50 NLP-ML scholarly articles presenting contributions to five
information extraction tasks 1. machine translation, 2. named entity
recognition, 3. question answering, 4. relation classification, and 5. text
classification. In this article, we describe the outcomes of this pilot
annotation phase. Through the exercise we have obtained an annotation
methodology; and found ten core information units that reflect the contribution
of the NLP-ML scholarly investigations. The resulting annotation scheme we
developed based on these information units is called NLPContributions.
  The overarching goal of our endeavor is four-fold: 1) to find a systematic
set of patterns of subject-predicate-object statements for the semantic
structuring of scholarly contributions that are more or less generically
applicable for NLP-ML research articles; 2) to apply the discovered patterns in
the creation of a larger annotated dataset for training machine readers of
research contributions; 3) to ingest the dataset into the Open Research
Knowledge Graph (ORKG) infrastructure as a showcase for creating user-friendly
state-of-the-art overviews; 4) to integrate the machine readers into the ORKG
to assist users in the manual curation of their respective article
contributions. We envision that the NLPContributions methodology engenders a
wider discussion on the topic toward its further refinement and development.
Our pilot annotated dataset of 50 NLP-ML scholarly articles according to the
NLPContributions scheme is openly available to the research community at
https://doi.org/10.25835/0019761."	ArXiv
2005	Trojaning Language Models for Fun and Profit	['Xinyang Zhang', 'Zheng Zhang', 'Shouling Ji', 'Ting Wang']	2020-08-01 18:22:38+00:00	http://arxiv.org/abs/2008.00312v2	"Recent years have witnessed the emergence of a new paradigm of building
natural language processing (NLP) systems: general-purpose, pre-trained
language models (LMs) are composed with simple downstream models and fine-tuned
for a variety of NLP tasks. This paradigm shift significantly simplifies the
system development cycles. However, as many LMs are provided by untrusted third
parties, their lack of standardization or regulation entails profound security
implications, which are largely unexplored.
  To bridge this gap, this work studies the security threats posed by malicious
LMs to NLP systems. Specifically, we present TROJAN-LM, a new class of
trojaning attacks in which maliciously crafted LMs trigger host NLP systems to
malfunction in a highly predictable manner. By empirically studying three
state-of-the-art LMs (BERT, GPT-2, XLNet) in a range of security-critical NLP
tasks (toxic comment detection, question answering, text completion) as well as
user studies on crowdsourcing platforms, we demonstrate that TROJAN-LM
possesses the following properties: (i) flexibility - the adversary is able to
flexibly dene logical combinations (e.g., 'and', 'or', 'xor') of arbitrary
words as triggers, (ii) efficacy - the host systems misbehave as desired by the
adversary with high probability when trigger-embedded inputs are present, (iii)
specificity - the trojan LMs function indistinguishably from their benign
counterparts on clean inputs, and (iv) fluency - the trigger-embedded inputs
appear as fluent natural language and highly relevant to their surrounding
contexts. We provide analytical justification for the practicality of
TROJAN-LM, and further discuss potential countermeasures and their challenges,
which lead to several promising research directions."	ArXiv
2006	Self-Explaining Structures Improve NLP Models	['Zijun Sun', 'Chun Fan', 'Qinghong Han', 'Xiaofei Sun', 'Yuxian Meng', 'Fei Wu', 'Jiwei Li']	2020-12-03 09:32:05+00:00	http://arxiv.org/abs/2012.01786v2	"Existing approaches to explaining deep learning models in NLP usually suffer
from two major drawbacks: (1) the main model and the explaining model are
decoupled: an additional probing or surrogate model is used to interpret an
existing model, and thus existing explaining tools are not self-explainable;
(2) the probing model is only able to explain a model's predictions by
operating on low-level features by computing saliency scores for individual
words but are clumsy at high-level text units such as phrases, sentences, or
paragraphs. To deal with these two issues, in this paper, we propose a simple
yet general and effective self-explaining framework for deep learning models in
NLP. The key point of the proposed framework is to put an additional layer, as
is called by the interpretation layer, on top of any existing NLP model. This
layer aggregates the information for each text span, which is then associated
with a specific weight, and their weighted combination is fed to the softmax
function for the final prediction. The proposed model comes with the following
merits: (1) span weights make the model self-explainable and do not require an
additional probing model for interpretation; (2) the proposed model is general
and can be adapted to any existing deep learning structures in NLP; (3) the
weight associated with each text span provides direct importance scores for
higher-level text units such as phrases and sentences. We for the first time
show that interpretability does not come at the cost of performance: a neural
model of self-explaining features obtains better performances than its
counterpart without the self-explaining nature, achieving a new SOTA
performance of 59.1 on SST-5 and a new SOTA performance of 92.3 on SNLI."	ArXiv
2007	"Extraction of Sleep Information from Clinical Notes of Patients with
  Alzheimer's Disease Using Natural Language Processing"	['Sonish Sivarajkumar', 'Thomas Yu CHow Tam', 'Haneef Ahamed Mohammad', 'Samual Viggiano', 'David Oniani', 'Shyam Visweswaran', 'Yanshan Wang']	2022-03-08 21:20:19+00:00	http://arxiv.org/abs/2204.09601v2	"Alzheimer's Disease (AD) is the most common form of dementia in the United
States. Sleep is one of the lifestyle-related factors that has been shown
critical for optimal cognitive function in old age. However, there is a lack of
research studying the association between sleep and AD incidence. A major
bottleneck for conducting such research is that the traditional way to acquire
sleep information is time-consuming, inefficient, non-scalable, and limited to
patients' subjective experience. A gold standard dataset is created from manual
annotation of 570 randomly sampled clinical note documents from the adSLEEP, a
corpus of 192,000 de-identified clinical notes of 7,266 AD patients retrieved
from the University of Pittsburgh Medical Center (UPMC). We developed a
rule-based Natural Language Processing (NLP) algorithm, machine learning
models, and Large Language Model(LLM)-based NLP algorithms to automate the
extraction of sleep-related concepts, including snoring, napping, sleep
problem, bad sleep quality, daytime sleepiness, night wakings, and sleep
duration, from the gold standard dataset. Rule-based NLP algorithm achieved the
best performance of F1 across all sleep-related concepts. In terms of Positive
Predictive Value (PPV), rule-based NLP algorithm achieved 1.00 for daytime
sleepiness and sleep duration, machine learning models: 0.95 and for napping,
0.86 for bad sleep quality and 0.90 for snoring; and LLAMA2 with finetuning
achieved PPV of 0.93 for Night Wakings, 0.89 for sleep problem, and 1.00 for
sleep duration. The results show that the rule-based NLP algorithm consistently
achieved the best performance for all sleep concepts. This study focused on the
clinical notes of patients with AD, but could be extended to general sleep
information extraction for other diseases."	ArXiv
2008	"SODA: A Natural Language Processing Package to Extract Social
  Determinants of Health for Cancer Studies"	['Zehao Yu', 'Xi Yang', 'Chong Dang', 'Prakash Adekkanattu', 'Braja Gopal Patra', 'Yifan Peng', 'Jyotishman Pathak', 'Debbie L. Wilson', 'Ching-Yuan Chang', 'Wei-Hsuan Lo-Ciganic', 'Thomas J. George', 'William R. Hogan', 'Yi Guo', 'Jiang Bian', 'Yonghui Wu']	2022-12-06 14:23:38+00:00	http://arxiv.org/abs/2212.03000v2	"Objective: We aim to develop an open-source natural language processing (NLP)
package, SODA (i.e., SOcial DeterminAnts), with pre-trained transformer models
to extract social determinants of health (SDoH) for cancer patients, examine
the generalizability of SODA to a new disease domain (i.e., opioid use), and
evaluate the extraction rate of SDoH using cancer populations.
  Methods: We identified SDoH categories and attributes and developed an SDoH
corpus using clinical notes from a general cancer cohort. We compared four
transformer-based NLP models to extract SDoH, examined the generalizability of
NLP models to a cohort of patients prescribed with opioids, and explored
customization strategies to improve performance. We applied the best NLP model
to extract 19 categories of SDoH from the breast (n=7,971), lung (n=11,804),
and colorectal cancer (n=6,240) cohorts.
  Results and Conclusion: We developed a corpus of 629 cancer patients notes
with annotations of 13,193 SDoH concepts/attributes from 19 categories of SDoH.
The Bidirectional Encoder Representations from Transformers (BERT) model
achieved the best strict/lenient F1 scores of 0.9216 and 0.9441 for SDoH
concept extraction, 0.9617 and 0.9626 for linking attributes to SDoH concepts.
Fine-tuning the NLP models using new annotations from opioid use patients
improved the strict/lenient F1 scores from 0.8172/0.8502 to 0.8312/0.8679. The
extraction rates among 19 categories of SDoH varied greatly, where 10 SDoH
could be extracted from >70% of cancer patients, but 9 SDoH had a low
extraction rate (<70% of cancer patients). The SODA package with pre-trained
transformer models is publicly available at
https://github.com/uf-hobiinformatics-lab/SDoH_SODA."	ArXiv
2009	ChatGPT: Jack of all trades, master of none	['Jan Kocoń', 'Igor Cichecki', 'Oliwier Kaszyca', 'Mateusz Kochanek', 'Dominika Szydło', 'Joanna Baran', 'Julita Bielaniewicz', 'Marcin Gruza', 'Arkadiusz Janz', 'Kamil Kanclerz', 'Anna Kocoń', 'Bartłomiej Koptyra', 'Wiktoria Mieleszczenko-Kowszewicz', 'Piotr Miłkowski', 'Marcin Oleksy', 'Maciej Piasecki', 'Łukasz Radliński', 'Konrad Wojtasik', 'Stanisław Woźniak', 'Przemysław Kazienko']	2023-02-21 15:20:37+00:00	http://arxiv.org/abs/2302.10724v4	"OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and
revolutionized the approach in artificial intelligence to human-model
interaction. Several publications on ChatGPT evaluation test its effectiveness
on well-known natural language processing (NLP) tasks. However, the existing
studies are mostly non-automated and tested on a very limited scale. In this
work, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks,
most of them subjective even to humans, such as sentiment analysis, emotion
recognition, offensiveness, and stance detection. In contrast, the other tasks
require more objective reasoning like word sense disambiguation, linguistic
acceptability, and question answering. We also evaluated GPT-4 model on five
selected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process
and analyzed more than 49k responses. Our comparison of its results with
available State-of-the-Art (SOTA) solutions showed that the average loss in
quality of the ChatGPT model was about 25% for zero-shot and few-shot
evaluation. For GPT-4 model, a loss for semantic tasks is significantly lower
than for ChatGPT. We showed that the more difficult the task (lower SOTA
performance), the higher the ChatGPT loss. It especially refers to pragmatic
NLP problems like emotion recognition. We also tested the ability to
personalize ChatGPT responses for selected subjective tasks via Random
Contextual Few-Shot Personalization, and we obtained significantly better
user-based predictions. Additional qualitative analysis revealed a ChatGPT
bias, most likely due to the rules imposed on human trainers by OpenAI. Our
results provide the basis for a fundamental discussion of whether the high
quality of recent predictive NLP models can indicate a tool's usefulness to
society and how the learning and validation procedures for such systems should
be established."	ArXiv
2010	"Unifying the Perspectives of NLP and Software Engineering: A Survey on
  Language Models for Code"	['Ziyin Zhang', 'Chaoyu Chen', 'Bingchang Liu', 'Cong Liao', 'Zi Gong', 'Hang Yu', 'Jianguo Li', 'Rui Wang']	2023-11-14 08:34:26+00:00	http://arxiv.org/abs/2311.07989v7	"In this work we systematically review the recent advancements in software
engineering with language models, covering 70+ models, 40+ evaluation tasks,
180+ datasets, and 900 related works. Unlike previous works, we integrate
software engineering (SE) with natural language processing (NLP) by discussing
the perspectives of both sides: SE applies language models for development
automation, while NLP adopts SE tasks for language model evaluation. We break
down code processing models into general language models represented by the GPT
family and specialized models that are specifically pretrained on code, often
with tailored objectives. We discuss the relations and differences between
these models, and highlight the historical transition of code modeling from
statistical models and RNNs to pretrained Transformers and LLMs, which is
exactly the same course that had been taken by NLP. We also go beyond
programming and review LLMs' application in other software engineering
activities including requirement engineering, testing, deployment, and
operations in an endeavor to provide a global view of NLP in SE, and identify
key challenges and potential future directions in this domain. We keep the
survey open and updated on GitHub at
https://github.com/codefuse-ai/Awesome-Code-LLM."	ArXiv
2011	Computational Approaches to Arabic-English Code-Switching	['Caroline Sabty']	2024-10-17 08:20:29+00:00	http://arxiv.org/abs/2410.13318v1	"Natural Language Processing (NLP) is a vital computational method for
addressing language processing, analysis, and generation. NLP tasks form the
core of many daily applications, from automatic text correction to speech
recognition. While significant research has focused on NLP tasks for the
English language, less attention has been given to Modern Standard Arabic and
Dialectal Arabic. Globalization has also contributed to the rise of
Code-Switching (CS), where speakers mix languages within conversations and even
within individual words (intra-word CS). This is especially common in Arab
countries, where people often switch between dialects or between dialects and a
foreign language they master. CS between Arabic and English is frequent in
Egypt, especially on social media. Consequently, a significant amount of
code-switched content can be found online. Such code-switched data needs to be
investigated and analyzed for several NLP tasks to tackle the challenges of
this multilingual phenomenon and Arabic language challenges. No work has been
done before for several integral NLP tasks on Arabic-English CS data. In this
work, we focus on the Named Entity Recognition (NER) task and other tasks that
help propose a solution for the NER task on CS data, e.g., Language
Identification. This work addresses this gap by proposing and applying
state-of-the-art techniques for Modern Standard Arabic and Arabic-English NER.
We have created the first annotated CS Arabic-English corpus for the NER task.
Also, we apply two enhancement techniques to improve the NER tagger on CS data
using CS contextual embeddings and data augmentation techniques. All methods
showed improvements in the performance of the NER taggers on CS data. Finally,
we propose several intra-word language identification approaches to determine
the language type of a mixed text and identify whether it is a named entity or
not."	ArXiv
2012	Distributed Representations for Compositional Semantics	['Karl Moritz Hermann']	2014-11-12 11:26:51+00:00	http://arxiv.org/abs/1411.3146v1	"The mathematical representation of semantics is a key issue for Natural
Language Processing (NLP). A lot of research has been devoted to finding ways
of representing the semantics of individual words in vector spaces.
Distributional approaches --- meaning distributed representations that exploit
co-occurrence statistics of large corpora --- have proved popular and
successful across a number of tasks. However, natural language usually comes in
structures beyond the word level, with meaning arising not only from the
individual words but also the structure they are contained in at the phrasal or
sentential level. Modelling the compositional process by which the meaning of
an utterance arises from the meaning of its parts is an equally fundamental
task of NLP.
  This dissertation explores methods for learning distributed semantic
representations and models for composing these into representations for larger
linguistic units. Our underlying hypothesis is that neural models are a
suitable vehicle for learning semantically rich representations and that such
representations in turn are suitable vehicles for solving important tasks in
natural language processing. The contribution of this thesis is a thorough
evaluation of our hypothesis, as part of which we introduce several new
approaches to representation learning and compositional semantics, as well as
multiple state-of-the-art models which apply distributed semantic
representations to various tasks in NLP."	ArXiv
2013	A factorization approach to next-to-leading-power threshold logarithms	['D. Bonocore', 'E. Laenen', 'L. Magnea', 'S. Melville', 'L. Vernazza', 'C. D. White']	2015-03-17 18:37:06+00:00	http://arxiv.org/abs/1503.05156v2	"Threshold logarithms become dominant in partonic cross sections when the
selected final state forces gluon radiation to be soft or collinear. Such
radiation factorizes at the level of scattering amplitudes, and this leads to
the resummation of threshold logarithms which appear at leading power in the
threshold variable. In this paper, we consider the extension of this
factorization to include effects suppressed by a single power of the threshold
variable. Building upon the Low-Burnett-Kroll-Del Duca (LBKD) theorem, we
propose a decomposition of radiative amplitudes into universal building blocks,
which contain all effects ultimately responsible for next-to-leading power
(NLP) threshold logarithms in hadronic cross sections for electroweak
annihilation processes. In particular, we provide a NLO evaluation of the
""radiative jet function"", responsible for the interference of next-to-soft and
collinear effects in these cross sections. As a test, using our expression for
the amplitude, we reproduce all abelian-like NLP threshold logarithms in the
NNLO Drell-Yan cross section, including the interplay of real and virtual
emissions. Our results are a significant step towards developing a generally
applicable resummation formalism for NLP threshold effects, and illustrate the
breakdown of next-to-soft theorems for gauge theory amplitudes at loop level."	ArXiv
2014	Parallax: Sparsity-aware Data Parallel Training of Deep Neural Networks	['Soojeong Kim', 'Gyeong-In Yu', 'Hojin Park', 'Sungwoo Cho', 'Eunji Jeong', 'Hyeonmin Ha', 'Sanha Lee', 'Joo Seong Jeong', 'Byung-Gon Chun']	2018-08-08 04:48:14+00:00	http://arxiv.org/abs/1808.02621v3	"The employment of high-performance servers and GPU accelerators for training
deep neural network models have greatly accelerated recent advances in deep
learning (DL). DL frameworks, such as TensorFlow, MXNet, and Caffe2, have
emerged to assist DL researchers to train their models in a distributed manner.
Although current DL frameworks scale well for image classification models,
there remain opportunities for scalable distributed training on natural
language processing (NLP) models. We found that current frameworks show
relatively low scalability on training NLP models due to the lack of
consideration to the difference in sparsity of model parameters. In this paper,
we propose Parallax, a framework that optimizes data parallel training by
utilizing the sparsity of model parameters. Parallax introduces a hybrid
approach that combines Parameter Server and AllReduce architectures to optimize
the amount of data transfer according to the sparsity. Experiments show that
Parallax built atop TensorFlow achieves scalable training throughput on both
dense and sparse models while requiring little effort from its users. Parallax
achieves up to 2.8x, 6.02x speedup for NLP models than TensorFlow and Horovod
with 48 GPUs, respectively. The training speed for the image classification
models is equal to Horovod and 1.53x faster than TensorFlow."	ArXiv
2015	"Neural Machine Translation Inspired Binary Code Similarity Comparison
  beyond Function Pairs"	['Fei Zuo', 'Xiaopeng Li', 'Patrick Young', 'Lannan Luo', 'Qiang Zeng', 'Zhexin Zhang']	2018-08-08 22:26:08+00:00	http://arxiv.org/abs/1808.04706v2	"Binary code analysis allows analyzing binary code without having access to
the corresponding source code. A binary, after disassembly, is expressed in an
assembly language. This inspires us to approach binary analysis by leveraging
ideas and techniques from Natural Language Processing (NLP), a rich area
focused on processing text of various natural languages. We notice that binary
code analysis and NLP share a lot of analogical topics, such as semantics
extraction, summarization, and classification. This work utilizes these ideas
to address two important code similarity comparison problems. (I) Given a pair
of basic blocks for different instruction set architectures (ISAs), determining
whether their semantics is similar or not; and (II) given a piece of code of
interest, determining if it is contained in another piece of assembly code for
a different ISA. The solutions to these two problems have many applications,
such as cross-architecture vulnerability discovery and code plagiarism
detection. We implement a prototype system INNEREYE and perform a comprehensive
evaluation. A comparison between our approach and existing approaches to
Problem I shows that our system outperforms them in terms of accuracy,
efficiency and scalability. And the case studies utilizing the system
demonstrate that our solution to Problem II is effective. Moreover, this
research showcases how to apply ideas and techniques from NLP to large-scale
binary code analysis."	ArXiv
2016	MedSTS: A Resource for Clinical Semantic Textual Similarity	['Yanshan Wang', 'Naveed Afzal', 'Sunyang Fu', 'Liwei Wang', 'Feichen Shen', 'Majid Rastegar-Mojarad', 'Hongfang Liu']	2018-08-28 16:43:19+00:00	http://arxiv.org/abs/1808.09397v1	"The wide adoption of electronic health records (EHRs) has enabled a wide
range of applications leveraging EHR data. However, the meaningful use of EHR
data largely depends on our ability to efficiently extract and consolidate
information embedded in clinical text where natural language processing (NLP)
techniques are essential. Semantic textual similarity (STS) that measures the
semantic similarity between text snippets plays a significant role in many NLP
applications. In the general NLP domain, STS shared tasks have made available a
huge collection of text snippet pairs with manual annotations in various
domains. In the clinical domain, STS can enable us to detect and eliminate
redundant information that may lead to a reduction in cognitive burden and an
improvement in the clinical decision-making process. This paper elaborates our
efforts to assemble a resource for STS in the medical domain, MedSTS. It
consists of a total of 174,629 sentence pairs gathered from a clinical corpus
at Mayo Clinic. A subset of MedSTS (MedSTS_ann) containing 1,068 sentence pairs
was annotated by two medical experts with semantic similarity scores of 0-5
(low to high similarity). We further analyzed the medical concepts in the
MedSTS corpus, and tested four STS systems on the MedSTS_ann corpus. In the
future, we will organize a shared task by releasing the MedSTS_ann corpus to
motivate the community to tackle the real world clinical problems."	ArXiv
2017	Multi-Source Cross-Lingual Model Transfer: Learning What to Share	['Xilun Chen', 'Ahmed Hassan Awadallah', 'Hany Hassan', 'Wei Wang', 'Claire Cardie']	2018-10-08 16:11:01+00:00	http://arxiv.org/abs/1810.03552v3	"Modern NLP applications have enjoyed a great boost utilizing neural networks
models. Such deep neural models, however, are not applicable to most human
languages due to the lack of annotated training data for various NLP tasks.
Cross-lingual transfer learning (CLTL) is a viable method for building NLP
models for a low-resource target language by leveraging labeled data from other
(source) languages. In this work, we focus on the multilingual transfer setting
where training data in multiple source languages is leveraged to further boost
target language performance.
  Unlike most existing methods that rely only on language-invariant features
for CLTL, our approach coherently utilizes both language-invariant and
language-specific features at instance level. Our model leverages adversarial
networks to learn language-invariant features, and mixture-of-experts models to
dynamically exploit the similarity between the target language and each
individual source language. This enables our model to learn effectively what to
share between various languages in the multilingual setup. Moreover, when
coupled with unsupervised multilingual embeddings, our model can operate in a
zero-resource setting where neither target language training data nor
cross-lingual resources are available. Our model achieves significant
performance gains over prior art, as shown in an extensive set of experiments
over multiple text classification and sequence tagging tasks including a
large-scale industry dataset."	ArXiv
2018	New Vistas to study Bhartrhari: Cognitive NLP	['Jayashree Gajjam', 'Diptesh Kanojia', 'Malhar Kulkarni']	2018-10-10 10:00:17+00:00	http://arxiv.org/abs/1810.04440v1	"The Sanskrit grammatical tradition which has commenced with Panini's
Astadhyayi mostly as a Padasastra has culminated as a Vakyasastra, at the hands
of Bhartrhari. The grammarian-philosopher Bhartrhari and his authoritative work
'Vakyapadiya' have been a matter of study for modern scholars, at least for
more than 50 years, since Ashok Aklujkar submitted his Ph.D. dissertation at
Harvard University. The notions of a sentence and a word as a meaningful
linguistic unit in the language have been a subject matter for the discussion
in many works that followed later on. While some scholars have applied
philological techniques to critically establish the text of the works of
Bhartrhari, some others have devoted themselves to exploring philosophical
insights from them. Some others have studied his works from the point of view
of modern linguistics, and psychology. Few others have tried to justify the
views by logical discussions.
  In this paper, we present a fresh view to study Bhartrhari, and his works,
especially the 'Vakyapadiya'. This view is from the field of Natural Language
Processing (NLP), more specifically, what is called as Cognitive NLP. We have
studied the definitions of a sentence given by Bhartrhari at the beginning of
the second chapter of 'Vakyapadiya'. We have researched one of these
definitions by conducting an experiment and following the methodology of
silent-reading of Sanskrit paragraphs. We collect the Gaze-behavior data of
participants and analyze it to understand the underlying comprehension
procedure in the human mind and present our results. We evaluate the
statistical significance of our results using T-test, and discuss the caveats
of our work. We also present some general remarks on this experiment and
usefulness of this method for gaining more insights in the work of Bhartrhari."	ArXiv
2019	"Text Processing Like Humans Do: Visually Attacking and Shielding NLP
  Systems"	['Steffen Eger', 'Gözde Gül Şahin', 'Andreas Rücklé', 'Ji-Ung Lee', 'Claudia Schulz', 'Mohsen Mesgar', 'Krishnkant Swarnkar', 'Edwin Simpson', 'Iryna Gurevych']	2019-03-27 16:01:18+00:00	http://arxiv.org/abs/1903.11508v2	"Visual modifications to text are often used to obfuscate offensive comments
in social media (e.g., ""!d10t"") or as a writing style (""1337"" in ""leet speak""),
among other scenarios. We consider this as a new type of adversarial attack in
NLP, a setting to which humans are very robust, as our experiments with both
simple and more difficult visual input perturbations demonstrate. We then
investigate the impact of visual adversarial attacks on current NLP systems on
character-, word-, and sentence-level tasks, showing that both neural and
non-neural models are, in contrast to humans, extremely sensitive to such
attacks, suffering performance decreases of up to 82\%. We then explore three
shielding methods---visual character embeddings, adversarial training, and
rule-based recovery---which substantially improve the robustness of the models.
However, the shielding methods still fall behind performances achieved in
non-attack scenarios, which demonstrates the difficulty of dealing with visual
attacks."	ArXiv
2020	Natural Language Processing for EHR-Based Computational Phenotyping	['Zexian Zeng', 'Yu Deng', 'Xiaoyu Li', 'Tristan Naumann', 'Yuan Luo']	2018-06-13 02:14:19+00:00	http://arxiv.org/abs/1806.04820v2	"This article reviews recent advances in applying natural language processing
(NLP) to Electronic Health Records (EHRs) for computational phenotyping.
NLP-based computational phenotyping has numerous applications including
diagnosis categorization, novel phenotype discovery, clinical trial screening,
pharmacogenomics, drug-drug interaction (DDI) and adverse drug event (ADE)
detection, as well as genome-wide and phenome-wide association studies.
Significant progress has been made in algorithm development and resource
construction for computational phenotyping. Among the surveyed methods,
well-designed keyword search and rule-based systems often achieve good
performance. However, the construction of keyword and rule lists requires
significant manual effort, which is difficult to scale. Supervised machine
learning models have been favored because they are capable of acquiring both
classification patterns and structures from data. Recently, deep learning and
unsupervised learning have received growing attention, with the former favored
for its performance and the latter for its ability to find novel phenotypes.
Integrating heterogeneous data sources have become increasingly important and
have shown promise in improving model performance. Often better performance is
achieved by combining multiple modalities of information. Despite these many
advances, challenges and opportunities remain for NLP-based computational
phenotyping, including better model interpretability and generalizability, and
proper characterization of feature relations in clinical narratives"	ArXiv
2021	Generation of Synthetic Electronic Medical Record Text	['Jiaqi Guan', 'Runzhe Li', 'Sheng Yu', 'Xuegong Zhang']	2018-12-06 20:35:14+00:00	http://arxiv.org/abs/1812.02793v1	"Machine learning (ML) and Natural Language Processing (NLP) have achieved
remarkable success in many fields and have brought new opportunities and high
expectation in the analyses of medical data. The most common type of medical
data is the massive free-text electronic medical records (EMR). It is widely
regarded that mining such massive data can bring up important information for
improving medical practices as well as for possible new discoveries on complex
diseases. However, the free EMR texts are lacking consistent standards, rich of
private information, and limited in availability. Also, as they are accumulated
from everyday practices, it is often hard to have a balanced number of samples
for the types of diseases under study. These problems hinder the development of
ML and NLP methods for EMR data analysis. To tackle these problems, we
developed a model to generate synthetic text of EMRs called Medical Text
Generative Adversarial Network or mtGAN. It is based on the GAN framework and
is trained by the REINFORCE algorithm. It takes disease features as inputs and
generates synthetic texts as EMRs for the corresponding diseases. We evaluate
the model from micro-level, macro-level and application-level on a Chinese EMR
text dataset. The results show that the method has a good capacity to fit real
data and can generate realistic and diverse EMR samples. This provides a novel
way to avoid potential leakage of patient privacy while still supply sufficient
well-controlled cohort data for developing downstream ML and NLP methods. It
can also be used as a data augmentation method to assist studies based on real
EMR data."	ArXiv
2022	"What Is One Grain of Sand in the Desert? Analyzing Individual Neurons in
  Deep NLP Models"	['Fahim Dalvi', 'Nadir Durrani', 'Hassan Sajjad', 'Yonatan Belinkov', 'Anthony Bau', 'James Glass']	2018-12-21 19:51:47+00:00	http://arxiv.org/abs/1812.09355v1	"Despite the remarkable evolution of deep neural networks in natural language
processing (NLP), their interpretability remains a challenge. Previous work
largely focused on what these models learn at the representation level. We
break this analysis down further and study individual dimensions (neurons) in
the vector representation learned by end-to-end neural models in NLP tasks. We
propose two methods: Linguistic Correlation Analysis, based on a supervised
method to extract the most relevant neurons with respect to an extrinsic task,
and Cross-model Correlation Analysis, an unsupervised method to extract salient
neurons w.r.t. the model itself. We evaluate the effectiveness of our
techniques by ablating the identified neurons and reevaluating the network's
performance for two tasks: neural machine translation (NMT) and neural language
modeling (NLM). We further present a comprehensive analysis of neurons with the
aim to address the following questions: i) how localized or distributed are
different linguistic properties in the models? ii) are certain neurons
exclusive to some properties and not others? iii) is the information more or
less distributed in NMT vs. NLM? and iv) how important are the neurons
identified through the linguistic correlation method to the overall task? Our
code is publicly available as part of the NeuroX toolkit (Dalvi et al. 2019)."	ArXiv
2023	"Development of Deep Learning Based Natural Language Processing Model for
  Turkish"	['Baris Baburoglu', 'Adem Tekerek', 'Mehmet Tekerek']	2019-05-07 21:09:49+00:00	http://arxiv.org/abs/1905.05699v1	"Natural language is one of the most fundamental features that distinguish
people from other living things and enable people to communicate each other.
Language is a tool that enables people to express their feelings and thoughts
and to transfers cultures through generations. Texts and audio are examples of
natural language in daily life. In the natural language, many words disappear
in time, on the other hand new words are derived. Therefore, while the process
of natural language processing (NLP) is complex even for human, it is difficult
to process in computer system. The area of linguistics examines how people use
language. NLP, which requires the collaboration of linguists and computer
scientists, plays an important role in human computer interaction. Studies in
NLP have increased with the use of artificial intelligence technologies in the
field of linguistics. With the deep learning methods which are one of the
artificial intelligence study areas, platforms close to natural language are
being developed. Developed platforms for language comprehension, machine
translation and part of speech (POS) tagging benefit from deep learning
methods. Recurrent Neural Network (RNN), one of the deep learning
architectures, is preferred for processing sequential data such as text or
audio data. In this study, Turkish POS tagging model has been proposed by using
Bidirectional Long-Short Term Memory (BLSTM) which is an RNN type. The proposed
POS tagging model is provided to natural language researchers with a platform
that allows them to perform and use their own analysis. In the development
phase of the platform developed by using BLSTM, the error rate of the POS
tagger has been reduced by taking feedback with expert opinion."	ArXiv
2024	SECRET: Semantically Enhanced Classification of Real-world Tasks	['Ayten Ozge Akmandor', 'Jorge Ortiz', 'Irene Manotas', 'Bongjun Ko', 'Niraj K. Jha']	2019-05-29 12:05:31+00:00	http://arxiv.org/abs/1905.12356v3	"Supervised machine learning (ML) algorithms are aimed at maximizing
classification performance under available energy and storage constraints. They
try to map the training data to the corresponding labels while ensuring
generalizability to unseen data. However, they do not integrate meaning-based
relationships among labels in the decision process. On the other hand, natural
language processing (NLP) algorithms emphasize the importance of semantic
information. In this paper, we synthesize the complementary advantages of
supervised ML and NLP algorithms into one method that we refer to as SECRET
(Semantically Enhanced Classification of REal-world Tasks). SECRET performs
classifications by fusing the semantic information of the labels with the
available data: it combines the feature space of the supervised algorithms with
the semantic space of the NLP algorithms and predicts labels based on this
joint space. Experimental results indicate that, compared to traditional
supervised learning, SECRET achieves up to 14.0% accuracy and 13.1% F1 score
improvements. Moreover, compared to ensemble methods, SECRET achieves up to
12.7% accuracy and 13.3% F1 score improvements. This points to a new research
direction for supervised classification based on incorporation of semantic
information."	ArXiv
2025	Choosing Transfer Languages for Cross-Lingual Learning	['Yu-Hsiang Lin', 'Chian-Yu Chen', 'Jean Lee', 'Zirui Li', 'Yuyan Zhang', 'Mengzhou Xia', 'Shruti Rijhwani', 'Junxian He', 'Zhisong Zhang', 'Xuezhe Ma', 'Antonios Anastasopoulos', 'Patrick Littell', 'Graham Neubig']	2019-05-29 19:19:47+00:00	http://arxiv.org/abs/1905.12688v2	"Cross-lingual transfer, where a high-resource transfer language is used to
improve the accuracy of a low-resource task language, is now an invaluable tool
for improving performance of natural language processing (NLP) on low-resource
languages. However, given a particular task language, it is not clear which
language to transfer from, and the standard strategy is to select languages
based on ad hoc criteria, usually the intuition of the experimenter. Since a
large number of features contribute to the success of cross-lingual transfer
(including phylogenetic similarity, typological properties, lexical overlap, or
size of available data), even the most enlightened experimenter rarely
considers all these factors for the particular task at hand. In this paper, we
consider this task of automatically selecting optimal transfer languages as a
ranking problem, and build models that consider the aforementioned features to
perform this prediction. In experiments on representative NLP tasks, we
demonstrate that our model predicts good transfer languages much better than ad
hoc baselines considering single features in isolation, and glean insights on
what features are most informative for each different NLP tasks, which may
inform future ad hoc selection even without use of our method. Code, data, and
pre-trained models are available at https://github.com/neulab/langrank"	ArXiv
2026	"HyperEmbed: Tradeoffs Between Resources and Performance in NLP Tasks
  with Hyperdimensional Computing enabled Embedding of n-gram Statistics"	['Pedro Alonso', 'Kumar Shridhar', 'Denis Kleyko', 'Evgeny Osipov', 'Marcus Liwicki']	2020-03-03 22:44:10+00:00	http://arxiv.org/abs/2003.01821v2	"Recent advances in Deep Learning have led to a significant performance
increase on several NLP tasks, however, the models become more and more
computationally demanding. Therefore, this paper tackles the domain of
computationally efficient algorithms for NLP tasks. In particular, it
investigates distributed representations of n-gram statistics of texts. The
representations are formed using hyperdimensional computing enabled embedding.
These representations then serve as features, which are used as input to
standard classifiers. We investigate the applicability of the embedding on one
large and three small standard datasets for classification tasks using nine
classifiers. The embedding achieved on par F1 scores while decreasing the time
and memory requirements by several times compared to the conventional n-gram
statistics, e.g., for one of the classifiers on a small dataset, the memory
reduction was 6.18 times; while train and test speed-ups were 4.62 and 3.84
times, respectively. For many classifiers on the large dataset, memory
reduction was ca. 100 times and train and test speed-ups were over 100 times.
Importantly, the usage of distributed representations formed via
hyperdimensional computing allows dissecting strict dependency between the
dimensionality of the representation and n-gram size, thus, opening a room for
tradeoffs."	ArXiv
2027	What the [MASK]? Making Sense of Language-Specific BERT Models	['Debora Nozza', 'Federico Bianchi', 'Dirk Hovy']	2020-03-05 20:42:51+00:00	http://arxiv.org/abs/2003.02912v1	"Recently, Natural Language Processing (NLP) has witnessed an impressive
progress in many areas, due to the advent of novel, pretrained contextual
representation models. In particular, Devlin et al. (2019) proposed a model,
called BERT (Bidirectional Encoder Representations from Transformers), which
enables researchers to obtain state-of-the art performance on numerous NLP
tasks by fine-tuning the representations on their data set and task, without
the need for developing and training highly-specific architectures. The authors
also released multilingual BERT (mBERT), a model trained on a corpus of 104
languages, which can serve as a universal language model. This model obtained
impressive results on a zero-shot cross-lingual natural inference task. Driven
by the potential of BERT models, the NLP community has started to investigate
and generate an abundant number of BERT models that are trained on a particular
language, and tested on a specific data domain and task. This allows us to
evaluate the true potential of mBERT as a universal language model, by
comparing it to the performance of these more specific models. This paper
presents the current state of the art in language-specific BERT models,
providing an overall picture with respect to different dimensions (i.e.
architectures, data domains, and tasks). Our aim is to provide an immediate and
straightforward overview of the commonalities and differences between
Language-Specific (language-specific) BERT models and mBERT. We also provide an
interactive and constantly updated website that can be used to explore the
information we have collected, at https://bertlang.unibocconi.it."	ArXiv
2028	LinCE: A Centralized Benchmark for Linguistic Code-switching Evaluation	['Gustavo Aguilar', 'Sudipta Kar', 'Thamar Solorio']	2020-05-09 00:00:08+00:00	http://arxiv.org/abs/2005.04322v1	"Recent trends in NLP research have raised an interest in linguistic
code-switching (CS); modern approaches have been proposed to solve a wide range
of NLP tasks on multiple language pairs. Unfortunately, these proposed methods
are hardly generalizable to different code-switched languages. In addition, it
is unclear whether a model architecture is applicable for a different task
while still being compatible with the code-switching setting. This is mainly
because of the lack of a centralized benchmark and the sparse corpora that
researchers employ based on their specific needs and interests. To facilitate
research in this direction, we propose a centralized benchmark for Linguistic
Code-switching Evaluation (LinCE) that combines ten corpora covering four
different code-switched language pairs (i.e., Spanish-English, Nepali-English,
Hindi-English, and Modern Standard Arabic-Egyptian Arabic) and four tasks
(i.e., language identification, named entity recognition, part-of-speech
tagging, and sentiment analysis). As part of the benchmark centralization
effort, we provide an online platform at ritual.uh.edu/lince, where researchers
can submit their results while comparing with others in real-time. In addition,
we provide the scores of different popular models, including LSTM, ELMo, and
multilingual BERT so that the NLP community can compare against
state-of-the-art systems. LinCE is a continuous effort, and we will expand it
with more low-resource languages and tasks."	ArXiv
2029	"Machine Reading Comprehension: The Role of Contextualized Language
  Models and Beyond"	['Zhuosheng Zhang', 'Hai Zhao', 'Rui Wang']	2020-05-13 10:58:50+00:00	http://arxiv.org/abs/2005.06249v1	"Machine reading comprehension (MRC) aims to teach machines to read and
comprehend human languages, which is a long-standing goal of natural language
processing (NLP). With the burst of deep neural networks and the evolution of
contextualized language models (CLMs), the research of MRC has experienced two
significant breakthroughs. MRC and CLM, as a phenomenon, have a great impact on
the NLP community. In this survey, we provide a comprehensive and comparative
review on MRC covering overall research topics about 1) the origin and
development of MRC and CLM, with a particular focus on the role of CLMs; 2) the
impact of MRC and CLM to the NLP community; 3) the definition, datasets, and
evaluation of MRC; 4) general MRC architecture and technical methods in the
view of two-stage Encoder-Decoder solving architecture from the insights of the
cognitive process of humans; 5) previous highlights, emerging topics, and our
empirical analysis, among which we especially focus on what works in different
periods of MRC researches. We propose a full-view categorization and new
taxonomies on these topics. The primary views we have arrived at are that 1)
MRC boosts the progress from language processing to understanding; 2) the rapid
improvement of MRC systems greatly benefits from the development of CLMs; 3)
the theme of MRC is gradually moving from shallow text matching to cognitive
reasoning."	ArXiv
2030	Deep Learning for Political Science	['Kakia Chatsiou', 'Slava Jankin Mikhaylov']	2020-05-13 19:14:37+00:00	http://arxiv.org/abs/2005.06540v1	"Political science, and social science in general, have traditionally been
using computational methods to study areas such as voting behavior, policy
making, international conflict, and international development. More recently,
increasingly available quantities of data are being combined with improved
algorithms and affordable computational resources to predict, learn, and
discover new insights from data that is large in volume and variety. New
developments in the areas of machine learning, deep learning, natural language
processing (NLP), and, more generally, artificial intelligence (AI) are opening
up new opportunities for testing theories and evaluating the impact of
interventions and programs in a more dynamic and effective way. Applications
using large volumes of structured and unstructured data are becoming common in
government and industry, and increasingly also in social science research. This
chapter offers an introduction to such methods drawing examples from political
science. Focusing on the areas where the strengths of the methods coincide with
challenges in these fields, the chapter first presents an introduction to AI
and its core technology - machine learning, with its rapidly developing
subfield of deep learning. The discussion of deep neural networks is
illustrated with the NLP tasks that are relevant to political science. The
latest advances in deep learning methods for NLP are also reviewed, together
with their potential for improving information extraction and pattern
recognition from political science texts."	ArXiv
2031	"Explaining Black Box Predictions and Unveiling Data Artifacts through
  Influence Functions"	['Xiaochuang Han', 'Byron C. Wallace', 'Yulia Tsvetkov']	2020-05-14 00:45:23+00:00	http://arxiv.org/abs/2005.06676v1	"Modern deep learning models for NLP are notoriously opaque. This has
motivated the development of methods for interpreting such models, e.g., via
gradient-based saliency maps or the visualization of attention weights. Such
approaches aim to provide explanations for a particular model prediction by
highlighting important words in the corresponding input text. While this might
be useful for tasks where decisions are explicitly influenced by individual
tokens in the input, we suspect that such highlighting is not suitable for
tasks where model decisions should be driven by more complex reasoning. In this
work, we investigate the use of influence functions for NLP, providing an
alternative approach to interpreting neural text classifiers. Influence
functions explain the decisions of a model by identifying influential training
examples. Despite the promise of this approach, influence functions have not
yet been extensively evaluated in the context of NLP, a gap addressed by this
work. We conduct a comparison between influence functions and common
word-saliency methods on representative tasks. As suspected, we find that
influence functions are particularly useful for natural language inference, a
task in which 'saliency maps' may not have clear interpretation. Furthermore,
we develop a new quantitative measure based on influence functions that can
reveal artifacts in training data."	ArXiv
2032	On choosing mixture components via non-local priors	['Jairo Fúquene', 'Mark Steel', 'David Rossell']	2016-04-01 16:22:00+00:00	http://arxiv.org/abs/1604.00314v5	"Choosing the number of mixture components remains an elusive challenge. Model
selection criteria can be either overly liberal or conservative and return
poorly-separated components of limited practical use. We formalize non-local
priors (NLPs) for mixtures and show how they lead to well-separated components
with non-negligible weight, interpretable as distinct subpopulations. We also
propose an estimator for posterior model probabilities under local and
non-local priors, showing that Bayes factors are ratios of posterior to prior
empty-cluster probabilities. The estimator is widely applicable and helps set
thresholds to drop unoccupied components in overfitted mixtures. We suggest
default prior parameters based on multi-modality for Normal/T mixtures and
minimal informativeness for categorical outcomes. We characterise theoretically
the NLP-induced sparsity, derive tractable expressions and algorithms. We fully
develop Normal, Binomial and product Binomial mixtures but the theory,
computation and principles hold more generally. We observed a serious lack of
sensitivity of the Bayesian information criterion (BIC), insufficient parsimony
of the AIC and a local prior, and a mixed behavior of the singular BIC. We also
considered overfitted mixtures, their performance was competitive but depended
on tuning parameters. Under our default prior elicitation NLPs offered a good
compromise between sparsity and power to detect meaningfully-separated
components."	ArXiv
2033	"KeyXtract Twitter Model - An Essential Keywords Extraction Model for
  Twitter Designed using NLP Tools"	['Tharindu Weerasooriya', 'Nandula Perera', 'S. R. Liyanage']	2017-08-09 17:04:34+00:00	http://arxiv.org/abs/1708.02912v1	"Since a tweet is limited to 140 characters, it is ambiguous and difficult for
traditional Natural Language Processing (NLP) tools to analyse. This research
presents KeyXtract which enhances the machine learning based Stanford CoreNLP
Part-of-Speech (POS) tagger with the Twitter model to extract essential
keywords from a tweet. The system was developed using rule-based parsers and
two corpora. The data for the research was obtained from a Twitter profile of a
telecommunication company. The system development consisted of two stages. At
the initial stage, a domain specific corpus was compiled after analysing the
tweets. The POS tagger extracted the Noun Phrases and Verb Phrases while the
parsers removed noise and extracted any other keywords missed by the POS
tagger. The system was evaluated using the Turing Test. After it was tested and
compared against Stanford CoreNLP, the second stage of the system was developed
addressing the shortcomings of the first stage. It was enhanced using Named
Entity Recognition and Lemmatization. The second stage was also tested using
the Turing test and its pass rate increased from 50.00% to 83.33%. The
performance of the final system output was measured using the F1 score.
Stanford CoreNLP with the Twitter model had an average F1 of 0.69 while the
improved system had a F1 of 0.77. The accuracy of the system could be improved
by using a complete domain specific corpus. Since the system used linguistic
features of a sentence, it could be applied to other NLP tools."	ArXiv
2034	Combining Discrete and Neural Features for Sequence Labeling	['Jie Yang', 'Zhiyang Teng', 'Meishan Zhang', 'Yue Zhang']	2017-08-24 05:24:26+00:00	http://arxiv.org/abs/1708.07279v1	"Neural network models have recently received heated research attention in the
natural language processing community. Compared with traditional models with
discrete features, neural models have two main advantages. First, they take
low-dimensional, real-valued embedding vectors as inputs, which can be trained
over large raw data, thereby addressing the issue of feature sparsity in
discrete models. Second, deep neural networks can be used to automatically
combine input features, and including non-local features that capture semantic
patterns that cannot be expressed using discrete indicator features. As a
result, neural network models have achieved competitive accuracies compared
with the best discrete models for a range of NLP tasks.
  On the other hand, manual feature templates have been carefully investigated
for most NLP tasks over decades and typically cover the most useful indicator
pattern for solving the problems. Such information can be complementary the
features automatically induced from neural networks, and therefore combining
discrete and neural features can potentially lead to better accuracy compared
with models that leverage discrete or neural features only.
  In this paper, we systematically investigate the effect of discrete and
neural feature combination for a range of fundamental NLP tasks based on
sequence labeling, including word segmentation, POS tagging and named entity
recognition for Chinese and English, respectively. Our results on standard
benchmarks show that state-of-the-art neural models can give accuracies
comparable to the best discrete models in the literature for most tasks and
combing discrete and neural features unanimously yield better results."	ArXiv
2035	A Deep Relevance Matching Model for Ad-hoc Retrieval	['Jiafeng Guo', 'Yixing Fan', 'Qingyao Ai', 'W. Bruce Croft']	2017-11-23 08:29:22+00:00	http://arxiv.org/abs/1711.08611v1	"In recent years, deep neural networks have led to exciting breakthroughs in
speech recognition, computer vision, and natural language processing (NLP)
tasks. However, there have been few positive results of deep models on ad-hoc
retrieval tasks. This is partially due to the fact that many important
characteristics of the ad-hoc retrieval task have not been well addressed in
deep models yet. Typically, the ad-hoc retrieval task is formalized as a
matching problem between two pieces of text in existing work using deep models,
and treated equivalent to many NLP tasks such as paraphrase identification,
question answering and automatic conversation. However, we argue that the
ad-hoc retrieval task is mainly about relevance matching while most NLP
matching tasks concern semantic matching, and there are some fundamental
differences between these two matching tasks. Successful relevance matching
requires proper handling of the exact matching signals, query term importance,
and diverse matching requirements. In this paper, we propose a novel deep
relevance matching model (DRMM) for ad-hoc retrieval. Specifically, our model
employs a joint deep architecture at the query term level for relevance
matching. By using matching histogram mapping, a feed forward matching network,
and a term gating network, we can effectively deal with the three relevance
matching factors mentioned above. Experimental results on two representative
benchmark collections show that our model can significantly outperform some
well-known retrieval models as well as state-of-the-art deep matching models."	ArXiv
2036	Detecting Malicious PowerShell Commands using Deep Neural Networks	['Danny Hendler', 'Shay Kels', 'Amir Rubin']	2018-04-11 19:16:03+00:00	http://arxiv.org/abs/1804.04177v2	"Microsoft's PowerShell is a command-line shell and scripting language that is
installed by default on Windows machines. While PowerShell can be configured by
administrators for restricting access and reducing vulnerabilities, these
restrictions can be bypassed. Moreover, PowerShell commands can be easily
generated dynamically, executed from memory, encoded and obfuscated, thus
making the logging and forensic analysis of code executed by PowerShell
challenging.For all these reasons, PowerShell is increasingly used by
cybercriminals as part of their attacks' tool chain, mainly for downloading
malicious contents and for lateral movement. Indeed, a recent comprehensive
technical report by Symantec dedicated to PowerShell's abuse by cybercrimials
reported on a sharp increase in the number of malicious PowerShell samples they
received and in the number of penetration tools and frameworks that use
PowerShell. This highlights the urgent need of developing effective methods for
detecting malicious PowerShell commands.In this work, we address this challenge
by implementing several novel detectors of malicious PowerShell commands and
evaluating their performance. We implemented both ""traditional"" natural
language processing (NLP) based detectors and detectors based on
character-level convolutional neural networks (CNNs). Detectors' performance
was evaluated using a large real-world dataset.Our evaluation results show
that, although our detectors individually yield high performance, an ensemble
detector that combines an NLP-based classifier with a CNN-based classifier
provides the best performance, since the latter classifier is able to detect
malicious commands that succeed in evading the former. Our analysis of these
evasive commands reveals that some obfuscation patterns automatically detected
by the CNN classifier are intrinsically difficult to detect using the NLP
techniques we applied."	ArXiv
2037	"A Deep Representation Empowered Distant Supervision Paradigm for
  Clinical Information Extraction"	['Yanshan Wang', 'Sunghwan Sohn', 'Sijia Liu', 'Feichen Shen', 'Liwei Wang', 'Elizabeth J. Atkinson', 'Shreyasee Amin', 'Hongfang Liu']	2018-04-20 20:18:46+00:00	http://arxiv.org/abs/1804.07814v1	"Objective: To automatically create large labeled training datasets and reduce
the efforts of feature engineering for training accurate machine learning
models for clinical information extraction. Materials and Methods: We propose a
distant supervision paradigm empowered by deep representation for extracting
information from clinical text. In this paradigm, the rule-based NLP algorithms
are utilized to generate weak labels and create large training datasets
automatically. Additionally, we use pre-trained word embeddings as deep
representation to eliminate the need of task-specific feature engineering for
machine learning. We evaluated the effectiveness of the proposed paradigm on
two clinical information extraction tasks: smoking status extraction and
proximal femur (hip) fracture extraction. We tested three prevalent machine
learning models, namely, Convolutional Neural Networks (CNN), Support Vector
Machine (SVM), and Random Forrest (RF). Results: The results indicate that CNN
is the best fit to the proposed distant supervision paradigm. It outperforms
the rule-based NLP algorithms given large datasets by capturing additional
extraction patterns. We also verified the advantage of word embedding feature
representation in the paradigm over term frequency-inverse document frequency
(tf-idf) and topic modeling representations. Discussion: In the clinical
domain, the limited amount of labeled data is always a bottleneck for applying
machine learning. Additionally, the performance of machine learning approaches
highly depends on task-specific feature engineering. The proposed paradigm
could alleviate those problems by leveraging rule-based NLP algorithms to
automatically assign weak labels and eliminating the need of task-specific
feature engineering using word embedding feature representation."	ArXiv
2038	"Transform the Non-linear Programming Problem to the Initial-value
  Problem to Solve"	['Sheng Zhang', 'Fei Liao', 'Yi-Nan Kong', 'Kai-Feng He']	2018-04-25 22:55:58+00:00	http://arxiv.org/abs/1804.09829v4	"A dynamic method to solve the Non-linear Programming (NLP) problem with
Equality Constraints (ECs) and Inequality Constraints (IECs) is proposed.
Inspired by the Lyapunov continuous-time dynamics stability theory in the
control field, the optimal solution is analogized to the stable equilibrium
point of a finite-dimensional dynamic system and it is solved in an asymptotic
manner. Under the premise that the Karush-Kuhn-Tucker (KKT) optimality
condition exists, the Dynamic Optimization Equation (DOE), which has the same
dimension to that of the optimization parameter vector, is established and its
solution will converge to the optimal solution of the NLP globally with a
theoretical guarantee. Using the matrix pseudo-inverse, the DOE is valid even
without the linearly independent regularity requirement on the nonlinear
constraints. In addition, the analytic expressions of the Lagrange multipliers
and KKT multipliers, which adjoin the ECs and the IECs respectively during the
entire optimization process, are also derived. Via the proposed method, the NLP
may be transformed to the Initial-value Problem (IVP) to be solved, with mature
Ordinary Differential Equation (ODE) integration methods. Illustrative examples
are solved and it is shown that the dynamic method developed may produce the
right numerical solutions with high efficiency."	ArXiv
2039	"Characterizing the impact of geometric properties of word embeddings on
  task performance"	['Brendan Whitaker', 'Denis Newman-Griffis', 'Aparajita Haldar', 'Hakan Ferhatosmanoglu', 'Eric Fosler-Lussier']	2019-04-09 18:53:00+00:00	http://arxiv.org/abs/1904.04866v1	"Analysis of word embedding properties to inform their use in downstream NLP
tasks has largely been studied by assessing nearest neighbors. However,
geometric properties of the continuous feature space contribute directly to the
use of embedding features in downstream models, and are largely unexplored. We
consider four properties of word embedding geometry, namely: position relative
to the origin, distribution of features in the vector space, global pairwise
distances, and local pairwise distances. We define a sequence of
transformations to generate new embeddings that expose subsets of these
properties to downstream models and evaluate change in task performance to
understand the contribution of each property to NLP models. We transform
publicly available pretrained embeddings from three popular toolkits (word2vec,
GloVe, and FastText) and evaluate on a variety of intrinsic tasks, which model
linguistic information in the vector space, and extrinsic tasks, which use
vectors as input to machine learning models. We find that intrinsic evaluations
are highly sensitive to absolute position, while extrinsic tasks rely primarily
on local similarity. Our findings suggest that future embedding models and
post-processing techniques should focus primarily on similarity to nearby
points in vector space."	ArXiv
2040	Pre-Training with Whole Word Masking for Chinese BERT	['Yiming Cui', 'Wanxiang Che', 'Ting Liu', 'Bing Qin', 'Ziqing Yang']	2019-06-19 13:54:25+00:00	http://arxiv.org/abs/1906.08101v3	"Bidirectional Encoder Representations from Transformers (BERT) has shown
marvelous improvements across various NLP tasks, and its consecutive variants
have been proposed to further improve the performance of the pre-trained
language models. In this paper, we aim to first introduce the whole word
masking (wwm) strategy for Chinese BERT, along with a series of Chinese
pre-trained language models. Then we also propose a simple but effective model
called MacBERT, which improves upon RoBERTa in several ways. Especially, we
propose a new masking strategy called MLM as correction (Mac). To demonstrate
the effectiveness of these models, we create a series of Chinese pre-trained
language models as our baselines, including BERT, RoBERTa, ELECTRA, RBT, etc.
We carried out extensive experiments on ten Chinese NLP tasks to evaluate the
created Chinese pre-trained language models as well as the proposed MacBERT.
Experimental results show that MacBERT could achieve state-of-the-art
performances on many NLP tasks, and we also ablate details with several
findings that may help future research. We open-source our pre-trained language
models for further facilitating our research community. Resources are
available: https://github.com/ymcui/Chinese-BERT-wwm"	ArXiv
2041	Integrating Multimodal Information in Large Pretrained Transformers	['Wasifur Rahman', 'Md. Kamrul Hasan', 'Sangwu Lee', 'Amir Zadeh', 'Chengfeng Mao', 'Louis-Philippe Morency', 'Ehsan Hoque']	2019-08-15 22:51:21+00:00	http://arxiv.org/abs/1908.05787v3	"Recent Transformer-based contextual word representations, including BERT and
XLNet, have shown state-of-the-art performance in multiple disciplines within
NLP. Fine-tuning the trained contextual models on task-specific datasets has
been the key to achieving superior performance downstream. While fine-tuning
these pre-trained models is straightforward for lexical applications
(applications with only language modality), it is not trivial for multimodal
language (a growing area in NLP focused on modeling face-to-face
communication). Pre-trained models don't have the necessary components to
accept two extra modalities of vision and acoustic. In this paper, we proposed
an attachment to BERT and XLNet called Multimodal Adaptation Gate (MAG). MAG
allows BERT and XLNet to accept multimodal nonverbal data during fine-tuning.
It does so by generating a shift to internal representation of BERT and XLNet;
a shift that is conditioned on the visual and acoustic modalities. In our
experiments, we study the commonly used CMU-MOSI and CMU-MOSEI datasets for
multimodal sentiment analysis. Fine-tuning MAG-BERT and MAG-XLNet significantly
boosts the sentiment analysis performance over previous baselines as well as
language-only fine-tuning of BERT and XLNet. On the CMU-MOSI dataset, MAG-XLNet
achieves human-level multimodal sentiment analysis performance for the first
time in the NLP community."	ArXiv
2042	FlauBERT: Unsupervised Language Model Pre-training for French	['Hang Le', 'Loïc Vial', 'Jibril Frej', 'Vincent Segonne', 'Maximin Coavoux', 'Benjamin Lecouteux', 'Alexandre Allauzen', 'Benoît Crabbé', 'Laurent Besacier', 'Didier Schwab']	2019-12-11 14:59:32+00:00	http://arxiv.org/abs/1912.05372v4	"Language models have become a key step to achieve state-of-the art results in
many different Natural Language Processing (NLP) tasks. Leveraging the huge
amount of unlabeled texts nowadays available, they provide an efficient way to
pre-train continuous word representations that can be fine-tuned for a
downstream task, along with their contextualization at the sentence level. This
has been widely demonstrated for English using contextualized representations
(Dai and Le, 2015; Peters et al., 2018; Howard and Ruder, 2018; Radford et al.,
2018; Devlin et al., 2019; Yang et al., 2019b). In this paper, we introduce and
share FlauBERT, a model learned on a very large and heterogeneous French
corpus. Models of different sizes are trained using the new CNRS (French
National Centre for Scientific Research) Jean Zay supercomputer. We apply our
French language models to diverse NLP tasks (text classification, paraphrasing,
natural language inference, parsing, word sense disambiguation) and show that
most of the time they outperform other pre-training approaches. Different
versions of FlauBERT as well as a unified evaluation protocol for the
downstream tasks, called FLUE (French Language Understanding Evaluation), are
shared to the research community for further reproducible experiments in French
NLP."	ArXiv
2043	The Lottery Ticket Hypothesis for Pre-trained BERT Networks	['Tianlong Chen', 'Jonathan Frankle', 'Shiyu Chang', 'Sijia Liu', 'Yang Zhang', 'Zhangyang Wang', 'Michael Carbin']	2020-07-23 19:35:39+00:00	http://arxiv.org/abs/2007.12223v2	"In natural language processing (NLP), enormous pre-trained models like BERT
have become the standard starting point for training on a range of downstream
tasks, and similar trends are emerging in other areas of deep learning. In
parallel, work on the lottery ticket hypothesis has shown that models for NLP
and computer vision contain smaller matching subnetworks capable of training in
isolation to full accuracy and transferring to other tasks. In this work, we
combine these observations to assess whether such trainable, transferrable
subnetworks exist in pre-trained BERT models. For a range of downstream tasks,
we indeed find matching subnetworks at 40% to 90% sparsity. We find these
subnetworks at (pre-trained) initialization, a deviation from prior NLP
research where they emerge only after some amount of training. Subnetworks
found on the masked language modeling task (the same task used to pre-train the
model) transfer universally; those found on other tasks transfer in a limited
fashion if at all. As large-scale pre-training becomes an increasingly central
paradigm in deep learning, our results demonstrate that the main lottery ticket
observations remain relevant in this context. Codes available at
https://github.com/VITA-Group/BERT-Tickets."	ArXiv
2044	Knowledge Graphs for Multilingual Language Translation and Generation	['Diego Moussallem']	2020-09-16 14:36:41+00:00	http://arxiv.org/abs/2009.07715v1	"The Natural Language Processing (NLP) community has recently seen outstanding
progress, catalysed by the release of different Neural Network (NN)
architectures. Neural-based approaches have proven effective by significantly
increasing the output quality of a large number of automated solutions for NLP
tasks (Belinkov and Glass, 2019). Despite these notable advancements, dealing
with entities still poses a difficult challenge as they are rarely seen in
training data. Entities can be classified into two groups, i.e., proper nouns
and common nouns. Proper nouns are also known as Named Entities (NE) and
correspond to the name of people, organizations, or locations, e.g., John, WHO,
or Canada. Common nouns describe classes of objects, e.g., spoon or cancer.
Both types of entities can be found in a Knowledge Graph (KG). Recent work has
successfully exploited the contribution of KGs in NLP tasks, such as Natural
Language Inference (NLI) (KM et al.,2018) and Question Answering (QA) (Sorokin
and Gurevych, 2018). Only a few works had exploited the benefits of KGs in
Neural Machine Translation (NMT) when the work presented herein began.
Additionally, few works had studied the contribution of KGs to Natural Language
Generation (NLG) tasks. Moreover, the multilinguality also remained an open
research area in these respective tasks (Young et al., 2018). In this thesis,
we focus on the use of KGs for machine translation and the generation of texts
to deal with the problems caused by entities and consequently enhance the
quality of automatically generated texts."	ArXiv
2045	"Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning
  in NLP Using Fewer Parameters & Less Data"	['Jonathan Pilault', 'Amine Elhattami', 'Christopher Pal']	2020-09-19 02:04:34+00:00	http://arxiv.org/abs/2009.09139v3	"Multi-Task Learning (MTL) networks have emerged as a promising method for
transferring learned knowledge across different tasks. However, MTL must deal
with challenges such as: overfitting to low resource tasks, catastrophic
forgetting, and negative task transfer, or learning interference. Often, in
Natural Language Processing (NLP), a separate model per task is needed to
obtain the best performance. However, many fine-tuning approaches are both
parameter inefficient, i.e., potentially involving one new model per task, and
highly susceptible to losing knowledge acquired during pretraining. We propose
a novel Transformer architecture consisting of a new conditional attention
mechanism as well as a set of task-conditioned modules that facilitate weight
sharing. Through this construction (a hypernetwork adapter), we achieve more
efficient parameter sharing and mitigate forgetting by keeping half of the
weights of a pretrained model fixed. We also use a new multi-task data sampling
strategy to mitigate the negative effects of data imbalance across tasks. Using
this approach, we are able to surpass single task fine-tuning methods while
being parameter and data efficient (using around 66% of the data for weight
updates). Compared to other BERT Large methods on GLUE, our 8-task model
surpasses other Adapter methods by 2.8% and our 24-task model outperforms by
0.7-1.0% models that use MTL and single task fine-tuning. We show that a larger
variant of our single multi-task model approach performs competitively across
26 NLP tasks and yields state-of-the-art results on a number of test and
development sets. Our code is publicly available at
https://github.com/CAMTL/CA-MTL."	ArXiv
2046	"Improving Robustness and Generality of NLP Models Using Disentangled
  Representations"	['Jiawei Wu', 'Xiaoya Li', 'Xiang Ao', 'Yuxian Meng', 'Fei Wu', 'Jiwei Li']	2020-09-21 02:48:46+00:00	http://arxiv.org/abs/2009.09587v1	"Supervised neural networks, which first map an input $x$ to a single
representation $z$, and then map $z$ to the output label $y$, have achieved
remarkable success in a wide range of natural language processing (NLP) tasks.
Despite their success, neural models lack for both robustness and generality:
small perturbations to inputs can result in absolutely different outputs; the
performance of a model trained on one domain drops drastically when tested on
another domain.
  In this paper, we present methods to improve robustness and generality of NLP
models from the standpoint of disentangled representation learning. Instead of
mapping $x$ to a single representation $z$, the proposed strategy maps $x$ to a
set of representations $\{z_1,z_2,...,z_K\}$ while forcing them to be
disentangled. These representations are then mapped to different logits $l$s,
the ensemble of which is used to make the final prediction $y$. We propose
different methods to incorporate this idea into currently widely-used models,
including adding an $L$2 regularizer on $z$s or adding Total Correlation (TC)
under the framework of variational information bottleneck (VIB). We show that
models trained with the proposed criteria provide better robustness and domain
adaptation ability in a wide range of supervised learning tasks."	ArXiv
2047	"Integration of Domain Knowledge using Medical Knowledge Graph Deep
  Learning for Cancer Phenotyping"	['Mohammed Alawad', 'Shang Gao', 'Mayanka Chandra Shekar', 'S. M. Shamimul Hasan', 'J. Blair Christian', 'Xiao-Cheng Wu', 'Eric B. Durbin', 'Jennifer Doherty', 'Antoinette Stroup', 'Linda Coyle', 'Lynne Penberthy', 'Georgia Tourassi']	2021-01-05 03:59:43+00:00	http://arxiv.org/abs/2101.01337v1	"A key component of deep learning (DL) for natural language processing (NLP)
is word embeddings. Word embeddings that effectively capture the meaning and
context of the word that they represent can significantly improve the
performance of downstream DL models for various NLP tasks. Many existing word
embeddings techniques capture the context of words based on word co-occurrence
in documents and text; however, they often cannot capture broader
domain-specific relationships between concepts that may be crucial for the NLP
task at hand. In this paper, we propose a method to integrate external
knowledge from medical terminology ontologies into the context captured by word
embeddings. Specifically, we use a medical knowledge graph, such as the unified
medical language system (UMLS), to find connections between clinical terms in
cancer pathology reports. This approach aims to minimize the distance between
connected clinical concepts. We evaluate the proposed approach using a
Multitask Convolutional Neural Network (MT-CNN) to extract six cancer
characteristics -- site, subsite, laterality, behavior, histology, and grade --
from a dataset of ~900K cancer pathology reports. The results show that the
MT-CNN model which uses our domain informed embeddings outperforms the same
MT-CNN using standard word2vec embeddings across all tasks, with an improvement
in the overall micro- and macro-F1 scores by 4.97\%and 22.5\%, respectively."	ArXiv
2048	Citizen Participation and Machine Learning for a Better Democracy	['M. Arana-Catania', 'F. A. Van Lier', 'Rob Procter', 'Nataliya Tkachenko', 'Yulan He', 'Arkaitz Zubiaga', 'Maria Liakata']	2021-02-28 13:30:07+00:00	http://arxiv.org/abs/2103.00508v1	"The development of democratic systems is a crucial task as confirmed by its
selection as one of the Millennium Sustainable Development Goals by the United
Nations. In this article, we report on the progress of a project that aims to
address barriers, one of which is information overload, to achieving effective
direct citizen participation in democratic decision-making processes. The main
objectives are to explore if the application of Natural Language Processing
(NLP) and machine learning can improve citizens' experience of digital citizen
participation platforms. Taking as a case study the ""Decide Madrid"" Consul
platform, which enables citizens to post proposals for policies they would like
to see adopted by the city council, we used NLP and machine learning to provide
new ways to (a) suggest to citizens proposals they might wish to support; (b)
group citizens by interests so that they can more easily interact with each
other; (c) summarise comments posted in response to proposals; (d) assist
citizens in aggregating and developing proposals. Evaluation of the results
confirms that NLP and machine learning have a role to play in addressing some
of the barriers users of platforms such as Consul currently experience."	ArXiv
2049	"Active$^2$ Learning: Actively reducing redundancies in Active Learning
  methods for Sequence Tagging and Machine Translation"	['Rishi Hazra', 'Parag Dutta', 'Shubham Gupta', 'Mohammed Abdul Qaathir', 'Ambedkar Dukkipati']	2021-03-11 06:27:31+00:00	http://arxiv.org/abs/2103.06490v2	"While deep learning is a powerful tool for natural language processing (NLP)
problems, successful solutions to these problems rely heavily on large amounts
of annotated samples. However, manually annotating data is expensive and
time-consuming. Active Learning (AL) strategies reduce the need for huge
volumes of labeled data by iteratively selecting a small number of examples for
manual annotation based on their estimated utility in training the given model.
In this paper, we argue that since AL strategies choose examples independently,
they may potentially select similar examples, all of which may not contribute
significantly to the learning process. Our proposed approach,
Active$\mathbf{^2}$ Learning (A$\mathbf{^2}$L), actively adapts to the deep
learning model being trained to eliminate further such redundant examples
chosen by an AL strategy. We show that A$\mathbf{^2}$L is widely applicable by
using it in conjunction with several different AL strategies and NLP tasks. We
empirically demonstrate that the proposed approach is further able to reduce
the data requirements of state-of-the-art AL strategies by an absolute
percentage reduction of $\approx\mathbf{3-25\%}$ on multiple NLP tasks while
achieving the same performance with no additional computation overhead."	ArXiv
2050	A Weakly Supervised Approach for Classifying Stance in Twitter Replies	['Sumeet Kumar', 'Ramon Villa Cox', 'Matthew Babcock', 'Kathleen M. Carley']	2021-03-12 06:02:45+00:00	http://arxiv.org/abs/2103.07098v1	"Conversations on social media (SM) are increasingly being used to investigate
social issues on the web, such as online harassment and rumor spread. For such
issues, a common thread of research uses adversarial reactions, e.g., replies
pointing out factual inaccuracies in rumors. Though adversarial reactions are
prevalent in online conversations, inferring those adverse views (or stance)
from the text in replies is difficult and requires complex natural language
processing (NLP) models. Moreover, conventional NLP models for stance mining
need labeled data for supervised learning. Getting labeled conversations can
itself be challenging as conversations can be on any topic, and topics change
over time. These challenges make learning the stance a difficult NLP problem.
  In this research, we first create a new stance dataset comprised of three
different topics by labeling both users' opinions on the topics (as in pro/con)
and users' stance while replying to others' posts (as in favor/oppose). As we
find limitations with supervised approaches, we propose a weakly-supervised
approach to predict the stance in Twitter replies. Our novel method allows
using a smaller number of hashtags to generate weak labels for Twitter replies.
Compared to supervised learning, our method improves the mean F1-macro by 8\%
on the hand-labeled dataset without using any hand-labeled examples in the
training set. We further show the applicability of our proposed method on COVID
19 related conversations on Twitter."	ArXiv
2051	"Effectiveness of Deep Networks in NLP using BiDAF as an example
  architecture"	['Soumyendu Sarkar']	2021-08-31 20:50:18+00:00	http://arxiv.org/abs/2109.00074v1	"Question Answering with NLP has progressed through the evolution of advanced
model architectures like BERT and BiDAF and earlier word, character, and
context-based embeddings. As BERT has leapfrogged the accuracy of models, an
element of the next frontier can be the introduction of deep networks and an
effective way to train them. In this context, I explored the effectiveness of
deep networks focussing on the model encoder layer of BiDAF. BiDAF with its
heterogeneous layers provides the opportunity not only to explore the
effectiveness of deep networks but also to evaluate whether the refinements
made in lower layers are additive to the refinements made in the upper layers
of the model architecture. I believe the next greatest model in NLP will in
fact fold in a solid language modeling like BERT with a composite architecture
which will bring in refinements in addition to generic language modeling and
will have a more extensive layered architecture. I experimented with the Bypass
network, Residual Highway network, and DenseNet architectures. In addition, I
evaluated the effectiveness of ensembling the last few layers of the network. I
also studied the difference character embeddings make in adding them to the
word embeddings, and whether the effects are additive with deep networks. My
studies indicate that deep networks are in fact effective in giving a boost.
Also, the refinements in the lower layers like embeddings are passed on
additively to the gains made through deep networks."	ArXiv
2052	Sequential Attention Module for Natural Language Processing	['Mengyuan Zhou', 'Jian Ma', 'Haiqin Yang', 'Lianxin Jiang', 'Yang Mo']	2021-09-07 11:48:23+00:00	http://arxiv.org/abs/2109.03009v1	"Recently, large pre-trained neural language models have attained remarkable
performance on many downstream natural language processing (NLP) applications
via fine-tuning. In this paper, we target at how to further improve the token
representations on the language models. We, therefore, propose a simple yet
effective plug-and-play module, Sequential Attention Module (SAM), on the token
embeddings learned from a pre-trained language model. Our proposed SAM consists
of two main attention modules deployed sequentially: Feature-wise Attention
Module (FAM) and Token-wise Attention Module (TAM). More specifically, FAM can
effectively identify the importance of features at each dimension and promote
the effect via dot-product on the original token embeddings for downstream NLP
applications. Meanwhile, TAM can further re-weight the features at the
token-wise level. Moreover, we propose an adaptive filter on FAM to prevent
noise impact and increase information absorption. Finally, we conduct extensive
experiments to demonstrate the advantages and properties of our proposed SAM.
We first show how SAM plays a primary role in the champion solution of two
subtasks of SemEval'21 Task 7. After that, we apply SAM on sentiment analysis
and three popular NLP tasks and demonstrate that SAM consistently outperforms
the state-of-the-art baselines."	ArXiv
2053	"Structure-Exploiting Newton-Type Method for Optimal Control of Switched
  Systems"	['Sotaro Katayama', 'Toshiyuki Ohtsuka']	2021-12-14 08:39:52+00:00	http://arxiv.org/abs/2112.07232v3	"This study proposes an efficient Newton-type method for the optimal control
of switched systems under a given mode sequence. A mesh-refinement-based
approach is utilized to discretize continuous-time optimal control problems
(OCPs) and formulate a nonlinear program (NLP), which guarantees the local
convergence of a Newton-type method. A dedicated structure-exploiting algorithm
(Riccati recursion) is proposed to perform a Newton-type method for the NLP
efficiently because its sparsity structure is different from a standard OCP.
The proposed method computes each Newton step with linear time-complexity for
the total number of discretization grids as the standard Riccati recursion
algorithm. Additionally, the computation is always successful if the solution
is sufficiently close to a local minimum. Conversely, general quadratic
programming (QP) solvers cannot accomplish this because the Hessian matrix is
inherently indefinite. Moreover, a modification on the reduced Hessian matrix
is proposed using the nature of the Riccati recursion algorithm as the dynamic
programming for a QP subproblem to enhance the convergence. A numerical
comparison is conducted with off-the-shelf NLP solvers, which demonstrates that
the proposed method is up to two orders of magnitude faster. Whole-body optimal
control of quadrupedal gaits is also demonstrated and shows that the proposed
method can achieve the whole-body model predictive control (MPC) of robotic
systems with rigid contacts."	ArXiv
2054	"AutoDistill: an End-to-End Framework to Explore and Distill
  Hardware-Efficient Language Models"	['Xiaofan Zhang', 'Zongwei Zhou', 'Deming Chen', 'Yu Emma Wang']	2022-01-21 04:32:19+00:00	http://arxiv.org/abs/2201.08539v1	"Recently, large pre-trained models have significantly improved the
performance of various Natural LanguageProcessing (NLP) tasks but they are
expensive to serve due to long serving latency and large memory usage. To
compress these models, knowledge distillation has attracted an increasing
amount of interest as one of the most effective methods for model compression.
However, existing distillation methods have not yet addressed the unique
challenges of model serving in datacenters, such as handling fast evolving
models, considering serving performance, and optimizing for multiple
objectives. To solve these problems, we propose AutoDistill, an end-to-end
model distillation framework integrating model architecture exploration and
multi-objective optimization for building hardware-efficient NLP pre-trained
models. We use Bayesian Optimization to conduct multi-objective Neural
Architecture Search for selecting student model architectures. The proposed
search comprehensively considers both prediction accuracy and serving latency
on target hardware. The experiments on TPUv4i show the finding of seven model
architectures with better pre-trained accuracy (up to 3.2% higher) and lower
inference latency (up to 1.44x faster) than MobileBERT. By running downstream
NLP tasks in the GLUE benchmark, the model distilled for pre-training by
AutoDistill with 28.5M parameters achieves an 81.69 average score, which is
higher than BERT_BASE, DistillBERT, TinyBERT, NAS-BERT, and MobileBERT. The
most compact model found by AutoDistill contains only 20.6M parameters but
still outperform BERT_BASE(109M), DistillBERT(67M), TinyBERT(67M), and
MobileBERT(25.3M) regarding the average GLUE score. By evaluating on SQuAD, a
model found by AutoDistill achieves an 88.4% F1 score with 22.8M parameters,
which reduces parameters by more than 62% while maintaining higher accuracy
than DistillBERT, TinyBERT, and NAS-BERT."	ArXiv
2055	Wide Attention Is The Way Forward For Transformers?	['Jason Ross Brown', 'Yiren Zhao', 'Ilia Shumailov', 'Robert D Mullins']	2022-10-02 21:49:54+00:00	http://arxiv.org/abs/2210.00640v2	"The Transformer is an extremely powerful and prominent deep learning
architecture. In this work, we challenge the commonly held belief in deep
learning that going deeper is better, and show an alternative design approach
that is building wider attention Transformers. We demonstrate that wide single
layer Transformer models can compete with or outperform deeper ones in a
variety of Natural Language Processing (NLP) tasks when both are trained from
scratch. The impact of changing the model aspect ratio on Transformers is then
studied systematically. This ratio balances the number of layers and the number
of attention heads per layer while keeping the total number of attention heads
and all other hyperparameters constant. On average, across 4 NLP tasks and 10
attention types, single layer wide models perform 0.3% better than their deep
counterparts. We show an in-depth evaluation and demonstrate how wide models
require a far smaller memory footprint and can run faster on commodity
hardware, in addition, these wider models are also more interpretable. For
example, a single layer Transformer on the IMDb byte level text classification
has 3.1x faster inference latency on a CPU than its equally accurate deeper
counterpart, and is half the size. We therefore put forward wider and shallower
models as a viable and desirable alternative for small models on NLP tasks, and
as an important area of research for domains beyond this."	ArXiv
2056	"Uncertainty Quantification with Pre-trained Language Models: A
  Large-Scale Empirical Analysis"	['Yuxin Xiao', 'Paul Pu Liang', 'Umang Bhatt', 'Willie Neiswanger', 'Ruslan Salakhutdinov', 'Louis-Philippe Morency']	2022-10-10 14:16:01+00:00	http://arxiv.org/abs/2210.04714v2	"Pre-trained language models (PLMs) have gained increasing popularity due to
their compelling prediction performance in diverse natural language processing
(NLP) tasks. When formulating a PLM-based prediction pipeline for NLP tasks, it
is also crucial for the pipeline to minimize the calibration error, especially
in safety-critical applications. That is, the pipeline should reliably indicate
when we can trust its predictions. In particular, there are various
considerations behind the pipeline: (1) the choice and (2) the size of PLM, (3)
the choice of uncertainty quantifier, (4) the choice of fine-tuning loss, and
many more. Although prior work has looked into some of these considerations,
they usually draw conclusions based on a limited scope of empirical studies.
There still lacks a holistic analysis on how to compose a well-calibrated
PLM-based prediction pipeline. To fill this void, we compare a wide range of
popular options for each consideration based on three prevalent NLP
classification tasks and the setting of domain shift. In response, we recommend
the following: (1) use ELECTRA for PLM encoding, (2) use larger PLMs if
possible, (3) use Temp Scaling as the uncertainty quantifier, and (4) use Focal
Loss for fine-tuning."	ArXiv
2057	A Kernel-Based View of Language Model Fine-Tuning	['Sadhika Malladi', 'Alexander Wettig', 'Dingli Yu', 'Danqi Chen', 'Sanjeev Arora']	2022-10-11 17:34:32+00:00	http://arxiv.org/abs/2210.05643v4	"It has become standard to solve NLP tasks by fine-tuning pre-trained language
models (LMs), especially in low-data settings. There is minimal theoretical
understanding of empirical success, e.g., why fine-tuning a model with $10^8$
or more parameters on a couple dozen training points does not result in
overfitting. We investigate whether the Neural Tangent Kernel (NTK) - which
originated as a model to study the gradient descent dynamics of infinitely wide
networks with suitable random initialization - describes fine-tuning of
pre-trained LMs. This study was inspired by the decent performance of NTK for
computer vision tasks (Wei et al., 2022). We extend the NTK formalism to Adam
and use Tensor Programs (Yang, 2020) to characterize conditions under which the
NTK lens may describe fine-tuning updates to pre-trained language models.
Extensive experiments on 14 NLP tasks validate our theory and show that
formulating the downstream task as a masked word prediction problem through
prompting often induces kernel-based dynamics during fine-tuning. Finally, we
use this kernel view to propose an explanation for the success of
parameter-efficient subspace-based fine-tuning methods."	ArXiv
2058	"Can Demographic Factors Improve Text Classification? Revisiting
  Demographic Adaptation in the Age of Transformers"	['Chia-Chien Hung', 'Anne Lauscher', 'Dirk Hovy', 'Simone Paolo Ponzetto', 'Goran Glavaš']	2022-10-13 21:16:27+00:00	http://arxiv.org/abs/2210.07362v2	"Demographic factors (e.g., gender or age) shape our language. Previous work
showed that incorporating demographic factors can consistently improve
performance for various NLP tasks with traditional NLP models. In this work, we
investigate whether these previous findings still hold with state-of-the-art
pretrained Transformer-based language models (PLMs). We use three common
specialization methods proven effective for incorporating external knowledge
into pretrained Transformers (e.g., domain-specific or geographic knowledge).
We adapt the language representations for the demographic dimensions of gender
and age, using continuous language modeling and dynamic multi-task learning for
adaptation, where we couple language modeling objectives with the prediction of
demographic classes. Our results, when employing a multilingual PLM, show
substantial gains in task performance across four languages (English, German,
French, and Danish), which is consistent with the results of previous work.
However, controlling for confounding factors - primarily domain and language
proficiency of Transformer-based PLMs - shows that downstream performance gains
from our demographic adaptation do not actually stem from demographic
knowledge. Our results indicate that demographic specialization of PLMs, while
holding promise for positive societal impact, still represents an unsolved
problem for (modern) NLP."	ArXiv
2059	Conversion of Legal Agreements into Smart Legal Contracts using NLP	['Eason Chen', 'Niall Roche', 'Yuen-Hsien Tseng', 'Walter Hernandez', 'Jiangbo Shangguan', 'Alastair Moore']	2022-08-27 06:54:58+00:00	http://arxiv.org/abs/2210.08954v2	"A Smart Legal Contract (SLC) is a specialized digital agreement comprising
natural language and computable components. The Accord Project provides an
open-source SLC framework containing three main modules: Cicero, Concerto, and
Ergo. Currently, we need lawyers, programmers, and clients to work together
with great effort to create a usable SLC using the Accord Project. This paper
proposes a pipeline to automate the SLC creation process with several Natural
Language Processing (NLP) models to convert law contracts to the Accord
Project's Concerto model. After evaluating the proposed pipeline, we discovered
that our NER pipeline accurately detects CiceroMark from Accord Project
template text with an accuracy of 0.8. Additionally, our Question Answering
method can extract one-third of the Concerto variables from the template text.
We also delve into some limitations and possible future research for the
proposed pipeline. Finally, we describe a web interface enabling users to build
SLCs. This interface leverages the proposed pipeline to convert text documents
to Smart Legal Contracts by using NLP models."	ArXiv
2060	Fine-mixing: Mitigating Backdoors in Fine-tuned Language Models	['Zhiyuan Zhang', 'Lingjuan Lyu', 'Xingjun Ma', 'Chenguang Wang', 'Xu Sun']	2022-10-18 02:44:38+00:00	http://arxiv.org/abs/2210.09545v1	"Deep Neural Networks (DNNs) are known to be vulnerable to backdoor attacks.
In Natural Language Processing (NLP), DNNs are often backdoored during the
fine-tuning process of a large-scale Pre-trained Language Model (PLM) with
poisoned samples. Although the clean weights of PLMs are readily available,
existing methods have ignored this information in defending NLP models against
backdoor attacks. In this work, we take the first step to exploit the
pre-trained (unfine-tuned) weights to mitigate backdoors in fine-tuned language
models. Specifically, we leverage the clean pre-trained weights via two
complementary techniques: (1) a two-step Fine-mixing technique, which first
mixes the backdoored weights (fine-tuned on poisoned data) with the pre-trained
weights, then fine-tunes the mixed weights on a small subset of clean data; (2)
an Embedding Purification (E-PUR) technique, which mitigates potential
backdoors existing in the word embeddings. We compare Fine-mixing with typical
backdoor mitigation methods on three single-sentence sentiment classification
tasks and two sentence-pair classification tasks and show that it outperforms
the baselines by a considerable margin in all scenarios. We also show that our
E-PUR method can benefit existing mitigation methods. Our work establishes a
simple but strong baseline defense for secure fine-tuned NLP models against
backdoor attacks."	ArXiv
2061	"Real-Time Trajectory Planning for AGV in the Presence of Moving
  Obstacles: A First-Search-Then-Optimization Approach"	['Bai Li', 'Youmin Zhang', 'Yakun Ouyang', 'Yi Liu', 'Xiang Zhong', 'Hangjie Cen', 'Qi Kong']	2019-02-17 04:19:00+00:00	http://arxiv.org/abs/1902.06201v6	"This paper focuses on automatic guided vehicle (AGV) trajectory planning in
the presence of moving obstacles with known but complicated trajectories. In
order to achieve good solution precision, optimality and unification, the
concerned task should be formulated as an optimal control problem, and then
discretized into a nonlinear programming (NLP) problem, which is numerically
optimized thereafter. Without a near-feasible or near-optimal initial guess,
the NLP-solving process is usually slow. With the purpose of accelerating the
NLP solution, a search-based rough planning stage is added to generate
appropriate initial guesses. Concretely, a continuous state space is
formulated, which consists of Cartesian product of 2D configuration space and a
time dimension. The rough trajectory is generated by a graph-search based
planner, namely the A* algorithm. Herein, the nodes in the graph are
constructed by discretizing the aforementioned continuous spatio-temporal
space. Through this first-search-then-optimization framework, optimal solutions
to unified trajectory planning problems can be obtained fast. Simulations have
been conducted to verify the real-time performance of our proposal."	ArXiv
2062	"Developing and Using Special-Purpose Lexicons for Cohort Selection from
  Clinical Notes"	['Samarth Rawal', 'Ashok Prakash', 'Soumya Adhya', 'Sidharth Kulkarni', 'Saadat Anwar', 'Chitta Baral', 'Murthy Devarakonda']	2019-02-26 00:45:56+00:00	http://arxiv.org/abs/1902.09674v1	"Background and Significance: Selecting cohorts for a clinical trial typically
requires costly and time-consuming manual chart reviews resulting in poor
participation. To help automate the process, National NLP Clinical Challenges
(N2C2) conducted a shared challenge by defining 13 criteria for clinical trial
cohort selection and by providing training and test datasets. This research was
motivated by the N2C2 challenge.
  Methods: We broke down the task into 13 independent subtasks corresponding to
each criterion and implemented subtasks using rules or a supervised machine
learning model. Each task critically depended on knowledge resources in the
form of task-specific lexicons, for which we developed a novel model-driven
approach. The approach allowed us to first expand the lexicon from a seed set
and then remove noise from the list, thus improving the accuracy.
  Results: Our system achieved an overall F measure of 0.9003 at the challenge,
and was statistically tied for the first place out of 45 participants. The
model-driven lexicon development and further debugging the rules/code on the
training set improved overall F measure to 0.9140, overtaking the best
numerical result at the challenge.
  Discussion: Cohort selection, like phenotype extraction and classification,
is amenable to rule-based or simple machine learning methods, however, the
lexicons involved, such as medication names or medical terms referring to a
medical problem, critically determine the overall accuracy. Automated lexicon
development has the potential for scalability and accuracy."	ArXiv
2063	Tackling Graphical NLP problems with Graph Recurrent Networks	['Linfeng Song']	2019-07-13 22:48:31+00:00	http://arxiv.org/abs/1907.06142v1	"How to properly model graphs is a long-existing and important problem in NLP
area, where several popular types of graphs are knowledge graphs, semantic
graphs and dependency graphs. Comparing with other data structures, such as
sequences and trees, graphs are generally more powerful in representing complex
correlations among entities. For example, a knowledge graph stores real-word
entities (such as ""Barack_Obama"" and ""U.S."") and their relations (such as
""live_in"" and ""lead_by""). Properly encoding a knowledge graph is beneficial to
user applications, such as question answering and knowledge discovery. Modeling
graphs is also very challenging, probably because graphs usually contain
massive and cyclic relations.
  Recent years have witnessed the success of deep learning, especially
RNN-based models, on many NLP problems. Besides, RNNs and their variations have
been extensively studied on several graph problems and showed preliminary
successes. Despite the successes that have been achieved, RNN-based models
suffer from several major drawbacks on graphs. First, they can only consume
sequential data, thus linearization is required to serialize input graphs,
resulting in the loss of important structural information. Second, the
serialization results are usually very long, so it takes a long time for RNNs
to encode them.
  In this thesis, we propose a novel graph neural network, named graph
recurrent network (GRN). We study our GRN model on 4 very different tasks, such
as machine reading comprehension, relation extraction and machine translation.
Some take undirected graphs without edge labels, while the others have directed
ones with edge labels. To consider these important differences, we gradually
enhance our GRN model, such as further considering edge labels and adding an
RNN decoder. Carefully designed experiments show the effectiveness of GRN on
all these tasks."	ArXiv
2064	"Exploring Benefits of Linear Solver Parallelism on Modern Nonlinear
  Optimization Applications"	['Byron Tasseff', 'Carleton Coffrin', 'Andreas Wächter', 'Carl Laird']	2019-09-17 21:13:31+00:00	http://arxiv.org/abs/1909.08104v1	"The advent of efficient interior point optimization methods has enabled the
tractable solution of large-scale linear and nonlinear programming (NLP)
problems. A prominent example of such a method is seen in Ipopt, a widely-used,
open-source nonlinear optimization solver. Algorithmically, Ipopt depends on
the use of a sparse symmetric indefinite linear system solver, which is heavily
employed within the optimization of barrier subproblems. As such, the
performance and reliability of Ipopt is dependent on the properties of the
selected linear solver. Inspired by a trend in mathematical programming toward
solving larger and more challenging NLPs, this work explores two core
questions: first, how does the scalability of available linear solvers, many of
which exhibit shared-memory parallelism, impact Ipopt performance; and second,
does the best linear solver vary across NLP problem classes, including
nonlinear network problems and problems constrained by partial differential
equations? To better understand these properties, this paper first describes
available open- and closed-source, serial and parallel linear solvers and the
fundamental differences among them. Second, it introduces the coupling of a new
open-source linear solver capable of heterogeneous parallelism over multi-core
central processing units and graphics processing units. Third, it compares
linear solvers using a variety of mathematical programming problems, including
standard test problems for linear and nonlinear optimization, optimal power
flow benchmarks, and scalable two- and three-dimensional partial differential
equation and optimal control problems. Finally, linear solver recommendations
are provided to maximize Ipopt performance across different application
domains."	ArXiv
2065	"Exploring the Limits of Transfer Learning with a Unified Text-to-Text
  Transformer"	['Colin Raffel', 'Noam Shazeer', 'Adam Roberts', 'Katherine Lee', 'Sharan Narang', 'Michael Matena', 'Yanqi Zhou', 'Wei Li', 'Peter J. Liu']	2019-10-23 17:37:36+00:00	http://arxiv.org/abs/1910.10683v4	"Transfer learning, where a model is first pre-trained on a data-rich task
before being fine-tuned on a downstream task, has emerged as a powerful
technique in natural language processing (NLP). The effectiveness of transfer
learning has given rise to a diversity of approaches, methodology, and
practice. In this paper, we explore the landscape of transfer learning
techniques for NLP by introducing a unified framework that converts all
text-based language problems into a text-to-text format. Our systematic study
compares pre-training objectives, architectures, unlabeled data sets, transfer
approaches, and other factors on dozens of language understanding tasks. By
combining the insights from our exploration with scale and our new ``Colossal
Clean Crawled Corpus'', we achieve state-of-the-art results on many benchmarks
covering summarization, question answering, text classification, and more. To
facilitate future work on transfer learning for NLP, we release our data set,
pre-trained models, and code."	ArXiv
2066	"Active$^2$ Learning: Actively reducing redundancies in Active Learning
  methods for Sequence Tagging and Machine Translation"	['Rishi Hazra', 'Parag Dutta', 'Shubham Gupta', 'Mohammed Abdul Qaathir', 'Ambedkar Dukkipati']	2019-11-01 07:31:02+00:00	http://arxiv.org/abs/1911.00234v4	"While deep learning is a powerful tool for natural language processing (NLP)
problems, successful solutions to these problems rely heavily on large amounts
of annotated samples. However, manually annotating data is expensive and
time-consuming. Active Learning (AL) strategies reduce the need for huge
volumes of labeled data by iteratively selecting a small number of examples for
manual annotation based on their estimated utility in training the given model.
In this paper, we argue that since AL strategies choose examples independently,
they may potentially select similar examples, all of which may not contribute
significantly to the learning process. Our proposed approach,
Active$\mathbf{^2}$ Learning (A$\mathbf{^2}$L), actively adapts to the deep
learning model being trained to eliminate such redundant examples chosen by an
AL strategy. We show that A$\mathbf{^2}$L is widely applicable by using it in
conjunction with several different AL strategies and NLP tasks. We empirically
demonstrate that the proposed approach is further able to reduce the data
requirements of state-of-the-art AL strategies by $\approx \mathbf{3-25\%}$ on
an absolute scale on multiple NLP tasks while achieving the same performance
with virtually no additional computation overhead."	ArXiv
2067	"Word Embedding Algorithms as Generalized Low Rank Models and their
  Canonical Form"	['Kian Kenyon-Dean']	2019-11-06 21:40:34+00:00	http://arxiv.org/abs/1911.02639v1	"Word embedding algorithms produce very reliable feature representations of
words that are used by neural network models across a constantly growing
multitude of NLP tasks. As such, it is imperative for NLP practitioners to
understand how their word representations are produced, and why they are so
impactful.
  The present work presents the Simple Embedder framework, generalizing the
state-of-the-art existing word embedding algorithms (including Word2vec (SGNS)
and GloVe) under the umbrella of generalized low rank models. We derive that
both of these algorithms attempt to produce embedding inner products that
approximate pointwise mutual information (PMI) statistics in the corpus. Once
cast as Simple Embedders, comparison of these models reveals that these
successful embedders all resemble a straightforward maximum likelihood estimate
(MLE) of the PMI parametrized by the inner product (between embeddings). This
MLE induces our proposed novel word embedding model, Hilbert-MLE, as the
canonical representative of the Simple Embedder framework.
  We empirically compare these algorithms with evaluations on 17 different
datasets. Hilbert-MLE consistently observes second-best performance on every
extrinsic evaluation (news classification, sentiment analysis, POS-tagging, and
supersense tagging), while the first-best model depends varying on the task.
Moreover, Hilbert-MLE consistently observes the least variance in results with
respect to the random initialization of the weights in bidirectional LSTMs. Our
empirical results demonstrate that Hilbert-MLE is a very consistent word
embedding algorithm that can be reliably integrated into existing NLP systems
to obtain high-quality results."	ArXiv
2068	Word Embedding based New Corpus for Low-resourced Language: Sindhi	['Wazir Ali', 'Jay Kumar', 'Junyu Lu', 'Zenglin Xu']	2019-11-28 08:11:44+00:00	http://arxiv.org/abs/1911.12579v3	"Representing words and phrases into dense vectors of real numbers which
encode semantic and syntactic properties is a vital constituent in natural
language processing (NLP). The success of neural network (NN) models in NLP
largely rely on such dense word representations learned on the large unlabeled
corpus. Sindhi is one of the rich morphological language, spoken by large
population in Pakistan and India lacks corpora which plays an essential role of
a test-bed for generating word embeddings and developing language independent
NLP systems. In this paper, a large corpus of more than 61 million words is
developed for low-resourced Sindhi language for training neural word
embeddings. The corpus is acquired from multiple web-resources using
web-scrappy. Due to the unavailability of open source preprocessing tools for
Sindhi, the prepossessing of such large corpus becomes a challenging problem
specially cleaning of noisy data extracted from web resources. Therefore, a
preprocessing pipeline is employed for the filtration of noisy text.
Afterwards, the cleaned vocabulary is utilized for training Sindhi word
embeddings with state-of-the-art GloVe, Skip-Gram (SG), and Continuous Bag of
Words (CBoW) word2vec algorithms. The intrinsic evaluation approach of cosine
similarity matrix and WordSim-353 are employed for the evaluation of generated
Sindhi word embeddings. Moreover, we compare the proposed word embeddings with
recently revealed Sindhi fastText (SdfastText) word representations. Our
intrinsic evaluation results demonstrate the high quality of our generated
Sindhi word embeddings using SG, CBoW, and GloVe as compare to SdfastText word
representations."	ArXiv
2069	"The Utility of General Domain Transfer Learning for Medical Language
  Tasks"	['Daniel Ranti', 'Katie Hanss', 'Shan Zhao', 'Varun Arvind', 'Joseph Titano', 'Anthony Costa', 'Eric Oermann']	2020-02-16 20:20:38+00:00	http://arxiv.org/abs/2002.06670v1	"The purpose of this study is to analyze the efficacy of transfer learning
techniques and transformer-based models as applied to medical natural language
processing (NLP) tasks, specifically radiological text classification. We used
1,977 labeled head CT reports, from a corpus of 96,303 total reports, to
evaluate the efficacy of pretraining using general domain corpora and a
combined general and medical domain corpus with a bidirectional representations
from transformers (BERT) model for the purpose of radiological text
classification. Model performance was benchmarked to a logistic regression
using bag-of-words vectorization and a long short-term memory (LSTM)
multi-label multi-class classification model, and compared to the published
literature in medical text classification. The BERT models using either set of
pretrained checkpoints outperformed the logistic regression model, achieving
sample-weighted average F1-scores of 0.87 and 0.87 for the general domain model
and the combined general and biomedical-domain model. General text transfer
learning may be a viable technique to generate state-of-the-art results within
medical NLP tasks on radiological corpora, outperforming other deep models such
as LSTMs. The efficacy of pretraining and transformer-based models could serve
to facilitate the creation of groundbreaking NLP models in the uniquely
challenging data environment of medical text."	ArXiv
2070	"An Efficient MPC Algorithm For Switched Systems with Minimum Dwell Time
  Constraints"	['Yutao Chen', 'Mircea Lazar']	2020-02-22 08:04:40+00:00	http://arxiv.org/abs/2002.09658v3	"This paper presents an efficient suboptimal model predictive control (MPC)
algorithm for nonlinear switched systems subject to minimum dwell time
constraints (MTC). While MTC are required for most physical systems due to
stability, power and mechanical restrictions, MPC optimization problems with
MTC are challenging to solve. To efficiently solve such problems, the on-line
MPC optimization problem is decomposed into a sequence of simpler problems,
which include two nonlinear programs (NLP) and a rounding step, as typically
done in mixed-integer optimal control (MIOC). Unlike the classical approach
that embeds MTC in a mixed-integer linear program (MILP) with combinatorial
constraints in the rounding step, our proposal is to embed the MTC in one of
the NLPs using move blocking. Such a formulation can speedup on-line
computations by employing recent move blocking algorithms for NLP problems and
by using a simple sum-up-rounding (SUR) method for the rounding step. An
explicit upper bound of the integer approximation error for the rounding step
is given. In addition, a combined shrinking and receding horizon strategy is
developed to satisfy closed-loop MTC. Recursive feasibility is proven using a
$l$-step control invariant ($l$-CI) set, where $l$ is the minimum dwell time
step length. An algorithm to compute $l$-CI sets for switched linear systems
off-line is also presented. Numerical studies show significant speed-up and
comparable control performance of the proposed MPC algorithm against the
classical approach, though at the cost of sub-optimal solutions."	ArXiv
2071	Lite Transformer with Long-Short Range Attention	['Zhanghao Wu', 'Zhijian Liu', 'Ji Lin', 'Yujun Lin', 'Song Han']	2020-04-24 17:52:25+00:00	http://arxiv.org/abs/2004.11886v1	"Transformer has become ubiquitous in natural language processing (e.g.,
machine translation, question answering); however, it requires enormous amount
of computations to achieve high performance, which makes it not suitable for
mobile applications that are tightly constrained by the hardware resources and
battery. In this paper, we present an efficient mobile NLP architecture, Lite
Transformer to facilitate deploying mobile NLP applications on edge devices.
The key primitive is the Long-Short Range Attention (LSRA), where one group of
heads specializes in the local context modeling (by convolution) while another
group specializes in the long-distance relationship modeling (by attention).
Such specialization brings consistent improvement over the vanilla transformer
on three well-established language tasks: machine translation, abstractive
summarization, and language modeling. Under constrained resources (500M/100M
MACs), Lite Transformer outperforms transformer on WMT'14 English-French by
1.2/1.7 BLEU, respectively. Lite Transformer reduces the computation of
transformer base model by 2.5x with 0.3 BLEU score degradation. Combining with
pruning and quantization, we further compressed the model size of Lite
Transformer by 18.2x. For language modeling, Lite Transformer achieves 1.8
lower perplexity than the transformer at around 500M MACs. Notably, Lite
Transformer outperforms the AutoML-based Evolved Transformer by 0.5 higher BLEU
for the mobile NLP setting without the costly architecture search that requires
more than 250 GPU years. Code has been made available at
https://github.com/mit-han-lab/lite-transformer."	ArXiv
2072	"BadNL: Backdoor Attacks against NLP Models with Semantic-preserving
  Improvements"	['Xiaoyi Chen', 'Ahmed Salem', 'Dingfan Chen', 'Michael Backes', 'Shiqing Ma', 'Qingni Shen', 'Zhonghai Wu', 'Yang Zhang']	2020-06-01 16:17:14+00:00	http://arxiv.org/abs/2006.01043v2	"Deep neural networks (DNNs) have progressed rapidly during the past decade
and have been deployed in various real-world applications. Meanwhile, DNN
models have been shown to be vulnerable to security and privacy attacks. One
such attack that has attracted a great deal of attention recently is the
backdoor attack. Specifically, the adversary poisons the target model's
training set to mislead any input with an added secret trigger to a target
class.
  Previous backdoor attacks predominantly focus on computer vision (CV)
applications, such as image classification. In this paper, we perform a
systematic investigation of backdoor attack on NLP models, and propose BadNL, a
general NLP backdoor attack framework including novel attack methods.
Specifically, we propose three methods to construct triggers, namely BadChar,
BadWord, and BadSentence, including basic and semantic-preserving variants. Our
attacks achieve an almost perfect attack success rate with a negligible effect
on the original model's utility. For instance, using the BadChar, our backdoor
attack achieves a 98.9% attack success rate with yielding a utility improvement
of 1.5% on the SST-5 dataset when only poisoning 3% of the original set.
Moreover, we conduct a user study to prove that our triggers can well preserve
the semantics from humans perspective."	ArXiv
2073	"A Thousand Words are Worth More Than One Recording: NLP Based Speaker
  Change Point Detection"	['O. H. Anidjar', 'C. Hajaj', 'A. Dvir', 'I. Gilad']	2020-05-18 17:47:01+00:00	http://arxiv.org/abs/2006.01206v1	"Speaker Diarization (SD) consists of splitting or segmenting an input audio
burst according to speaker identities. In this paper, we focus on the crucial
task of the SD problem which is the audio segmenting process and suggest a
solution for the Change Point Detection (CPD) problem. We empirically
demonstrate the negative correlation between an increase in the number of
speakers and the Recall and F1-Score measurements. This negative correlation is
shown to be the outcome of a massive experimental evaluation process, which
accounts its superiority to recently developed voice based solutions. In order
to overcome the number of speakers issue, we suggest a robust solution based on
a novel Natural Language Processing (NLP) technique, as well as a metadata
features extraction process, rather than a vocal based alone. To the best of
our knowledge, we are the first to propose an intelligent NLP based solution
that (I) tackles the CPD problem with a dataset in Hebrew, and (II) solves the
CPD variant of the SD problem. We empirically show, based on two distinct
datasets, that our method is abled to accurately identify the CPDs in an audio
burst with 82.12% and 89.02% of success in the Recall and F1-score
measurements."	ArXiv
2074	"Cluster-Based Information Retrieval by using (K-means)- Hierarchical
  Parallel Genetic Algorithms Approach"	['Sarah Hussein Toman', 'Mohammed Hamzah Abed', 'Zinah Hussein Toman']	2020-08-01 02:05:58+00:00	http://arxiv.org/abs/2008.00150v1	"Cluster-based information retrieval is one of the Information retrieval(IR)
tools that organize, extract features and categorize the web documents
according to their similarity. Unlike traditional approaches, cluster-based IR
is fast in processing large datasets of document. To improve the quality of
retrieved documents, increase the efficiency of IR and reduce irrelevant
documents from user search. in this paper, we proposed a (K-means) -
Hierarchical Parallel Genetic Algorithms Approach (HPGA) that combines the
K-means clustering algorithm with hybrid PG of multi-deme and master/slave PG
algorithms. K-means uses to cluster the population to k subpopulations then
take most clusters relevant to the query to manipulate in a parallel way by the
two levels of genetic parallelism, thus, irrelevant documents will not be
included in subpopulations, as a way to improve the quality of results. Three
common datasets (NLP, CISI, and CACM) are used to compute the recall,
precision, and F-measure averages. Finally, we compared the precision values of
three datasets with Genetic-IR and classic-IR. The proposed approach precision
improvements with IR-GA were 45% in the CACM, 27% in the CISI, and 25% in the
NLP. While, by comparing with Classic-IR, (k-means)-HPGA got 47% in CACM, 28%
in CISI, and 34% in NLP."	ArXiv
2075	"Multi-Perspective Semantic Information Retrieval in the Biomedical
  Domain"	['Samarth Rawal']	2020-07-17 21:05:44+00:00	http://arxiv.org/abs/2008.01526v1	"Information Retrieval (IR) is the task of obtaining pieces of data (such as
documents) that are relevant to a particular query or need from a large
repository of information. IR is a valuable component of several downstream
Natural Language Processing (NLP) tasks. Practically, IR is at the heart of
many widely-used technologies like search engines. While probabilistic ranking
functions like the Okapi BM25 function have been utilized in IR systems since
the 1970's, modern neural approaches pose certain advantages compared to their
classical counterparts. In particular, the release of BERT (Bidirectional
Encoder Representations from Transformers) has had a significant impact in the
NLP community by demonstrating how the use of a Masked Language Model trained
on a large corpus of data can improve a variety of downstream NLP tasks,
including sentence classification and passage re-ranking. IR Systems are also
important in the biomedical and clinical domains. Given the increasing amount
of scientific literature across biomedical domain, the ability find answers to
specific clinical queries from a repository of millions of articles is a matter
of practical value to medical professionals. Moreover, there are
domain-specific challenges present, including handling clinical jargon and
evaluating the similarity or relatedness of various medical symptoms when
determining the relevance between a query and a sentence. This work presents
contributions to several aspects of the Biomedical Semantic Information
Retrieval domain. First, it introduces Multi-Perspective Sentence Relevance, a
novel methodology of utilizing BERT-based models for contextual IR. The system
is evaluated using the BioASQ Biomedical IR Challenge. Finally, practical
contributions in the form of a live IR system for medics and a proposed
challenge on the Living Systematic Review clinical task are provided."	ArXiv
2076	Compression of Deep Learning Models for Text: A Survey	['Manish Gupta', 'Puneet Agrawal']	2020-08-12 10:42:14+00:00	http://arxiv.org/abs/2008.05221v4	"In recent years, the fields of natural language processing (NLP) and
information retrieval (IR) have made tremendous progress thanksto deep learning
models like Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs) and
Long Short-Term Memory (LSTMs)networks, and Transformer [120] based models like
Bidirectional Encoder Representations from Transformers (BERT) [24],
GenerativePre-training Transformer (GPT-2) [94], Multi-task Deep Neural Network
(MT-DNN) [73], Extra-Long Network (XLNet) [134], Text-to-text transfer
transformer (T5) [95], T-NLG [98] and GShard [63]. But these models are
humongous in size. On the other hand,real world applications demand small model
size, low response times and low computational power wattage. In this survey,
wediscuss six different types of methods (Pruning, Quantization, Knowledge
Distillation, Parameter Sharing, Tensor Decomposition, andSub-quadratic
Transformer based methods) for compression of such models to enable their
deployment in real industry NLP projects.Given the critical need of building
applications with efficient and small models, and the large amount of recently
published work inthis area, we believe that this survey organizes the plethora
of work done by the 'deep learning for NLP' community in the past fewyears and
presents it as a coherent story."	ArXiv
2077	"Text Classification based on Multi-granularity Attention Hybrid Neural
  Network"	['Zhenyu Liu', 'Chaohong Lu', 'Haiwei Huang', 'Shengfei Lyu', 'Zhenchao Tao']	2020-08-12 13:02:48+00:00	http://arxiv.org/abs/2008.05282v1	"Neural network-based approaches have become the driven forces for Natural
Language Processing (NLP) tasks. Conventionally, there are two mainstream
neural architectures for NLP tasks: the recurrent neural network (RNN) and the
convolution neural network (ConvNet). RNNs are good at modeling long-term
dependencies over input texts, but preclude parallel computation. ConvNets do
not have memory capability and it has to model sequential data as un-ordered
features. Therefore, ConvNets fail to learn sequential dependencies over the
input texts, but it is able to carry out high-efficient parallel computation.
As each neural architecture, such as RNN and ConvNets, has its own pro and con,
integration of different architectures is assumed to be able to enrich the
semantic representation of texts, thus enhance the performance of NLP tasks.
However, few investigation explores the reconciliation of these seemingly
incompatible architectures. To address this issue, we propose a hybrid
architecture based on a novel hierarchical multi-granularity attention
mechanism, named Multi-granularity Attention-based Hybrid Neural Network
(MahNN). The attention mechanism is to assign different weights to different
parts of the input sequence to increase the computation efficiency and
performance of neural models. In MahNN, two types of attentions are introduced:
the syntactical attention and the semantical attention. The syntactical
attention computes the importance of the syntactic elements (such as words or
sentence) at the lower symbolic level and the semantical attention is used to
compute the importance of the embedded space dimension corresponding to the
upper latent semantics. We adopt the text classification as an exemplifying way
to illustrate the ability of MahNN to understand texts."	ArXiv
2078	"A Survey of Active Learning for Text Classification using Deep Neural
  Networks"	['Christopher Schröder', 'Andreas Niekler']	2020-08-17 12:53:20+00:00	http://arxiv.org/abs/2008.07267v1	"Natural language processing (NLP) and neural networks (NNs) have both
undergone significant changes in recent years. For active learning (AL)
purposes, NNs are, however, less commonly used -- despite their current
popularity. By using the superior text classification performance of NNs for
AL, we can either increase a model's performance using the same amount of data
or reduce the data and therefore the required annotation efforts while keeping
the same performance. We review AL for text classification using deep neural
networks (DNNs) and elaborate on two main causes which used to hinder the
adoption: (a) the inability of NNs to provide reliable uncertainty estimates,
on which the most commonly used query strategies rely, and (b) the challenge of
training DNNs on small data. To investigate the former, we construct a taxonomy
of query strategies, which distinguishes between data-based, model-based, and
prediction-based instance selection, and investigate the prevalence of these
classes in recent research. Moreover, we review recent NN-based advances in NLP
like word embeddings or language models in the context of (D)NNs, survey the
current state-of-the-art at the intersection of AL, text classification, and
DNNs and relate recent advances in NLP to AL. Finally, we analyze recent work
in AL for text classification, connect the respective query strategies to the
taxonomy, and outline commonalities and shortcomings. As a result, we highlight
gaps in current research and present open research questions."	ArXiv
2079	"Sentence, Phrase, and Triple Annotations to Build a Knowledge Graph of
  Natural Language Processing Contributions -- A Trial Dataset"	"[""Jennifer D'Souza"", 'Sören Auer']"	2020-10-09 06:45:35+00:00	http://arxiv.org/abs/2010.04388v3	"Purpose: The aim of this work is to normalize the NLPCONTRIBUTIONS scheme
(henceforward, NLPCONTRIBUTIONGRAPH) to structure, directly from article
sentences, the contributions information in Natural Language Processing (NLP)
scholarly articles via a two-stage annotation methodology: 1) pilot stage - to
define the scheme (described in prior work); and 2) adjudication stage - to
normalize the graphing model (the focus of this paper).
  Design/methodology/approach: We re-annotate, a second time, the
contributions-pertinent information across 50 prior-annotated NLP scholarly
articles in terms of a data pipeline comprising: contribution-centered
sentences, phrases, and triple statements. To this end, specifically, care was
taken in the adjudication annotation stage to reduce annotation noise while
formulating the guidelines for our proposed novel NLP contributions structuring
and graphing scheme.
  Findings: The application of NLPCONTRIBUTIONGRAPH on the 50 articles resulted
finally in a dataset of 900 contribution-focused sentences, 4,702
contribution-information-centered phrases, and 2,980 surface-structured
triples. The intra-annotation agreement between the first and second stages, in
terms of F1, was 67.92% for sentences, 41.82% for phrases, and 22.31% for
triple statements indicating that with increased granularity of the
information, the annotation decision variance is greater.
  Practical Implications: We demonstrate NLPCONTRIBUTIONGRAPH data integrated
into the Open Research Knowledge Graph (ORKG), a next-generation KG-based
digital library with intelligent computations enabled over structured scholarly
knowledge, as a viable aid to assist researchers in their day-to-day tasks."	ArXiv
2080	"BERT-EMD: Many-to-Many Layer Mapping for BERT Compression with Earth
  Mover's Distance"	['Jianquan Li', 'Xiaokang Liu', 'Honghong Zhao', 'Ruifeng Xu', 'Min Yang', 'Yaohong Jin']	2020-10-13 02:53:52+00:00	http://arxiv.org/abs/2010.06133v1	"Pre-trained language models (e.g., BERT) have achieved significant success in
various natural language processing (NLP) tasks. However, high storage and
computational costs obstruct pre-trained language models to be effectively
deployed on resource-constrained devices. In this paper, we propose a novel
BERT distillation method based on many-to-many layer mapping, which allows each
intermediate student layer to learn from any intermediate teacher layers. In
this way, our model can learn from different teacher layers adaptively for
various NLP tasks. %motivated by the intuition that different NLP tasks require
different levels of linguistic knowledge contained in the intermediate layers
of BERT. In addition, we leverage Earth Mover's Distance (EMD) to compute the
minimum cumulative cost that must be paid to transform knowledge from teacher
network to student network. EMD enables the effective matching for many-to-many
layer mapping. %EMD can be applied to network layers with different sizes and
effectively measures semantic distance between the teacher network and student
network. Furthermore, we propose a cost attention mechanism to learn the layer
weights used in EMD automatically, which is supposed to further improve the
model's performance and accelerate convergence time. Extensive experiments on
GLUE benchmark demonstrate that our model achieves competitive performance
compared to strong competitors in terms of both accuracy and model compression."	ArXiv
2081	"Vector-Vector-Matrix Architecture: A Novel Hardware-Aware Framework for
  Low-Latency Inference in NLP Applications"	['Matthew Khoury', 'Rumen Dangovski', 'Longwu Ou', 'Preslav Nakov', 'Yichen Shen', 'Li Jing']	2020-10-06 16:54:08+00:00	http://arxiv.org/abs/2010.08412v1	"Deep neural networks have become the standard approach to building reliable
Natural Language Processing (NLP) applications, ranging from Neural Machine
Translation (NMT) to dialogue systems. However, improving accuracy by
increasing the model size requires a large number of hardware computations,
which can slow down NLP applications significantly at inference time. To
address this issue, we propose a novel vector-vector-matrix architecture
(VVMA), which greatly reduces the latency at inference time for NMT. This
architecture takes advantage of specialized hardware that has low-latency
vector-vector operations and higher-latency vector-matrix operations. It also
reduces the number of parameters and FLOPs for virtually all models that rely
on efficient matrix multipliers without significantly impacting accuracy. We
present empirical results suggesting that our framework can reduce the latency
of sequence-to-sequence and Transformer models used for NMT by a factor of
four. Finally, we show evidence suggesting that our VVMA extends to other
domains, and we discuss novel hardware for its efficient use."	ArXiv
2082	VisBERT: Hidden-State Visualizations for Transformers	['Betty van Aken', 'Benjamin Winter', 'Alexander Löser', 'Felix A. Gers']	2020-11-09 15:37:43+00:00	http://arxiv.org/abs/2011.04507v1	"Explainability and interpretability are two important concepts, the absence
of which can and should impede the application of well-performing neural
networks to real-world problems. At the same time, they are difficult to
incorporate into the large, black-box models that achieve state-of-the-art
results in a multitude of NLP tasks. Bidirectional Encoder Representations from
Transformers (BERT) is one such black-box model. It has become a staple
architecture to solve many different NLP tasks and has inspired a number of
related Transformer models. Understanding how these models draw conclusions is
crucial for both their improvement and application. We contribute to this
challenge by presenting VisBERT, a tool for visualizing the contextual token
representations within BERT for the task of (multi-hop) Question Answering.
Instead of analyzing attention weights, we focus on the hidden states resulting
from each encoder block within the BERT model. This way we can observe how the
semantic representations are transformed throughout the layers of the model.
VisBERT enables users to get insights about the model's internal state and to
explore its inference steps or potential shortcomings. The tool allows us to
identify distinct phases in BERT's transformations that are similar to a
traditional NLP pipeline and offer insights during failed predictions."	ArXiv
2083	"Improving Clinical Document Understanding on COVID-19 Research with
  Spark NLP"	['Veysel Kocaman', 'David Talby']	2020-12-07 19:17:05+00:00	http://arxiv.org/abs/2012.04005v1	"Following the global COVID-19 pandemic, the number of scientific papers
studying the virus has grown massively, leading to increased interest in
automated literate review. We present a clinical text mining system that
improves on previous efforts in three ways. First, it can recognize over 100
different entity types including social determinants of health, anatomy, risk
factors, and adverse events in addition to other commonly used clinical and
biomedical entities. Second, the text processing pipeline includes assertion
status detection, to distinguish between clinical facts that are present,
absent, conditional, or about someone other than the patient. Third, the deep
learning models used are more accurate than previously available, leveraging an
integrated pipeline of state-of-the-art pretrained named entity recognition
models, and improving on the previous best performing benchmarks for assertion
status detection. We illustrate extracting trends and insights, e.g. most
frequent disorders and symptoms, and most common vital signs and EKG findings,
from the COVID-19 Open Research Dataset (CORD-19). The system is built using
the Spark NLP library which natively supports scaling to use distributed
clusters, leveraging GPUs, configurable and reusable NLP pipelines, healthcare
specific embeddings, and the ability to train models to support new entity
types or human languages with no code changes."	ArXiv
2084	"Understanding and Improving Encoder Layer Fusion in Sequence-to-Sequence
  Learning"	['Xuebo Liu', 'Longyue Wang', 'Derek F. Wong', 'Liang Ding', 'Lidia S. Chao', 'Zhaopeng Tu']	2020-12-29 14:26:59+00:00	http://arxiv.org/abs/2012.14768v2	"Encoder layer fusion (EncoderFusion) is a technique to fuse all the encoder
layers (instead of the uppermost layer) for sequence-to-sequence (Seq2Seq)
models, which has proven effective on various NLP tasks. However, it is still
not entirely clear why and when EncoderFusion should work. In this paper, our
main contribution is to take a step further in understanding EncoderFusion.
Many of previous studies believe that the success of EncoderFusion comes from
exploiting surface and syntactic information embedded in lower encoder layers.
Unlike them, we find that the encoder embedding layer is more important than
other intermediate encoder layers. In addition, the uppermost decoder layer
consistently pays more attention to the encoder embedding layer across NLP
tasks. Based on this observation, we propose a simple fusion method,
SurfaceFusion, by fusing only the encoder embedding layer for the softmax
layer. Experimental results show that SurfaceFusion outperforms EncoderFusion
on several NLP benchmarks, including machine translation, text summarization,
and grammatical error correction. It obtains the state-of-the-art performance
on WMT16 Romanian-English and WMT14 English-French translation tasks. Extensive
analyses reveal that SurfaceFusion learns more expressive bilingual word
embeddings by building a closer relationship between relevant source and target
embedding. Source code is freely available at
https://github.com/SunbowLiu/SurfaceFusion."	ArXiv
2085	"Facilitating Knowledge Sharing from Domain Experts to Data Scientists
  for Building NLP Models"	['Soya Park', 'April Wang', 'Ban Kawas', 'Q. Vera Liao', 'David Piorkowski', 'Marina Danilevsky']	2021-01-29 19:37:05+00:00	http://arxiv.org/abs/2102.00036v1	"Data scientists face a steep learning curve in understanding a new domain for
which they want to build machine learning (ML) models. While input from domain
experts could offer valuable help, such input is often limited, expensive, and
generally not in a form readily consumable by a model development pipeline. In
this paper, we propose Ziva, a framework to guide domain experts in sharing
essential domain knowledge to data scientists for building NLP models. With
Ziva, experts are able to distill and share their domain knowledge using domain
concept extractors and five types of label justification over a representative
data sample. The design of Ziva is informed by preliminary interviews with data
scientists, in order to understand current practices of domain knowledge
acquisition process for ML development projects. To assess our design, we run a
mix-method case-study to evaluate how Ziva can facilitate interaction of domain
experts and data scientists. Our results highlight that (1) domain experts are
able to use Ziva to provide rich domain knowledge, while maintaining low mental
load and stress levels; and (2) data scientists find Ziva's output helpful for
learning essential information about the domain, offering scalability of
information, and lowering the burden on domain experts to share knowledge. We
conclude this work by experimenting with building NLP models using the Ziva
output by our case study."	ArXiv
2086	"VERB: Visualizing and Interpreting Bias Mitigation Techniques for Word
  Representations"	['Archit Rathore', 'Sunipa Dev', 'Jeff M. Phillips', 'Vivek Srikumar', 'Yan Zheng', 'Chin-Chia Michael Yeh', 'Junpeng Wang', 'Wei Zhang', 'Bei Wang']	2021-04-06 21:29:16+00:00	http://arxiv.org/abs/2104.02797v1	"Word vector embeddings have been shown to contain and amplify biases in data
they are extracted from. Consequently, many techniques have been proposed to
identify, mitigate, and attenuate these biases in word representations. In this
paper, we utilize interactive visualization to increase the interpretability
and accessibility of a collection of state-of-the-art debiasing techniques. To
aid this, we present Visualization of Embedding Representations for deBiasing
system (""VERB""), an open-source web-based visualization tool that helps the
users gain a technical understanding and visual intuition of the inner workings
of debiasing techniques, with a focus on their geometric properties. In
particular, VERB offers easy-to-follow use cases in exploring the effects of
these debiasing techniques on the geometry of high-dimensional word vectors. To
help understand how various debiasing techniques change the underlying
geometry, VERB decomposes each technique into interpretable sequences of
primitive transformations and highlights their effect on the word vectors using
dimensionality reduction and interactive visual exploration. VERB is designed
to target natural language processing (NLP) practitioners who are designing
decision-making systems on top of word embeddings, and also researchers working
with fairness and ethics of machine learning systems in NLP. It can also serve
as a visual medium for education, which helps an NLP novice to understand and
mitigate biases in word embeddings."	ArXiv
2087	"FedNLP: Benchmarking Federated Learning Methods for Natural Language
  Processing Tasks"	['Bill Yuchen Lin', 'Chaoyang He', 'Zihang Zeng', 'Hulin Wang', 'Yufen Huang', 'Christophe Dupuy', 'Rahul Gupta', 'Mahdi Soltanolkotabi', 'Xiang Ren', 'Salman Avestimehr']	2021-04-18 11:04:49+00:00	http://arxiv.org/abs/2104.08815v3	"Increasing concerns and regulations about data privacy and sparsity
necessitate the study of privacy-preserving, decentralized learning methods for
natural language processing (NLP) tasks. Federated learning (FL) provides
promising approaches for a large number of clients (e.g., personal devices or
organizations) to collaboratively learn a shared global model to benefit all
clients while allowing users to keep their data locally. Despite interest in
studying FL methods for NLP tasks, a systematic comparison and analysis is
lacking in the literature. Herein, we present the FedNLP, a benchmarking
framework for evaluating federated learning methods on four different task
formulations: text classification, sequence tagging, question answering, and
seq2seq. We propose a universal interface between Transformer-based language
models (e.g., BERT, BART) and FL methods (e.g., FedAvg, FedOPT, etc.) under
various non-IID partitioning strategies. Our extensive experiments with FedNLP
provide empirical comparisons between FL methods and helps us better understand
the inherent challenges of this direction. The comprehensive analysis points to
intriguing and exciting future research aimed at developing FL methods for NLP
tasks."	ArXiv
2088	Hidden Backdoors in Human-Centric Language Models	['Shaofeng Li', 'Hui Liu', 'Tian Dong', 'Benjamin Zi Hao Zhao', 'Minhui Xue', 'Haojin Zhu', 'Jialiang Lu']	2021-05-01 04:41:00+00:00	http://arxiv.org/abs/2105.00164v3	"Natural language processing (NLP) systems have been proven to be vulnerable
to backdoor attacks, whereby hidden features (backdoors) are trained into a
language model and may only be activated by specific inputs (called triggers),
to trick the model into producing unexpected behaviors. In this paper, we
create covert and natural triggers for textual backdoor attacks, \textit{hidden
backdoors}, where triggers can fool both modern language models and human
inspection. We deploy our hidden backdoors through two state-of-the-art trigger
embedding methods. The first approach via homograph replacement, embeds the
trigger into deep neural networks through the visual spoofing of lookalike
character replacement. The second approach uses subtle differences between text
generated by language models and real natural text to produce trigger sentences
with correct grammar and high fluency. We demonstrate that the proposed hidden
backdoors can be effective across three downstream security-critical NLP tasks,
representative of modern human-centric NLP systems, including toxic comment
detection, neural machine translation (NMT), and question answering (QA). Our
two hidden backdoor attacks can achieve an Attack Success Rate (ASR) of at
least $97\%$ with an injection rate of only $3\%$ in toxic comment detection,
$95.1\%$ ASR in NMT with less than $0.5\%$ injected data, and finally $91.12\%$
ASR against QA updated with only 27 poisoning data samples on a model
previously trained with 92,024 samples (0.029\%). We are able to demonstrate
the adversary's high success rate of attacks, while maintaining functionality
for regular users, with triggers inconspicuous by the human administrators."	ArXiv
2089	"Potential Idiomatic Expression (PIE)-English: Corpus for Classes of
  Idioms"	['Tosin P. Adewumi', 'Roshanak Vadoodi', 'Aparajita Tripathy', 'Konstantina Nikolaidou', 'Foteini Liwicki', 'Marcus Liwicki']	2021-04-25 13:05:29+00:00	http://arxiv.org/abs/2105.03280v2	"We present a fairly large, Potential Idiomatic Expression (PIE) dataset for
Natural Language Processing (NLP) in English. The challenges with NLP systems
with regards to tasks such as Machine Translation (MT), word sense
disambiguation (WSD) and information retrieval make it imperative to have a
labelled idioms dataset with classes such as it is in this work. To the best of
the authors' knowledge, this is the first idioms corpus with classes of idioms
beyond the literal and the general idioms classification. In particular, the
following classes are labelled in the dataset: metaphor, simile, euphemism,
parallelism, personification, oxymoron, paradox, hyperbole, irony and literal.
We obtain an overall inter-annotator agreement (IAA) score, between two
independent annotators, of 88.89%. Many past efforts have been limited in the
corpus size and classes of samples but this dataset contains over 20,100
samples with almost 1,200 cases of idioms (with their meanings) from 10 classes
(or senses). The corpus may also be extended by researchers to meet specific
needs. The corpus has part of speech (PoS) tagging from the NLTK library.
Classification experiments performed on the corpus to obtain a baseline and
comparison among three common models, including the BERT model, give good
results. We also make publicly available the corpus and the relevant codes for
working with it for NLP tasks."	ArXiv
2090	On Guaranteed Optimal Robust Explanations for NLP Models	['Emanuele La Malfa', 'Agnieszka Zbrzezny', 'Rhiannon Michelmore', 'Nicola Paoletti', 'Marta Kwiatkowska']	2021-05-08 08:44:48+00:00	http://arxiv.org/abs/2105.03640v2	"We build on abduction-based explanations for ma-chine learning and develop a
method for computing local explanations for neural network models in natural
language processing (NLP). Our explanations comprise a subset of the words of
the in-put text that satisfies two key features: optimality w.r.t. a
user-defined cost function, such as the length of explanation, and robustness,
in that they ensure prediction invariance for any bounded perturbation in the
embedding space of the left out words. We present two solution algorithms,
respectively based on implicit hitting sets and maximum universal subsets,
introducing a number of algorithmic improvements to speed up convergence of
hard instances. We show how our method can be con-figured with different
perturbation sets in the em-bedded space and used to detect bias in predictions
by enforcing include/exclude constraints on biased terms, as well as to enhance
existing heuristic-based NLP explanation frameworks such as Anchors. We
evaluate our framework on three widely used sentiment analysis tasks and texts
of up to100words from SST, Twitter and IMDB datasets,demonstrating the
effectiveness of the derived explanations."	ArXiv
2091	"NLP for Climate Policy: Creating a Knowledge Platform for Holistic and
  Effective Climate Action"	['Pradip Swarnakar', 'Ashutosh Modi']	2021-05-12 12:30:02+00:00	http://arxiv.org/abs/2105.05621v1	"Climate change is a burning issue of our time, with the Sustainable
Development Goal (SDG) 13 of the United Nations demanding global climate
action. Realizing the urgency, in 2015 in Paris, world leaders signed an
agreement committing to taking voluntary action to reduce carbon emissions.
However, the scale, magnitude, and climate action processes vary globally,
especially between developed and developing countries. Therefore, from
parliament to social media, the debates and discussions on climate change
gather data from wide-ranging sources essential to the policy design and
implementation. The downside is that we do not currently have the mechanisms to
pool the worldwide dispersed knowledge emerging from the structured and
unstructured data sources.
  The paper thematically discusses how NLP techniques could be employed in
climate policy research and contribute to society's good at large. In
particular, we exemplify symbiosis of NLP and Climate Policy Research via four
methodologies. The first one deals with the major topics related to climate
policy using automated content analysis. We investigate the opinions
(sentiments) of major actors' narratives towards climate policy in the second
methodology. The third technique explores the climate actors' beliefs towards
pro or anti-climate orientation. Finally, we discuss developing a Climate
Knowledge Graph.
  The present theme paper further argues that creating a knowledge platform
would help in the formulation of a holistic climate policy and effective
climate action. Such a knowledge platform would integrate the policy actors'
varied opinions from different social sectors like government, business, civil
society, and the scientific community. The research outcome will add value to
effective climate action because policymakers can make informed decisions by
looking at the diverse public opinion on a comprehensive platform."	ArXiv
2092	"Context-Sensitive Visualization of Deep Learning Natural Language
  Processing Models"	['Andrew Dunn', 'Diana Inkpen', 'Răzvan Andonie']	2021-05-25 20:26:38+00:00	http://arxiv.org/abs/2105.12202v1	"The introduction of Transformer neural networks has changed the landscape of
Natural Language Processing (NLP) during the last years. So far, none of the
visualization systems has yet managed to examine all the facets of the
Transformers. This gave us the motivation of the current work. We propose a new
NLP Transformer context-sensitive visualization method that leverages existing
NLP tools to find the most significant groups of tokens (words) that have the
greatest effect on the output, thus preserving some context from the original
text. First, we use a sentence-level dependency parser to highlight promising
word groups. The dependency parser creates a tree of relationships between the
words in the sentence. Next, we systematically remove adjacent and non-adjacent
tuples of \emph{n} tokens from the input text, producing several new texts with
those tokens missing. The resulting texts are then passed to a pre-trained BERT
model. The classification output is compared with that of the full text, and
the difference in the activation strength is recorded. The modified texts that
produce the largest difference in the target classification output neuron are
selected, and the combination of removed words are then considered to be the
most influential on the model's output. Finally, the most influential word
combinations are visualized in a heatmap."	ArXiv
2093	"Toward Explainable Users: Using NLP to Enable AI to Understand Users'
  Perceptions of Cyber Attacks"	['Faranak Abri', 'Luis Felipe Gutierrez', 'Chaitra T. Kulkarni', 'Akbar Siami Namin', 'Keith S. Jones']	2021-06-03 17:17:16+00:00	http://arxiv.org/abs/2106.01998v1	"To understand how end-users conceptualize consequences of cyber security
attacks, we performed a card sorting study, a well-known technique in Cognitive
Sciences, where participants were free to group the given consequences of
chosen cyber attacks into as many categories as they wished using rationales
they see fit. The results of the open card sorting study showed a large amount
of inter-participant variation making the research team wonder how the
consequences of security attacks were comprehended by the participants. As an
exploration of whether it is possible to explain user's mental model and
behavior through Artificial Intelligence (AI) techniques, the research team
compared the card sorting data with the outputs of a number of Natural Language
Processing (NLP) techniques with the goal of understanding how participants
perceived and interpreted the consequences of cyber attacks written in natural
languages. The results of the NLP-based exploration methods revealed an
interesting observation implying that participants had mostly employed checking
individual keywords in each sentence to group cyber attack consequences
together and less considered the semantics behind the description of
consequences of cyber attacks. The results reported in this paper are seemingly
useful and important for cyber attacks comprehension from user's perspectives.
To the best of our knowledge, this paper is the first introducing the use of AI
techniques in explaining and modeling users' behavior and their perceptions
about a context. The novel idea introduced here is about explaining users using
AI."	ArXiv
2094	Adversarial Attacks on Deep Models for Financial Transaction Records	['Ivan Fursov', 'Matvey Morozov', 'Nina Kaploukhaya', 'Elizaveta Kovtun', 'Rodrigo Rivera-Castro', 'Gleb Gusev', 'Dmitry Babaev', 'Ivan Kireev', 'Alexey Zaytsev', 'Evgeny Burnaev']	2021-06-15 18:15:26+00:00	http://arxiv.org/abs/2106.08361v1	"Machine learning models using transaction records as inputs are popular among
financial institutions. The most efficient models use deep-learning
architectures similar to those in the NLP community, posing a challenge due to
their tremendous number of parameters and limited robustness. In particular,
deep-learning models are vulnerable to adversarial attacks: a little change in
the input harms the model's output.
  In this work, we examine adversarial attacks on transaction records data and
defences from these attacks. The transaction records data have a different
structure than the canonical NLP or time series data, as neighbouring records
are less connected than words in sentences, and each record consists of both
discrete merchant code and continuous transaction amount. We consider a
black-box attack scenario, where the attack doesn't know the true decision
model, and pay special attention to adding transaction tokens to the end of a
sequence. These limitations provide more realistic scenario, previously
unexplored in NLP world.
  The proposed adversarial attacks and the respective defences demonstrate
remarkable performance using relevant datasets from the financial industry. Our
results show that a couple of generated transactions are sufficient to fool a
deep-learning model. Further, we improve model robustness via adversarial
training or separate adversarial examples detection. This work shows that
embedding protection from adversarial attacks improves model robustness,
allowing a wider adoption of deep models for transaction records in banking and
finance."	ArXiv
2095	Analyzing Research Trends in Inorganic Materials Literature Using NLP	['Fusataka Kuniyoshi', 'Jun Ozawa', 'Makoto Miwa']	2021-06-27 06:29:10+00:00	http://arxiv.org/abs/2106.14157v1	"In the field of inorganic materials science, there is a growing demand to
extract knowledge such as physical properties and synthesis processes of
materials by machine-reading a large number of papers. This is because
materials researchers refer to many papers in order to come up with promising
terms of experiments for material synthesis. However, there are only a few
systems that can extract material names and their properties. This study
proposes a large-scale natural language processing (NLP) pipeline for
extracting material names and properties from materials science literature to
enable the search and retrieval of results in materials science. Therefore, we
propose a label definition for extracting material names and properties and
accordingly build a corpus containing 836 annotated paragraphs extracted from
301 papers for training a named entity recognition (NER) model. Experimental
results demonstrate the utility of this NER model; it achieves successful
extraction with a micro-F1 score of 78.1%. To demonstrate the efficacy of our
approach, we present a thorough evaluation on a real-world automatically
annotated corpus by applying our trained NER model to 12,895 materials science
papers. We analyze the trend in materials science by visualizing the outputs of
the NLP pipeline. For example, the country-by-year analysis indicates that in
recent years, the number of papers on ""MoS2,"" a material used in perovskite
solar cells, has been increasing rapidly in China but decreasing in the United
States. Further, according to the conditions-by-year analysis, the processing
temperature of the catalyst material ""PEDOT:PSS"" is shifting below 200 degree,
and the number of reports with a processing time exceeding 5 h is increasing
slightly."	ArXiv
2096	"Machine Reading of Hypotheses for Organizational Research Reviews and
  Pre-trained Models via R Shiny App for Non-Programmers"	['Victor Zitian Chen', 'Felipe Montano-Campos', 'Wlodek Zadrozny', 'Evan Canfield']	2021-06-30 14:47:15+00:00	http://arxiv.org/abs/2106.16102v3	"The volume of scientific publications in organizational research becomes
exceedingly overwhelming for human researchers who seek to timely extract and
review knowledge. This paper introduces natural language processing (NLP)
models to accelerate the discovery, extraction, and organization of theoretical
developments (i.e., hypotheses) from social science publications. We illustrate
and evaluate NLP models in the context of a systematic review of stakeholder
value constructs and hypotheses. Specifically, we develop NLP models to
automatically 1) detect sentences in scholarly documents as hypotheses or not
(Hypothesis Detection), 2) deconstruct the hypotheses into nodes (constructs)
and links (causal/associative relationships) (Relationship Deconstruction ),
and 3) classify the features of links in terms causality (versus association)
and direction (positive, negative, versus nonlinear) (Feature Classification).
Our models have reported high performance metrics for all three tasks. While
our models are built in Python, we have made the pre-trained models fully
accessible for non-programmers. We have provided instructions on installing and
using our pre-trained models via an R Shiny app graphic user interface (GUI).
Finally, we suggest the next paths to extend our methodology for
computer-assisted knowledge synthesis."	ArXiv
2097	"An Exact Sequential Linear Programming Algorithm for the Optimal Power
  Flow Problem"	['Sleiman', 'Mhanna', 'Pierluigi', 'Mancarella']	2021-07-12 02:04:23+00:00	http://arxiv.org/abs/2107.05164v1	"Despite major advancements in nonlinear programming (NLP) and convex
relaxations, most system operators around the world still predominantly use
some form of linear programming (LP) approximation of the AC power flow
equations. This is largely due to LP technology's superior reliability and
computational efficiency, especially in real-time market applications,
security-constrained applications, and extensions involving integer variables,
in addition to its ability to readily generate locational marginal prices (LMP)
for market applications. In the aim of leveraging the advantages of LP while
retaining the accuracy of NLP interior-point methods (IPMs), this paper
proposes a sequential linear programming (SLP) approach consisting of a
sequence of carefully constructed supporting hyperplanes and halfspaces. The
algorithm is numerically demonstrated to converge on 138 test cases with up the
3375 buses to feasible high-quality solutions (i) without AC feasibility
restoration (i.e., using LP solvers exclusively), (ii) in computation times
generally within the same order of magnitude as those from a state-of-the-art
NLP solver, and (iii) with robustness against the choice of starting point. In
particular, the (relative) optimality gaps and the mean constraint violations
are on average around 1e-3% and 1e-7, respectively, under a single parameter
setting for all the 138 test cases. To the best of our knowledge, the proposed
SLP approach is the first to use LP exclusively to reach feasible and
high-quality solutions to the nonconvex AC OPF in a reliable way, which paves
the way for system and market operators to keep using their LP solvers but now
with the ability to accurately capture transmission losses, price reactive
power (Q-LMP), and obtain more accurate LMP."	ArXiv
2098	Clinical Relation Extraction Using Transformer-based Models	['Xi Yang', 'Zehao Yu', 'Yi Guo', 'Jiang Bian', 'Yonghui Wu']	2021-07-19 15:15:51+00:00	http://arxiv.org/abs/2107.08957v2	"The newly emerged transformer technology has a tremendous impact on NLP
research. In the general English domain, transformer-based models have achieved
state-of-the-art performances on various NLP benchmarks. In the clinical
domain, researchers also have investigated transformer models for clinical
applications. The goal of this study is to systematically explore three widely
used transformer-based models (i.e., BERT, RoBERTa, and XLNet) for clinical
relation extraction and develop an open-source package with clinical
pre-trained transformer-based models to facilitate information extraction in
the clinical domain. We developed a series of clinical RE models based on three
transformer architectures, namely BERT, RoBERTa, and XLNet. We evaluated these
models using 2 publicly available datasets from 2018 MADE1.0 and 2018 n2c2
challenges. We compared two classification strategies (binary vs. multi-class
classification) and investigated two approaches to generate candidate relations
in different experimental settings. In this study, we compared three
transformer-based (BERT, RoBERTa, and XLNet) models for relation extraction. We
demonstrated that the RoBERTa-clinical RE model achieved the best performance
on the 2018 MADE1.0 dataset with an F1-score of 0.8958. On the 2018 n2c2
dataset, the XLNet-clinical model achieved the best F1-score of 0.9610. Our
results indicated that the binary classification strategy consistently
outperformed the multi-class classification strategy for clinical relation
extraction. Our methods and models are publicly available at
https://github.com/uf-hobi-informatics-lab/ClinicalTransformerRelationExtraction.
We believe this work will improve current practice on clinical relation
extraction and other related NLP tasks in the biomedical domain."	ArXiv
2099	"Detecting Requirements Smells With Deep Learning: Experiences,
  Challenges and Future Work"	['Mohammad Kasra Habib', 'Stefan Wagner', 'Daniel Graziotin']	2021-08-06 12:45:15+00:00	http://arxiv.org/abs/2108.03087v1	"Requirements Engineering (RE) is the initial step towards building a software
system. The success or failure of a software project is firmly tied to this
phase, based on communication among stakeholders using natural language. The
problem with natural language is that it can easily lead to different
understandings if it is not expressed precisely by the stakeholders involved,
which results in building a product different from the expected one. Previous
work proposed to enhance the quality of the software requirements detecting
language errors based on ISO 29148 requirements language criteria. The existing
solutions apply classical Natural Language Processing (NLP) to detect them. NLP
has some limitations, such as domain dependability which results in poor
generalization capability. Therefore, this work aims to improve the previous
work by creating a manually labeled dataset and using ensemble learning, Deep
Learning (DL), and techniques such as word embeddings and transfer learning to
overcome the generalization problem that is tied with classical NLP and improve
precision and recall metrics using a manually labeled dataset. The current
findings show that the dataset is unbalanced and which class examples should be
added more. It is tempting to train algorithms even if the dataset is not
considerably representative. Whence, the results show that models are
overfitting; in Machine Learning this issue is solved by adding more instances
to the dataset, improving label quality, removing noise, and reducing the
learning algorithms complexity, which is planned for this research."	ArXiv
2100	On Measures of Biases and Harms in NLP	['Sunipa Dev', 'Emily Sheng', 'Jieyu Zhao', 'Aubrie Amstutz', 'Jiao Sun', 'Yu Hou', 'Mattie Sanseverino', 'Jiin Kim', 'Akihiro Nishi', 'Nanyun Peng', 'Kai-Wei Chang']	2021-08-07 04:08:47+00:00	http://arxiv.org/abs/2108.03362v2	"Recent studies show that Natural Language Processing (NLP) technologies
propagate societal biases about demographic groups associated with attributes
such as gender, race, and nationality. To create interventions and mitigate
these biases and associated harms, it is vital to be able to detect and measure
such biases. While existing works propose bias evaluation and mitigation
methods for various tasks, there remains a need to cohesively understand the
biases and the specific harms they measure, and how different measures compare
with each other. To address this gap, this work presents a practical framework
of harms and a series of questions that practitioners can answer to guide the
development of bias measures. As a validation of our framework and
documentation questions, we also present several case studies of how existing
bias measures in NLP -- both intrinsic measures of bias in representations and
extrinsic measures of bias of downstream applications -- can be aligned with
different harms and how our proposed documentation questions facilitates more
holistic understanding of what bias measures are measuring."	ArXiv
2101	"AdapterHub Playground: Simple and Flexible Few-Shot Learning with
  Adapters"	['Tilman Beck', 'Bela Bohlender', 'Christina Viehmann', 'Vincent Hane', 'Yanik Adamson', 'Jaber Khuri', 'Jonas Brossmann', 'Jonas Pfeiffer', 'Iryna Gurevych']	2021-08-18 11:56:01+00:00	http://arxiv.org/abs/2108.08103v3	"The open-access dissemination of pretrained language models through online
repositories has led to a democratization of state-of-the-art natural language
processing (NLP) research. This also allows people outside of NLP to use such
models and adapt them to specific use-cases. However, a certain amount of
technical proficiency is still required which is an entry barrier for users who
want to apply these models to a certain task but lack the necessary knowledge
or resources. In this work, we aim to overcome this gap by providing a tool
which allows researchers to leverage pretrained models without writing a single
line of code. Built upon the parameter-efficient adapter modules for transfer
learning, our AdapterHub Playground provides an intuitive interface, allowing
the usage of adapters for prediction, training and analysis of textual data for
a variety of NLP tasks. We present the tool's architecture and demonstrate its
advantages with prototypical use-cases, where we show that predictive
performance can easily be increased in a few-shot learning scenario. Finally,
we evaluate its usability in a user study. We provide the code and a live
interface at https://adapter-hub.github.io/playground."	ArXiv
2102	Deep Natural Language Processing for LinkedIn Search	['Weiwei Guo', 'Xiaowei Liu', 'Sida Wang', 'Michaeel Kazi', 'Zhiwei Wang', 'Zhoutong Fu', 'Jun Jia', 'Liang Zhang', 'Huiji Gao', 'Bo Long']	2021-08-16 23:37:33+00:00	http://arxiv.org/abs/2108.13300v1	"Many search systems work with large amounts of natural language data, e.g.,
search queries, user profiles, and documents. Building a successful search
system requires a thorough understanding of textual data semantics, where deep
learning based natural language processing techniques (deep NLP) can be of
great help. In this paper, we introduce a comprehensive study for applying deep
NLP techniques to five representative tasks in search systems: query intent
prediction (classification), query tagging (sequential tagging), document
ranking (ranking), query auto completion (language modeling), and query
suggestion (sequence to sequence). We also introduce BERT pre-training as a
sixth task that can be applied to many of the other tasks. Through the model
design and experiments of the six tasks, readers can find answers to four
important questions: (1). When is deep NLP helpful/not helpful in search
systems? (2). How to address latency challenges? (3). How to ensure model
robustness? This work builds on existing efforts of LinkedIn search, and is
tested at scale on LinkedIn's commercial search engines. We believe our
experiences can provide useful insights for the industry and research
communities."	ArXiv
2103	"A Comparative Study of Sentiment Analysis Using NLP and Different
  Machine Learning Techniques on US Airline Twitter Data"	['Md. Taufiqul Haque Khan Tusar', 'Md. Touhidul Islam']	2021-10-02 18:05:00+00:00	http://arxiv.org/abs/2110.00859v1	"Today's business ecosystem has become very competitive. Customer satisfaction
has become a major focus for business growth. Business organizations are
spending a lot of money and human resources on various strategies to understand
and fulfill their customer's needs. But, because of defective manual analysis
on multifarious needs of customers, many organizations are failing to achieve
customer satisfaction. As a result, they are losing customer's loyalty and
spending extra money on marketing. We can solve the problems by implementing
Sentiment Analysis. It is a combined technique of Natural Language Processing
(NLP) and Machine Learning (ML). Sentiment Analysis is broadly used to extract
insights from wider public opinion behind certain topics, products, and
services. We can do it from any online available data. In this paper, we have
introduced two NLP techniques (Bag-of-Words and TF-IDF) and various ML
classification algorithms (Support Vector Machine, Logistic Regression,
Multinomial Naive Bayes, Random Forest) to find an effective approach for
Sentiment Analysis on a large, imbalanced, and multi-classed dataset. Our best
approaches provide 77% accuracy using Support Vector Machine and Logistic
Regression with Bag-of-Words technique."	ArXiv
2104	"Mind the Style of Text! Adversarial and Backdoor Attacks Based on Text
  Style Transfer"	['Fanchao Qi', 'Yangyi Chen', 'Xurui Zhang', 'Mukai Li', 'Zhiyuan Liu', 'Maosong Sun']	2021-10-14 03:54:16+00:00	http://arxiv.org/abs/2110.07139v1	"Adversarial attacks and backdoor attacks are two common security threats that
hang over deep learning. Both of them harness task-irrelevant features of data
in their implementation. Text style is a feature that is naturally irrelevant
to most NLP tasks, and thus suitable for adversarial and backdoor attacks. In
this paper, we make the first attempt to conduct adversarial and backdoor
attacks based on text style transfer, which is aimed at altering the style of a
sentence while preserving its meaning. We design an adversarial attack method
and a backdoor attack method, and conduct extensive experiments to evaluate
them. Experimental results show that popular NLP models are vulnerable to both
adversarial and backdoor attacks based on text style transfer -- the attack
success rates can exceed 90% without much effort. It reflects the limited
ability of NLP models to handle the feature of text style that has not been
widely realized. In addition, the style transfer-based adversarial and backdoor
attack methods show superiority to baselines in many aspects. All the code and
data of this paper can be obtained at https://github.com/thunlp/StyleAttack."	ArXiv
2105	"EmbRace: Accelerating Sparse Communication for Distributed Training of
  NLP Neural Networks"	['Shengwei Li', 'Zhiquan Lai', 'Dongsheng Li', 'Yiming Zhang', 'Xiangyu Ye', 'Yabo Duan']	2021-10-18 09:35:40+00:00	http://arxiv.org/abs/2110.09132v2	"Distributed data-parallel training has been widely adopted for deep neural
network (DNN) models. Although current deep learning (DL) frameworks scale well
for dense models like image classification models, we find that these DL
frameworks have relatively low scalability for sparse models like natural
language processing (NLP) models that have highly sparse embedding tables. Most
existing works overlook the sparsity of model parameters thus suffering from
significant but unnecessary communication overhead. In this paper, we propose
EmbRace, an efficient communication framework to accelerate communications of
distributed training for sparse models. EmbRace introduces Sparsity-aware
Hybrid Communication, which integrates AlltoAll and model parallelism into
data-parallel training, so as to reduce the communication overhead of highly
sparse parameters. To effectively overlap sparse communication with both
backward and forward computation, EmbRace further designs a 2D Communication
Scheduling approach which optimizes the model computation procedure, relaxes
the dependency of embeddings, and schedules the sparse communications of each
embedding row with a priority queue. We have implemented a prototype of EmbRace
based on PyTorch and Horovod, and conducted comprehensive evaluations with four
representative NLP models. Experimental results show that EmbRace achieves up
to 2.41X speedup compared to the state-of-the-art distributed training
baselines."	ArXiv
2106	The Arabic Parallel Gender Corpus 2.0: Extensions and Analyses	['Bashar Alhafni', 'Nizar Habash', 'Houda Bouamor']	2021-10-18 12:06:17+00:00	http://arxiv.org/abs/2110.09216v1	"Gender bias in natural language processing (NLP) applications, particularly
machine translation, has been receiving increasing attention. Much of the
research on this issue has focused on mitigating gender bias in English NLP
models and systems. Addressing the problem in poorly resourced, and/or
morphologically rich languages has lagged behind, largely due to the lack of
datasets and resources. In this paper, we introduce a new corpus for gender
identification and rewriting in contexts involving one or two target users (I
and/or You) -- first and second grammatical persons with independent
grammatical gender preferences. We focus on Arabic, a gender-marking
morphologically rich language. The corpus has multiple parallel components:
four combinations of 1st and 2nd person in feminine and masculine grammatical
genders, as well as English, and English to Arabic machine translation output.
This corpus expands on Habash et al. (2019)'s Arabic Parallel Gender Corpus
(APGC v1.0) by adding second person targets as well as increasing the total
number of sentences over 6.5 times, reaching over 590K words. Our new dataset
will aid the research and development of gender identification, controlled text
generation, and post-editing rewrite systems that could be used to personalize
NLP applications and provide users with the correct outputs based on their
grammatical gender preferences. We make the Arabic Parallel Gender Corpus (APGC
v2.0) publicly available."	ArXiv
2107	Better than Average: Paired Evaluation of NLP Systems	['Maxime Peyrard', 'Wei Zhao', 'Steffen Eger', 'Robert West']	2021-10-20 19:40:31+00:00	http://arxiv.org/abs/2110.10746v1	"Evaluation in NLP is usually done by comparing the scores of competing
systems independently averaged over a common set of test instances. In this
work, we question the use of averages for aggregating evaluation scores into a
final number used to decide which system is best, since the average, as well as
alternatives such as the median, ignores the pairing arising from the fact that
systems are evaluated on the same test instances. We illustrate the importance
of taking the instance-level pairing of evaluation scores into account and
demonstrate, both theoretically and empirically, the advantages of aggregation
methods based on pairwise comparisons, such as the Bradley-Terry (BT) model, a
mechanism based on the estimated probability that a given system scores better
than another on the test set. By re-evaluating 296 real NLP evaluation setups
across four tasks and 18 evaluation metrics, we show that the choice of
aggregation mechanism matters and yields different conclusions as to which
systems are state of the art in about 30% of the setups. To facilitate the
adoption of pairwise evaluation, we release a practical tool for performing the
full analysis of evaluation scores with the mean, median, BT, and two variants
of BT (Elo and TrueSkill), alongside functionality for appropriate statistical
testing."	ArXiv
2108	Triggerless Backdoor Attack for NLP Tasks with Clean Labels	['Leilei Gan', 'Jiwei Li', 'Tianwei Zhang', 'Xiaoya Li', 'Yuxian Meng', 'Fei Wu', 'Yi Yang', 'Shangwei Guo', 'Chun Fan']	2021-11-15 18:36:25+00:00	http://arxiv.org/abs/2111.07970v2	"Backdoor attacks pose a new threat to NLP models. A standard strategy to
construct poisoned data in backdoor attacks is to insert triggers (e.g., rare
words) into selected sentences and alter the original label to a target label.
This strategy comes with a severe flaw of being easily detected from both the
trigger and the label perspectives: the trigger injected, which is usually a
rare word, leads to an abnormal natural language expression, and thus can be
easily detected by a defense model; the changed target label leads the example
to be mistakenly labeled and thus can be easily detected by manual inspections.
To deal with this issue, in this paper, we propose a new strategy to perform
textual backdoor attacks which do not require an external trigger, and the
poisoned samples are correctly labeled. The core idea of the proposed strategy
is to construct clean-labeled examples, whose labels are correct but can lead
to test label changes when fused with the training set. To generate poisoned
clean-labeled examples, we propose a sentence generation model based on the
genetic algorithm to cater to the non-differentiable characteristic of text
data. Extensive experiments demonstrate that the proposed attacking strategy is
not only effective, but more importantly, hard to defend due to its triggerless
and clean-labeled nature. Our work marks the first step towards developing
triggerless attacking strategies in NLP."	ArXiv
2109	"To Augment or Not to Augment? A Comparative Study on Text Augmentation
  Techniques for Low-Resource NLP"	['Gözde Gül Şahin']	2021-11-18 10:52:48+00:00	http://arxiv.org/abs/2111.09618v1	"Data-hungry deep neural networks have established themselves as the standard
for many NLP tasks including the traditional sequence tagging ones. Despite
their state-of-the-art performance on high-resource languages, they still fall
behind of their statistical counter-parts in low-resource scenarios. One
methodology to counter attack this problem is text augmentation, i.e.,
generating new synthetic training data points from existing data. Although NLP
has recently witnessed a load of textual augmentation techniques, the field
still lacks a systematic performance analysis on a diverse set of languages and
sequence tagging tasks. To fill this gap, we investigate three categories of
text augmentation methodologies which perform changes on the syntax (e.g.,
cropping sub-sentences), token (e.g., random word insertion) and character
(e.g., character swapping) levels. We systematically compare them on
part-of-speech tagging, dependency parsing and semantic role labeling for a
diverse set of language families using various models including the
architectures that rely on pretrained multilingual contextualized language
models such as mBERT. Augmentation most significantly improves dependency
parsing, followed by part-of-speech tagging and semantic role labeling. We find
the experimented techniques to be effective on morphologically rich languages
in general rather than analytic languages such as Vietnamese. Our results
suggest that the augmentation techniques can further improve over strong
baselines based on mBERT. We identify the character-level methods as the most
consistent performers, while synonym replacement and syntactic augmenters
provide inconsistent improvements. Finally, we discuss that the results most
heavily depend on the task, language pair, and the model type."	ArXiv
2110	"Evaluating the application of NLP tools in mainstream participatory
  budgeting processes in Scotland"	['Jonathan Davies', 'Miguel Arana-Catania', 'Rob Procter', 'Felix-Anselm van Lier', 'Yulan He']	2021-11-23 10:23:58+00:00	http://arxiv.org/abs/2111.11766v1	"In recent years participatory budgeting (PB) in Scotland has grown from a
handful of community-led processes to a movement supported by local and
national government. This is epitomized by an agreement between the Scottish
Government and the Convention of Scottish Local Authorities (COSLA) that at
least 1% of local authority budgets will be subject to PB. This ongoing
research paper explores the challenges that emerge from this 'scaling up' or
'mainstreaming' across the 32 local authorities that make up Scotland. The main
objective is to evaluate local authority use of the digital platform Consul,
which applies Natural Language Processing (NLP) to address these challenges.
This project adopts a qualitative longitudinal design with interviews,
observations of PB processes, and analysis of the digital platform data.
Thematic analysis is employed to capture the major issues and themes which
emerge. Longitudinal analysis then explores how these evolve over time. The
potential for 32 live study sites provides a unique opportunity to explore
discrete political and social contexts which materialize and allow for a deeper
dive into the challenges and issues that may exist, something a wider
cross-sectional study would miss. Initial results show that issues and
challenges which come from scaling up may be tackled using NLP technology
which, in a previous controlled use case-based evaluation, has shown to improve
the effectiveness of citizen participation."	ArXiv
2111	Simple Contrastive Representation Adversarial Learning for NLP Tasks	['Deshui Miao', 'Jiaqi Zhang', 'Wenbo Xie', 'Jian Song', 'Xin Li', 'Lijuan Jia', 'Ning Guo']	2021-11-26 03:16:09+00:00	http://arxiv.org/abs/2111.13301v2	"Self-supervised learning approach like contrastive learning is attached great
attention in natural language processing. It uses pairs of training data
augmentations to build a classification task for an encoder with well
representation ability. However, the construction of learning pairs over
contrastive learning is much harder in NLP tasks. Previous works generate
word-level changes to form pairs, but small transforms may cause notable
changes on the meaning of sentences as the discrete and sparse nature of
natural language. In this paper, adversarial training is performed to generate
challenging and harder learning adversarial examples over the embedding space
of NLP as learning pairs. Using contrastive learning improves the
generalization ability of adversarial training because contrastive loss can
uniform the sample distribution. And at the same time, adversarial training
also enhances the robustness of contrastive learning. Two novel frameworks,
supervised contrastive adversarial learning (SCAL) and unsupervised SCAL
(USCAL), are proposed, which yields learning pairs by utilizing the adversarial
training for contrastive learning. The label-based loss of supervised tasks is
exploited to generate adversarial examples while unsupervised tasks bring
contrastive loss. To validate the effectiveness of the proposed framework, we
employ it to Transformer-based models for natural language understanding,
sentence semantic textual similarity and adversarial learning tasks.
Experimental results on GLUE benchmark tasks show that our fine-tuned
supervised method outperforms BERT$_{base}$ over 1.75\%. We also evaluate our
unsupervised method on semantic textual similarity (STS) tasks, and our method
gets 77.29\% with BERT$_{base}$. The robustness of our approach conducts
state-of-the-art results under multiple adversarial datasets on NLI tasks."	ArXiv
2112	"Semantic Annotation and Querying Framework based on Semi-structured
  Ayurvedic Text"	['Hrishikesh Terdalkar', 'Arnab Bhattacharya', 'Madhulika Dubey', 'Ramamurthy S', 'Bhavna Naneria Singh']	2022-02-01 04:33:13+00:00	http://arxiv.org/abs/2202.00216v1	"Knowledge bases (KB) are an important resource in a number of natural
language processing (NLP) and information retrieval (IR) tasks, such as
semantic search, automated question-answering etc. They are also useful for
researchers trying to gain information from a text. Unfortunately, however, the
state-of-the-art in Sanskrit NLP does not yet allow automated construction of
knowledge bases due to unavailability or lack of sufficient accuracy of tools
and methods. Thus, in this work, we describe our efforts on manual annotation
of Sanskrit text for the purpose of knowledge graph (KG) creation. We choose
the chapter Dhanyavarga from Bhavaprakashanighantu of the Ayurvedic text
Bhavaprakasha for annotation. The constructed knowledge graph contains 410
entities and 764 relationships. Since Bhavaprakashanighantu is a technical
glossary text that describes various properties of different substances, we
develop an elaborate ontology to capture the semantics of the entity and
relationship types present in the text. To query the knowledge graph, we design
31 query templates that cover most of the common question patterns. For both
manual annotation and querying, we customize the Sangrahaka framework
previously developed by us. The entire system including the dataset is
available from https://sanskrit.iitk.ac.in/ayurveda/ . We hope that the
knowledge graph that we have created through manual annotation and subsequent
curation will help in development and testing of NLP tools in future as well as
studying of the Bhavaprakasanighantu text."	ArXiv
2113	"Causal effect of racial bias in data and machine learning algorithms on
  user persuasiveness & discriminatory decision making: An Empirical Study"	['Kinshuk Sengupta', 'Praveen Ranjan Srivastava']	2022-01-22 08:26:09+00:00	http://arxiv.org/abs/2202.00471v3	"Language data and models demonstrate various types of bias, be it ethnic,
religious, gender, or socioeconomic. AI/NLP models, when trained on the
racially biased dataset, AI/NLP models instigate poor model explainability,
influence user experience during decision making and thus further magnifies
societal biases, raising profound ethical implications for society. The
motivation of the study is to investigate how AI systems imbibe bias from data
and produce unexplainable discriminatory outcomes and influence an individual's
articulateness of system outcome due to the presence of racial bias features in
datasets. The design of the experiment involves studying the counterfactual
impact of racial bias features present in language datasets and its associated
effect on the model outcome. A mixed research methodology is adopted to
investigate the cross implication of biased model outcome on user experience,
effect on decision-making through controlled lab experimentation. The findings
provide foundation support for correlating the implication of carry-over an
artificial intelligence model solving NLP task due to biased concept presented
in the dataset. Further, the research outcomes justify the negative influence
on users' persuasiveness that leads to alter the decision-making quotient of an
individual when trying to rely on the model outcome to act. The paper bridges
the gap across the harm caused in establishing poor customer trustworthiness
due to an inequitable system design and provides strong support for
researchers, policymakers, and data scientists to build responsible AI
frameworks within organizations."	ArXiv
2114	"Detecting Privacy Requirements from User Stories with NLP Transfer
  Learning Models"	['Francesco Casillo', 'Vincenzo Deufemia', 'Carmine Gravino']	2022-02-02 14:02:13+00:00	http://arxiv.org/abs/2202.01035v1	"To provide privacy-aware software systems, it is crucial to consider privacy
from the very beginning of the development. However, developers do not have the
expertise and the knowledge required to embed the legal and social requirements
for data protection into software systems. Objective: We present an approach to
decrease privacy risks during agile software development by automatically
detecting privacy-related information in the context of user story
requirements, a prominent notation in agile Requirement Engineering (RE).
Methods: The proposed approach combines Natural Language Processing (NLP) and
linguistic resources with deep learning algorithms to identify privacy aspects
into User Stories. NLP technologies are used to extract information regarding
the semantic and syntactic structure of the text. This information is then
processed by a pre-trained convolutional neural network, which paved the way
for the implementation of a Transfer Learning technique. We evaluate the
proposed approach by performing an empirical study with a dataset of 1680 user
stories. Results: The experimental results show that deep learning algorithms
allow to obtain better predictions than those achieved with conventional
(shallow) machine learning methods. Moreover, the application of Transfer
Learning allows to considerably improve the accuracy of the predictions, ca.
10%. Conclusions: Our study contributes to encourage software engineering
researchers in considering the opportunities to automate privacy detection in
the early phase of design, by also exploiting transfer learning models."	ArXiv
2115	"Russian SuperGLUE 1.1: Revising the Lessons not Learned by Russian NLP
  models"	['Alena Fenogenova', 'Maria Tikhonova', 'Vladislav Mikhailov', 'Tatiana Shavrina', 'Anton Emelyanov', 'Denis Shevelev', 'Alexandr Kukushkin', 'Valentin Malykh', 'Ekaterina Artemova']	2022-02-15 23:45:30+00:00	http://arxiv.org/abs/2202.07791v1	"In the last year, new neural architectures and multilingual pre-trained
models have been released for Russian, which led to performance evaluation
problems across a range of language understanding tasks.
  This paper presents Russian SuperGLUE 1.1, an updated benchmark styled after
GLUE for Russian NLP models. The new version includes a number of technical,
user experience and methodological improvements, including fixes of the
benchmark vulnerabilities unresolved in the previous version: novel and
improved tests for understanding the meaning of a word in context (RUSSE) along
with reading comprehension and common sense reasoning (DaNetQA, RuCoS, MuSeRC).
Together with the release of the updated datasets, we improve the benchmark
toolkit based on \texttt{jiant} framework for consistent training and
evaluation of NLP-models of various architectures which now supports the most
recent models for Russian. Finally, we provide the integration of Russian
SuperGLUE with a framework for industrial evaluation of the open-source models,
MOROCCO (MOdel ResOurCe COmparison), in which the models are evaluated
according to the weighted average metric over all tasks, the inference speed,
and the occupied amount of RAM. Russian SuperGLUE is publicly available at
https://russiansuperglue.com/."	ArXiv
2116	Did AI get more negative recently?	['Dominik Beese', 'Begüm Altunbaş', 'Görkem Güzeler', 'Steffen Eger']	2022-02-28 08:37:03+00:00	http://arxiv.org/abs/2202.13610v3	"In this paper, we classify scientific articles in the domain of natural
language processing (NLP) and machine learning (ML), as core subfields of
artificial intelligence (AI), into whether (i) they extend the current
state-of-the-art by the introduction of novel techniques which beat existing
models or whether (ii) they mainly criticize the existing state-of-the-art,
i.e. that it is deficient with respect to some property (e.g. wrong evaluation,
wrong datasets, misleading task specification). We refer to contributions under
(i) as having a 'positive stance' and contributions under (ii) as having a
'negative stance' (to related work). We annotate over 1.5 k papers from NLP and
ML to train a SciBERT-based model to automatically predict the stance of a
paper based on its title and abstract. We then analyse large-scale trends on
over 41 k papers from the last approximately 35 years in NLP and ML, finding
that papers have become substantially more positive over time, but negative
papers also got more negative and we observe considerably more negative papers
in recent years. Negative papers are also more influential in terms of
citations they receive."	ArXiv
2117	"Librarian-in-the-Loop: A Natural Language Processing Paradigm for
  Detecting Informal Mentions of Research Data in Academic Literature"	['Lizhou Fan', 'Sara Lafia', 'David Bleckley', 'Elizabeth Moss', 'Andrea Thomer', 'Libby Hemphill']	2022-03-10 02:11:30+00:00	http://arxiv.org/abs/2203.05112v1	"Data citations provide a foundation for studying research data impact.
Collecting and managing data citations is a new frontier in archival science
and scholarly communication. However, the discovery and curation of research
data citations is labor intensive. Data citations that reference unique
identifiers (i.e. DOIs) are readily findable; however, informal mentions made
to research data are more challenging to infer. We propose a natural language
processing (NLP) paradigm to support the human task of identifying informal
mentions made to research datasets. The work of discovering informal data
mentions is currently performed by librarians and their staff in the
Inter-university Consortium for Political and Social Research (ICPSR), a large
social science data archive that maintains a large bibliography of data-related
literature. The NLP model is bootstrapped from data citations actively
collected by librarians at ICPSR. The model combines pattern matching with
multiple iterations of human annotations to learn additional rules for
detecting informal data mentions. These examples are then used to train an NLP
pipeline. The librarian-in-the-loop paradigm is centered in the data work
performed by ICPSR librarians, supporting broader efforts to build a more
comprehensive bibliography of data-related literature that reflects the
scholarly communities of research data users."	ArXiv
2118	SecureBERT: A Domain-Specific Language Model for Cybersecurity	['Ehsan Aghaei', 'Xi Niu', 'Waseem Shadid', 'Ehab Al-Shaer']	2022-04-06 09:17:21+00:00	http://arxiv.org/abs/2204.02685v3	"Natural Language Processing (NLP) has recently gained wide attention in
cybersecurity, particularly in Cyber Threat Intelligence (CTI) and cyber
automation. Increased connection and automation have revolutionized the world's
economic and cultural infrastructures, while they have introduced risks in
terms of cyber attacks. CTI is information that helps cybersecurity analysts
make intelligent security decisions, that is often delivered in the form of
natural language text, which must be transformed to machine readable format
through an automated procedure before it can be used for automated security
measures.
  This paper proposes SecureBERT, a cybersecurity language model capable of
capturing text connotations in cybersecurity text (e.g., CTI) and therefore
successful in automation for many critical cybersecurity tasks that would
otherwise rely on human expertise and time-consuming manual efforts. SecureBERT
has been trained using a large corpus of cybersecurity text.To make SecureBERT
effective not just in retaining general English understanding, but also when
applied to text with cybersecurity implications, we developed a customized
tokenizer as well as a method to alter pre-trained weights. The SecureBERT is
evaluated using the standard Masked Language Model (MLM) test as well as two
additional standard NLP tasks. Our evaluation studies show that
SecureBERT\footnote{\url{https://github.com/ehsanaghaei/SecureBERT}}
outperforms existing similar models, confirming its capability for solving
crucial NLP tasks in cybersecurity."	ArXiv
2119	"Revise and Resubmit: An Intertextual Model of Text-based Collaboration
  in Peer Review"	['Ilia Kuznetsov', 'Jan Buchmann', 'Max Eichler', 'Iryna Gurevych']	2022-04-22 16:39:38+00:00	http://arxiv.org/abs/2204.10805v2	"Peer review is a key component of the publishing process in most fields of
science. The increasing submission rates put a strain on reviewing quality and
efficiency, motivating the development of applications to support the reviewing
and editorial work. While existing NLP studies focus on the analysis of
individual texts, editorial assistance often requires modeling interactions
between pairs of texts -- yet general frameworks and datasets to support this
scenario are missing. Relationships between texts are the core object of the
intertextuality theory -- a family of approaches in literary studies not yet
operationalized in NLP. Inspired by prior theoretical work, we propose the
first intertextual model of text-based collaboration, which encompasses three
major phenomena that make up a full iteration of the review-revise-and-resubmit
cycle: pragmatic tagging, linking and long-document version alignment. While
peer review is used across the fields of science and publication formats,
existing datasets solely focus on conference-style review in computer science.
Addressing this, we instantiate our proposed model in the first annotated
multi-domain corpus in journal-style post-publication open peer review, and
provide detailed insights into the practical aspects of intertextual
annotation. Our resource is a major step towards multi-domain, fine-grained
applications of NLP in editorial support for peer review, and our intertextual
framework paves the path for general-purpose modeling of text-based
collaboration. Our corpus and accompanying code are publicly available."	ArXiv
2120	"A global analysis of metrics used for measuring performance in natural
  language processing"	['Kathrin Blagec', 'Georg Dorffner', 'Milad Moradi', 'Simon Ott', 'Matthias Samwald']	2022-04-25 11:41:50+00:00	http://arxiv.org/abs/2204.11574v1	"Measuring the performance of natural language processing models is
challenging. Traditionally used metrics, such as BLEU and ROUGE, originally
devised for machine translation and summarization, have been shown to suffer
from low correlation with human judgment and a lack of transferability to other
tasks and languages. In the past 15 years, a wide range of alternative metrics
have been proposed. However, it is unclear to what extent this has had an
impact on NLP benchmarking efforts. Here we provide the first large-scale
cross-sectional analysis of metrics used for measuring performance in natural
language processing. We curated, mapped and systematized more than 3500 machine
learning model performance results from the open repository 'Papers with Code'
to enable a global and comprehensive analysis. Our results suggest that the
large majority of natural language processing metrics currently used have
properties that may result in an inadequate reflection of a models'
performance. Furthermore, we found that ambiguities and inconsistencies in the
reporting of metrics may lead to difficulties in interpreting and comparing
model performances, impairing transparency and reproducibility in NLP research."	ArXiv
2121	"Detecting Textual Adversarial Examples Based on Distributional
  Characteristics of Data Representations"	['Na Liu', 'Mark Dras', 'Wei Emma Zhang']	2022-04-29 02:32:02+00:00	http://arxiv.org/abs/2204.13853v1	"Although deep neural networks have achieved state-of-the-art performance in
various machine learning tasks, adversarial examples, constructed by adding
small non-random perturbations to correctly classified inputs, successfully
fool highly expressive deep classifiers into incorrect predictions. Approaches
to adversarial attacks in natural language tasks have boomed in the last five
years using character-level, word-level, phrase-level, or sentence-level
textual perturbations. While there is some work in NLP on defending against
such attacks through proactive methods, like adversarial training, there is to
our knowledge no effective general reactive approaches to defence via detection
of textual adversarial examples such as is found in the image processing
literature. In this paper, we propose two new reactive methods for NLP to fill
this gap, which unlike the few limited application baselines from NLP are based
entirely on distribution characteristics of learned representations: we adapt
one from the image processing literature (Local Intrinsic Dimensionality
(LID)), and propose a novel one (MultiDistance Representation Ensemble Method
(MDRE)). Adapted LID and MDRE obtain state-of-the-art results on
character-level, word-level, and phrase-level attacks on the IMDB dataset as
well as on the later two with respect to the MultiNLI dataset. For future
research, we publish our code."	ArXiv
2122	Few-shot learning for medical text: A systematic review	['Yao Ge', 'Yuting Guo', 'Yuan-Chi Yang', 'Mohammed Ali Al-Garadi', 'Abeed Sarker']	2022-04-21 18:15:51+00:00	http://arxiv.org/abs/2204.14081v1	"Objective: Few-shot learning (FSL) methods require small numbers of labeled
instances for training. As many medical topics have limited annotated textual
data in practical settings, FSL-based natural language processing (NLP) methods
hold substantial promise. We aimed to conduct a systematic review to explore
the state of FSL methods for medical NLP. Materials and Methods: We searched
for articles published between January 2016 and August 2021 using
PubMed/Medline, Embase, ACL Anthology, and IEEE Xplore Digital Library. To
identify the latest relevant methods, we also searched other sources such as
preprint servers (eg., medRxiv) via Google Scholar. We included all articles
that involved FSL and any type of medical text. We abstracted articles based on
data source(s), aim(s), training set size(s), primary method(s)/approach(es),
and evaluation method(s). Results: 31 studies met our inclusion criteria-all
published after 2018; 22 (71%) since 2020. Concept extraction/named entity
recognition was the most frequently addressed task (13/31; 42%), followed by
text classification (10/31; 32%). Twenty-one (68%) studies reconstructed
existing datasets to create few-shot scenarios synthetically, and MIMIC-III was
the most frequently used dataset (7/31; 23%). Common methods included FSL with
attention mechanisms (12/31; 39%), prototypical networks (8/31; 26%), and
meta-learning (6/31; 19%). Discussion: Despite the potential for FSL in
biomedical NLP, progress has been limited compared to domain-independent FSL.
This may be due to the paucity of standardized, public datasets, and the
relative underperformance of FSL methods on biomedical topics. Creation and
release of specialized datasets for biomedical FSL may aid method development
by enabling comparative analyses."	ArXiv
2123	Prompt Consistency for Zero-Shot Task Generalization	['Chunting Zhou', 'Junxian He', 'Xuezhe Ma', 'Taylor Berg-Kirkpatrick', 'Graham Neubig']	2022-04-29 19:18:37+00:00	http://arxiv.org/abs/2205.00049v2	"One of the most impressive results of recent NLP history is the ability of
pre-trained language models to solve new tasks in a zero-shot setting. To
achieve this, NLP tasks are framed as natural language prompts, generating a
response indicating the predicted output. Nonetheless, the performance in such
settings often lags far behind its supervised counterpart, suggesting a large
space for potential improvement. In this paper, we explore methods to utilize
unlabeled data to improve zero-shot performance. Specifically, we take
advantage of the fact that multiple prompts can be used to specify a single
task, and propose to regularize prompt consistency, encouraging consistent
predictions over this diverse set of prompts. Our method makes it possible to
fine-tune the model either with extra unlabeled training data, or directly on
test input at inference time in an unsupervised manner. In experiments, our
approach outperforms the state-of-the-art zero-shot learner, T0 (Sanh et al.,
2022), on 9 out of 11 datasets across 4 NLP tasks by up to 10.6 absolute points
in terms of accuracy. The gains are often attained with a small number of
unlabeled examples."	ArXiv
2124	"Re-defining Radiology Quality Assurance (QA) -- Artificial Intelligence
  (AI)-Based QA by Restricted Investigation of Unequal Scores (AQUARIUS)"	['Axel Wismueller', 'Larry Stockmaster', 'Ali Vosoughi']	2022-05-02 02:56:28+00:00	http://arxiv.org/abs/2205.00629v2	"There is an urgent need for streamlining radiology Quality Assurance (QA)
programs to make them better and faster. Here, we present a novel approach,
Artificial Intelligence (AI)-Based QUality Assurance by Restricted
Investigation of Unequal Scores (AQUARIUS), for re-defining radiology QA, which
reduces human effort by up to several orders of magnitude over existing
approaches. AQUARIUS typically includes automatic comparison of AI-based image
analysis with natural language processing (NLP) on radiology reports. Only the
usually small subset of cases with discordant reads is subsequently reviewed by
human experts. To demonstrate the clinical applicability of AQUARIUS, we
performed a clinical QA study on Intracranial Hemorrhage (ICH) detection in
1936 head CT scans from a large academic hospital. Immediately following image
acquisition, scans were automatically analyzed for ICH using a commercially
available software (Aidoc, Tel Aviv, Israel). Cases rated positive for ICH by
AI (ICH-AI+) were automatically flagged in radiologists' reading worklists,
where flagging was randomly switched off with probability 50%. Using AQUARIUS
with NLP on final radiology reports and targeted expert neuroradiology review
of only 29 discordantly classified cases reduced the human QA effort by 98.5%,
where we found a total of six non-reported true ICH+ cases, with radiologists'
missed ICH detection rates of 0.52% and 2.5% for flagged and non-flagged cases,
respectively. We conclude that AQUARIUS, by combining AI-based image analysis
with NLP-based pre-selection of cases for targeted human expert review, can
efficiently identify missed findings in radiology studies and significantly
expedite radiology QA programs in a hybrid human-machine interoperability
approach."	ArXiv
2125	Towards Answering Open-ended Ethical Quandary Questions	['Yejin Bang', 'Nayeon Lee', 'Tiezheng Yu', 'Leila Khalatbari', 'Yan Xu', 'Samuel Cahyawijaya', 'Dan Su', 'Bryan Wilie', 'Romain Barraud', 'Elham J. Barezi', 'Andrea Madotto', 'Hayden Kee', 'Pascale Fung']	2022-05-12 09:52:59+00:00	http://arxiv.org/abs/2205.05989v3	"Considerable advancements have been made in various NLP tasks based on the
impressive power of large language models (LLMs) and many NLP applications are
deployed in our daily lives. In this work, we challenge the capability of LLMs
with the new task of Ethical Quandary Generative Question Answering. Ethical
quandary questions are more challenging to address because multiple conflicting
answers may exist to a single quandary. We explore the current capability of
LLMs in providing an answer with a deliberative exchange of different
perspectives to an ethical quandary, in the approach of Socratic philosophy,
instead of providing a closed answer like an oracle. We propose a model that
searches for different ethical principles applicable to the ethical quandary
and generates an answer conditioned on the chosen principles through
prompt-based few-shot learning. We also discuss the remaining challenges and
ethical issues involved in this task and suggest the direction toward
developing responsible NLP systems by incorporating human values explicitly."	ArXiv
2126	FedAdapter: Efficient Federated Learning for Modern NLP	['Dongqi Cai', 'Yaozong Wu', 'Shangguang Wang', 'Felix Xiaozhu Lin', 'Mengwei Xu']	2022-05-20 13:10:43+00:00	http://arxiv.org/abs/2205.10162v2	"Transformer-based pre-trained models have revolutionized NLP for superior
performance and generality. Fine-tuning pre-trained models for downstream tasks
often requires private data, for which federated learning is the de-facto
approach (i.e., FedNLP). However, our measurements show that FedNLP is
prohibitively slow due to the large model sizes and the resultant high
network/computation cost. Towards practical FedNLP, we identify as the key
building blocks adapters, small bottleneck modules inserted at a variety of
model layers. A key challenge is to properly configure the depth and width of
adapters, to which the training speed and efficiency is highly sensitive. No
silver-bullet configuration exists: the optimal choice varies across downstream
NLP tasks, desired model accuracy, and mobile resources. To automate adapter
configuration, we propose FedAdapter, a framework that enhances the existing
FedNLP with two novel designs. First, FedAdapter progressively upgrades the
adapter configuration throughout a training session; the principle is to
quickly learn shallow knowledge by only training fewer and smaller adapters at
the model's top layers, and incrementally learn deep knowledge by incorporating
deeper and larger adapters. Second, FedAdapter continuously profiles future
adapter configurations by allocating participant devices to trial groups.
Extensive experiments show that FedAdapter can reduce FedNLP's model
convergence delay to no more than several hours, which is up to 155.5$\times$
faster compared to vanilla FedNLP and 48$\times$ faster compared to strong
baselines."	ArXiv
2127	Toward Understanding Bias Correlations for Mitigation in NLP	['Lu Cheng', 'Suyu Ge', 'Huan Liu']	2022-05-24 22:48:47+00:00	http://arxiv.org/abs/2205.12391v1	"Natural Language Processing (NLP) models have been found discriminative
against groups of different social identities such as gender and race. With the
negative consequences of these undesired biases, researchers have responded
with unprecedented effort and proposed promising approaches for bias
mitigation. In spite of considerable practical importance, current algorithmic
fairness literature lacks an in-depth understanding of the relations between
different forms of biases. Social bias is complex by nature. Numerous studies
in social psychology identify the ""generalized prejudice"", i.e., generalized
devaluing sentiments across different groups. For example, people who devalue
ethnic minorities are also likely to devalue women and gays. Therefore, this
work aims to provide a first systematic study toward understanding bias
correlations in mitigation. In particular, we examine bias mitigation in two
common NLP tasks -- toxicity detection and word embeddings -- on three social
identities, i.e., race, gender, and religion. Our findings suggest that biases
are correlated and present scenarios in which independent debiasing approaches
dominant in current literature may be insufficient. We further investigate
whether jointly mitigating correlated biases is more desired than independent
and individual debiasing. Lastly, we shed light on the inherent issue of
debiasing-accuracy trade-off in bias mitigation. This study serves to motivate
future research on joint bias mitigation that accounts for correlated biases."	ArXiv
2128	"Do we need Label Regularization to Fine-tune Pre-trained Language
  Models?"	['Ivan Kobyzev', 'Aref Jafari', 'Mehdi Rezagholizadeh', 'Tianda Li', 'Alan Do-Omri', 'Peng Lu', 'Pascal Poupart', 'Ali Ghodsi']	2022-05-25 01:26:31+00:00	http://arxiv.org/abs/2205.12428v2	"Knowledge Distillation (KD) is a prominent neural model compression technique
that heavily relies on teacher network predictions to guide the training of a
student model. Considering the ever-growing size of pre-trained language models
(PLMs), KD is often adopted in many NLP tasks involving PLMs. However, it is
evident that in KD, deploying the teacher network during training adds to the
memory and computational requirements of training. In the computer vision
literature, the necessity of the teacher network is put under scrutiny by
showing that KD is a label regularization technique that can be replaced with
lighter teacher-free variants such as the label-smoothing technique. However,
to the best of our knowledge, this issue is not investigated in NLP. Therefore,
this work concerns studying different label regularization techniques and
whether we actually need them to improve the fine-tuning of smaller PLM
networks on downstream tasks. In this regard, we did a comprehensive set of
experiments on different PLMs such as BERT, RoBERTa, and GPT with more than 600
distinct trials and ran each configuration five times. This investigation led
to a surprising observation that KD and other label regularization techniques
do not play any meaningful role over regular fine-tuning when the student model
is pre-trained. We further explore this phenomenon in different settings of NLP
and computer vision tasks and demonstrate that pre-training itself acts as a
kind of regularization, and additional label regularization is unnecessary."	ArXiv
2129	"Evaluating the Diversity, Equity and Inclusion of NLP Technology: A Case
  Study for Indian Languages"	['Simran Khanuja', 'Sebastian Ruder', 'Partha Talukdar']	2022-05-25 11:38:04+00:00	http://arxiv.org/abs/2205.12676v3	"In order for NLP technology to be widely applicable, fair, and useful, it
needs to serve a diverse set of speakers across the world's languages, be
equitable, i.e., not unduly biased towards any particular language, and be
inclusive of all users, particularly in low-resource settings where compute
constraints are common. In this paper, we propose an evaluation paradigm that
assesses NLP technologies across all three dimensions. While diversity and
inclusion have received attention in recent literature, equity is currently
unexplored. We propose to address this gap using the Gini coefficient, a
well-established metric used for estimating societal wealth inequality. Using
our paradigm, we highlight the distressed state of current technologies for
Indian (IN) languages (a linguistically large and diverse set, with a varied
speaker population), across all three dimensions. To improve upon these
metrics, we demonstrate the importance of region-specific choices in model
building and dataset creation, and more importantly, propose a novel,
generalisable approach to optimal resource allocation during fine-tuning.
Finally, we discuss steps to mitigate these biases and encourage the community
to employ multi-faceted evaluation when building linguistically diverse and
equitable technologies."	ArXiv
2130	"NusaX: Multilingual Parallel Sentiment Dataset for 10 Indonesian Local
  Languages"	['Genta Indra Winata', 'Alham Fikri Aji', 'Samuel Cahyawijaya', 'Rahmad Mahendra', 'Fajri Koto', 'Ade Romadhony', 'Kemal Kurniawan', 'David Moeljadi', 'Radityo Eko Prasojo', 'Pascale Fung', 'Timothy Baldwin', 'Jey Han Lau', 'Rico Sennrich', 'Sebastian Ruder']	2022-05-31 17:03:50+00:00	http://arxiv.org/abs/2205.15960v2	"Natural language processing (NLP) has a significant impact on society via
technologies such as machine translation and search engines. Despite its
success, NLP technology is only widely available for high-resource languages
such as English and Chinese, while it remains inaccessible to many languages
due to the unavailability of data resources and benchmarks. In this work, we
focus on developing resources for languages in Indonesia. Despite being the
second most linguistically diverse country, most languages in Indonesia are
categorized as endangered and some are even extinct. We develop the first-ever
parallel resource for 10 low-resource languages in Indonesia. Our resource
includes datasets, a multi-task benchmark, and lexicons, as well as a parallel
Indonesian-English dataset. We provide extensive analyses and describe the
challenges when creating such resources. We hope that our work can spark NLP
research on Indonesian and other underrepresented languages."	ArXiv
2131	"Astock: A New Dataset and Automated Stock Trading based on
  Stock-specific News Analyzing Model"	['Jinan Zou', 'Haiyao Cao', 'Lingqiao Liu', 'Yuhao Lin', 'Ehsan Abbasnejad', 'Javen Qinfeng Shi']	2022-06-14 05:55:23+00:00	http://arxiv.org/abs/2206.06606v1	"Natural Language Processing(NLP) demonstrates a great potential to support
financial decision-making by analyzing the text from social media or news
outlets. In this work, we build a platform to study the NLP-aided stock
auto-trading algorithms systematically. In contrast to the previous work, our
platform is characterized by three features: (1) We provide financial news for
each specific stock. (2) We provide various stock factors for each stock. (3)
We evaluate performance from more financial-relevant metrics. Such a design
allows us to develop and evaluate NLP-aided stock auto-trading algorithms in a
more realistic setting. In addition to designing an evaluation platform and
dataset collection, we also made a technical contribution by proposing a system
to automatically learn a good feature representation from various input
information. The key to our algorithm is a method called semantic role labeling
Pooling (SRLP), which leverages Semantic Role Labeling (SRL) to create a
compact representation of each news paragraph. Based on SRLP, we further
incorporate other stock factors to make the final prediction. In addition, we
propose a self-supervised learning strategy based on SRLP to enhance the
out-of-distribution generalization performance of our system. Through our
experimental study, we show that the proposed method achieves better
performance and outperforms all the baselines' annualized rate of return as
well as the maximum drawdown of the CSI300 index and XIN9 index on real
trading. Our Astock dataset and code are available at
https://github.com/JinanZou/Astock."	ArXiv
2132	A Unified Understanding of Deep NLP Models for Text Classification	['Zhen Li', 'Xiting Wang', 'Weikai Yang', 'Jing Wu', 'Zhengyan Zhang', 'Zhiyuan Liu', 'Maosong Sun', 'Hui Zhang', 'Shixia Liu']	2022-06-19 08:55:07+00:00	http://arxiv.org/abs/2206.09355v1	"The rapid development of deep natural language processing (NLP) models for
text classification has led to an urgent need for a unified understanding of
these models proposed individually. Existing methods cannot meet the need for
understanding different models in one framework due to the lack of a unified
measure for explaining both low-level (e.g., words) and high-level (e.g.,
phrases) features. We have developed a visual analysis tool, DeepNLPVis, to
enable a unified understanding of NLP models for text classification. The key
idea is a mutual information-based measure, which provides quantitative
explanations on how each layer of a model maintains the information of input
words in a sample. We model the intra- and inter-word information at each layer
measuring the importance of a word to the final prediction as well as the
relationships between words, such as the formation of phrases. A multi-level
visualization, which consists of a corpus-level, a sample-level, and a
word-level visualization, supports the analysis from the overall training set
to individual samples. Two case studies on classification tasks and comparison
between models demonstrate that DeepNLPVis can help users effectively identify
potential problems caused by samples and model architectures and then make
informed improvements."	ArXiv
2133	Discovering Salient Neurons in Deep NLP Models	['Nadir Durrani', 'Fahim Dalvi', 'Hassan Sajjad']	2022-06-27 13:31:49+00:00	http://arxiv.org/abs/2206.13288v2	"While a lot of work has been done in understanding representations learned
within deep NLP models and what knowledge they capture, little attention has
been paid towards individual neurons. We present a technique called as
Linguistic Correlation Analysis to extract salient neurons in the model, with
respect to any extrinsic property - with the goal of understanding how such a
knowledge is preserved within neurons. We carry out a fine-grained analysis to
answer the following questions: (i) can we identify subsets of neurons in the
network that capture specific linguistic properties? (ii) how localized or
distributed neurons are across the network? iii) how redundantly is the
information preserved? iv) how fine-tuning pre-trained models towards
downstream NLP tasks, impacts the learned linguistic knowledge? iv) how do
architectures vary in learning different linguistic properties? Our
data-driven, quantitative analysis illuminates interesting findings: (i) we
found small subsets of neurons that can predict different linguistic tasks, ii)
with neurons capturing basic lexical information (such as suffixation)
localized in lower most layers, iii) while those learning complex concepts
(such as syntactic role) predominantly in middle and higher layers, iii) that
salient linguistic neurons are relocated from higher to lower layers during
transfer learning, as the network preserve the higher layers for task specific
information, iv) we found interesting differences across pre-trained models,
with respect to how linguistic information is preserved within, and v) we found
that concept exhibit similar neuron distribution across different languages in
the multilingual transformer models. Our code is publicly available as part of
the NeuroX toolkit."	ArXiv
2134	Improving Task Generalization via Unified Schema Prompt	['Wanjun Zhong', 'Yifan Gao', 'Ning Ding', 'Zhiyuan Liu', 'Ming Zhou', 'Jiahai Wang', 'Jian Yin', 'Nan Duan']	2022-08-05 15:26:36+00:00	http://arxiv.org/abs/2208.03229v1	"Task generalization has been a long standing challenge in Natural Language
Processing (NLP). Recent research attempts to improve the task generalization
ability of pre-trained language models by mapping NLP tasks into human-readable
prompted forms. However, these approaches require laborious and inflexible
manual collection of prompts, and different prompts on the same downstream task
may receive unstable performance. We propose Unified Schema Prompt, a flexible
and extensible prompting method, which automatically customizes the learnable
prompts for each task according to the task input schema. It models the shared
knowledge between tasks, while keeping the characteristics of different task
schema, and thus enhances task generalization ability. The schema prompt takes
the explicit data structure of each task to formulate prompts so that little
human effort is involved. To test the task generalization ability of schema
prompt at scale, we conduct schema prompt-based multitask pre-training on a
wide variety of general NLP tasks. The framework achieves strong zero-shot and
few-shot generalization performance on 16 unseen downstream tasks from 8 task
types (e.g., QA, NLI, etc). Furthermore, comprehensive analyses demonstrate the
effectiveness of each component in the schema prompt, its flexibility in task
compositionality, and its ability to improve performance under a full-data
fine-tuning setting."	ArXiv
2135	"Pre-trained Language Models for the Legal Domain: A Case Study on Indian
  Law"	['Shounak Paul', 'Arpan Mandal', 'Pawan Goyal', 'Saptarshi Ghosh']	2022-09-13 15:01:11+00:00	http://arxiv.org/abs/2209.06049v5	"NLP in the legal domain has seen increasing success with the emergence of
Transformer-based Pre-trained Language Models (PLMs) pre-trained on legal text.
PLMs trained over European and US legal text are available publicly; however,
legal text from other domains (countries), such as India, have a lot of
distinguishing characteristics. With the rapidly increasing volume of Legal NLP
applications in various countries, it has become necessary to pre-train such
LMs over legal text of other countries as well. In this work, we attempt to
investigate pre-training in the Indian legal domain. We re-train (continue
pre-training) two popular legal PLMs, LegalBERT and CaseLawBERT, on Indian
legal data, as well as train a model from scratch with a vocabulary based on
Indian legal text. We apply these PLMs over three benchmark legal NLP tasks --
Legal Statute Identification from facts, Semantic Segmentation of Court
Judgment Documents, and Court Appeal Judgment Prediction -- over both Indian
and non-Indian (EU, UK) datasets. We observe that our approach not only
enhances performance on the new domain (Indian texts) but also over the
original domain (European and UK texts). We also conduct explainability
experiments for a qualitative comparison of all these different PLMs."	ArXiv
2136	Enhance the Visual Representation via Discrete Adversarial Training	['Xiaofeng Mao', 'Yuefeng Chen', 'Ranjie Duan', 'Yao Zhu', 'Gege Qi', 'Shaokai Ye', 'Xiaodan Li', 'Rong Zhang', 'Hui Xue']	2022-09-16 06:25:06+00:00	http://arxiv.org/abs/2209.07735v1	"Adversarial Training (AT), which is commonly accepted as one of the most
effective approaches defending against adversarial examples, can largely harm
the standard performance, thus has limited usefulness on industrial-scale
production and applications. Surprisingly, this phenomenon is totally opposite
in Natural Language Processing (NLP) task, where AT can even benefit for
generalization. We notice the merit of AT in NLP tasks could derive from the
discrete and symbolic input space. For borrowing the advantage from NLP-style
AT, we propose Discrete Adversarial Training (DAT). DAT leverages VQGAN to
reform the image data to discrete text-like inputs, i.e. visual words. Then it
minimizes the maximal risk on such discrete images with symbolic adversarial
perturbations. We further give an explanation from the perspective of
distribution to demonstrate the effectiveness of DAT. As a plug-and-play
technique for enhancing the visual representation, DAT achieves significant
improvement on multiple tasks including image classification, object detection
and self-supervised learning. Especially, the model pre-trained with Masked
Auto-Encoding (MAE) and fine-tuned by our DAT without extra data can get 31.40
mCE on ImageNet-C and 32.77% top-1 accuracy on Stylized-ImageNet, building the
new state-of-the-art. The code will be available at
https://github.com/alibaba/easyrobust."	ArXiv
2137	"AfroLM: A Self-Active Learning-based Multilingual Pretrained Language
  Model for 23 African Languages"	['Bonaventure F. P. Dossou', 'Atnafu Lambebo Tonja', 'Oreen Yousuf', 'Salomey Osei', 'Abigail Oppong', 'Iyanuoluwa Shode', 'Oluwabusayo Olufunke Awoyomi', 'Chris Chinenye Emezue']	2022-11-07 02:15:25+00:00	http://arxiv.org/abs/2211.03263v2	"In recent years, multilingual pre-trained language models have gained
prominence due to their remarkable performance on numerous downstream Natural
Language Processing tasks (NLP). However, pre-training these large multilingual
language models requires a lot of training data, which is not available for
African Languages. Active learning is a semi-supervised learning algorithm, in
which a model consistently and dynamically learns to identify the most
beneficial samples to train itself on, in order to achieve better optimization
and performance on downstream tasks. Furthermore, active learning effectively
and practically addresses real-world data scarcity. Despite all its benefits,
active learning, in the context of NLP and especially multilingual language
models pretraining, has received little consideration. In this paper, we
present AfroLM, a multilingual language model pretrained from scratch on 23
African languages (the largest effort to date) using our novel self-active
learning framework. Pretrained on a dataset significantly (14x) smaller than
existing baselines, AfroLM outperforms many multilingual pretrained language
models (AfriBERTa, XLMR-base, mBERT) on various NLP downstream tasks (NER, text
classification, and sentiment analysis). Additional out-of-domain sentiment
analysis experiments show that \textbf{AfroLM} is able to generalize well
across various domains. We release the code source, and our datasets used in
our framework at https://github.com/bonaventuredossou/MLM_AL."	ArXiv
2138	"Bridging Fairness and Environmental Sustainability in Natural Language
  Processing"	['Marius Hessenthaler', 'Emma Strubell', 'Dirk Hovy', 'Anne Lauscher']	2022-11-08 14:05:07+00:00	http://arxiv.org/abs/2211.04256v1	"Fairness and environmental impact are important research directions for the
sustainable development of artificial intelligence. However, while each topic
is an active research area in natural language processing (NLP), there is a
surprising lack of research on the interplay between the two fields. This
lacuna is highly problematic, since there is increasing evidence that an
exclusive focus on fairness can actually hinder environmental sustainability,
and vice versa. In this work, we shed light on this crucial intersection in NLP
by (1) investigating the efficiency of current fairness approaches through
surveying example methods for reducing unfair stereotypical bias from the
literature, and (2) evaluating a common technique to reduce energy consumption
(and thus environmental impact) of English NLP models, knowledge distillation
(KD), for its impact on fairness. In this case study, we evaluate the effect of
important KD factors, including layer and dimensionality reduction, with
respect to: (a) performance on the distillation task (natural language
inference and semantic similarity prediction), and (b) multiple measures and
dimensions of stereotypical bias (e.g., gender bias measured via the Word
Embedding Association Test). Our results lead us to clarify current assumptions
regarding the effect of KD on unfair bias: contrary to other findings, we show
that KD can actually decrease model fairness."	ArXiv
2139	A Universal Discriminator for Zero-Shot Generalization	['Haike Xu', 'Zongyu Lin', 'Jing Zhou', 'Yanan Zheng', 'Zhilin Yang']	2022-11-15 12:33:31+00:00	http://arxiv.org/abs/2211.08099v2	"Generative modeling has been the dominant approach for large-scale
pretraining and zero-shot generalization. In this work, we challenge this
convention by showing that discriminative approaches perform substantially
better than generative ones on a large number of NLP tasks. Technically, we
train a single discriminator to predict whether a text sample comes from the
true data distribution, similar to GANs. Since many NLP tasks can be formulated
as selecting from a few options, we use this discriminator to predict the
concatenation of input and which option has the highest probability of coming
from the true data distribution. This simple formulation achieves
state-of-the-art zero-shot results on the T0 benchmark, outperforming T0 by
16.0\%, 7.8\%, and 11.5\% respectively on different scales. In the finetuning
setting, our approach also achieves new state-of-the-art results on a wide
range of NLP tasks, with only 1/4 parameters of previous methods. Meanwhile,
our approach requires minimal prompting efforts, which largely improves
robustness and is essential for real-world applications. Furthermore, we also
jointly train a generalized UD in combination with generative tasks, which
maintains its advantage on discriminative tasks and simultaneously works on
generative tasks."	ArXiv
2140	"PyTAIL: Interactive and Incremental Learning of NLP Models with Human in
  the Loop for Online Data"	['Shubhanshu Mishra', 'Jana Diesner']	2022-11-24 20:08:15+00:00	http://arxiv.org/abs/2211.13786v1	"Online data streams make training machine learning models hard because of
distribution shift and new patterns emerging over time. For natural language
processing (NLP) tasks that utilize a collection of features based on lexicons
and rules, it is important to adapt these features to the changing data. To
address this challenge we introduce PyTAIL, a python library, which allows a
human in the loop approach to actively train NLP models. PyTAIL enhances
generic active learning, which only suggests new instances to label by also
suggesting new features like rules and lexicons to label. Furthermore, PyTAIL
is flexible enough for users to accept, reject, or update rules and lexicons as
the model is being trained. Finally, we simulate the performance of PyTAIL on
existing social media benchmark datasets for text classification. We compare
various active learning strategies on these benchmarks. The model closes the
gap with as few as 10% of the training data. Finally, we also highlight the
importance of tracking evaluation metric on remaining data (which is not yet
merged with active learning) alongside the test dataset. This highlights the
effectiveness of the model in accurately annotating the remaining dataset,
which is especially suitable for batch processing of large unlabelled corpora.
PyTAIL will be available at https://github.com/socialmediaie/pytail."	ArXiv
2141	"Multi-View Knowledge Distillation from Crowd Annotations for
  Out-of-Domain Generalization"	['Dustin Wright', 'Isabelle Augenstein']	2022-12-19 12:40:18+00:00	http://arxiv.org/abs/2212.09409v2	"Selecting an effective training signal for tasks in natural language
processing is difficult: expert annotations are expensive, and crowd-sourced
annotations may not be reliable. At the same time, recent work in NLP has
demonstrated that learning from a distribution over labels acquired from crowd
annotations can be effective. However, there are many ways to acquire such a
distribution, and the performance allotted by any one method can fluctuate
based on the task and the amount of available crowd annotations, making it
difficult to know a priori which distribution is best. This paper
systematically analyzes this in the out-of-domain setting, adding to the NLP
literature which has focused on in-domain evaluation, and proposes new methods
for acquiring soft-labels from crowd-annotations by aggregating the
distributions produced by existing methods. In particular, we propose to
aggregate multiple-views of crowd annotations via temperature scaling and
finding their Jensen-Shannon centroid. We demonstrate that these aggregation
methods lead to the most consistent performance across four NLP tasks on
out-of-domain test sets, mitigating fluctuations in performance from the
individual distributions. Additionally, aggregation results in the most
consistently well-calibrated uncertainty estimation. We argue that aggregating
different views of crowd-annotations is an effective and minimal intervention
to acquire soft-labels which induce robust classifiers despite the
inconsistency of the individual soft-labeling methods."	ArXiv
2142	"Training language models to summarize narratives improves brain
  alignment"	['Khai Loong Aw', 'Mariya Toneva']	2022-12-21 10:15:19+00:00	http://arxiv.org/abs/2212.10898v2	"Building systems that achieve a deeper understanding of language is one of
the central goals of natural language processing (NLP). Towards this goal,
recent works have begun to train language models on narrative datasets which
require extracting the most critical information by integrating across long
contexts. However, it is still an open question whether these models are
learning a deeper understanding of the text, or if the models are simply
learning a heuristic to complete the task. This work investigates this further
by turning to the one language processing system that truly understands complex
language: the human brain. We show that training language models for deeper
narrative understanding results in richer representations that have improved
alignment to human brain activity. We further find that the improvements in
brain alignment are larger for character names than for other discourse
features, which indicates that these models are learning important narrative
elements. Taken together, these results suggest that this type of training can
indeed lead to deeper language understanding. These findings have consequences
both for cognitive neuroscience by revealing some of the significant factors
behind brain-NLP alignment, and for NLP by highlighting that understanding of
long-range context can be improved beyond language modeling."	ArXiv
2143	Tsetlin Machine Embedding: Representing Words Using Logical Expressions	['Bimal Bhattarai', 'Ole-Christoffer Granmo', 'Lei Jiao', 'Rohan Yadav', 'Jivitesh Sharma']	2023-01-02 15:02:45+00:00	http://arxiv.org/abs/2301.00709v1	"Embedding words in vector space is a fundamental first step in
state-of-the-art natural language processing (NLP). Typical NLP solutions
employ pre-defined vector representations to improve generalization by
co-locating similar words in vector space. For instance, Word2Vec is a
self-supervised predictive model that captures the context of words using a
neural network. Similarly, GLoVe is a popular unsupervised model incorporating
corpus-wide word co-occurrence statistics. Such word embedding has
significantly boosted important NLP tasks, including sentiment analysis,
document classification, and machine translation. However, the embeddings are
dense floating-point vectors, making them expensive to compute and difficult to
interpret. In this paper, we instead propose to represent the semantics of
words with a few defining words that are related using propositional logic. To
produce such logical embeddings, we introduce a Tsetlin Machine-based
autoencoder that learns logical clauses self-supervised. The clauses consist of
contextual words like ""black,"" ""cup,"" and ""hot"" to define other words like
""coffee,"" thus being human-understandable. We evaluate our embedding approach
on several intrinsic and extrinsic benchmarks, outperforming GLoVe on six
classification tasks. Furthermore, we investigate the interpretability of our
embedding using the logical representations acquired during training. We also
visualize word clusters in vector space, demonstrating how our logical
embedding co-locate similar words."	ArXiv
2144	"NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental
  Health on Social Media"	['Muskan Garg', 'Chandni Saxena', 'Usman Naseem', 'Bonnie J Dorr']	2023-01-26 09:26:01+00:00	http://arxiv.org/abs/2301.11004v5	"Interactions among humans on social media often convey intentions behind
their actions, yielding a psychological language resource for Mental Health
Analysis (MHA) of online users. The success of Computational Intelligence
Techniques (CIT) for inferring mental illness from such social media resources
points to NLP as a lens for causal analysis and perception mining. However, we
argue that more consequential and explainable research is required for optimal
impact on clinical psychology practice and personalized mental healthcare. To
bridge this gap, we posit two significant dimensions: (1) Causal analysis to
illustrate a cause and effect relationship in the user generated text; (2)
Perception mining to infer psychological perspectives of social effects on
online users intentions. Within the scope of Natural Language Processing (NLP),
we further explore critical areas of inquiry associated with these two
dimensions, specifically through recent advancements in discourse analysis.
This position paper guides the community to explore solutions in this space and
advance the state of practice in developing conversational agents for inferring
mental health from social media. We advocate for a more explainable approach
toward modeling computational psychology problems through the lens of language
as we observe an increased number of research contributions in dataset and
problem formulation for causal relation extraction and perception enhancements
while inferring mental states."	ArXiv
2145	Theme-driven Keyphrase Extraction to Analyze Social Media Discourse	['William Romano', 'Omar Sharif', 'Madhusudan Basak', 'Joseph Gatto', 'Sarah Preum']	2023-01-27 03:00:46+00:00	http://arxiv.org/abs/2301.11508v2	"Social media platforms are vital resources for sharing self-reported health
experiences, offering rich data on various health topics. Despite advancements
in Natural Language Processing (NLP) enabling large-scale social media data
analysis, a gap remains in applying keyphrase extraction to health-related
content. Keyphrase extraction is used to identify salient concepts in social
media discourse without being constrained by predefined entity classes. This
paper introduces a theme-driven keyphrase extraction framework tailored for
social media, a pioneering approach designed to capture clinically relevant
keyphrases from user-generated health texts. Themes are defined as broad
categories determined by the objectives of the extraction task. We formulate
this novel task of theme-driven keyphrase extraction and demonstrate its
potential for efficiently mining social media text for the use case of
treatment for opioid use disorder. This paper leverages qualitative and
quantitative analysis to demonstrate the feasibility of extracting actionable
insights from social media data and efficiently extracting keyphrases using
minimally supervised NLP models. Our contributions include the development of a
novel data collection and curation framework for theme-driven keyphrase
extraction and the creation of MOUD-Keyphrase, the first dataset of its kind
comprising human-annotated keyphrases from a Reddit community. We also identify
the scope of minimally supervised NLP models to extract keyphrases from social
media data efficiently. Lastly, we found that a large language model (ChatGPT)
outperforms unsupervised keyphrase extraction models, and we evaluate its
efficacy in this task."	ArXiv
2146	idT5: Indonesian Version of Multilingual T5 Transformer	['Mukhlish Fuadi', 'Adhi Dharma Wibawa', 'Surya Sumpeno']	2023-02-02 03:56:16+00:00	http://arxiv.org/abs/2302.00856v2	"Indonesian language is spoken by almost 200 million people and is the 10th
most spoken language in the world, but it is under-represented in NLP (Natural
Language Processing) research. A sparsity of language resources has hampered
previous work on Indonesian. The Transformer is a new architecture rapidly
becoming dominant for NLP, surpassing alternatives like convolutional and
recurrent neural networks. T5 (Text-to-Text Transfer Transformer) is a
Transformer model that converts all text-based language problems to
text-to-text format for English. The multilingual variant is mT5 (multilingual
T5) which has shown promising results on many NLP tasks across languages.
However, the size of this multilingual model is a drawback for its application
in real production applications, which sometimes require only one language. In
this study, the mT5 model was adapted for only one language, Indonesian,
resulting in a pre-trained T5 model that was specific only for Indonesian with
a smaller size. For performance comparison, we fine-tuned this model and the
mT5 model to the Sentiment Analysis (SA), Question Generation (QG), and
Question Answering (QA) tasks with the exact mechanism and dataset. Fine-tuned
model based on our model achieved 77.18% accuracy on SA, 8% higher than the
mT5-based model, and obtained nearly the same score as the mT5-based model on
QG and QA. The results confirm that it is possible to produce a smaller
pre-trained model that maintains comparable yields while reducing the model
size by up to 58%. In addition, the resulting model requires less memory, loads
faster, and inference times faster."	ArXiv
2147	"Bioformer: an efficient transformer language model for biomedical text
  mining"	['Li Fang', 'Qingyu Chen', 'Chih-Hsuan Wei', 'Zhiyong Lu', 'Kai Wang']	2023-02-03 08:04:59+00:00	http://arxiv.org/abs/2302.01588v1	"Pretrained language models such as Bidirectional Encoder Representations from
Transformers (BERT) have achieved state-of-the-art performance in natural
language processing (NLP) tasks. Recently, BERT has been adapted to the
biomedical domain. Despite the effectiveness, these models have hundreds of
millions of parameters and are computationally expensive when applied to
large-scale NLP applications. We hypothesized that the number of parameters of
the original BERT can be dramatically reduced with minor impact on performance.
In this study, we present Bioformer, a compact BERT model for biomedical text
mining. We pretrained two Bioformer models (named Bioformer8L and Bioformer16L)
which reduced the model size by 60% compared to BERTBase. Bioformer uses a
biomedical vocabulary and was pre-trained from scratch on PubMed abstracts and
PubMed Central full-text articles. We thoroughly evaluated the performance of
Bioformer as well as existing biomedical BERT models including BioBERT and
PubMedBERT on 15 benchmark datasets of four different biomedical NLP tasks:
named entity recognition, relation extraction, question answering and document
classification. The results show that with 60% fewer parameters, Bioformer16L
is only 0.1% less accurate than PubMedBERT while Bioformer8L is 0.9% less
accurate than PubMedBERT. Both Bioformer16L and Bioformer8L outperformed
BioBERTBase-v1.1. In addition, Bioformer16L and Bioformer8L are 2-3 fold as
fast as PubMedBERT/BioBERTBase-v1.1. Bioformer has been successfully deployed
to PubTator Central providing gene annotations over 35 million PubMed abstracts
and 5 million PubMed Central full-text articles. We make Bioformer publicly
available via https://github.com/WGLab/bioformer, including pre-trained models,
datasets, and instructions for downstream use."	ArXiv
2148	Lightweight Transformers for Clinical Natural Language Processing	['Omid Rohanian', 'Mohammadmahdi Nouriborji', 'Hannah Jauncey', 'Samaneh Kouchaki', 'ISARIC Clinical Characterisation Group', 'Lei Clifton', 'Laura Merson', 'David A. Clifton']	2023-02-09 16:07:31+00:00	http://arxiv.org/abs/2302.04725v1	"Specialised pre-trained language models are becoming more frequent in NLP
since they can potentially outperform models trained on generic texts. BioBERT
and BioClinicalBERT are two examples of such models that have shown promise in
medical NLP tasks. Many of these models are overparametrised and
resource-intensive, but thanks to techniques like Knowledge Distillation (KD),
it is possible to create smaller versions that perform almost as well as their
larger counterparts. In this work, we specifically focus on development of
compact language models for processing clinical texts (i.e. progress notes,
discharge summaries etc). We developed a number of efficient lightweight
clinical transformers using knowledge distillation and continual learning, with
the number of parameters ranging from 15 million to 65 million. These models
performed comparably to larger models such as BioBERT and ClinicalBioBERT and
significantly outperformed other compact models trained on general or
biomedical data. Our extensive evaluation was done across several standard
datasets and covered a wide range of clinical text-mining tasks, including
Natural Language Inference, Relation Extraction, Named Entity Recognition, and
Sequence Classification. To our knowledge, this is the first comprehensive
study specifically focused on creating efficient and compact transformers for
clinical NLP tasks. The models and code used in this study can be found on our
Huggingface profile at https://huggingface.co/nlpie and Github page at
https://github.com/nlpie-research/Lightweight-Clinical-Transformers,
respectively, promoting reproducibility of our results."	ArXiv
2149	"Contextualized Medication Information Extraction Using Transformer-based
  Deep Learning Architectures"	['Aokun Chen', 'Zehao Yu', 'Xi Yang', 'Yi Guo', 'Jiang Bian', 'Yonghui Wu']	2023-03-14 22:22:28+00:00	http://arxiv.org/abs/2303.08259v1	"Objective: To develop a natural language processing (NLP) system to extract
medications and contextual information that help understand drug changes. This
project is part of the 2022 n2c2 challenge.
  Materials and methods: We developed NLP systems for medication mention
extraction, event classification (indicating medication changes discussed or
not), and context classification to classify medication changes context into 5
orthogonal dimensions related to drug changes. We explored 6 state-of-the-art
pretrained transformer models for the three subtasks, including GatorTron, a
large language model pretrained using >90 billion words of text (including >80
billion words from >290 million clinical notes identified at the University of
Florida Health). We evaluated our NLP systems using annotated data and
evaluation scripts provided by the 2022 n2c2 organizers.
  Results:Our GatorTron models achieved the best F1-scores of 0.9828 for
medication extraction (ranked 3rd), 0.9379 for event classification (ranked
2nd), and the best micro-average accuracy of 0.9126 for context classification.
GatorTron outperformed existing transformer models pretrained using smaller
general English text and clinical text corpora, indicating the advantage of
large language models.
  Conclusion: This study demonstrated the advantage of using large transformer
models for contextual medication information extraction from clinical
narratives."	ArXiv
2150	"An Empirical Study of Pre-trained Language Models in Simple Knowledge
  Graph Question Answering"	['Nan Hu', 'Yike Wu', 'Guilin Qi', 'Dehai Min', 'Jiaoyan Chen', 'Jeff Z. Pan', 'Zafar Ali']	2023-03-18 08:57:09+00:00	http://arxiv.org/abs/2303.10368v1	"Large-scale pre-trained language models (PLMs) such as BERT have recently
achieved great success and become a milestone in natural language processing
(NLP). It is now the consensus of the NLP community to adopt PLMs as the
backbone for downstream tasks. In recent works on knowledge graph question
answering (KGQA), BERT or its variants have become necessary in their KGQA
models. However, there is still a lack of comprehensive research and comparison
of the performance of different PLMs in KGQA. To this end, we summarize two
basic KGQA frameworks based on PLMs without additional neural network modules
to compare the performance of nine PLMs in terms of accuracy and efficiency. In
addition, we present three benchmarks for larger-scale KGs based on the popular
SimpleQuestions benchmark to investigate the scalability of PLMs. We carefully
analyze the results of all PLMs-based KGQA basic frameworks on these benchmarks
and two other popular datasets, WebQuestionSP and FreebaseQA, and find that
knowledge distillation techniques and knowledge enhancement methods in PLMs are
promising for KGQA. Furthermore, we test ChatGPT, which has drawn a great deal
of attention in the NLP community, demonstrating its impressive capabilities
and limitations in zero-shot KGQA. We have released the code and benchmarks to
promote the use of PLMs on KGQA."	ArXiv
2151	"Exploring Natural Language Processing Methods for Interactive Behaviour
  Modelling"	['Guanhua Zhang', 'Matteo Bortoletto', 'Zhiming Hu', 'Lei Shi', 'Mihai Bâce', 'Andreas Bulling']	2023-03-28 15:15:03+00:00	http://arxiv.org/abs/2303.16039v2	"Analysing and modelling interactive behaviour is an important topic in
human-computer interaction (HCI) and a key requirement for the development of
intelligent interactive systems. Interactive behaviour has a sequential
(actions happen one after another) and hierarchical (a sequence of actions
forms an activity driven by interaction goals) structure, which may be similar
to the structure of natural language. Designed based on such a structure,
natural language processing (NLP) methods have achieved groundbreaking success
in various downstream tasks. However, few works linked interactive behaviour
with natural language. In this paper, we explore the similarity between
interactive behaviour and natural language by applying an NLP method, byte pair
encoding (BPE), to encode mouse and keyboard behaviour. We then analyse the
vocabulary, i.e., the set of action sequences, learnt by BPE, as well as use
the vocabulary to encode the input behaviour for interactive task recognition.
An existing dataset collected in constrained lab settings and our novel
out-of-the-lab dataset were used for evaluation. Results show that this natural
language-inspired approach not only learns action sequences that reflect
specific interaction goals, but also achieves higher F1 scores on task
recognition than other methods. Our work reveals the similarity between
interactive behaviour and natural language, and presents the potential of
applying the new pack of methods that leverage insights from NLP to model
interactive behaviour in HCI."	ArXiv
2152	"Attention is Not Always What You Need: Towards Efficient Classification
  of Domain-Specific Text"	['Yasmen Wahba', 'Nazim Madhavji', 'John Steinbacher']	2023-03-31 03:17:23+00:00	http://arxiv.org/abs/2303.17786v1	"For large-scale IT corpora with hundreds of classes organized in a hierarchy,
the task of accurate classification of classes at the higher level in the
hierarchies is crucial to avoid errors propagating to the lower levels. In the
business world, an efficient and explainable ML model is preferred over an
expensive black-box model, especially if the performance increase is marginal.
A current trend in the Natural Language Processing (NLP) community is towards
employing huge pre-trained language models (PLMs) or what is known as
self-attention models (e.g., BERT) for almost any kind of NLP task (e.g.,
question-answering, sentiment analysis, text classification). Despite the
widespread use of PLMs and the impressive performance in a broad range of NLP
tasks, there is a lack of a clear and well-justified need to as why these
models are being employed for domain-specific text classification (TC) tasks,
given the monosemic nature of specialized words (i.e., jargon) found in
domain-specific text which renders the purpose of contextualized embeddings
(e.g., PLMs) futile. In this paper, we compare the accuracies of some
state-of-the-art (SOTA) models reported in the literature against a Linear SVM
classifier and TFIDF vectorization model on three TC datasets. Results show a
comparable performance for the LinearSVM. The findings of this study show that
for domain-specific TC tasks, a linear model can provide a comparable, cheap,
reproducible, and interpretable alternative to attention-based models."	ArXiv
2153	"Identifying Symptoms of Delirium from Clinical Narratives Using Natural
  Language Processing"	['Aokun Chen', 'Daniel Paredes', 'Zehao Yu', 'Xiwei Lou', 'Roberta Brunson', 'Jamie N. Thomas', 'Kimberly A. Martinez', 'Robert J. Lucero', 'Tanja Magoc', 'Laurence M. Solberg', 'Urszula A. Snigurska', 'Sarah E. Ser', 'Mattia Prosperi', 'Jiang Bian', 'Ragnhildur I. Bjarnadottir', 'Yonghui Wu']	2023-03-31 20:16:44+00:00	http://arxiv.org/abs/2304.00111v1	"Delirium is an acute decline or fluctuation in attention, awareness, or other
cognitive function that can lead to serious adverse outcomes. Despite the
severe outcomes, delirium is frequently unrecognized and uncoded in patients'
electronic health records (EHRs) due to its transient and diverse nature.
Natural language processing (NLP), a key technology that extracts medical
concepts from clinical narratives, has shown great potential in studies of
delirium outcomes and symptoms. To assist in the diagnosis and phenotyping of
delirium, we formed an expert panel to categorize diverse delirium symptoms,
composed annotation guidelines, created a delirium corpus with diverse delirium
symptoms, and developed NLP methods to extract delirium symptoms from clinical
notes. We compared 5 state-of-the-art transformer models including 2 models
(BERT and RoBERTa) from the general domain and 3 models (BERT_MIMIC,
RoBERTa_MIMIC, and GatorTron) from the clinical domain. GatorTron achieved the
best strict and lenient F1 scores of 0.8055 and 0.8759, respectively. We
conducted an error analysis to identify challenges in annotating delirium
symptoms and developing NLP systems. To the best of our knowledge, this is the
first large language model-based delirium symptom extraction system. Our study
lays the foundation for the future development of computable phenotypes and
diagnosis methods for delirium."	ArXiv
2154	"PromptAid: Prompt Exploration, Perturbation, Testing and Iteration using
  Visual Analytics for Large Language Models"	['Aditi Mishra', 'Utkarsh Soni', 'Anjana Arunkumar', 'Jinbin Huang', 'Bum Chul Kwon', 'Chris Bryan']	2023-04-04 17:14:54+00:00	http://arxiv.org/abs/2304.01964v2	"Large Language Models (LLMs) have gained widespread popularity due to their
ability to perform ad-hoc Natural Language Processing (NLP) tasks with a simple
natural language prompt. Part of the appeal for LLMs is their approachability
to the general public, including individuals with no prior technical experience
in NLP techniques. However, natural language prompts can vary significantly in
terms of their linguistic structure, context, and other semantics. Modifying
one or more of these aspects can result in significant differences in task
performance. Non-expert users may find it challenging to identify the changes
needed to improve a prompt, especially when they lack domain-specific knowledge
and lack appropriate feedback. To address this challenge, we present PromptAid,
a visual analytics system designed to interactively create, refine, and test
prompts through exploration, perturbation, testing, and iteration. PromptAid
uses multiple, coordinated visualizations which allow users to improve prompts
by using the three strategies: keyword perturbations, paraphrasing
perturbations, and obtaining the best set of in-context few-shot examples.
PromptAid was designed through an iterative prototyping process involving NLP
experts and was evaluated through quantitative and qualitative assessments for
LLMs. Our findings indicate that PromptAid helps users to iterate over prompt
template alterations with less cognitive overhead, generate diverse prompts
with help of recommendations, and analyze the performance of the generated
prompts while surpassing existing state-of-the-art prompting interfaces in
performance."	ArXiv
2155	"GPT4Rec: A Generative Framework for Personalized Recommendation and User
  Interests Interpretation"	['Jinming Li', 'Wentao Zhang', 'Tian Wang', 'Guanglei Xiong', 'Alan Lu', 'Gerard Medioni']	2023-04-08 00:30:08+00:00	http://arxiv.org/abs/2304.03879v1	"Recent advancements in Natural Language Processing (NLP) have led to the
development of NLP-based recommender systems that have shown superior
performance. However, current models commonly treat items as mere IDs and adopt
discriminative modeling, resulting in limitations of (1) fully leveraging the
content information of items and the language modeling capabilities of NLP
models; (2) interpreting user interests to improve relevance and diversity; and
(3) adapting practical circumstances such as growing item inventories. To
address these limitations, we present GPT4Rec, a novel and flexible generative
framework inspired by search engines. It first generates hypothetical ""search
queries"" given item titles in a user's history, and then retrieves items for
recommendation by searching these queries. The framework overcomes previous
limitations by learning both user and item embeddings in the language space. To
well-capture user interests with different aspects and granularity for
improving relevance and diversity, we propose a multi-query generation
technique with beam search. The generated queries naturally serve as
interpretable representations of user interests and can be searched to
recommend cold-start items. With GPT-2 language model and BM25 search engine,
our framework outperforms state-of-the-art methods by $75.7\%$ and $22.2\%$ in
Recall@K on two public datasets. Experiments further revealed that multi-query
generation with beam search improves both the diversity of retrieved items and
the coverage of a user's multi-interests. The adaptiveness and interpretability
of generated queries are discussed with qualitative case studies."	ArXiv
2156	Topological properties and organizing principles of semantic networks	['Gabriel Budel', 'Ying Jin', 'Piet Van Mieghem', 'Maksim Kitsak']	2023-04-24 11:12:21+00:00	http://arxiv.org/abs/2304.12940v2	"Interpreting natural language is an increasingly important task in computer
algorithms due to the growing availability of unstructured textual data.
Natural Language Processing (NLP) applications rely on semantic networks for
structured knowledge representation. The fundamental properties of semantic
networks must be taken into account when designing NLP algorithms, yet they
remain to be structurally investigated. We study the properties of semantic
networks from ConceptNet, defined by 7 semantic relations from 11 different
languages. We find that semantic networks have universal basic properties: they
are sparse, highly clustered, and many exhibit power-law degree distributions.
Our findings show that the majority of the considered networks are scale-free.
Some networks exhibit language-specific properties determined by grammatical
rules, for example networks from highly inflected languages, such as e.g.
Latin, German, French and Spanish, show peaks in the degree distribution that
deviate from a power law. We find that depending on the semantic relation type
and the language, the link formation in semantic networks is guided by
different principles. In some networks the connections are similarity-based,
while in others the connections are more complementarity-based. Finally, we
demonstrate how knowledge of similarity and complementarity in semantic
networks can improve NLP algorithms in missing link inference."	ArXiv
2157	Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond	['Jingfeng Yang', 'Hongye Jin', 'Ruixiang Tang', 'Xiaotian Han', 'Qizhang Feng', 'Haoming Jiang', 'Bing Yin', 'Xia Hu']	2023-04-26 17:52:30+00:00	http://arxiv.org/abs/2304.13712v2	"This paper presents a comprehensive and practical guide for practitioners and
end-users working with Large Language Models (LLMs) in their downstream natural
language processing (NLP) tasks. We provide discussions and insights into the
usage of LLMs from the perspectives of models, data, and downstream tasks.
Firstly, we offer an introduction and brief summary of current GPT- and
BERT-style LLMs. Then, we discuss the influence of pre-training data, training
data, and test data. Most importantly, we provide a detailed discussion about
the use and non-use cases of large language models for various natural language
processing tasks, such as knowledge-intensive tasks, traditional natural
language understanding tasks, natural language generation tasks, emergent
abilities, and considerations for specific tasks.We present various use cases
and non-use cases to illustrate the practical applications and limitations of
LLMs in real-world scenarios. We also try to understand the importance of data
and the specific challenges associated with each NLP task. Furthermore, we
explore the impact of spurious biases on LLMs and delve into other essential
considerations, such as efficiency, cost, and latency, to ensure a
comprehensive understanding of deploying LLMs in practice. This comprehensive
guide aims to provide researchers and practitioners with valuable insights and
best practices for working with LLMs, thereby enabling the successful
implementation of these models in a wide range of NLP tasks. A curated list of
practical guide resources of LLMs, regularly updated, can be found at
\url{https://github.com/Mooler0410/LLMsPracticalGuide}."	ArXiv
2158	"COCKATIEL: COntinuous Concept ranKed ATtribution with Interpretable
  ELements for explaining neural net classifiers on NLP tasks"	['Fanny Jourdan', 'Agustin Picard', 'Thomas Fel', 'Laurent Risser', 'Jean Michel Loubes', 'Nicholas Asher']	2023-05-11 12:22:20+00:00	http://arxiv.org/abs/2305.06754v2	"Transformer architectures are complex and their use in NLP, while it has
engendered many successes, makes their interpretability or explainability
challenging. Recent debates have shown that attention maps and attribution
methods are unreliable (Pruthi et al., 2019; Brunner et al., 2019). In this
paper, we present some of their limitations and introduce COCKATIEL, which
successfully addresses some of them. COCKATIEL is a novel, post-hoc,
concept-based, model-agnostic XAI technique that generates meaningful
explanations from the last layer of a neural net model trained on an NLP
classification task by using Non-Negative Matrix Factorization (NMF) to
discover the concepts the model leverages to make predictions and by exploiting
a Sensitivity Analysis to estimate accurately the importance of each of these
concepts for the model. It does so without compromising the accuracy of the
underlying model or requiring a new one to be trained. We conduct experiments
in single and multi-aspect sentiment analysis tasks and we show COCKATIEL's
superior ability to discover concepts that align with humans' on Transformer
models without any supervision, we objectively verify the faithfulness of its
explanations through fidelity metrics, and we showcase its ability to provide
meaningful explanations in two different datasets."	ArXiv
2159	Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning	['Saibo Geng', 'Martin Josifoski', 'Maxime Peyrard', 'Robert West']	2023-05-23 11:54:37+00:00	http://arxiv.org/abs/2305.13971v6	"Despite their impressive performance, large language models (LMs) still
struggle with reliably generating complex output structures when not finetuned
to follow the required output format exactly. To address this issue,
grammar-constrained decoding (GCD) can be used to control the generation of
LMs, guaranteeing that the output follows a given structure. Most existing GCD
methods are, however, limited to specific tasks, such as parsing or code
generation. In this work, we demonstrate that formal grammars can describe the
output space for a much wider range of tasks and argue that GCD can serve as a
unified framework for structured NLP tasks in general. For increased
flexibility, we introduce input-dependent grammars, which allow the grammar to
depend on the input and thus enable the generation of different output
structures for different inputs. We then empirically demonstrate the power and
flexibility of GCD-enhanced LMs on (1) information extraction, (2) entity
disambiguation, and (3) constituency parsing. Our results indicate that
grammar-constrained LMs substantially outperform unconstrained LMs or even beat
task-specific finetuned models. Grammar constraints thus hold great promise for
harnessing off-the-shelf LMs for a wide range of structured NLP tasks,
especially where training data is scarce or finetuning is expensive. Code and
data: https://github.com/epfl-dlab/GCD."	ArXiv
2160	An Empirical Study on Information Extraction using Large Language Models	['Ridong Han', 'Chaohao Yang', 'Tao Peng', 'Prayag Tiwari', 'Xiang Wan', 'Lu Liu', 'Benyou Wang']	2023-05-23 18:17:43+00:00	http://arxiv.org/abs/2305.14450v2	"Human-like large language models (LLMs), especially the most powerful and
popular ones in OpenAI's GPT family, have proven to be very helpful for many
natural language processing (NLP) related tasks. Therefore, various attempts
have been made to apply LLMs to information extraction (IE), which is a
fundamental NLP task that involves extracting information from unstructured
plain text. To demonstrate the latest representative progress in LLMs'
information extraction ability, we assess the information extraction ability of
GPT-4 (the latest version of GPT at the time of writing this paper) from four
perspectives: Performance, Evaluation Criteria, Robustness, and Error Types.
Our results suggest a visible performance gap between GPT-4 and
state-of-the-art (SOTA) IE methods. To alleviate this problem, considering the
LLMs' human-like characteristics, we propose and analyze the effects of a
series of simple prompt-based methods, which can be generalized to other LLMs
and NLP tasks. Rich experiments show our methods' effectiveness and some of
their remaining issues in improving GPT-4's information extraction ability."	ArXiv
2161	"GlobalBench: A Benchmark for Global Progress in Natural Language
  Processing"	['Yueqi Song', 'Catherine Cui', 'Simran Khanuja', 'Pengfei Liu', 'Fahim Faisal', 'Alissa Ostapenko', 'Genta Indra Winata', 'Alham Fikri Aji', 'Samuel Cahyawijaya', 'Yulia Tsvetkov', 'Antonios Anastasopoulos', 'Graham Neubig']	2023-05-24 04:36:32+00:00	http://arxiv.org/abs/2305.14716v1	"Despite the major advances in NLP, significant disparities in NLP system
performance across languages still exist. Arguably, these are due to uneven
resource allocation and sub-optimal incentives to work on less resourced
languages. To track and further incentivize the global development of equitable
language technology, we introduce GlobalBench. Prior multilingual benchmarks
are static and have focused on a limited number of tasks and languages. In
contrast, GlobalBench is an ever-expanding collection that aims to dynamically
track progress on all NLP datasets in all languages. Rather than solely
measuring accuracy, GlobalBench also tracks the estimated per-speaker utility
and equity of technology across all languages, providing a multi-faceted view
of how language technology is serving people of the world. Furthermore,
GlobalBench is designed to identify the most under-served languages, and
rewards research efforts directed towards those languages. At present, the most
under-served languages are the ones with a relatively high population, but
nonetheless overlooked by composite multilingual benchmarks (like Punjabi,
Portuguese, and Wu Chinese). Currently, GlobalBench covers 966 datasets in 190
languages, and has 1,128 system submissions spanning 62 languages."	ArXiv
2162	GPTAraEval: A Comprehensive Evaluation of ChatGPT on Arabic NLP	['Md Tawkat Islam Khondaker', 'Abdul Waheed', 'El Moatez Billah Nagoudi', 'Muhammad Abdul-Mageed']	2023-05-24 10:12:39+00:00	http://arxiv.org/abs/2305.14976v2	"ChatGPT's emergence heralds a transformative phase in NLP, particularly
demonstrated through its excellent performance on many English benchmarks.
However, the model's efficacy across diverse linguistic contexts remains
largely uncharted territory. This work aims to bridge this knowledge gap, with
a primary focus on assessing ChatGPT's capabilities on Arabic languages and
dialectal varieties. Our comprehensive study conducts a large-scale automated
and human evaluation of ChatGPT, encompassing 44 distinct language
understanding and generation tasks on over 60 different datasets. To our
knowledge, this marks the first extensive performance analysis of ChatGPT's
deployment in Arabic NLP. Our findings indicate that, despite its remarkable
performance in English, ChatGPT is consistently surpassed by smaller models
that have undergone finetuning on Arabic. We further undertake a meticulous
comparison of ChatGPT and GPT-4's Modern Standard Arabic (MSA) and Dialectal
Arabic (DA), unveiling the relative shortcomings of both models in handling
Arabic dialects compared to MSA. Although we further explore and confirm the
utility of employing GPT-4 as a potential alternative for human evaluation, our
work adds to a growing body of research underscoring the limitations of
ChatGPT."	ArXiv
2163	LAraBench: Benchmarking Arabic AI with Large Language Models	['Ahmed Abdelali', 'Hamdy Mubarak', 'Shammur Absar Chowdhury', 'Maram Hasanain', 'Basel Mousi', 'Sabri Boughorbel', 'Yassine El Kheir', 'Daniel Izham', 'Fahim Dalvi', 'Majd Hawasly', 'Nizi Nazar', 'Yousseif Elshahawy', 'Ahmed Ali', 'Nadir Durrani', 'Natasa Milic-Frayling', 'Firoj Alam']	2023-05-24 10:16:16+00:00	http://arxiv.org/abs/2305.14982v2	"Recent advancements in Large Language Models (LLMs) have significantly
influenced the landscape of language and speech research. Despite this
progress, these models lack specific benchmarking against state-of-the-art
(SOTA) models tailored to particular languages and tasks. LAraBench addresses
this gap for Arabic Natural Language Processing (NLP) and Speech Processing
tasks, including sequence tagging and content classification across different
domains. We utilized models such as GPT-3.5-turbo, GPT-4, BLOOMZ,
Jais-13b-chat, Whisper, and USM, employing zero and few-shot learning
techniques to tackle 33 distinct tasks across 61 publicly available datasets.
This involved 98 experimental setups, encompassing ~296K data points, ~46 hours
of speech, and 30 sentences for Text-to-Speech (TTS). This effort resulted in
330+ sets of experiments. Our analysis focused on measuring the performance gap
between SOTA models and LLMs. The overarching trend observed was that SOTA
models generally outperformed LLMs in zero-shot learning, with a few
exceptions. Notably, larger computational models with few-shot learning
techniques managed to reduce these performance gaps. Our findings provide
valuable insights into the applicability of LLMs for Arabic NLP and speech
processing tasks."	ArXiv
2164	"Exploring Adapter-based Transfer Learning for Recommender Systems:
  Empirical Studies and Practical Insights"	['Junchen Fu', 'Fajie Yuan', 'Yu Song', 'Zheng Yuan', 'Mingyue Cheng', 'Shenghui Cheng', 'Jiaqi Zhang', 'Jie Wang', 'Yunzhu Pan']	2023-05-24 11:23:31+00:00	http://arxiv.org/abs/2305.15036v2	"Adapters, a plug-in neural network module with some tunable parameters, have
emerged as a parameter-efficient transfer learning technique for adapting
pre-trained models to downstream tasks, especially for natural language
processing (NLP) and computer vision (CV) fields. Meanwhile, learning
recommendation models directly from raw item modality features -- e.g., texts
of NLP and images of CV -- can enable effective and transferable recommender
systems (called TransRec). In view of this, a natural question arises: can
adapter-based learning techniques achieve parameter-efficient TransRec with
good performance?
  To this end, we perform empirical studies to address several key
sub-questions. First, we ask whether the adapter-based TransRec performs
comparably to TransRec based on standard full-parameter fine-tuning? does it
hold for recommendation with different item modalities, e.g., textual RS and
visual RS. If yes, we benchmark these existing adapters, which have been shown
to be effective in NLP and CV tasks, in item recommendation tasks. Third, we
carefully study several key factors for the adapter-based TransRec in terms of
where and how to insert these adapters? Finally, we look at the effects of
adapter-based TransRec by either scaling up its source training data or scaling
down its target training data. Our paper provides key insights and practical
guidance on unified & transferable recommendation -- a less studied
recommendation scenario. We release our codes and other materials at:
https://github.com/westlake-repl/Adapter4Rec/."	ArXiv
2165	"Annotation Imputation to Individualize Predictions: Initial Studies on
  Distribution Dynamics and Model Predictions"	['London Lowmanstone', 'Ruyuan Wan', 'Risako Owan', 'Jaehyung Kim', 'Dongyeop Kang']	2023-05-24 11:54:46+00:00	http://arxiv.org/abs/2305.15070v3	"Annotating data via crowdsourcing is time-consuming and expensive. Due to
these costs, dataset creators often have each annotator label only a small
subset of the data. This leads to sparse datasets with examples that are marked
by few annotators. The downside of this process is that if an annotator doesn't
get to label a particular example, their perspective on it is missed. This is
especially concerning for subjective NLP datasets where there is no single
correct label: people may have different valid opinions. Thus, we propose using
imputation methods to generate the opinions of all annotators for all examples,
creating a dataset that does not leave out any annotator's view. We then train
and prompt models, using data from the imputed dataset, to make predictions
about the distribution of responses and individual annotations.
  In our analysis of the results, we found that the choice of imputation method
significantly impacts soft label changes and distribution. While the imputation
introduces noise in the prediction of the original dataset, it has shown
potential in enhancing shots for prompts, particularly for low-response-rate
annotators. We have made all of our code and data publicly available."	ArXiv
2166	"The Utility of Large Language Models and Generative AI for Education
  Research"	['Andrew Katz', 'Umair Shakir', 'Ben Chambers']	2023-05-29 14:42:28+00:00	http://arxiv.org/abs/2305.18125v1	"The use of natural language processing (NLP) techniques in engineering
education can provide valuable insights into the underlying processes involved
in generating text. While accessing these insights can be labor-intensive if
done manually, recent advances in NLP and large language models have made it a
realistic option for individuals. This study explores and evaluates a
combination of clustering, summarization, and prompting techniques to analyze
over 1,000 student essays in which students discussed their career interests.
The specific assignment prompted students to define and explain their career
goals as engineers. Using text embedding representations of student responses,
we clustered the responses together to identify thematically similar statements
from students. The clustered responses were then summarized to quickly identify
career interest themes. We also used a set of a priori codes about career
satisfaction and sectors to demonstrate an alternative approach to using these
generative text models to analyze student writing. The results of this study
demonstrate the feasibility and usefulness of NLP techniques in engineering
education research. By automating the initial analysis of student essays,
researchers and educators can more efficiently and accurately identify key
themes and patterns in student writing. The methods presented in this paper
have broader applications for engineering education and research purposes
beyond analyzing student essays. By explaining these methods to the engineering
education community, readers can utilize them in their own contexts."	ArXiv
2167	"SlimFit: Memory-Efficient Fine-Tuning of Transformer-based Models Using
  Training Dynamics"	['Arash Ardakani', 'Altan Haan', 'Shangyin Tan', 'Doru Thom Popovici', 'Alvin Cheung', 'Costin Iancu', 'Koushik Sen']	2023-05-29 17:50:52+00:00	http://arxiv.org/abs/2305.18513v1	"Transformer-based models, such as BERT and ViT, have achieved
state-of-the-art results across different natural language processing (NLP) and
computer vision (CV) tasks. However, these models are extremely memory
intensive during their fine-tuning process, making them difficult to deploy on
GPUs with limited memory resources. To address this issue, we introduce a new
tool called SlimFit that reduces the memory requirements of these models by
dynamically analyzing their training dynamics and freezing less-contributory
layers during fine-tuning. The layers to freeze are chosen using a runtime
inter-layer scheduling algorithm. SlimFit adopts quantization and pruning for
particular layers to balance the load of dynamic activations and to minimize
the memory footprint of static activations, where static activations refer to
those that cannot be discarded regardless of freezing. This allows SlimFit to
freeze up to 95% of layers and reduce the overall on-device GPU memory usage of
transformer-based models such as ViT and BERT by an average of 2.2x, across
different NLP and CV benchmarks/datasets such as GLUE, SQuAD 2.0, CIFAR-10,
CIFAR-100 and ImageNet with an average degradation of 0.2% in accuracy. For
such NLP and CV tasks, SlimFit can reduce up to 3.1x the total on-device memory
usage with an accuracy degradation of only up to 0.4%. As a result, while
fine-tuning of ViT on ImageNet and BERT on SQuAD 2.0 with a batch size of 128
requires 3 and 2 32GB GPUs respectively, SlimFit enables their fine-tuning on a
single 32GB GPU without any significant accuracy degradation."	ArXiv
2168	Forgotten Knowledge: Examining the Citational Amnesia in NLP	['Janvijay Singh', 'Mukund Rungta', 'Diyi Yang', 'Saif M. Mohammad']	2023-05-29 18:30:34+00:00	http://arxiv.org/abs/2305.18554v2	"Citing papers is the primary method through which modern scientific writing
discusses and builds on past work. Collectively, citing a diverse set of papers
(in time and area of study) is an indicator of how widely the community is
reading. Yet, there is little work looking at broad temporal patterns of
citation. This work systematically and empirically examines: How far back in
time do we tend to go to cite papers? How has that changed over time, and what
factors correlate with this citational attention/amnesia? We chose NLP as our
domain of interest and analyzed approximately 71.5K papers to show and quantify
several key trends in citation. Notably, around 62% of cited papers are from
the immediate five years prior to publication, whereas only about 17% are more
than ten years old. Furthermore, we show that the median age and age diversity
of cited papers were steadily increasing from 1990 to 2014, but since then, the
trend has reversed, and current NLP papers have an all-time low temporal
citation diversity. Finally, we show that unlike the 1990s, the highly cited
papers in the last decade were also papers with the least citation diversity,
likely contributing to the intense (and arguably harmful) recency focus. Code,
data, and a demo are available on the project homepage."	ArXiv
2169	Measuring the Robustness of NLP Models to Domain Shifts	['Nitay Calderon', 'Naveh Porat', 'Eyal Ben-David', 'Alexander Chapanin', 'Zorik Gekhman', 'Nadav Oved', 'Vitaly Shalumov', 'Roi Reichart']	2023-05-31 20:25:08+00:00	http://arxiv.org/abs/2306.00168v5	"Existing research on Domain Robustness (DR) suffers from disparate setups,
limited task variety, and scarce research on recent capabilities such as
in-context learning. Furthermore, the common practice of measuring DR might not
be fully accurate. Current research focuses on challenge sets and relies solely
on the Source Drop (SD): Using the source in-domain performance as a reference
point for degradation. However, we argue that the Target Drop (TD), which
measures degradation from the target in-domain performance, should be used as a
complementary point of view. To address these issues, we first curated a DR
benchmark comprised of 7 diverse NLP tasks, which enabled us to measure both
the SD and the TD. We then conducted a comprehensive large-scale DR study
involving over 14,000 domain shifts across 21 fine-tuned models and few-shot
LLMs. We found that both model types suffer from drops upon domain shifts.
While fine-tuned models excel in-domain, few-shot LLMs often surpass them
cross-domain, showing better robustness. In addition, we found that a large SD
can often be explained by shifting to a harder domain rather than by a genuine
DR challenge, and this highlights the importance of TD as a complementary
metric. We hope our study will shed light on the current DR state of NLP models
and promote improved evaluation practices toward more robust models."	ArXiv
2170	NLPositionality: Characterizing Design Biases of Datasets and Models	['Sebastin Santy', 'Jenny T. Liang', 'Ronan Le Bras', 'Katharina Reinecke', 'Maarten Sap']	2023-06-02 23:02:09+00:00	http://arxiv.org/abs/2306.01943v1	"Design biases in NLP systems, such as performance differences for different
populations, often stem from their creator's positionality, i.e., views and
lived experiences shaped by identity and background. Despite the prevalence and
risks of design biases, they are hard to quantify because researcher, system,
and dataset positionality is often unobserved. We introduce NLPositionality, a
framework for characterizing design biases and quantifying the positionality of
NLP datasets and models. Our framework continuously collects annotations from a
diverse pool of volunteer participants on LabintheWild, and statistically
quantifies alignment with dataset labels and model predictions. We apply
NLPositionality to existing datasets and models for two tasks -- social
acceptability and hate speech detection. To date, we have collected 16,299
annotations in over a year for 600 instances from 1,096 annotators across 87
countries. We find that datasets and models align predominantly with Western,
White, college-educated, and younger populations. Additionally, certain groups,
such as non-binary people and non-native English speakers, are further
marginalized by datasets and models as they rank least in alignment across all
tasks. Finally, we draw from prior literature to discuss how researchers can
examine their own positionality and that of their datasets and models, opening
the door for more inclusive NLP systems."	ArXiv
2171	"Mixture-of-Supernets: Improving Weight-Sharing Supernet Training with
  Architecture-Routed Mixture-of-Experts"	['Ganesh Jawahar', 'Haichuan Yang', 'Yunyang Xiong', 'Zechun Liu', 'Dilin Wang', 'Fei Sun', 'Meng Li', 'Aasish Pappu', 'Barlas Oguz', 'Muhammad Abdul-Mageed', 'Laks V. S. Lakshmanan', 'Raghuraman Krishnamoorthi', 'Vikas Chandra']	2023-06-08 00:35:36+00:00	http://arxiv.org/abs/2306.04845v2	"Weight-sharing supernets are crucial for performance estimation in
cutting-edge neural architecture search (NAS) frameworks. Despite their ability
to generate diverse subnetworks without retraining, the quality of these
subnetworks is not guaranteed due to weight sharing. In NLP tasks like machine
translation and pre-trained language modeling, there is a significant
performance gap between supernet and training from scratch for the same model
architecture, necessitating retraining post optimal architecture
identification.
  This study introduces a solution called mixture-of-supernets, a generalized
supernet formulation leveraging mixture-of-experts (MoE) to enhance supernet
model expressiveness with minimal training overhead. Unlike conventional
supernets, this method employs an architecture-based routing mechanism,
enabling indirect sharing of model weights among subnetworks. This
customization of weights for specific architectures, learned through gradient
descent, minimizes retraining time, significantly enhancing training efficiency
in NLP. The proposed method attains state-of-the-art (SoTA) performance in NAS
for fast machine translation models, exhibiting a superior latency-BLEU
tradeoff compared to HAT, the SoTA NAS framework for machine translation.
Furthermore, it excels in NAS for building memory-efficient task-agnostic BERT
models, surpassing NAS-BERT and AutoDistil across various model sizes. The code
can be found at: https://github.com/UBC-NLP/MoS."	ArXiv
2172	"AutoML in the Age of Large Language Models: Current Challenges, Future
  Opportunities and Risks"	['Alexander Tornede', 'Difan Deng', 'Theresa Eimer', 'Joseph Giovanelli', 'Aditya Mohan', 'Tim Ruhkopf', 'Sarah Segel', 'Daphne Theodorakopoulos', 'Tanja Tornede', 'Henning Wachsmuth', 'Marius Lindauer']	2023-06-13 19:51:22+00:00	http://arxiv.org/abs/2306.08107v3	"The fields of both Natural Language Processing (NLP) and Automated Machine
Learning (AutoML) have achieved remarkable results over the past years. In NLP,
especially Large Language Models (LLMs) have experienced a rapid series of
breakthroughs very recently. We envision that the two fields can radically push
the boundaries of each other through tight integration. To showcase this
vision, we explore the potential of a symbiotic relationship between AutoML and
LLMs, shedding light on how they can benefit each other. In particular, we
investigate both the opportunities to enhance AutoML approaches with LLMs from
different perspectives and the challenges of leveraging AutoML to further
improve LLMs. To this end, we survey existing work, and we critically assess
risks. We strongly believe that the integration of the two fields has the
potential to disrupt both fields, NLP and AutoML. By highlighting conceivable
synergies, but also risks, we aim to foster further exploration at the
intersection of AutoML and LLMs."	ArXiv
2173	"Towards AGI in Computer Vision: Lessons Learned from GPT and Large
  Language Models"	['Lingxi Xie', 'Longhui Wei', 'Xiaopeng Zhang', 'Kaifeng Bi', 'Xiaotao Gu', 'Jianlong Chang', 'Qi Tian']	2023-06-14 17:15:01+00:00	http://arxiv.org/abs/2306.08641v1	"The AI community has been pursuing algorithms known as artificial general
intelligence (AGI) that apply to any kind of real-world problem. Recently, chat
systems powered by large language models (LLMs) emerge and rapidly become a
promising direction to achieve AGI in natural language processing (NLP), but
the path towards AGI in computer vision (CV) remains unclear. One may owe the
dilemma to the fact that visual signals are more complex than language signals,
yet we are interested in finding concrete reasons, as well as absorbing
experiences from GPT and LLMs to solve the problem. In this paper, we start
with a conceptual definition of AGI and briefly review how NLP solves a wide
range of tasks via a chat system. The analysis inspires us that unification is
the next important goal of CV. But, despite various efforts in this direction,
CV is still far from a system like GPT that naturally integrates all tasks. We
point out that the essential weakness of CV lies in lacking a paradigm to learn
from environments, yet NLP has accomplished the task in the text world. We then
imagine a pipeline that puts a CV algorithm (i.e., an agent) in world-scale,
interactable environments, pre-trains it to predict future frames with respect
to its action, and then fine-tunes it with instruction to accomplish various
tasks. We expect substantial research and engineering efforts to push the idea
forward and scale it up, for which we share our perspectives on future research
directions."	ArXiv
2174	"One Law, Many Languages: Benchmarking Multilingual Legal Reasoning for
  Judicial Support"	['Ronja Stern', 'Vishvaksenan Rasiah', 'Veton Matoshi', 'Srinanda Brügger Bose', 'Matthias Stürmer', 'Ilias Chalkidis', 'Daniel E. Ho', 'Joel Niklaus']	2023-06-15 16:19:15+00:00	http://arxiv.org/abs/2306.09237v3	"Recent strides in Large Language Models (LLMs) have saturated many Natural
Language Processing (NLP) benchmarks, emphasizing the need for more challenging
ones to properly assess LLM capabilities. However, domain-specific and
multilingual benchmarks are rare because they require in-depth expertise to
develop. Still, most public models are trained predominantly on English
corpora, while other languages remain understudied, particularly for practical
domain-specific NLP tasks. In this work, we introduce a novel NLP benchmark for
the legal domain that challenges LLMs in five key dimensions: processing
\emph{long documents} (up to 50K tokens), using \emph{domain-specific
knowledge} (embodied in legal texts), \emph{multilingual} understanding
(covering five languages), \emph{multitasking} (comprising legal
document-to-document Information Retrieval, Court View Generation, Leading
Decision Summarization, Citation Extraction, and eight challenging Text
Classification tasks) and \emph{reasoning} (comprising especially Court View
Generation, but also the Text Classification tasks). Our benchmark contains
diverse datasets from the Swiss legal system, allowing for a comprehensive
study of the underlying non-English, inherently multilingual legal system.
Despite the large size of our datasets (some with hundreds of thousands of
examples), existing publicly available multilingual models struggle with most
tasks, even after extensive in-domain pre-training and fine-tuning. We publish
all resources (benchmark suite, pre-trained models, code) under permissive open
CC BY-SA licenses."	ArXiv
2175	"MISMATCH: Fine-grained Evaluation of Machine-generated Text with
  Mismatch Error Types"	['Keerthiram Murugesan', 'Sarathkrishna Swaminathan', 'Soham Dan', 'Subhajit Chaudhury', 'Chulaka Gunasekara', 'Maxwell Crouse', 'Diwakar Mahajan', 'Ibrahim Abdelaziz', 'Achille Fokoue', 'Pavan Kapanipathi', 'Salim Roukos', 'Alexander Gray']	2023-06-18 01:38:53+00:00	http://arxiv.org/abs/2306.10452v1	"With the growing interest in large language models, the need for evaluating
the quality of machine text compared to reference (typically human-generated)
text has become focal attention. Most recent works focus either on
task-specific evaluation metrics or study the properties of machine-generated
text captured by the existing metrics. In this work, we propose a new
evaluation scheme to model human judgments in 7 NLP tasks, based on the
fine-grained mismatches between a pair of texts. Inspired by the recent efforts
in several NLP tasks for fine-grained evaluation, we introduce a set of 13
mismatch error types such as spatial/geographic errors, entity errors, etc, to
guide the model for better prediction of human judgments. We propose a neural
framework for evaluating machine texts that uses these mismatch error types as
auxiliary tasks and re-purposes the existing single-number evaluation metrics
as additional scalar features, in addition to textual features extracted from
the machine and reference texts. Our experiments reveal key insights about the
existing metrics via the mismatch errors. We show that the mismatch errors
between the sentence pairs on the held-out datasets from 7 NLP tasks align well
with the human evaluation."	ArXiv
2176	Are aligned neural networks adversarially aligned?	['Nicholas Carlini', 'Milad Nasr', 'Christopher A. Choquette-Choo', 'Matthew Jagielski', 'Irena Gao', 'Anas Awadalla', 'Pang Wei Koh', 'Daphne Ippolito', 'Katherine Lee', 'Florian Tramer', 'Ludwig Schmidt']	2023-06-26 17:18:44+00:00	http://arxiv.org/abs/2306.15447v2	"Large language models are now tuned to align with the goals of their
creators, namely to be ""helpful and harmless."" These models should respond
helpfully to user questions, but refuse to answer requests that could cause
harm. However, adversarial users can construct inputs which circumvent attempts
at alignment. In this work, we study adversarial alignment, and ask to what
extent these models remain aligned when interacting with an adversarial user
who constructs worst-case inputs (adversarial examples). These inputs are
designed to cause the model to emit harmful content that would otherwise be
prohibited. We show that existing NLP-based optimization attacks are
insufficiently powerful to reliably attack aligned text models: even when
current NLP-based attacks fail, we can find adversarial inputs with brute
force. As a result, the failure of current attacks should not be seen as proof
that aligned text models remain aligned under adversarial inputs.
  However the recent trend in large-scale ML models is multimodal models that
allow users to provide images that influence the text that is generated. We
show these models can be easily attacked, i.e., induced to perform arbitrary
un-aligned behavior through adversarial perturbation of the input image. We
conjecture that improved NLP attacks may demonstrate this same level of
adversarial control over text-only models."	ArXiv
2177	Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research	['Ji-Ung Lee', 'Haritz Puerto', 'Betty van Aken', 'Yuki Arase', 'Jessica Zosa Forde', 'Leon Derczynski', 'Andreas Rücklé', 'Iryna Gurevych', 'Roy Schwartz', 'Emma Strubell', 'Jesse Dodge']	2023-06-29 12:44:53+00:00	http://arxiv.org/abs/2306.16900v2	"Many recent improvements in NLP stem from the development and use of large
pre-trained language models (PLMs) with billions of parameters. Large model
sizes makes computational cost one of the main limiting factors for training
and evaluating such models; and has raised severe concerns about the
sustainability, reproducibility, and inclusiveness for researching PLMs. These
concerns are often based on personal experiences and observations. However,
there had not been any large-scale surveys that investigate them. In this work,
we provide a first attempt to quantify these concerns regarding three topics,
namely, environmental impact, equity, and impact on peer reviewing. By
conducting a survey with 312 participants from the NLP community, we capture
existing (dis)parities between different and within groups with respect to
seniority, academia, and industry; and their impact on the peer reviewing
process. For each topic, we provide an analysis and devise recommendations to
mitigate found disparities, some of which already successfully implemented.
Finally, we discuss additional concerns raised by many participants in
free-text responses."	ArXiv
2178	"On the (In)Effectiveness of Large Language Models for Chinese Text
  Correction"	['Yinghui Li', 'Haojing Huang', 'Shirong Ma', 'Yong Jiang', 'Yangning Li', 'Feng Zhou', 'Hai-Tao Zheng', 'Qingyu Zhou']	2023-07-18 06:48:52+00:00	http://arxiv.org/abs/2307.09007v2	"Recently, the development and progress of Large Language Models (LLMs) have
amazed the entire Artificial Intelligence community. Benefiting from their
emergent abilities, LLMs have attracted more and more researchers to study
their capabilities and performance on various downstream Natural Language
Processing (NLP) tasks. While marveling at LLMs' incredible performance on all
kinds of tasks, we notice that they also have excellent multilingual processing
capabilities, such as Chinese. To explore the Chinese processing ability of
LLMs, we focus on Chinese Text Correction, a fundamental and challenging
Chinese NLP task. Specifically, we evaluate various representative LLMs on the
Chinese Grammatical Error Correction (CGEC) and Chinese Spelling Check (CSC)
tasks, which are two main Chinese Text Correction scenarios. Additionally, we
also fine-tune LLMs for Chinese Text Correction to better observe the potential
capabilities of LLMs. From extensive analyses and comparisons with previous
state-of-the-art small models, we empirically find that the LLMs currently have
both amazing performance and unsatisfactory behavior for Chinese Text
Correction. We believe our findings will promote the landing and application of
LLMs in the Chinese NLP community."	ArXiv
2179	Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation	['Hao Peng', 'Qingqing Cao', 'Jesse Dodge', 'Matthew E. Peters', 'Jared Fernandez', 'Tom Sherborne', 'Kyle Lo', 'Sam Skjonsberg', 'Emma Strubell', 'Darrell Plessas', 'Iz Beltagy', 'Evan Pete Walsh', 'Noah A. Smith', 'Hannaneh Hajishirzi']	2023-07-19 01:05:33+00:00	http://arxiv.org/abs/2307.09701v1	"Rising computational demands of modern natural language processing (NLP)
systems have increased the barrier to entry for cutting-edge research while
posing serious environmental concerns. Yet, progress on model efficiency has
been impeded by practical challenges in model evaluation and comparison. For
example, hardware is challenging to control due to disparate levels of
accessibility across different institutions. Moreover, improvements in metrics
such as FLOPs often fail to translate to progress in real-world applications.
In response, we introduce Pentathlon, a benchmark for holistic and realistic
evaluation of model efficiency. Pentathlon focuses on inference, which accounts
for a majority of the compute in a model's lifecycle. It offers a
strictly-controlled hardware platform, and is designed to mirror real-world
applications scenarios. It incorporates a suite of metrics that target
different aspects of efficiency, including latency, throughput, memory
overhead, and energy consumption. Pentathlon also comes with a software library
that can be seamlessly integrated into any codebase and enable evaluation. As a
standardized and centralized evaluation platform, Pentathlon can drastically
reduce the workload to make fair and reproducible efficiency comparisons. While
initially focused on natural language processing (NLP) models, Pentathlon is
designed to allow flexible extension to other fields. We envision Pentathlon
will stimulate algorithmic innovations in building efficient models, and foster
an increased awareness of the social and environmental implications in the
development of future-generation NLP models."	ArXiv
2180	"Solving scalability issues in calculating PV hosting capacity in low
  voltage distribution networks"	['Tomislav Antic', 'Andrew Keane', 'Tomislav Capuder']	2023-07-19 13:24:04+00:00	http://arxiv.org/abs/2307.09971v1	"The share of end-users with installed rooftop photovoltaic (PV) systems is
continuously growing. Since most end-users are located at the low voltage (LV)
level and due to technical limitations of LV networks, it is necessary to
calculate PV hosting capacity. Most approaches in calculating a network's
hosting capacity are based on three-phase optimal power flow (OPF)
formulations. Linearized and relaxed three-phase OPF formulations respectively
lose their accuracy and exactness when applied to solve the hosting capacity
problem, and only non-linear programming (NLP) models guarantee the exact
solution. Compared to linearized or relaxed models, NLP models require a higher
computational time for finding an optimal solution. The binary variables uplift
the problem to mixed-integer (MI)NLP and increase the computational burden. To
resolve the scalability issues in calculating the hosting capacity of
single-phase connected PVs, we propose a method that does not entail binary
variables but still ensures that PVs are not connected to more than one phase
at a time. Due to a risk of a sub-optimal solution, the proposed approach is
compared to the results obtained by the MINLP formulation. The comparison
includes values of the solution time and technical quantities such as network
losses, voltage deviations, and voltage unbalance factor."	ArXiv
2181	"Disentangling Societal Inequality from Model Biases: Gender Inequality
  in Divorce Court Proceedings"	['Sujan Dutta', 'Parth Srivastava', 'Vaishnavi Solunke', 'Swaprava Nath', 'Ashiqur R. KhudaBukhsh']	2023-07-09 02:31:56+00:00	http://arxiv.org/abs/2307.10200v1	"Divorce is the legal dissolution of a marriage by a court. Since this is
usually an unpleasant outcome of a marital union, each party may have reasons
to call the decision to quit which is generally documented in detail in the
court proceedings. Via a substantial corpus of 17,306 court proceedings, this
paper investigates gender inequality through the lens of divorce court
proceedings. While emerging data sources (e.g., public court records) on
sensitive societal issues hold promise in aiding social science research,
biases present in cutting-edge natural language processing (NLP) methods may
interfere with or affect such studies. We thus require a thorough analysis of
potential gaps and limitations present in extant NLP resources. In this paper,
on the methodological side, we demonstrate that existing NLP resources required
several non-trivial modifications to quantify societal inequalities. On the
substantive side, we find that while a large number of court cases perhaps
suggest changing norms in India where women are increasingly challenging
patriarchy, AI-powered analyses of these court proceedings indicate striking
gender inequality with women often subjected to domestic violence."	ArXiv
2182	"Gradient-Based Word Substitution for Obstinate Adversarial Examples
  Generation in Language Models"	['Yimu Wang', 'Peng Shi', 'Hongyang Zhang']	2023-07-24 03:44:17+00:00	http://arxiv.org/abs/2307.12507v2	"In this paper, we study the problem of generating obstinate (over-stability)
adversarial examples by word substitution in NLP, where input text is
meaningfully changed but the model's prediction does not, even though it
should. Previous word substitution approaches have predominantly focused on
manually designed antonym-based strategies for generating obstinate adversarial
examples, which hinders its application as these strategies can only find a
subset of obstinate adversarial examples and require human efforts. To address
this issue, in this paper, we introduce a novel word substitution method named
GradObstinate, a gradient-based approach that automatically generates obstinate
adversarial examples without any constraints on the search space or the need
for manual design principles. To empirically evaluate the efficacy of
GradObstinate, we conduct comprehensive experiments on five representative
models (Electra, ALBERT, Roberta, DistillBERT, and CLIP) finetuned on four NLP
benchmarks (SST-2, MRPC, SNLI, and SQuAD) and a language-grounding benchmark
(MSCOCO). Extensive experiments show that our proposed GradObstinate generates
more powerful obstinate adversarial examples, exhibiting a higher attack
success rate compared to antonym-based methods. Furthermore, to show the
transferability of obstinate word substitutions found by GradObstinate, we
replace the words in four representative NLP benchmarks with their obstinate
substitutions. Notably, obstinate substitutions exhibit a high success rate
when transferred to other models in black-box settings, including even GPT-3
and ChatGPT. Examples of obstinate adversarial examples found by GradObstinate
are available at https://huggingface.co/spaces/anonauthors/SecretLanguage."	ArXiv
2183	Toward Quantum Machine Translation of Syntactically Distinct Languages	['Mina Abbaszade', 'Mariam Zomorodi', 'Vahid Salari', 'Philip Kurian']	2023-07-31 11:24:54+00:00	http://arxiv.org/abs/2307.16576v1	"The present study aims to explore the feasibility of language translation
using quantum natural language processing algorithms on noisy
intermediate-scale quantum (NISQ) devices. Classical methods in natural
language processing (NLP) struggle with handling large-scale computations
required for complex language tasks, but quantum NLP on NISQ devices holds
promise in harnessing quantum parallelism and entanglement to efficiently
process and analyze vast amounts of linguistic data, potentially
revolutionizing NLP applications. Our research endeavors to pave the way for
quantum neural machine translation, which could potentially offer advantages
over classical methods in the future. We employ Shannon entropy to demonstrate
the significant role of some appropriate angles of rotation gates in the
performance of parametrized quantum circuits. In particular, we utilize these
angles (parameters) as a means of communication between quantum circuits of
different languages. To achieve our objective, we adopt the encoder-decoder
model of classical neural networks and implement the translation task using
long short-term memory (LSTM). Our experiments involved 160 samples comprising
English sentences and their Persian translations. We trained the models with
different optimisers implementing stochastic gradient descent (SGD) as primary
and subsequently incorporating two additional optimizers in conjunction with
SGD. Notably, we achieved optimal results-with mean absolute error of 0.03,
mean squared error of 0.002, and 0.016 loss-by training the best model,
consisting of two LSTM layers and using the Adam optimiser. Our small dataset,
though consisting of simple synonymous sentences with word-to-word mappings,
points to the utility of Shannon entropy as a figure of merit in more complex
machine translation models for intricate sentence structures."	ArXiv
2184	"Unmasking Nationality Bias: A Study of Human Perception of Nationalities
  in AI-Generated Articles"	"['Pranav Narayanan Venkit', 'Sanjana Gautam', 'Ruchi Panchanadikar', ""Ting-Hao `Kenneth' Huang"", 'Shomir Wilson']"	2023-08-08 15:46:27+00:00	http://arxiv.org/abs/2308.04346v1	"We investigate the potential for nationality biases in natural language
processing (NLP) models using human evaluation methods. Biased NLP models can
perpetuate stereotypes and lead to algorithmic discrimination, posing a
significant challenge to the fairness and justice of AI systems. Our study
employs a two-step mixed-methods approach that includes both quantitative and
qualitative analysis to identify and understand the impact of nationality bias
in a text generation model. Through our human-centered quantitative analysis,
we measure the extent of nationality bias in articles generated by AI sources.
We then conduct open-ended interviews with participants, performing qualitative
coding and thematic analysis to understand the implications of these biases on
human readers. Our findings reveal that biased NLP models tend to replicate and
amplify existing societal biases, which can translate to harm if used in a
sociotechnical setting. The qualitative analysis from our interviews offers
insights into the experience readers have when encountering such articles,
highlighting the potential to shift a reader's perception of a country. These
findings emphasize the critical role of public perception in shaping AI's
impact on society and the need to correct biases in AI systems."	ArXiv
2185	LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking	['Fahim Dalvi', 'Maram Hasanain', 'Sabri Boughorbel', 'Basel Mousi', 'Samir Abdaljalil', 'Nizi Nazar', 'Ahmed Abdelali', 'Shammur Absar Chowdhury', 'Hamdy Mubarak', 'Ahmed Ali', 'Majd Hawasly', 'Nadir Durrani', 'Firoj Alam']	2023-08-09 13:22:37+00:00	http://arxiv.org/abs/2308.04945v2	"The recent development and success of Large Language Models (LLMs)
necessitate an evaluation of their performance across diverse NLP tasks in
different languages. Although several frameworks have been developed and made
publicly available, their customization capabilities for specific tasks and
datasets are often complex for different users. In this study, we introduce the
LLMeBench framework, which can be seamlessly customized to evaluate LLMs for
any NLP task, regardless of language. The framework features generic dataset
loaders, several model providers, and pre-implements most standard evaluation
metrics. It supports in-context learning with zero- and few-shot settings. A
specific dataset and task can be evaluated for a given LLM in less than 20
lines of code while allowing full flexibility to extend the framework for
custom datasets, models, or tasks. The framework has been tested on 31 unique
NLP tasks using 53 publicly available datasets within 90 experimental setups,
involving approximately 296K data points. We open-sourced LLMeBench for the
community (https://github.com/qcri/LLMeBench/) and a video demonstrating the
framework is available online. (https://youtu.be/9cC2m_abk3A)"	ArXiv
2186	Evolution of ESG-focused DLT Research: An NLP Analysis of the Literature	['Walter Hernandez', 'Kamil Tylinski', 'Alastair Moore', 'Niall Roche', 'Nikhil Vadgama', 'Horst Treiblmaier', 'Jiangbo Shangguan', 'Paolo Tasca', 'Jiahua Xu']	2023-08-23 20:42:32+00:00	http://arxiv.org/abs/2308.12420v2	"As Distributed Ledger Technologies (DLTs) rapidly evolve, their impacts
extend beyond technology, influencing environmental and societal aspects. This
evolution has increased publications, making manual literature analysis
increasingly challenging. We address this with a Natural Language Processing
(NLP)-based systematic literature review method to explore the intersection of
Distributed Ledger Technology (DLT) with its Environmental, Social, and
Governance (ESG) aspects. Our approach involves building and refining a
directed citation network from 107 seed papers to a corpus of 24,539
publications and fine-tuning a transformer-based language model for Named
Entity Recognition (NER) on DLT and ESG domains. Applying this model, we
distilled the corpus to 505 key publications, enabling an inaugural literature
review and temporal graph analysis of DLT's evolution in ESG contexts. Our
contributions include an adaptable and scalable NLP-driven systematic
literature review methodology and a unique NER dataset of 54,808 entities,
tailored for DLT and ESG research. Our inaugural literature review demonstrates
their applicability and effectiveness in analyzing DLT's evolution and impacts,
proving invaluable for stakeholders in the DLT domain."	ArXiv
2187	OYXOY: A Modern NLP Test Suite for Modern Greek	['Konstantinos Kogkalidis', 'Stergios Chatzikyriakidis', 'Eirini Chrysovalantou Giannikouri', 'Vassiliki Katsouli', 'Christina Klironomou', 'Christina Koula', 'Dimitris Papadakis', 'Thelka Pasparaki', 'Erofili Psaltaki', 'Efthymia Sakellariou', 'Hara Soupiona']	2023-09-13 15:00:56+00:00	http://arxiv.org/abs/2309.07009v2	"This paper serves as a foundational step towards the development of a
linguistically motivated and technically relevant evaluation suite for Greek
NLP. We initiate this endeavor by introducing four expert-verified evaluation
tasks, specifically targeted at natural language inference, word sense
disambiguation (through example comparison or sense selection) and metaphor
detection. More than language-adapted replicas of existing tasks, we contribute
two innovations which will resonate with the broader resource and evaluation
community. Firstly, our inference dataset is the first of its kind, marking not
just \textit{one}, but rather \textit{all} possible inference labels,
accounting for possible shifts due to e.g. ambiguity or polysemy. Secondly, we
demonstrate a cost-efficient method to obtain datasets for under-resourced
languages. Using ChatGPT as a language-neutral parser, we transform the
Dictionary of Standard Modern Greek into a structured format, from which we
derive the other three tasks through simple projections. Alongside each task,
we conduct experiments using currently available state of the art machinery.
Our experimental baselines affirm the challenging nature of our tasks and
highlight the need for expedited progress in order for the Greek NLP ecosystem
to keep pace with contemporary mainstream research."	ArXiv
2188	"Sensitivity, Performance, Robustness: Deconstructing the Effect of
  Sociodemographic Prompting"	['Tilman Beck', 'Hendrik Schuff', 'Anne Lauscher', 'Iryna Gurevych']	2023-09-13 15:42:06+00:00	http://arxiv.org/abs/2309.07034v2	"Annotators' sociodemographic backgrounds (i.e., the individual compositions
of their gender, age, educational background, etc.) have a strong impact on
their decisions when working on subjective NLP tasks, such as toxic language
detection. Often, heterogeneous backgrounds result in high disagreements. To
model this variation, recent work has explored sociodemographic prompting, a
technique, which steers the output of prompt-based models towards answers that
humans with specific sociodemographic profiles would give. However, the
available NLP literature disagrees on the efficacy of this technique - it
remains unclear for which tasks and scenarios it can help, and the role of the
individual factors in sociodemographic prompting is still unexplored. We
address this research gap by presenting the largest and most comprehensive
study of sociodemographic prompting today. We analyze its influence on model
sensitivity, performance and robustness across seven datasets and six
instruction-tuned model families. We show that sociodemographic information
affects model predictions and can be beneficial for improving zero-shot
learning in subjective NLP tasks. However, its outcomes largely vary for
different model types, sizes, and datasets, and are subject to large variance
with regards to prompt formulations. Most importantly, our results show that
sociodemographic prompting should be used with care for sensitive applications,
such as toxicity annotation or when studying LLM alignment. Code and data:
https://github.com/UKPLab/arxiv2023-sociodemographic-prompting"	ArXiv
2189	"Fabricator: An Open Source Toolkit for Generating Labeled Training Data
  with Teacher LLMs"	['Jonas Golde', 'Patrick Haller', 'Felix Hamborg', 'Julian Risch', 'Alan Akbik']	2023-09-18 08:45:47+00:00	http://arxiv.org/abs/2309.09582v2	"Most NLP tasks are modeled as supervised learning and thus require labeled
training data to train effective models. However, manually producing such data
at sufficient quality and quantity is known to be costly and time-intensive.
Current research addresses this bottleneck by exploring a novel paradigm called
zero-shot learning via dataset generation. Here, a powerful LLM is prompted
with a task description to generate labeled data that can be used to train a
downstream NLP model. For instance, an LLM might be prompted to ""generate 500
movie reviews with positive overall sentiment, and another 500 with negative
sentiment."" The generated data could then be used to train a binary sentiment
classifier, effectively leveraging an LLM as a teacher to a smaller student
model. With this demo, we introduce Fabricator, an open-source Python toolkit
for dataset generation. Fabricator implements common dataset generation
workflows, supports a wide range of downstream NLP tasks (such as text
classification, question answering, and entity recognition), and is integrated
with well-known libraries to facilitate quick experimentation. With Fabricator,
we aim to support researchers in conducting reproducible dataset generation
experiments using LLMs and help practitioners apply this approach to train
models for downstream tasks."	ArXiv
2190	Towards LLM-guided Causal Explainability for Black-box Text Classifiers	['Amrita Bhattacharjee', 'Raha Moraffah', 'Joshua Garland', 'Huan Liu']	2023-09-23 11:22:28+00:00	http://arxiv.org/abs/2309.13340v2	"With the advent of larger and more complex deep learning models, such as in
Natural Language Processing (NLP), model qualities like explainability and
interpretability, albeit highly desirable, are becoming harder challenges to
tackle and solve. For example, state-of-the-art models in text classification
are black-box by design. Although standard explanation methods provide some
degree of explainability, these are mostly correlation-based methods and do not
provide much insight into the model. The alternative of causal explainability
is more desirable to achieve but extremely challenging in NLP due to a variety
of reasons. Inspired by recent endeavors to utilize Large Language Models
(LLMs) as experts, in this work, we aim to leverage the instruction-following
and textual understanding capabilities of recent state-of-the-art LLMs to
facilitate causal explainability via counterfactual explanation generation for
black-box text classifiers. To do this, we propose a three-step pipeline via
which, we use an off-the-shelf LLM to: (1) identify the latent or unobserved
features in the input text, (2) identify the input features associated with the
latent features, and finally (3) use the identified input features to generate
a counterfactual explanation. We experiment with our pipeline on multiple NLP
text classification datasets, with several recent LLMs, and present interesting
and promising findings."	ArXiv
2191	Survey of Social Bias in Vision-Language Models	['Nayeon Lee', 'Yejin Bang', 'Holy Lovenia', 'Samuel Cahyawijaya', 'Wenliang Dai', 'Pascale Fung']	2023-09-24 15:34:56+00:00	http://arxiv.org/abs/2309.14381v1	"In recent years, the rapid advancement of machine learning (ML) models,
particularly transformer-based pre-trained models, has revolutionized Natural
Language Processing (NLP) and Computer Vision (CV) fields. However, researchers
have discovered that these models can inadvertently capture and reinforce
social biases present in their training datasets, leading to potential social
harms, such as uneven resource allocation and unfair representation of specific
social groups. Addressing these biases and ensuring fairness in artificial
intelligence (AI) systems has become a critical concern in the ML community.
  The recent introduction of pre-trained vision-and-language (VL) models in the
emerging multimodal field demands attention to the potential social biases
present in these models as well. Although VL models are susceptible to social
bias, there is a limited understanding compared to the extensive discussions on
bias in NLP and CV. This survey aims to provide researchers with a high-level
insight into the similarities and differences of social bias studies in
pre-trained models across NLP, CV, and VL. By examining these perspectives, the
survey aims to offer valuable guidelines on how to approach and mitigate social
bias in both unimodal and multimodal settings. The findings and recommendations
presented here can benefit the ML community, fostering the development of
fairer and non-biased AI models in various applications and research endeavors."	ArXiv
2192	How many words does ChatGPT know? The answer is ChatWords	['Gonzalo Martínez', 'Javier Conde', 'Pedro Reviriego', 'Elena Merino-Gómez', 'José Alberto Hernández', 'Fabrizio Lombardi']	2023-09-28 18:13:02+00:00	http://arxiv.org/abs/2309.16777v1	"The introduction of ChatGPT has put Artificial Intelligence (AI) Natural
Language Processing (NLP) in the spotlight. ChatGPT adoption has been
exponential with millions of users experimenting with it in a myriad of tasks
and application domains with impressive results. However, ChatGPT has
limitations and suffers hallucinations, for example producing answers that look
plausible but they are completely wrong. Evaluating the performance of ChatGPT
and similar AI tools is a complex issue that is being explored from different
perspectives. In this work, we contribute to those efforts with ChatWords, an
automated test system, to evaluate ChatGPT knowledge of an arbitrary set of
words. ChatWords is designed to be extensible, easy to use, and adaptable to
evaluate also other NLP AI tools. ChatWords is publicly available and its main
goal is to facilitate research on the lexical knowledge of AI tools. The
benefits of ChatWords are illustrated with two case studies: evaluating the
knowledge that ChatGPT has of the Spanish lexicon (taken from the official
dictionary of the ""Real Academia Espa\~nola"") and of the words that appear in
the Quixote, the well-known novel written by Miguel de Cervantes. The results
show that ChatGPT is only able to recognize approximately 80% of the words in
the dictionary and 90% of the words in the Quixote, in some cases with an
incorrect meaning. The implications of the lexical knowledge of NLP AI tools
and potential applications of ChatWords are also discussed providing directions
for further work on the study of the lexical knowledge of AI tools."	ArXiv
2193	"Faithful Explanations of Black-box NLP Models Using LLM-generated
  Counterfactuals"	['Yair Gat', 'Nitay Calderon', 'Amir Feder', 'Alexander Chapanin', 'Amit Sharma', 'Roi Reichart']	2023-10-01 07:31:04+00:00	http://arxiv.org/abs/2310.00603v2	"Causal explanations of the predictions of NLP systems are essential to ensure
safety and establish trust. Yet, existing methods often fall short of
explaining model predictions effectively or efficiently and are often
model-specific. In this paper, we address model-agnostic explanations,
proposing two approaches for counterfactual (CF) approximation. The first
approach is CF generation, where a large language model (LLM) is prompted to
change a specific text concept while keeping confounding concepts unchanged.
While this approach is demonstrated to be very effective, applying LLM at
inference-time is costly. We hence present a second approach based on matching,
and propose a method that is guided by an LLM at training-time and learns a
dedicated embedding space. This space is faithful to a given causal graph and
effectively serves to identify matches that approximate CFs. After showing
theoretically that approximating CFs is required in order to construct faithful
explanations, we benchmark our approaches and explain several models, including
LLMs with billions of parameters. Our empirical results demonstrate the
excellent performance of CF generation models as model-agnostic explainers.
Moreover, our matching approach, which requires far less test-time resources,
also provides effective explanations, surpassing many baselines. We also find
that Top-K techniques universally improve every tested method. Finally, we
showcase the potential of LLMs in constructing new benchmarks for model
explanation and subsequently validate our conclusions. Our work illuminates new
pathways for efficient and accurate approaches to interpreting NLP systems."	ArXiv
2194	Fooling the Textual Fooler via Randomizing Latent Representations	['Duy C. Hoang', 'Quang H. Nguyen', 'Saurav Manchanda', 'MinLong Peng', 'Kok-Seng Wong', 'Khoa D. Doan']	2023-10-02 06:57:25+00:00	http://arxiv.org/abs/2310.01452v2	"Despite outstanding performance in a variety of NLP tasks, recent studies
have revealed that NLP models are vulnerable to adversarial attacks that
slightly perturb the input to cause the models to misbehave. Among these
attacks, adversarial word-level perturbations are well-studied and effective
attack strategies. Since these attacks work in black-box settings, they do not
require access to the model architecture or model parameters and thus can be
detrimental to existing NLP applications. To perform an attack, the adversary
queries the victim model many times to determine the most important words in an
input text and to replace these words with their corresponding synonyms. In
this work, we propose a lightweight and attack-agnostic defense whose main goal
is to perplex the process of generating an adversarial example in these
query-based black-box attacks; that is to fool the textual fooler. This
defense, named AdvFooler, works by randomizing the latent representation of the
input at inference time. Different from existing defenses, AdvFooler does not
necessitate additional computational overhead during training nor relies on
assumptions about the potential adversarial perturbation set while having a
negligible impact on the model's accuracy. Our theoretical and empirical
analyses highlight the significance of robustness resulting from confusing the
adversary via randomizing the latent space, as well as the impact of
randomization on clean accuracy. Finally, we empirically demonstrate near
state-of-the-art robustness of AdvFooler against representative adversarial
word-level attacks on two benchmark datasets."	ArXiv
2195	"Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology
  View"	['Jintian Zhang', 'Xin Xu', 'Ningyu Zhang', 'Ruibo Liu', 'Bryan Hooi', 'Shumin Deng']	2023-10-03 15:05:52+00:00	http://arxiv.org/abs/2310.02124v3	"As Natural Language Processing (NLP) systems are increasingly employed in
intricate social environments, a pressing query emerges: Can these NLP systems
mirror human-esque collaborative intelligence, in a multi-agent society
consisting of multiple large language models (LLMs)? This paper probes the
collaboration mechanisms among contemporary NLP systems by melding practical
experiments with theoretical insights. We fabricate four unique `societies'
comprised of LLM agents, where each agent is characterized by a specific
`trait' (easy-going or overconfident) and engages in collaboration with a
distinct `thinking pattern' (debate or reflection). Through evaluating these
multi-agent societies on three benchmark datasets, we discern that certain
collaborative strategies not only outshine previous top-tier approaches, but
also optimize efficiency (using fewer API tokens). Moreover, our results
further illustrate that LLM agents manifest human-like social behaviors, such
as conformity and consensus reaching, mirroring foundational social psychology
theories. In conclusion, we integrate insights from social psychology to
contextualize the collaboration of LLM agents, inspiring further investigations
into the collaboration mechanism for LLMs. We commit to sharing our code and
datasets\footnote{\url{https://github.com/zjunlp/MachineSoM}.}, hoping to
catalyze further research in this promising avenue."	ArXiv
2196	Generative Judge for Evaluating Alignment	['Junlong Li', 'Shichao Sun', 'Weizhe Yuan', 'Run-Ze Fan', 'Hai Zhao', 'Pengfei Liu']	2023-10-09 07:27:15+00:00	http://arxiv.org/abs/2310.05470v2	"The rapid development of Large Language Models (LLMs) has substantially
expanded the range of tasks they can address. In the field of Natural Language
Processing (NLP), researchers have shifted their focus from conventional NLP
tasks (e.g., sequence tagging and parsing) towards tasks that revolve around
aligning with human needs (e.g., brainstorming and email writing). This shift
in task distribution imposes new requirements on evaluating these aligned
models regarding generality (i.e., assessing performance across diverse
scenarios), flexibility (i.e., examining under different protocols), and
interpretability (i.e., scrutinizing models with explanations). In this paper,
we propose a generative judge with 13B parameters, Auto-J, designed to address
these challenges. Our model is trained on user queries and LLM-generated
responses under massive real-world scenarios and accommodates diverse
evaluation protocols (e.g., pairwise response comparison and single-response
evaluation) with well-structured natural language critiques. To demonstrate the
efficacy of our approach, we construct a new testbed covering 58 different
scenarios. Experimentally, Auto-J outperforms a series of strong competitors,
including both open-source and closed-source models, by a large margin. We also
provide detailed analysis and case studies to further reveal the potential of
our method and make a variety of resources public at
https://github.com/GAIR-NLP/auto-j."	ArXiv
2197	"Evolution of Natural Language Processing Technology: Not Just Language
  Processing Towards General Purpose AI"	['Masahiro Yamamoto']	2023-10-10 00:41:38+00:00	http://arxiv.org/abs/2310.06228v1	"Since the invention of computers, communication through natural language
(actual human language) has been a dream technology. However, natural language
is extremely difficult to mathematically formulate, making it difficult to
realize as an algorithm without considering programming. While there have been
numerous technological developments, one cannot say that any results allowing
free utilization have been achieved thus far. In the case of language learning
in humans, for instance when learning one's mother tongue or foreign language,
one must admit that this process is similar to the adage ""practice makes
perfect"" in principle, even though the learning method is significant up to a
point. Deep learning has played a central role in contemporary AI technology in
recent years. When applied to natural language processing (NLP), this produced
unprecedented results. Achievements exceeding the initial predictions have been
reported from the results of learning vast amounts of textual data using deep
learning. For instance, four arithmetic operations could be performed without
explicit learning, thereby enabling the explanation of complex images and the
generation of images from corresponding explanatory texts. It is an accurate
example of the learner embodying the concept of ""practice makes perfect"" by
using vast amounts of textual data. This report provides a technological
explanation of how cutting-edge NLP has made it possible to realize the
""practice makes perfect"" principle. Additionally, examples of how this can be
applied to business are provided. We reported in June 2022 in Japanese on the
NLP movement from late 2021 to early 2022. We would like to summarize this as a
memorandum since this is just the initial movement leading to the current large
language models (LLMs)."	ArXiv
2198	"Key-phrase boosted unsupervised summary generation for FinTech
  organization"	['Aadit Deshpande', 'Shreya Goyal', 'Prateek Nagwanshi', 'Avinash Tripathy']	2023-10-16 11:30:47+00:00	http://arxiv.org/abs/2310.10294v1	"With the recent advances in social media, the use of NLP techniques in social
media data analysis has become an emerging research direction. Business
organizations can particularly benefit from such an analysis of social media
discourse, providing an external perspective on consumer behavior. Some of the
NLP applications such as intent detection, sentiment classification, text
summarization can help FinTech organizations to utilize the social media
language data to find useful external insights and can be further utilized for
downstream NLP tasks. Particularly, a summary which highlights the intents and
sentiments of the users can be very useful for these organizations to get an
external perspective. This external perspective can help organizations to
better manage their products, offers, promotional campaigns, etc. However,
certain challenges, such as a lack of labeled domain-specific datasets impede
further exploration of these tasks in the FinTech domain. To overcome these
challenges, we design an unsupervised phrase-based summary generation from
social media data, using 'Action-Object' pairs (intent phrases). We evaluated
the proposed method with other key-phrase based summary generation methods in
the direction of contextual information of various Reddit discussion threads,
available in the different summaries. We introduce certain ""Context Metrics""
such as the number of Unique words, Action-Object pairs, and Noun chunks to
evaluate the contextual information retrieved from the source text in these
phrase-based summaries. We demonstrate that our methods significantly
outperform the baseline on these metrics, thus providing a qualitative and
quantitative measure of their efficacy. Proposed framework has been leveraged
as a web utility portal hosted within Amex."	ArXiv
2199	"From Dissonance to Insights: Dissecting Disagreements in Rationale
  Construction for Case Outcome Classification"	['Shanshan Xu', 'T. Y. S. S Santosh', 'Oana Ichim', 'Isabella Risini', 'Barbara Plank', 'Matthias Grabmair']	2023-10-18 11:04:31+00:00	http://arxiv.org/abs/2310.11878v5	"In legal NLP, Case Outcome Classification (COC) must not only be accurate but
also trustworthy and explainable. Existing work in explainable COC has been
limited to annotations by a single expert. However, it is well-known that
lawyers may disagree in their assessment of case facts. We hence collect a
novel dataset RAVE: Rationale Variation in ECHR1, which is obtained from two
experts in the domain of international human rights law, for whom we observe
weak agreement. We study their disagreements and build a two-level
task-independent taxonomy, supplemented with COC-specific subcategories. To our
knowledge, this is the first work in the legal NLP that focuses on human label
variation. We quantitatively assess different taxonomy categories and find that
disagreements mainly stem from underspecification of the legal context, which
poses challenges given the typically limited granularity and noise in COC
metadata. We further assess the explainablility of SOTA COC models on RAVE and
observe limited agreement between models and experts. Overall, our case study
reveals hitherto underappreciated complexities in creating benchmark datasets
in legal NLP that revolve around identifying aspects of a case's facts
supposedly relevant to its outcome."	ArXiv
2200	CreoleVal: Multilingual Multitask Benchmarks for Creoles	['Heather Lent', 'Kushal Tatariya', 'Raj Dabre', 'Yiyi Chen', 'Marcell Fekete', 'Esther Ploeger', 'Li Zhou', 'Ruth-Ann Armstrong', 'Abee Eijansantos', 'Catriona Malau', 'Hans Erik Heje', 'Ernests Lavrinovics', 'Diptesh Kanojia', 'Paul Belony', 'Marcel Bollmann', 'Loïc Grobol', 'Miryam de Lhoneux', 'Daniel Hershcovich', 'Michel DeGraff', 'Anders Søgaard', 'Johannes Bjerva']	2023-10-30 14:24:20+00:00	http://arxiv.org/abs/2310.19567v3	"Creoles represent an under-explored and marginalized group of languages, with
few available resources for NLP research.While the genealogical ties between
Creoles and a number of highly-resourced languages imply a significant
potential for transfer learning, this potential is hampered due to this lack of
annotated data. In this work we present CreoleVal, a collection of benchmark
datasets spanning 8 different NLP tasks, covering up to 28 Creole languages; it
is an aggregate of novel development datasets for reading comprehension,
relation classification, and machine translation for Creoles, in addition to a
practical gateway to a handful of preexisting benchmarks. For each benchmark,
we conduct baseline experiments in a zero-shot setting in order to further
ascertain the capabilities and limitations of transfer learning for Creoles.
Ultimately, we see CreoleVal as an opportunity to empower research on Creoles
in NLP and computational linguistics, and in general, a step towards more
equitable language technology around the globe."	ArXiv
2201	"Synthetic Imitation Edit Feedback for Factual Alignment in Clinical
  Summarization"	['Prakamya Mishra', 'Zonghai Yao', 'Shuwei Chen', 'Beining Wang', 'Rohan Mittal', 'Hong Yu']	2023-10-30 21:33:22+00:00	http://arxiv.org/abs/2310.20033v2	"Large Language Models (LLMs) like the GPT and LLaMA families have
demonstrated exceptional capabilities in capturing and condensing critical
contextual information and achieving state-of-the-art performance in the
summarization task. However, community concerns about these models'
hallucination issues continue to rise. LLMs sometimes generate factually
hallucinated summaries, which can be extremely harmful in the clinical domain
NLP tasks (e.g., clinical note summarization), where factually incorrect
statements can lead to critically erroneous diagnoses. Fine-tuning LLMs using
human feedback has shown the promise of aligning LLMs to be factually
consistent during generation, but such training procedure requires high-quality
human-annotated data, which can be extremely expensive to get in the clinical
domain. In this work, we propose a new pipeline using ChatGPT instead of human
experts to generate high-quality feedback data for improving factual
consistency in the clinical note summarization task. We focus specifically on
edit feedback because recent work discusses the shortcomings of human alignment
via preference feedback in complex situations (such as clinical NLP tasks that
require extensive expert knowledge), as well as some advantages of collecting
edit feedback from domain experts. In addition, although GPT has reached the
expert level in many clinical NLP tasks (e.g., USMLE QA), there is not much
previous work discussing whether GPT can generate expert-level edit feedback
for LMs in the clinical note summarization task. We hope to fill this gap.
Finally, our evaluations demonstrate the potential use of GPT edits in human
alignment, especially from a factuality perspective."	ArXiv
2202	"Investigating the Encoding of Words in BERT's Neurons using Feature
  Textualization"	['Tanja Baeumel', 'Soniya Vijayakumar', 'Josef van Genabith', 'Guenter Neumann', 'Simon Ostermann']	2023-11-14 15:21:49+00:00	http://arxiv.org/abs/2311.08240v1	"Pretrained language models (PLMs) form the basis of most state-of-the-art NLP
technologies. Nevertheless, they are essentially black boxes: Humans do not
have a clear understanding of what knowledge is encoded in different parts of
the models, especially in individual neurons. The situation is different in
computer vision, where feature visualization provides a decompositional
interpretability technique for neurons of vision models. Activation
maximization is used to synthesize inherently interpretable visual
representations of the information encoded in individual neurons. Our work is
inspired by this but presents a cautionary tale on the interpretability of
single neurons, based on the first large-scale attempt to adapt activation
maximization to NLP, and, more specifically, large PLMs. We propose feature
textualization, a technique to produce dense representations of neurons in the
PLM word embedding space. We apply feature textualization to the BERT model
(Devlin et al., 2019) to investigate whether the knowledge encoded in
individual neurons can be interpreted and symbolized. We find that the produced
representations can provide insights about the knowledge encoded in individual
neurons, but that individual neurons do not represent clearcut symbolic units
of language such as words. Additionally, we use feature textualization to
investigate how many neurons are needed to encode words in BERT."	ArXiv
2203	"Aligning with Whom? Large Language Models Have Gender and Racial Biases
  in Subjective NLP Tasks"	['Huaman Sun', 'Jiaxin Pei', 'Minje Choi', 'David Jurgens']	2023-11-16 10:02:24+00:00	http://arxiv.org/abs/2311.09730v1	"Human perception of language depends on personal backgrounds like gender and
ethnicity. While existing studies have shown that large language models (LLMs)
hold values that are closer to certain societal groups, it is unclear whether
their prediction behaviors on subjective NLP tasks also exhibit a similar bias.
In this study, leveraging the POPQUORN dataset which contains annotations of
diverse demographic backgrounds, we conduct a series of experiments on four
popular LLMs to investigate their capability to understand group differences
and potential biases in their predictions for politeness and offensiveness. We
find that for both tasks, model predictions are closer to the labels from White
and female participants. We further explore prompting with the target
demographic labels and show that including the target demographic in the prompt
actually worsens the model's performance. More specifically, when being
prompted to respond from the perspective of ""Black"" and ""Asian"" individuals,
models show lower performance in predicting both overall scores as well as the
scores from corresponding groups. Our results suggest that LLMs hold gender and
racial biases for subjective NLP tasks and that demographic-infused prompts
alone may be insufficient to mitigate such effects. Code and data are available
at https://github.com/Jiaxin-Pei/LLM-Group-Bias."	ArXiv
2204	"Responsible AI Considerations in Text Summarization Research: A Review
  of Current Practices"	['Yu Lu Liu', 'Meng Cao', 'Su Lin Blodgett', 'Jackie Chi Kit Cheung', 'Alexandra Olteanu', 'Adam Trischler']	2023-11-18 15:35:36+00:00	http://arxiv.org/abs/2311.11103v1	"AI and NLP publication venues have increasingly encouraged researchers to
reflect on possible ethical considerations, adverse impacts, and other
responsible AI issues their work might engender. However, for specific NLP
tasks our understanding of how prevalent such issues are, or when and why these
issues are likely to arise, remains limited. Focusing on text summarization --
a common NLP task largely overlooked by the responsible AI community -- we
examine research and reporting practices in the current literature. We conduct
a multi-round qualitative analysis of 333 summarization papers from the ACL
Anthology published between 2020-2022. We focus on how, which, and when
responsible AI issues are covered, which relevant stakeholders are considered,
and mismatches between stated and realized research goals. We also discuss
current evaluation practices and consider how authors discuss the limitations
of both prior work and their own work. Overall, we find that relatively few
papers engage with possible stakeholders or contexts of use, which limits their
consideration of potential downstream adverse impacts or other responsible AI
issues. Based on our findings, we make recommendations on concrete practices
and research directions."	ArXiv
2205	"On Significance of Subword tokenization for Low Resource and Efficient
  Named Entity Recognition: A case study in Marathi"	['Harsh Chaudhari', 'Anuja Patil', 'Dhanashree Lavekar', 'Pranav Khairnar', 'Raviraj Joshi', 'Sachin Pande']	2023-12-03 06:53:53+00:00	http://arxiv.org/abs/2312.01306v1	"Named Entity Recognition (NER) systems play a vital role in NLP applications
such as machine translation, summarization, and question-answering. These
systems identify named entities, which encompass real-world concepts like
locations, persons, and organizations. Despite extensive research on NER
systems for the English language, they have not received adequate attention in
the context of low resource languages. In this work, we focus on NER for
low-resource language and present our case study in the context of the Indian
language Marathi. The advancement of NLP research revolves around the
utilization of pre-trained transformer models such as BERT for the development
of NER models. However, we focus on improving the performance of shallow models
based on CNN, and LSTM by combining the best of both worlds. In the era of
transformers, these traditional deep learning models are still relevant because
of their high computational efficiency. We propose a hybrid approach for
efficient NER by integrating a BERT-based subword tokenizer into vanilla
CNN/LSTM models. We show that this simple approach of replacing a traditional
word-based tokenizer with a BERT-tokenizer brings the accuracy of vanilla
single-layer models closer to that of deep pre-trained models like BERT. We
show the importance of using sub-word tokenization for NER and present our
study toward building efficient NLP systems. The evaluation is performed on
L3Cube-MahaNER dataset using tokenizers from MahaBERT, MahaGPT, IndicBERT, and
mBERT."	ArXiv
2206	"Learn or Recall? Revisiting Incremental Learning with Pre-trained
  Language Models"	['Junhao Zheng', 'Shengjie Qiu', 'Qianli Ma']	2023-12-13 04:14:22+00:00	http://arxiv.org/abs/2312.07887v5	"Incremental Learning (IL) has been a long-standing problem in both vision and
Natural Language Processing (NLP) communities. In recent years, as Pre-trained
Language Models (PLMs) have achieved remarkable progress in various NLP
downstream tasks, utilizing PLMs as backbones has become a common practice in
recent research of IL in NLP. Most assume that catastrophic forgetting is the
biggest obstacle to achieving superior IL performance and propose various
techniques to overcome this issue. However, we find that this assumption is
problematic. Specifically, we revisit more than 20 methods on four
classification tasks (Text Classification, Intent Classification, Relation
Extraction, and Named Entity Recognition) under the two most popular IL
settings (Class-Incremental and Task-Incremental) and reveal that most of them
severely underestimate the inherent anti-forgetting ability of PLMs. Based on
the observation, we propose a frustratingly easy method called SEQ* for IL with
PLMs. The results show that SEQ* has competitive or superior performance
compared to state-of-the-art (SOTA) IL methods and requires considerably less
trainable parameters and training time. These findings urge us to revisit the
IL with PLMs and encourage future studies to have a fundamental understanding
of the catastrophic forgetting in PLMs. The data, code and scripts are publicly
available at
https://github.com/zzz47zzz/codebase-for-incremental-learning-with-llm."	ArXiv
2207	"Towards Model-Based Data Acquisition for Subjective Multi-Task NLP
  Problems"	['Kamil Kanclerz', 'Julita Bielaniewicz', 'Marcin Gruza', 'Jan Kocon', 'Stanisław Woźniak', 'Przemysław Kazienko']	2023-12-13 15:03:27+00:00	http://arxiv.org/abs/2312.08198v1	"Data annotated by humans is a source of knowledge by describing the
peculiarities of the problem and therefore fueling the decision process of the
trained model. Unfortunately, the annotation process for subjective natural
language processing (NLP) problems like offensiveness or emotion detection is
often very expensive and time-consuming. One of the inevitable risks is to
spend some of the funds and annotator effort on annotations that do not provide
any additional knowledge about the specific task. To minimize these costs, we
propose a new model-based approach that allows the selection of tasks annotated
individually for each text in a multi-task scenario. The experiments carried
out on three datasets, dozens of NLP tasks, and thousands of annotations show
that our method allows up to 40% reduction in the number of annotations with
negligible loss of knowledge. The results also emphasize the need to collect a
diverse amount of data required to efficiently train a model, depending on the
subjectivity of the annotation task. We also focused on measuring the relation
between subjective tasks by evaluating the model in single-task and multi-task
scenarios. Moreover, for some datasets, training only on the labels predicted
by our model improved the efficiency of task selection as a self-supervised
learning regularization technique."	ArXiv
2208	Catwalk: A Unified Language Model Evaluation Framework for Many Datasets	['Dirk Groeneveld', 'Anas Awadalla', 'Iz Beltagy', 'Akshita Bhagia', 'Ian Magnusson', 'Hao Peng', 'Oyvind Tafjord', 'Pete Walsh', 'Kyle Richardson', 'Jesse Dodge']	2023-12-15 23:11:45+00:00	http://arxiv.org/abs/2312.10253v1	"The success of large language models has shifted the evaluation paradigms in
natural language processing (NLP). The community's interest has drifted towards
comparing NLP models across many tasks, domains, and datasets, often at an
extreme scale. This imposes new engineering challenges: efforts in constructing
datasets and models have been fragmented, and their formats and interfaces are
incompatible. As a result, it often takes extensive (re)implementation efforts
to make fair and controlled comparisons at scale.
  Catwalk aims to address these issues. Catwalk provides a unified interface to
a broad range of existing NLP datasets and models, ranging from both canonical
supervised training and fine-tuning, to more modern paradigms like in-context
learning. Its carefully-designed abstractions allow for easy extensions to many
others. Catwalk substantially lowers the barriers to conducting controlled
experiments at scale. For example, we finetuned and evaluated over 64 models on
over 86 datasets with a single command, without writing any code. Maintained by
the AllenNLP team at the Allen Institute for Artificial Intelligence (AI2),
Catwalk is an ongoing open-source effort: https://github.com/allenai/catwalk."	ArXiv
2209	"Solving mathematical programs with complementarity constraints arising
  in nonsmooth optimal control"	['Armin Nurkanović', 'Anton Pozharskiy', 'Moritz Diehl']	2023-12-18 08:55:01+00:00	http://arxiv.org/abs/2312.11022v2	"This paper examines solution methods for mathematical programs with
complementarity constraints (MPCC) obtained from the time-discretization of
optimal control problems (OCPs) subject to nonsmooth dynamical systems. The
MPCC theory and stationarity concepts are reviewed and summarized. The focus is
on relaxation-based methods for MPCCs, which solve a (finite) sequence of more
regular nonlinear programs (NLP), where a regularization/homotopy parameter is
driven to zero. Such methods perform reasonably well on currently available
benchmarks. However, these results do not always generalize to MPCCs obtained
from nonsmooth OCPs. To provide a more complete picture, this paper introduces
a novel benchmark collection of such problems, which we call nosbench. The
problem set includes 603 different MPCCs and we split it into a few
representative subsets to accelerate the testing. We compare different
relaxation-based methods, NLP solvers, homotopy parameter update and relaxation
parameter steering strategies. Moreover, we check whether the obtained
stationary points allow first-order descent directions, which may be the case
for some of the weaker MPCC stationarity concepts. In the best case, the
Scholtes' relaxation [Scholtes, 2002] with IPOPT [W\""achter and Biegler, 2006]
as NLP solver manages to solve 73.8 % of the problems. This highlights the need
for further improvements in algorithms and software for MPCCs."	ArXiv
2210	"Self-Admitted Technical Debt Detection Approaches: A Decade Systematic
  Review"	['Edi Sutoyo', 'Andrea Capiluppi']	2023-12-19 12:01:13+00:00	http://arxiv.org/abs/2312.15020v3	"Technical debt (TD) represents the long-term costs associated with suboptimal
design or code decisions in software development, often made to meet short-term
delivery goals. Self-Admitted Technical Debt (SATD) occurs when developers
explicitly acknowledge these trade-offs in the codebase, typically through
comments or annotations. Automated detection of SATD has become an increasingly
important research area, particularly with the rise of natural language
processing (NLP), machine learning (ML), and deep learning (DL) techniques that
aim to streamline SATD detection.
  This systematic literature review provides a comprehensive analysis of SATD
detection approaches published between 2014 and 2024, focusing on the evolution
of techniques from NLP-based models to more advanced ML, DL, and
Transformers-based models such as BERT. The review identifies key trends in
SATD detection methodologies and tools, evaluates the effectiveness of
different approaches using metrics like precision, recall, and F1-score, and
highlights the primary challenges in this domain, including dataset
heterogeneity, model generalizability, and the explainability of models.
  The findings suggest that while early NLP methods laid the foundation for
SATD detection, more recent advancements in DL and Transformers models have
significantly improved detection accuracy. However, challenges remain in
scaling these models for broader industrial use. This SLR offers insights into
current research gaps and provides directions for future work, aiming to
improve the robustness and practicality of SATD detection tools."	ArXiv
2211	"The What, Why, and How of Context Length Extension Techniques in Large
  Language Models -- A Detailed Survey"	['Saurav Pawar', 'S. M Towhidul Islam Tonmoy', 'S M Mehedi Zaman', 'Vinija Jain', 'Aman Chadha', 'Amitava Das']	2024-01-15 18:07:21+00:00	http://arxiv.org/abs/2401.07872v1	"The advent of Large Language Models (LLMs) represents a notable breakthrough
in Natural Language Processing (NLP), contributing to substantial progress in
both text comprehension and generation. However, amidst these advancements, it
is noteworthy that LLMs often face a limitation in terms of context length
extrapolation. Understanding and extending the context length for LLMs is
crucial in enhancing their performance across various NLP applications. In this
survey paper, we delve into the multifaceted aspects of exploring why it is
essential, and the potential transformations that superior techniques could
bring to NLP applications. We study the inherent challenges associated with
extending context length and present an organized overview of the existing
strategies employed by researchers. Additionally, we discuss the intricacies of
evaluating context extension techniques and highlight the open challenges that
researchers face in this domain. Furthermore, we explore whether there is a
consensus within the research community regarding evaluation standards and
identify areas where further agreement is needed. This comprehensive survey
aims to serve as a valuable resource for researchers, guiding them through the
nuances of context length extension techniques and fostering discussions on
future advancements in this evolving field."	ArXiv
2212	"Beyond the Frame: Single and mutilple video summarization method with
  user-defined length"	['Vahid Ahmadi Kalkhorani', 'Qingquan Zhang', 'Guanqun Song', 'Ting Zhu']	2023-12-23 04:32:07+00:00	http://arxiv.org/abs/2401.10254v1	"Video smmarization is a crucial method to reduce the time of videos which
reduces the spent time to watch/review a long video. This apporach has became
more important as the amount of publisehed video is increasing everyday. A
single or multiple videos can be summarized into a relatively short video using
various of techniques from multimodal audio-visual techniques, to natural
language processing approaches. Audiovisual techniques may be used to recognize
significant visual events and pick the most important parts, while NLP
techniques can be used to evaluate the audio transcript and extract the main
sentences (timestamps) and corresponding video frames from the original video.
Another approach is to use the best of both domain. Meaning that we can use
audio-visual cues as well as video transcript to extract and summarize the
video. In this paper, we combine a variety of NLP techniques (extractive and
contect-based summarizers) with video processing techniques to convert a long
video into a single relatively short video. We design this toll in a way that
user can specify the relative length of the summarized video. We have also
explored ways of summarizing and concatenating multiple videos into a single
short video which will help having most important concepts from the same
subject in a single short video. Out approach shows that video summarizing is a
difficult but significant work, with substantial potential for further research
and development, and it is possible thanks to the development of NLP models."	ArXiv
2213	"Assertion Detection Large Language Model In-context Learning LoRA
  Fine-tuning"	['Yuelyu Ji', 'Zeshui Yu', 'Yanshan Wang']	2024-01-31 05:11:00+00:00	http://arxiv.org/abs/2401.17602v1	"In this study, we aim to address the task of assertion detection when
extracting medical concepts from clinical notes, a key process in clinical
natural language processing (NLP). Assertion detection in clinical NLP usually
involves identifying assertion types for medical concepts in the clinical text,
namely certainty (whether the medical concept is positive, negated, possible,
or hypothetical), temporality (whether the medical concept is for present or
the past history), and experiencer (whether the medical concept is described
for the patient or a family member). These assertion types are essential for
healthcare professionals to quickly and clearly understand the context of
medical conditions from unstructured clinical texts, directly influencing the
quality and outcomes of patient care. Although widely used, traditional
methods, particularly rule-based NLP systems and machine learning or deep
learning models, demand intensive manual efforts to create patterns and tend to
overlook less common assertion types, leading to an incomplete understanding of
the context. To address this challenge, our research introduces a novel
methodology that utilizes Large Language Models (LLMs) pre-trained on a vast
array of medical data for assertion detection. We enhanced the current method
with advanced reasoning techniques, including Tree of Thought (ToT), Chain of
Thought (CoT), and Self-Consistency (SC), and refine it further with Low-Rank
Adaptation (LoRA) fine-tuning. We first evaluated the model on the i2b2 2010
assertion dataset. Our method achieved a micro-averaged F-1 of 0.89, with 0.11
improvements over the previous works. To further assess the generalizability of
our approach, we extended our evaluation to a local dataset that focused on
sleep concept extraction. Our approach achieved an F-1 of 0.74, which is 0.31
higher than the previous method."	ArXiv
2214	"Leveraging Large Language Models for Enhanced NLP Task Performance
  through Knowledge Distillation and Optimized Training Strategies"	['Yining Huang', 'Keke Tang', 'Meilian Chen']	2024-02-14 16:10:45+00:00	http://arxiv.org/abs/2402.09282v4	"Emerging Large Language Models (LLMs) like GPT-4 have revolutionized Natural
Language Processing (NLP), showing potential in traditional tasks such as Named
Entity Recognition (NER). Our study explores a three-phase training strategy
that harnesses GPT-4's capabilities to enhance the BERT model's performance on
NER. Initially, GPT-4 annotates a subset of the CONLL2003 and additional BBC
dataset without fine-tuning. We then train BERT using a mix of original and
LLM-annotated data, analyzing the efficacy of LLM annotations against
traditional methods. The second phase involves comparative experiments with
different training regimens, assessing the synergy between distilled and
original data. We observe that sequential strategies, particularly a simple mix
of training first with distilled data followed by original data, significantly
boost performance. In the third phase, we investigate various data blending
techniques, including sigmoid and power decay functions, to optimize the
training process further. Our results indicate that a strategic mix of
distilled and original data markedly elevates the NER capabilities of BERT. Our
approach presents a scalable methodology that reduces manual annotation costs
and increases efficiency, making it especially pertinent in resource-limited
and closed-network environments. The study concludes that while the 'Simple
Mix' strategy yields the best results, understanding its underlying mechanisms
requires further research. Future work will also focus on refining prompt
designs and enhancing annotation selection processes, aiming to extend our
methodology to diverse NLP tasks."	ArXiv
2215	"Malaysian English News Decoded: A Linguistic Resource for Named Entity
  and Relation Extraction"	['Mohan Raj Chanthran', 'Lay-Ki Soon', 'Huey Fang Ong', 'Bhawani Selvaretnam']	2024-02-22 13:12:05+00:00	http://arxiv.org/abs/2402.14521v1	"Standard English and Malaysian English exhibit notable differences, posing
challenges for natural language processing (NLP) tasks on Malaysian English.
Unfortunately, most of the existing datasets are mainly based on standard
English and therefore inadequate for improving NLP tasks in Malaysian English.
An experiment using state-of-the-art Named Entity Recognition (NER) solutions
on Malaysian English news articles highlights that they cannot handle
morphosyntactic variations in Malaysian English. To the best of our knowledge,
there is no annotated dataset available to improvise the model. To address
these issues, we constructed a Malaysian English News (MEN) dataset, which
contains 200 news articles that are manually annotated with entities and
relations. We then fine-tuned the spaCy NER tool and validated that having a
dataset tailor-made for Malaysian English could improve the performance of NER
in Malaysian English significantly. This paper presents our effort in the data
acquisition, annotation methodology, and thorough analysis of the annotated
dataset. To validate the quality of the annotation, inter-annotator agreement
was used, followed by adjudication of disagreements by a subject matter expert.
Upon completion of these tasks, we managed to develop a dataset with 6,061
entities and 3,268 relation instances. Finally, we discuss on spaCy fine-tuning
setup and analysis on the NER performance. This unique dataset will contribute
significantly to the advancement of NLP research in Malaysian English, allowing
researchers to accelerate their progress, particularly in NER and relation
extraction. The dataset and annotation guideline has been published on Github."	ArXiv
2216	Vygotsky Distance: Measure for Benchmark Task Similarity	['Maxim K. Surkov', 'Ivan P. Yamshchikov']	2024-02-22 12:00:32+00:00	http://arxiv.org/abs/2402.14890v2	"Evaluation plays a significant role in modern natural language processing.
Most modern NLP benchmarks consist of arbitrary sets of tasks that neither
guarantee any generalization potential for the model once applied outside the
test set nor try to minimize the resource consumption needed for model
evaluation. This paper presents a theoretical instrument and a practical
algorithm to calculate similarity between benchmark tasks, we call this
similarity measure ""Vygotsky distance"". The core idea of this similarity
measure is that it is based on relative performance of the ""students"" on a
given task, rather that on the properties of the task itself. If two tasks are
close to each other in terms of Vygotsky distance the models tend to have
similar relative performance on them. Thus knowing Vygotsky distance between
tasks one can significantly reduce the number of evaluation tasks while
maintaining a high validation quality. Experiments on various benchmarks,
including GLUE, SuperGLUE, CLUE, and RussianSuperGLUE, demonstrate that a vast
majority of NLP benchmarks could be at least 40% smaller in terms of the tasks
included. Most importantly, Vygotsky distance could also be used for the
validation of new tasks thus increasing the generalization potential of the
future NLP models."	ArXiv
2217	"On the use of Silver Standard Data for Zero-shot Classification Tasks in
  Information Extraction"	['Jianwei Wang', 'Tianyin Wang', 'Ziqian Zeng']	2024-02-28 05:45:37+00:00	http://arxiv.org/abs/2402.18061v2	"The superior performance of supervised classification methods in the
information extraction (IE) area heavily relies on a large amount of gold
standard data. Recent zero-shot classification methods converted the task to
other NLP tasks (e.g., textual entailment) and used off-the-shelf models of
these NLP tasks to directly perform inference on the test data without using a
large amount of IE annotation data. A potentially valuable by-product of these
methods is the large-scale silver standard data, i.e., pseudo-labeled data by
the off-the-shelf models of other NLP tasks. However, there is no further
investigation into the use of these data. In this paper, we propose a new
framework, Clean-LaVe, which aims to utilize silver standard data to enhance
the zero-shot performance. Clean-LaVe includes four phases: (1) Obtaining
silver data; (2) Identifying relatively clean data from silver data; (3)
Finetuning the off-the-shelf model using clean data; (4) Inference on the test
data. The experimental results show that Clean-LaVe can outperform the baseline
by 5% and 6% on TACRED and Wiki80 dataset in the zero-shot relation
classification task, and by 3%-7% on Smile (Korean and Polish) in the zero-shot
cross-lingual relation classification task, and by 8% on ACE05-E+ in the
zero-shot event argument classification task. The code is share in
https://github.com/wjw136/Clean_LaVe.git."	ArXiv
2218	Can Humans Identify Domains?	['Maria Barrett', 'Max Müller-Eberstein', 'Elisa Bassignana', 'Amalie Brogaard Pauli', 'Mike Zhang', 'Rob van der Goot']	2024-04-02 09:49:07+00:00	http://arxiv.org/abs/2404.01785v1	"Textual domain is a crucial property within the Natural Language Processing
(NLP) community due to its effects on downstream model performance. The concept
itself is, however, loosely defined and, in practice, refers to any
non-typological property, such as genre, topic, medium or style of a document.
We investigate the core notion of domains via human proficiency in identifying
related intrinsic textual properties, specifically the concepts of genre
(communicative purpose) and topic (subject matter). We publish our annotations
in *TGeGUM*: A collection of 9.1k sentences from the GUM dataset (Zeldes, 2017)
with single sentence and larger context (i.e., prose) annotations for one of 11
genres (source type), and its topic/subtopic as per the Dewey Decimal library
classification system (Dewey, 1979), consisting of 10/100 hierarchical topics
of increased granularity. Each instance is annotated by three annotators, for a
total of 32.7k annotations, allowing us to examine the level of human
disagreement and the relative difficulty of each annotation task. With a
Fleiss' kappa of at most 0.53 on the sentence level and 0.66 at the prose
level, it is evident that despite the ubiquity of domains in NLP, there is
little human consensus on how to define them. By training classifiers to
perform the same task, we find that this uncertainty also extends to NLP
models."	ArXiv
2219	"LATTE: Low-Precision Approximate Attention with Head-wise Trainable
  Threshold for Efficient Transformer"	['Jiing-Ping Wang', 'Ming-Guang Lin', 'An-Yeu', 'Wu']	2024-04-11 07:23:19+00:00	http://arxiv.org/abs/2404.07519v1	"With the rise of Transformer models in NLP and CV domain, Multi-Head
Attention has been proven to be a game-changer. However, its expensive
computation poses challenges to the model throughput and efficiency, especially
for the long sequence tasks. Exploiting the sparsity in attention has been
proven to be an effective way to reduce computation. Nevertheless, prior works
do not consider the various distributions among different heads and lack a
systematic method to determine the threshold. To address these challenges, we
propose Low-Precision Approximate Attention with Head-wise Trainable Threshold
for Efficient Transformer (LATTE). LATTE employs a headwise threshold-based
filter with the low-precision dot product and computation reuse mechanism to
reduce the computation of MHA. Moreover, the trainable threshold is introduced
to provide a systematic method for adjusting the thresholds and enable
end-to-end optimization. Experimental results indicate LATTE can smoothly adapt
to both NLP and CV tasks, offering significant computation savings with only a
minor compromise in performance. Also, the trainable threshold is shown to be
essential for the leverage between the performance and the computation. As a
result, LATTE filters up to 85.16% keys with only a 0.87% accuracy drop in the
CV task and 89.91% keys with a 0.86 perplexity increase in the NLP task."	ArXiv
2220	ExeGPT: Constraint-Aware Resource Scheduling for LLM Inference	['Hyungjun Oh', 'Kihong Kim', 'Jaemin Kim', 'Sungkyun Kim', 'Junyeol Lee', 'Du-seong Chang', 'Jiwon Seo']	2024-03-15 06:21:56+00:00	http://arxiv.org/abs/2404.07947v1	"This paper presents ExeGPT, a distributed system designed for
constraint-aware LLM inference. ExeGPT finds and runs with an optimal execution
schedule to maximize inference throughput while satisfying a given latency
constraint. By leveraging the distribution of input and output sequences, it
effectively allocates resources and determines optimal execution
configurations, including batch sizes and partial tensor parallelism. We also
introduce two scheduling strategies based on Round-Robin Allocation and
Workload-Aware Allocation policies, suitable for different NLP workloads. We
evaluate ExeGPT on six LLM instances of T5, OPT, and GPT-3 and five NLP tasks,
each with four distinct latency constraints. Compared to FasterTransformer,
ExeGPT achieves up to 15.2x improvements in throughput and 6x improvements in
latency. Overall, ExeGPT achieves an average throughput gain of 2.9x across
twenty evaluation scenarios. Moreover, when adapting to changing sequence
distributions, the cost of adjusting the schedule in ExeGPT is reasonably
modest. ExeGPT proves to be an effective solution for optimizing and executing
LLM inference for diverse NLP workload and serving conditions."	ArXiv
2221	"Can a Multichoice Dataset be Repurposed for Extractive Question
  Answering?"	['Teresa Lynn', 'Malik H. Altakrori', 'Samar Mohamed Magdy', 'Rocktim Jyoti Das', 'Chenyang Lyu', 'Mohamed Nasr', 'Younes Samih', 'Alham Fikri Aji', 'Preslav Nakov', 'Shantanu Godbole', 'Salim Roukos', 'Radu Florian', 'Nizar Habash']	2024-04-26 11:46:05+00:00	http://arxiv.org/abs/2404.17342v1	"The rapid evolution of Natural Language Processing (NLP) has favored major
languages such as English, leaving a significant gap for many others due to
limited resources. This is especially evident in the context of data
annotation, a task whose importance cannot be underestimated, but which is
time-consuming and costly. Thus, any dataset for resource-poor languages is
precious, in particular when it is task-specific. Here, we explore the
feasibility of repurposing existing datasets for a new NLP task: we repurposed
the Belebele dataset (Bandarkar et al., 2023), which was designed for
multiple-choice question answering (MCQA), to enable extractive QA (EQA) in the
style of machine reading comprehension. We present annotation guidelines and a
parallel EQA dataset for English and Modern Standard Arabic (MSA). We also
present QA evaluation results for several monolingual and cross-lingual QA
pairs including English, MSA, and five Arabic dialects. Our aim is to enable
others to adapt our approach for the 120+ other language variants in Belebele,
many of which are deemed under-resourced. We also conduct a thorough analysis
and share our insights from the process, which we hope will contribute to a
deeper understanding of the challenges and the opportunities associated with
task reformulation in NLP research."	ArXiv
2222	"Modeling Orthographic Variation Improves NLP Performance for Nigerian
  Pidgin"	['Pin-Jie Lin', 'Merel Scholman', 'Muhammed Saeed', 'Vera Demberg']	2024-04-28 18:07:13+00:00	http://arxiv.org/abs/2404.18264v1	"Nigerian Pidgin is an English-derived contact language and is traditionally
an oral language, spoken by approximately 100 million people. No orthographic
standard has yet been adopted, and thus the few available Pidgin datasets that
exist are characterised by noise in the form of orthographic variations. This
contributes to under-performance of models in critical NLP tasks. The current
work is the first to describe various types of orthographic variations commonly
found in Nigerian Pidgin texts, and model this orthographic variation. The
variations identified in the dataset form the basis of a phonetic-theoretic
framework for word editing, which is used to generate orthographic variations
to augment training data. We test the effect of this data augmentation on two
critical NLP tasks: machine translation and sentiment analysis. The proposed
variation generation framework augments the training data with new orthographic
variants which are relevant for the test set but did not occur in the training
set originally. Our results demonstrate the positive effect of augmenting the
training data with a combination of real texts from other corpora as well as
synthesized orthographic variation, resulting in performance improvements of
2.1 points in sentiment analysis and 1.4 BLEU points in translation to English."	ArXiv
2223	"RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural
  Language Processing"	['Yucheng Hu', 'Yuxing Lu']	2024-04-30 13:14:51+00:00	http://arxiv.org/abs/2404.19543v1	"Large Language Models (LLMs) have catalyzed significant advancements in
Natural Language Processing (NLP), yet they encounter challenges such as
hallucination and the need for domain-specific knowledge. To mitigate these,
recent methodologies have integrated information retrieved from external
resources with LLMs, substantially enhancing their performance across NLP
tasks. This survey paper addresses the absence of a comprehensive overview on
Retrieval-Augmented Language Models (RALMs), both Retrieval-Augmented
Generation (RAG) and Retrieval-Augmented Understanding (RAU), providing an
in-depth examination of their paradigm, evolution, taxonomy, and applications.
The paper discusses the essential components of RALMs, including Retrievers,
Language Models, and Augmentations, and how their interactions lead to diverse
model structures and applications. RALMs demonstrate utility in a spectrum of
tasks, from translation and dialogue systems to knowledge-intensive
applications. The survey includes several evaluation methods of RALMs,
emphasizing the importance of robustness, accuracy, and relevance in their
assessment. It also acknowledges the limitations of RALMs, particularly in
retrieval quality and computational efficiency, offering directions for future
research. In conclusion, this survey aims to offer a structured insight into
RALMs, their potential, and the avenues for their future development in NLP.
The paper is supplemented with a Github Repository containing the surveyed
works and resources for further study:
https://github.com/2471023025/RALM_Survey."	ArXiv
2224	"1-Diffractor: Efficient and Utility-Preserving Text Obfuscation
  Leveraging Word-Level Metric Differential Privacy"	['Stephen Meisenbacher', 'Maulik Chevli', 'Florian Matthes']	2024-05-02 19:07:32+00:00	http://arxiv.org/abs/2405.01678v1	"The study of privacy-preserving Natural Language Processing (NLP) has gained
rising attention in recent years. One promising avenue studies the integration
of Differential Privacy in NLP, which has brought about innovative methods in a
variety of application settings. Of particular note are $\textit{word-level
Metric Local Differential Privacy (MLDP)}$ mechanisms, which work to obfuscate
potentially sensitive input text by performing word-by-word
$\textit{perturbations}$. Although these methods have shown promising results
in empirical tests, there are two major drawbacks: (1) the inevitable loss of
utility due to addition of noise, and (2) the computational expensiveness of
running these mechanisms on high-dimensional word embeddings. In this work, we
aim to address these challenges by proposing $\texttt{1-Diffractor}$, a new
mechanism that boasts high speedups in comparison to previous mechanisms, while
still demonstrating strong utility- and privacy-preserving capabilities. We
evaluate $\texttt{1-Diffractor}$ for utility on several NLP tasks, for
theoretical and task-based privacy, and for efficiency in terms of speed and
memory. $\texttt{1-Diffractor}$ shows significant improvements in efficiency,
while still maintaining competitive utility and privacy scores across all
conducted comparative tests against previous MLDP mechanisms. Our code is made
available at: https://github.com/sjmeis/Diffractor."	ArXiv
2225	"Aspect-based Sentiment Evaluation of Chess Moves (ASSESS): an NLP-based
  Method for Evaluating Chess Strategies from Textbooks"	['Haifa Alrdahi', 'Riza Batista-Navarro']	2024-05-10 14:23:43+00:00	http://arxiv.org/abs/2405.06499v1	"The chess domain is well-suited for creating an artificial intelligence (AI)
system that mimics real-world challenges, including decision-making. Throughout
the years, minimal attention has been paid to investigating insights derived
from unstructured chess data sources. In this study, we examine the complicated
relationships between multiple referenced moves in a chess-teaching textbook,
and propose a novel method designed to encapsulate chess knowledge derived from
move-action phrases. This study investigates the feasibility of using a
modified sentiment analysis method as a means for evaluating chess moves based
on text. Our proposed Aspect-Based Sentiment Analysis (ABSA) method represents
an advancement in evaluating the sentiment associated with referenced chess
moves. By extracting insights from move-action phrases, our approach aims to
provide a more fine-grained and contextually aware `chess move'-based sentiment
classification. Through empirical experiments and analysis, we evaluate the
performance of our fine-tuned ABSA model, presenting results that confirm the
efficiency of our approach in advancing aspect-based sentiment classification
within the chess domain. This research contributes to the area of game-playing
by machines and shows the practical applicability of leveraging NLP techniques
to understand the context of strategic games."	ArXiv
2226	A Comprehensive Analysis of Static Word Embeddings for Turkish	['Karahan Sarıtaş', 'Cahid Arda Öz', 'Tunga Güngör']	2024-05-13 14:23:37+00:00	http://arxiv.org/abs/2405.07778v1	"Word embeddings are fixed-length, dense and distributed word representations
that are used in natural language processing (NLP) applications. There are
basically two types of word embedding models which are non-contextual (static)
models and contextual models. The former method generates a single embedding
for a word regardless of its context, while the latter method produces distinct
embeddings for a word based on the specific contexts in which it appears. There
are plenty of works that compare contextual and non-contextual embedding models
within their respective groups in different languages. However, the number of
studies that compare the models in these two groups with each other is very few
and there is no such study in Turkish. This process necessitates converting
contextual embeddings into static embeddings. In this paper, we compare and
evaluate the performance of several contextual and non-contextual models in
both intrinsic and extrinsic evaluation settings for Turkish. We make a
fine-grained comparison by analyzing the syntactic and semantic capabilities of
the models separately. The results of the analyses provide insights about the
suitability of different embedding models in different types of NLP tasks. We
also build a Turkish word embedding repository comprising the embedding models
used in this work, which may serve as a valuable resource for researchers and
practitioners in the field of Turkish NLP. We make the word embeddings,
scripts, and evaluation datasets publicly available."	ArXiv
2227	Benchmarking the Performance of Pre-trained LLMs across Urdu NLP Tasks	['Munief Hassan Tahir', 'Sana Shams', 'Layba Fiaz', 'Farah Adeeba', 'Sarmad Hussain']	2024-05-24 11:30:37+00:00	http://arxiv.org/abs/2405.15453v2	"Large Language Models (LLMs) pre-trained on multilingual data have
revolutionized natural language processing research, by transitioning from
languages and task specific model pipelines to a single model adapted on a
variety of tasks. However majority of existing multilingual NLP benchmarks for
LLMs provide evaluation data in only few languages with little linguistic
diversity. In addition these benchmarks lack quality assessment against the
respective state-of the art models. This study presents an in-depth examination
of 7 prominent LLMs: GPT-3.5-turbo, Llama 2-7B-Chat, Llama 3.1-8B, Bloomz 3B,
Bloomz 7B1, Ministral-8B and Whisper (Large, medium and small variant) across
17 tasks using 22 datasets, 13.8 hours of speech, in a zero-shot setting, and
their performance against state-of-the-art (SOTA) models, has been compared and
analyzed. Our experiments show that SOTA models currently outperform
encoder-decoder models in majority of Urdu NLP tasks under zero-shot settings.
However, comparing Llama 3.1-8B over prior version Llama 2-7B-Chat, we can
deduce that with improved language coverage, LLMs can surpass these SOTA
models. Our results emphasize that models with fewer parameters but richer
language-specific data, like Llama 3.1-8B, often outperform larger models with
lower language diversity, such as GPT-3.5, in several tasks."	ArXiv
2228	The Task-oriented Queries Benchmark (ToQB)	['Keun Soo Yim']	2024-06-05 05:05:41+00:00	http://arxiv.org/abs/2406.02943v1	"Task-oriented queries (e.g., one-shot queries to play videos, order food, or
call a taxi) are crucial for assessing the quality of virtual assistants,
chatbots, and other large language model (LLM)-based services. However, a
standard benchmark for task-oriented queries is not yet available, as existing
benchmarks in the relevant NLP (Natural Language Processing) fields have
primarily focused on task-oriented dialogues. Thus, we present a new
methodology for efficiently generating the Task-oriented Queries Benchmark
(ToQB) using existing task-oriented dialogue datasets and an LLM service. Our
methodology involves formulating the underlying NLP task to summarize the
original intent of a speaker in each dialogue, detailing the key steps to
perform the devised NLP task using an LLM service, and outlining a framework
for automating a major part of the benchmark generation process. Through a case
study encompassing three domains (i.e., two single-task domains and one
multi-task domain), we demonstrate how to customize the LLM prompts (e.g.,
omitting system utterances or speaker labels) for those three domains and
characterize the generated task-oriented queries. The generated ToQB dataset is
made available to the public. We further discuss new domains that can be added
to ToQB by community contributors and its practical applications."	ArXiv
2229	"GET: A Generative EEG Transformer for Continuous Context-Based Neural
  Signals"	['Omair Ali', 'Muhammad Saif-ur-Rehman', 'Marita Metzler', 'Tobias Glasmachers', 'Ioannis Iossifidis', 'Christian Klaes']	2024-06-05 10:10:00+00:00	http://arxiv.org/abs/2406.03115v3	"Generating continuous electroencephalography (EEG) signals through advanced
artificial neural networks presents a novel opportunity to enhance
brain-computer interface (BCI) technology. This capability has the potential to
significantly enhance applications ranging from simulating dynamic brain
activity and data augmentation to improving real-time epilepsy detection and
BCI inference. By harnessing generative transformer neural networks,
specifically designed for EEG signal generation, we can revolutionize the
interpretation and interaction with neural data. Generative AI has demonstrated
significant success across various domains, from natural language processing
(NLP) and computer vision to content creation in visual arts and music. It
distinguishes itself by using large-scale datasets to construct context windows
during pre-training, a technique that has proven particularly effective in NLP,
where models are fine-tuned for specific downstream tasks after extensive
foundational training. However, the application of generative AI in the field
of BCIs, particularly through the development of continuous, context-rich
neural signal generators, has been limited. To address this, we introduce the
Generative EEG Transformer (GET), a model leveraging transformer architecture
tailored for EEG data. The GET model is pre-trained on diverse EEG datasets,
including motor imagery and alpha wave datasets, enabling it to produce
high-fidelity neural signals that maintain contextual integrity. Our empirical
findings indicate that GET not only faithfully reproduces the frequency
spectrum of the training data and input prompts but also robustly generates
continuous neural signals. By adopting the successful training strategies of
the NLP domain for BCIs, the GET sets a new standard for the development and
application of neural signal generation technologies."	ArXiv
2230	"SynAsk: Unleashing the Power of Large Language Models in Organic
  Synthesis"	['Chonghuan Zhang', 'Qianghua Lin', 'Biwei Zhu', 'Haopeng Yang', 'Xiao Lian', 'Hao Deng', 'Jiajun Zheng', 'Kuangbiao Liao']	2024-06-07 02:58:12+00:00	http://arxiv.org/abs/2406.04593v2	"The field of natural language processing (NLP) has witnessed a transformative
shift with the emergence of large language models (LLMs), revolutionizing
various language tasks and applications, and the integration of LLM into
specialized domains enhances their capabilities for domain-specific
applications. Notably, NLP has made significant strides in organic chemistry,
particularly in predicting synthetic tasks, paving the way for the development
of LLMs tailored to the organic chemistry field. In this work, we introduce
SynAsk, a comprehensive organic chemistry domain-specific LLM platform
developed by AIChemEco Inc. By finetuning an LLM with domain-specific data and
integrating it with a chain of thought approach, SynAsk seamlessly accesses our
knowledge base and advanced chemistry tools in a question-and-answer format.
This includes functionalities such as a basic chemistry knowledge base,
molecular information retrieval, reaction performance prediction,
retrosynthesis prediction, chemical literature acquisition, and more. This
novel methodology synergizes fine-tuning techniques with external resource
integration, resulting in an organic chemistry-specific model poised to
facilitate research and discovery in the field. Accessible via
http://synask.aichemeco.com, SynAsk represents a significant advancement in
leveraging NLP for synthetic applications."	ArXiv
2231	"LLMs instead of Human Judges? A Large Scale Empirical Study across 20
  NLP Evaluation Tasks"	['Anna Bavaresco', 'Raffaella Bernardi', 'Leonardo Bertolazzi', 'Desmond Elliott', 'Raquel Fernández', 'Albert Gatt', 'Esam Ghaleb', 'Mario Giulianelli', 'Michael Hanna', 'Alexander Koller', 'André F. T. Martins', 'Philipp Mondorf', 'Vera Neplenbroek', 'Sandro Pezzelle', 'Barbara Plank', 'David Schlangen', 'Alessandro Suglia', 'Aditya K Surikuchi', 'Ece Takmaz', 'Alberto Testoni']	2024-06-26 14:56:13+00:00	http://arxiv.org/abs/2406.18403v2	"There is an increasing trend towards evaluating NLP models with LLMs instead
of human judgments, raising questions about the validity of these evaluations,
as well as their reproducibility in the case of proprietary models. We provide
JUDGE-BENCH, an extensible collection of 20 NLP datasets with human annotations
covering a broad range of evaluated properties and types of data, and
comprehensively evaluate 11 current LLMs, covering both open-weight and
proprietary models, for their ability to replicate the annotations. Our
evaluations show substantial variance across models and datasets. Models are
reliable evaluators on some tasks, but overall display substantial variability
depending on the property being evaluated, the expertise level of the human
judges, and whether the language is human or model-generated. We conclude that
LLMs should be carefully validated against human judgments before being used as
evaluators."	ArXiv
2232	"Voices Unheard: NLP Resources and Models for Yorùbá Regional
  Dialects"	['Orevaoghene Ahia', 'Anuoluwapo Aremu', 'Diana Abagyan', 'Hila Gonen', 'David Ifeoluwa Adelani', 'Daud Abolade', 'Noah A. Smith', 'Yulia Tsvetkov']	2024-06-27 22:38:04+00:00	http://arxiv.org/abs/2406.19564v1	"Yor\`ub\'a an African language with roughly 47 million speakers encompasses a
continuum with several dialects. Recent efforts to develop NLP technologies for
African languages have focused on their standard dialects, resulting in
disparities for dialects and varieties for which there are little to no
resources or tools. We take steps towards bridging this gap by introducing a
new high-quality parallel text and speech corpus YOR\`ULECT across three
domains and four regional Yor\`ub\'a dialects. To develop this corpus, we
engaged native speakers, travelling to communities where these dialects are
spoken, to collect text and speech data. Using our newly created corpus, we
conducted extensive experiments on (text) machine translation, automatic speech
recognition, and speech-to-text translation. Our results reveal substantial
performance disparities between standard Yor\`ub\'a and the other dialects
across all tasks. However, we also show that with dialect-adaptive finetuning,
we are able to narrow this gap. We believe our dataset and experimental
analysis will contribute greatly to developing NLP tools for Yor\`ub\'a and its
dialects, and potentially for other African languages, by improving our
understanding of existing challenges and offering a high-quality dataset for
further development. We release YOR\`ULECT dataset and models publicly under an
open license."	ArXiv
2233	"CogErgLLM: Exploring Large Language Model Systems Design Perspective
  Using Cognitive Ergonomics"	['Azmine Toushik Wasi', 'Mst Rafia Islam']	2024-07-03 07:59:52+00:00	http://arxiv.org/abs/2407.02885v5	"Integrating cognitive ergonomics with LLMs is crucial for improving safety,
reliability, and user satisfaction in human-AI interactions. Current LLM
designs often lack this integration, resulting in systems that may not fully
align with human cognitive capabilities and limitations. This oversight
exacerbates biases in LLM outputs and leads to suboptimal user experiences due
to inconsistent application of user-centered design principles. Researchers are
increasingly leveraging NLP, particularly LLMs, to model and understand human
behavior across social sciences, psychology, psychiatry, health, and
neuroscience. Our position paper explores the need to integrate cognitive
ergonomics into LLM design, providing a comprehensive framework and practical
guidelines for ethical development. By addressing these challenges, we aim to
advance safer, more reliable, and ethically sound human-AI interactions."	ArXiv
2234	On Evaluating Explanation Utility for Human-AI Decision Making in NLP	['Fateme Hashemi Chaleshtori', 'Atreya Ghosal', 'Alexander Gill', 'Purbid Bambroo', 'Ana Marasović']	2024-07-03 23:53:27+00:00	http://arxiv.org/abs/2407.03545v2	"Is explainability a false promise? This debate has emerged from the
insufficient evidence that explanations help people in situations they are
introduced for. More human-centered, application-grounded evaluations of
explanations are needed to settle this. Yet, with no established guidelines for
such studies in NLP, researchers accustomed to standardized proxy evaluations
must discover appropriate measurements, tasks, datasets, and sensible models
for human-AI teams in their studies.
  To aid with this, we first review existing metrics suitable for
application-grounded evaluation. We then establish criteria to select
appropriate datasets, and using them, we find that only 4 out of over 50
datasets available for explainability research in NLP meet them. We then
demonstrate the importance of reassessing the state of the art to form and
study human-AI teams: teaming people with models for certain tasks might only
now start to make sense, and for others, it remains unsound. Finally, we
present the exemplar studies of human-AI decision-making for one of the
identified tasks -- verifying the correctness of a legal claim given a
contract. Our results show that providing AI predictions, with or without
explanations, does not cause decision makers to speed up their work without
compromising performance. We argue for revisiting the setup of human-AI teams
and improving automatic deferral of instances to AI, where explanations could
play a useful role."	ArXiv
2235	"All order factorization for virtual Compton scattering at
  next-to-leading power"	['Jakob Schoenleber', 'Robert Szafron']	2024-07-12 13:47:19+00:00	http://arxiv.org/abs/2407.09263v2	"We discuss all-order factorization for the virtual Compton process at
next-to-leading power (NLP) in the $\Lambda_{\rm QCD}/Q$ and $\sqrt{-t}/Q$
expansion (twist-3), both in the double-deeply-virtual case and the
single-deeply-virtual case. We use the soft-collinear effective theory (SCET)
as the main theoretical tool. We conclude that collinear factorization holds in
the double-deeply virtual case, where both photons are far off-shell. The
agreement is found with the known results for the hard matching coefficients at
leading order $\alpha_s^0$, and we can therefore connect the traditional
approach with SCET. In the single-deeply-virtual case, commonly called deeply
virtual Compton scattering (DVCS), the contribution of non-target collinear
regions complicates the factorization. These include momentum modes collinear
to the real photon and (ultra)soft interactions between the photon-collinear
and target-collinear modes. However, such contributions appear only for the
transversely polarized virtual photon at the NLP accuracy and in fact it is the
only NLP $\sim (\Lambda_{\rm QCD}/Q)^1 \sim (\sqrt{-t}/Q)^1$ contribution in
that case. We therefore conclude that the DVCS amplitude for a longitudinally
polarized virtual photon, where the leading power $\sim (\Lambda_{\rm QCD}/Q)^0
\sim (\sqrt{-t}/Q)^0$ contribution vanishes, is free of non-target collinear
contributions and the collinear factorization in terms of twist-3 GPDs holds in
that case as well."	ArXiv
2236	"The Impact of LoRA Adapters for LLMs on Clinical NLP Classification
  Under Data Limitations"	['Thanh-Dung Le', 'Ti Ti Nguyen', 'Vu Nguyen Ha']	2024-07-27 16:48:03+00:00	http://arxiv.org/abs/2407.19299v1	"Fine-tuning Large Language Models (LLMs) for clinical Natural Language
Processing (NLP) poses significant challenges due to the domain gap and limited
data availability. This study investigates the effectiveness of various adapter
techniques, equivalent to Low-Rank Adaptation (LoRA), for fine-tuning LLMs in a
resource-constrained hospital environment. We experimented with four
structures-Adapter, Lightweight, TinyAttention, and Gated Residual Network
(GRN)-as final layers for clinical notes classification. We fine-tuned
biomedical pre-trained models, including CamemBERT-bio, AliBERT, and DrBERT,
alongside two Transformer-based models. Our extensive experimental results
indicate that i) employing adapter structures does not yield significant
improvements in fine-tuning biomedical pre-trained LLMs, and ii) simpler
Transformer-based models, trained from scratch, perform better under resource
constraints. Among the adapter structures, GRN demonstrated superior
performance with accuracy, precision, recall, and an F1 score of 0.88.
Moreover, the total training time for LLMs exceeded 1000 hours, compared to
under 6 hours for simpler transformer-based models, highlighting that LLMs are
more suitable for environments with extensive computational resources and
larger datasets. Consequently, this study demonstrates that simpler
Transformer-based models can be effectively trained from scratch, providing a
viable solution for clinical NLP tasks in low-resource environments with
limited data availability. By identifying the GRN as the most effective adapter
structure, we offer a practical approach to enhance clinical note
classification without requiring extensive computational resources."	ArXiv
2237	"Artificial Intelligence in Extracting Diagnostic Data from Dental
  Records"	['Yao-Shun Chuang', 'Chun-Teh Lee', 'Oluwabunmi Tokede', 'Guo-Hao Lin', 'Ryan Brandon', 'Trung Duong Tran', 'Xiaoqian Jiang', 'Muhammad F. Walji']	2024-07-23 04:05:48+00:00	http://arxiv.org/abs/2407.21050v2	"This research addresses the issue of missing structured data in dental
records by extracting diagnostic information from unstructured text. The
updated periodontology classification system's complexity has increased
incomplete or missing structured diagnoses. To tackle this, we use advanced AI
and NLP methods, leveraging GPT-4 to generate synthetic notes for fine-tuning a
RoBERTa model. This significantly enhances the model's ability to understand
medical and dental language. We evaluated the model using 120 randomly selected
clinical notes from two datasets, demonstrating its improved diagnostic
extraction accuracy. The results showed high accuracy in diagnosing periodontal
status, stage, and grade, with Site 1 scoring 0.99 and Site 2 scoring 0.98. In
the subtype category, Site 2 achieved perfect scores, outperforming Site 1.
This method enhances extraction accuracy and broadens its use across dental
contexts. The study underscores AI and NLP's transformative impact on
healthcare delivery and management. Integrating AI and NLP technologies
enhances documentation and simplifies administrative tasks by precisely
extracting complex clinical information. This approach effectively addresses
challenges in dental diagnostics. Using synthetic training data from LLMs
optimizes the training process, improving accuracy and efficiency in
identifying periodontal diagnoses from clinical notes. This innovative method
holds promise for broader healthcare applications, potentially improving
patient care quality."	ArXiv
2238	RedWhale: An Adapted Korean LLM Through Efficient Continual Pretraining	['Anh-Dung Vo', 'Minseong Jung', 'Wonbeen Lee', 'Daewoo Choi']	2024-08-21 02:49:41+00:00	http://arxiv.org/abs/2408.11294v1	"The field of Natural Language Processing (NLP) has seen significant
advancements with the development of Large Language Models (LLMs). However,
much of this research remains focused on English, often overlooking
low-resource languages like Korean. This oversight presents challenges due to
the unique non-alphabetic token structure of Korean and the substantial memory
and computational demands required for LLM training, which frequently lead to
memory constraints and out-of-memory errors. To address these issues, we
present RedWhale, a model specifically tailored for Korean language processing.
RedWhale is developed using an efficient continual pretraining approach that
includes a comprehensive Korean corpus preprocessing pipeline, a specialized
tokenizer, an optimized model initialization technique, and a multistage
pretraining strategy. These innovations collectively reduce training time and
computational costs while maintaining high levels of accuracy and
comprehension. By leveraging cross-lingual transfer learning, which exploits
shared linguistic similarities across languages, RedWhale builds on English
models to enhance Korean language processing. Experimental results demonstrate
that RedWhale outperforms other leading models on Korean NLP benchmarks,
including the Korean Balanced Evaluation of Significant Tasks (KoBEST), showing
superior understanding and generation of Korean text. Furthermore, RedWhale
showed no signs of convergence even after pretraining on 9.7 billion tokens,
indicating the potential for further improvements with additional training.
This work represents a significant advancement in bridging the linguistic
divide, particularly in enhancing NLP capabilities for the Korean language."	ArXiv
2239	Risks and NLP Design: A Case Study on Procedural Document QA	['Nikita Haduong', 'Alice Gao', 'Noah A. Smith']	2024-08-16 17:23:43+00:00	http://arxiv.org/abs/2408.11860v1	"As NLP systems are increasingly deployed at scale, concerns about their
potential negative impacts have attracted the attention of the research
community, yet discussions of risk have mostly been at an abstract level and
focused on generic AI or NLP applications. We argue that clearer assessments of
risks and harms to users--and concrete strategies to mitigate them--will be
possible when we specialize the analysis to more concrete applications and
their plausible users. As an illustration, this paper is grounded in cooking
recipe procedural document question answering (ProcDocQA), where there are
well-defined risks to users such as injuries or allergic reactions. Our case
study shows that an existing language model, applied in ""zero-shot"" mode,
quantitatively answers real-world questions about recipes as well or better
than the humans who have answered the questions on the web. Using a novel
questionnaire informed by theoretical work on AI risk, we conduct a
risk-oriented error analysis that could then inform the design of a future
system to be deployed with lower risk of harm and better performance."	ArXiv
2240	An Empirical Study on Information Extraction using Large Language Models	['Ridong Han', 'Chaohao Yang', 'Tao Peng', 'Prayag Tiwari', 'Xiang Wan', 'Lu Liu', 'Benyou Wang']	2024-08-31 07:10:16+00:00	http://arxiv.org/abs/2409.00369v3	"Human-like large language models (LLMs), especially the most powerful and
popular ones in OpenAI's GPT family, have proven to be very helpful for many
natural language processing (NLP) related tasks. Therefore, various attempts
have been made to apply LLMs to information extraction (IE), which is a
fundamental NLP task that involves extracting information from unstructured
plain text. To demonstrate the latest representative progress in LLMs'
information extraction ability, we assess the information extraction ability of
GPT-4 (the latest version of GPT at the time of writing this paper) from four
perspectives: Performance, Evaluation Criteria, Robustness, and Error Types.
Our results suggest a visible performance gap between GPT-4 and
state-of-the-art (SOTA) IE methods. To alleviate this problem, considering the
LLMs' human-like characteristics, we propose and analyze the effects of a
series of simple prompt-based methods, which can be generalized to other LLMs
and NLP tasks. Rich experiments show our methods' effectiveness and some of
their remaining issues in improving GPT-4's information extraction ability."	ArXiv
2241	"Can LLMs Generate Novel Research Ideas? A Large-Scale Human Study with
  100+ NLP Researchers"	['Chenglei Si', 'Diyi Yang', 'Tatsunori Hashimoto']	2024-09-06 08:25:03+00:00	http://arxiv.org/abs/2409.04109v1	"Recent advancements in large language models (LLMs) have sparked optimism
about their potential to accelerate scientific discovery, with a growing number
of works proposing research agents that autonomously generate and validate new
ideas. Despite this, no evaluations have shown that LLM systems can take the
very first step of producing novel, expert-level ideas, let alone perform the
entire research process. We address this by establishing an experimental design
that evaluates research idea generation while controlling for confounders and
performs the first head-to-head comparison between expert NLP researchers and
an LLM ideation agent. By recruiting over 100 NLP researchers to write novel
ideas and blind reviews of both LLM and human ideas, we obtain the first
statistically significant conclusion on current LLM capabilities for research
ideation: we find LLM-generated ideas are judged as more novel (p < 0.05) than
human expert ideas while being judged slightly weaker on feasibility. Studying
our agent baselines closely, we identify open problems in building and
evaluating research agents, including failures of LLM self-evaluation and their
lack of diversity in generation. Finally, we acknowledge that human judgements
of novelty can be difficult, even by experts, and propose an end-to-end study
design which recruits researchers to execute these ideas into full projects,
enabling us to study whether these novelty and feasibility judgements result in
meaningful differences in research outcome."	ArXiv
2242	HULLMI: Human vs LLM identification with explainability	['Prathamesh Dinesh Joshi', 'Sahil Pocker', 'Raj Abhijit Dandekar', 'Rajat Dandekar', 'Sreedath Panat']	2024-09-07 12:27:25+00:00	http://arxiv.org/abs/2409.04808v1	"As LLMs become increasingly proficient at producing human-like responses,
there has been a rise of academic and industrial pursuits dedicated to flagging
a given piece of text as ""human"" or ""AI"". Most of these pursuits involve modern
NLP detectors like T5-Sentinel and RoBERTa-Sentinel, without paying too much
attention to issues of interpretability and explainability of these models. In
our study, we provide a comprehensive analysis that shows that traditional ML
models (Naive-Bayes,MLP, Random Forests, XGBoost) perform as well as modern NLP
detectors, in human vs AI text detection. We achieve this by implementing a
robust testing procedure on diverse datasets, including curated corpora and
real-world samples. Subsequently, by employing the explainable AI technique
LIME, we uncover parts of the input that contribute most to the prediction of
each model, providing insights into the detection process. Our study
contributes to the growing need for developing production-level LLM detection
tools, which can leverage a wide range of traditional as well as modern NLP
detectors we propose. Finally, the LIME techniques we demonstrate also have the
potential to equip these detection tools with interpretability analysis
features, making them more reliable and trustworthy in various domains like
education, healthcare, and media."	ArXiv
2243	Native vs Non-Native Language Prompting: A Comparative Analysis	['Mohamed Bayan Kmainasi', 'Rakif Khan', 'Ali Ezzat Shahroor', 'Boushra Bendou', 'Maram Hasanain', 'Firoj Alam']	2024-09-11 06:59:37+00:00	http://arxiv.org/abs/2409.07054v2	"Large language models (LLMs) have shown remarkable abilities in different
fields, including standard Natural Language Processing (NLP) tasks. To elicit
knowledge from LLMs, prompts play a key role, consisting of natural language
instructions. Most open and closed source LLMs are trained on available labeled
and unlabeled resources--digital content such as text, images, audio, and
videos. Hence, these models have better knowledge for high-resourced languages
but struggle with low-resourced languages. Since prompts play a crucial role in
understanding their capabilities, the language used for prompts remains an
important research question. Although there has been significant research in
this area, it is still limited, and less has been explored for medium to
low-resourced languages. In this study, we investigate different prompting
strategies (native vs. non-native) on 11 different NLP tasks associated with 12
different Arabic datasets (9.7K data points). In total, we conducted 197
experiments involving 3 LLMs, 12 datasets, and 3 prompting strategies. Our
findings suggest that, on average, the non-native prompt performs the best,
followed by mixed and native prompts."	ArXiv
2244	"Recent Trends of Multimodal Affective Computing: A Survey from NLP
  Perspective"	['Guimin Hu', 'Yi Xin', 'Weimin Lyu', 'Haojian Huang', 'Chang Sun', 'Zhihong Zhu', 'Lin Gui', 'Ruichu Cai', 'Erik Cambria', 'Hasti Seifi']	2024-09-11 16:24:06+00:00	http://arxiv.org/abs/2409.07388v2	"Multimodal affective computing (MAC) has garnered increasing attention due to
its broad applications in analyzing human behaviors and intentions, especially
in text-dominated multimodal affective computing field. This survey presents
the recent trends of multimodal affective computing from NLP perspective
through four hot tasks: multimodal sentiment analysis, multimodal emotion
recognition in conversation, multimodal aspect-based sentiment analysis and
multimodal multi-label emotion recognition. The goal of this survey is to
explore the current landscape of multimodal affective research, identify
development trends, and highlight the similarities and differences across
various tasks, offering a comprehensive report on the recent progress in
multimodal affective computing from an NLP perspective. This survey covers the
formalization of tasks, provides an overview of relevant works, describes
benchmark datasets, and details the evaluation metrics for each task.
Additionally, it briefly discusses research in multimodal affective computing
involving facial expressions, acoustic signals, physiological signals, and
emotion causes. Additionally, we discuss the technical approaches, challenges,
and future directions in multimodal affective computing. To support further
research, we released a repository that compiles related works in multimodal
affective computing, providing detailed resources and references for the
community."	ArXiv
2245	"AlpaPICO: Extraction of PICO Frames from Clinical Trial Documents Using
  LLMs"	['Madhusudan Ghosh', 'Shrimon Mukherjee', 'Asmit Ganguly', 'Partha Basuchowdhuri', 'Sudip Kumar Naskar', 'Debasis Ganguly']	2024-09-15 11:53:24+00:00	http://arxiv.org/abs/2409.09704v1	"In recent years, there has been a surge in the publication of clinical trial
reports, making it challenging to conduct systematic reviews. Automatically
extracting Population, Intervention, Comparator, and Outcome (PICO) from
clinical trial studies can alleviate the traditionally time-consuming process
of manually scrutinizing systematic reviews. Existing approaches of PICO frame
extraction involves supervised approach that relies on the existence of
manually annotated data points in the form of BIO label tagging. Recent
approaches, such as In-Context Learning (ICL), which has been shown to be
effective for a number of downstream NLP tasks, require the use of labeled
examples. In this work, we adopt ICL strategy by employing the pretrained
knowledge of Large Language Models (LLMs), gathered during the pretraining
phase of an LLM, to automatically extract the PICO-related terminologies from
clinical trial documents in unsupervised set up to bypass the availability of
large number of annotated data instances. Additionally, to showcase the highest
effectiveness of LLM in oracle scenario where large number of annotated samples
are available, we adopt the instruction tuning strategy by employing Low Rank
Adaptation (LORA) to conduct the training of gigantic model in low resource
environment for the PICO frame extraction task. Our empirical results show that
our proposed ICL-based framework produces comparable results on all the version
of EBM-NLP datasets and the proposed instruction tuned version of our framework
produces state-of-the-art results on all the different EBM-NLP datasets. Our
project is available at \url{https://github.com/shrimonmuke0202/AlpaPICO.git}."	ArXiv
2246	"DiMB-RE: Mining the Scientific Literature for Diet-Microbiome
  Associations"	['Gibong Hong', 'Veronica Hindle', 'Nadine M. Veasley', 'Hannah D. Holscher', 'Halil Kilicoglu']	2024-09-29 06:58:26+00:00	http://arxiv.org/abs/2409.19581v1	"Motivation: The gut microbiota has recently emerged as a key factor that
underpins certain connections between diet and human health. A tremendous
amount of knowledge has been amassed from experimental studies on diet, human
metabolism and microbiome. However, this evidence remains mostly buried in
scientific publications, and biomedical literature mining in this domain
remains scarce. We developed DiMB-RE, a comprehensive corpus annotated with 15
entity types (e.g., Nutrient, Microorganism) and 13 relation types (e.g.,
increases, improves) capturing diet-microbiome associations. We also trained
and evaluated state-of-the-art natural language processing (NLP) models for
named entity, trigger, and relation extraction as well as factuality detection
using DiMB-RE.
  Results: DiMB-RE consists of 14,450 entities and 4,206 relationships from 165
articles. While NLP models performed reasonably well for named entity
recognition (0.760 F$_{1}$), end-to-end relation extraction performance was
modest (0.356 F$_{1}$), partly due to missed entities and triggers as well as
cross-sentence relations.
  Conclusions: To our knowledge, DiMB-RE is largest and most diverse dataset
focusing on diet-microbiome interactions. It can serve as a benchmark corpus
for biomedical literature mining.
  Availability: DiMB-RE and the NLP models are available at
https://github.com/ScienceNLP-Lab/DiMB-RE."	ArXiv
2247	"Blocks Architecture (BloArk): Efficient, Cost-Effective, and Incremental
  Dataset Architecture for Wikipedia Revision History"	['Lingxi Li', 'Zonghai Yao', 'Sunjae Kwon', 'Hong Yu']	2024-10-06 08:58:14+00:00	http://arxiv.org/abs/2410.04410v1	"Wikipedia (Wiki) is one of the most widely used and publicly available
resources for natural language processing (NLP) applications. Wikipedia
Revision History (WikiRevHist) shows the order in which edits were made to any
Wiki page since its first modification. While the most up-to-date Wiki has been
widely used as a training source, WikiRevHist can also be valuable resources
for NLP applications. However, there are insufficient tools available to
process WikiRevHist without having substantial computing resources, making
additional customization, and spending extra time adapting others' works.
Therefore, we report Blocks Architecture (BloArk), an efficiency-focused data
processing architecture that reduces running time, computing resource
requirements, and repeated works in processing WikiRevHist dataset. BloArk
consists of three parts in its infrastructure: blocks, segments, and
warehouses. On top of that, we build the core data processing pipeline: builder
and modifier. The BloArk builder transforms the original WikiRevHist dataset
from XML syntax into JSON Lines (JSONL) format for improving the concurrent and
storage efficiency. The BloArk modifier takes previously-built warehouses to
operate incremental modifications for improving the utilization of existing
databases and reducing the cost of reusing others' works. In the end, BloArk
can scale up easily in both processing Wikipedia Revision History and
incrementally modifying existing dataset for downstream NLP use cases. The
source code, documentations, and example usages are publicly available online
and open-sourced under GPL-2.0 license."	ArXiv
2248	"Balancing Innovation and Privacy: Data Security Strategies in Natural
  Language Processing Applications"	['Shaobo Liu', 'Guiran Liu', 'Binrong Zhu', 'Yuanshuai Luo', 'Linxiao Wu', 'Rui Wang']	2024-10-11 06:05:10+00:00	http://arxiv.org/abs/2410.08553v1	"This research addresses privacy protection in Natural Language Processing
(NLP) by introducing a novel algorithm based on differential privacy, aimed at
safeguarding user data in common applications such as chatbots, sentiment
analysis, and machine translation. With the widespread application of NLP
technology, the security and privacy protection of user data have become
important issues that need to be solved urgently. This paper proposes a new
privacy protection algorithm designed to effectively prevent the leakage of
user sensitive information. By introducing a differential privacy mechanism,
our model ensures the accuracy and reliability of data analysis results while
adding random noise. This method not only reduces the risk caused by data
leakage but also achieves effective processing of data while protecting user
privacy. Compared to traditional privacy methods like data anonymization and
homomorphic encryption, our approach offers significant advantages in terms of
computational efficiency and scalability while maintaining high accuracy in
data analysis. The proposed algorithm's efficacy is demonstrated through
performance metrics such as accuracy (0.89), precision (0.85), and recall
(0.88), outperforming other methods in balancing privacy and utility. As
privacy protection regulations become increasingly stringent, enterprises and
developers must take effective measures to deal with privacy risks. Our
research provides an important reference for the application of privacy
protection technology in the field of NLP, emphasizing the need to achieve a
balance between technological innovation and user privacy. In the future, with
the continuous advancement of technology, privacy protection will become a core
element of data-driven applications and promote the healthy development of the
entire industry."	ArXiv
2249	"LlamaLens: Specialized Multilingual LLM for Analyzing News and Social
  Media Content"	['Mohamed Bayan Kmainasi', 'Ali Ezzat Shahroor', 'Maram Hasanain', 'Sahinur Rahman Laskar', 'Naeemul Hassan', 'Firoj Alam']	2024-10-20 06:37:37+00:00	http://arxiv.org/abs/2410.15308v1	"Large Language Models (LLMs) have demonstrated remarkable success as
general-purpose task solvers across various fields, including NLP, healthcare,
finance, and law. However, their capabilities remain limited when addressing
domain-specific problems, particularly in downstream NLP tasks. Research has
shown that models fine-tuned on instruction-based downstream NLP datasets
outperform those that are not fine-tuned. While most efforts in this area have
primarily focused on resource-rich languages like English and broad domains,
little attention has been given to multilingual settings and specific domains.
To address this gap, this study focuses on developing a specialized LLM,
LlamaLens, for analyzing news and social media content in a multilingual
context. To the best of our knowledge, this is the first attempt to tackle both
domain specificity and multilinguality, with a particular focus on news and
social media. Our experimental setup includes 19 tasks, represented by 52
datasets covering Arabic, English, and Hindi. We demonstrate that LlamaLens
outperforms the current state-of-the-art (SOTA) on 16 testing sets, and
achieves comparable performance on 10 sets. We make the models and resources
publicly available for the research community.(https://huggingface.co/QCRI)"	ArXiv
2250	AUTALIC: A Dataset for Anti-AUTistic Ableist Language In Context	['Naba Rizvi', 'Harper Strickland', 'Daniel Gitelman', 'Tristan Cooper', 'Alexis Morales-Flores', 'Michael Golden', 'Aekta Kallepalli', 'Akshat Alurkar', 'Haaset Owens', 'Saleha Ahmedi', 'Isha Khirwadkar', 'Imani Munyaka', 'Nedjma Ousidhoum']	2024-10-21 21:21:29+00:00	http://arxiv.org/abs/2410.16520v2	"As our understanding of autism and ableism continues to increase, so does our
understanding of ableist language towards autistic people. Such language poses
a significant challenge in NLP research due to its subtle and context-dependent
nature. Yet, detecting anti-autistic ableist language remains underexplored,
with existing NLP tools often failing to capture its nuanced expressions. We
present AUTALIC, the first benchmark dataset dedicated to the detection of
anti-autistic ableist language in context, addressing a significant gap in the
field. The dataset comprises 2,400 autism-related sentences collected from
Reddit, accompanied by surrounding context, and is annotated by trained experts
with backgrounds in neurodiversity. Our comprehensive evaluation reveals that
current language models, including state-of-the-art LLMs, struggle to reliably
identify anti-autistic ableism and align with human judgments, underscoring
their limitations in this domain. We publicly release AUTALIC along with the
individual annotations which serve as a valuable resource to researchers
working on ableism, neurodiversity, and also studying disagreements in
annotation tasks. This dataset serves as a crucial step towards developing more
inclusive and context-aware NLP systems that better reflect diverse
perspectives."	ArXiv
2251	"Collage: Decomposable Rapid Prototyping for Information Extraction on
  Scientific PDFs"	['Sireesh Gururaja', 'Yueheng Zhang', 'Guannan Tang', 'Tianhao Zhang', 'Kevin Murphy', 'Yu-Tsen Yi', 'Junwon Seo', 'Anthony Rollett', 'Emma Strubell']	2024-10-30 22:00:34+00:00	http://arxiv.org/abs/2410.23478v1	"Recent years in NLP have seen the continued development of domain-specific
information extraction tools for scientific documents, alongside the release of
increasingly multimodal pretrained transformer models. While the opportunity
for scientists outside of NLP to evaluate and apply such systems to their own
domains has never been clearer, these models are difficult to compare: they
accept different input formats, are often black-box and give little insight
into processing failures, and rarely handle PDF documents, the most common
format of scientific publication. In this work, we present Collage, a tool
designed for rapid prototyping, visualization, and evaluation of different
information extraction models on scientific PDFs. Collage allows the use and
evaluation of any HuggingFace token classifier, several LLMs, and multiple
other task-specific models out of the box, and provides extensible software
interfaces to accelerate experimentation with new models. Further, we enable
both developers and users of NLP-based tools to inspect, debug, and better
understand modeling pipelines by providing granular views of intermediate
states of processing. We demonstrate our system in the context of information
extraction to assist with literature review in materials science."	ArXiv
2252	"Enhancing literature review with LLM and NLP methods. Algorithmic
  trading case"	['Stanisław Łaniewski', 'Robert Ślepaczuk']	2024-10-23 13:37:27+00:00	http://arxiv.org/abs/2411.05013v1	"This study utilizes machine learning algorithms to analyze and organize
knowledge in the field of algorithmic trading. By filtering a dataset of 136
million research papers, we identified 14,342 relevant articles published
between 1956 and Q1 2020. We compare traditional practices-such as
keyword-based algorithms and embedding techniques-with state-of-the-art topic
modeling methods that employ dimensionality reduction and clustering. This
comparison allows us to assess the popularity and evolution of different
approaches and themes within algorithmic trading. We demonstrate the usefulness
of Natural Language Processing (NLP) in the automatic extraction of knowledge,
highlighting the new possibilities created by the latest iterations of Large
Language Models (LLMs) like ChatGPT. The rationale for focusing on this topic
stems from our analysis, which reveals that research articles on algorithmic
trading are increasing at a faster rate than the overall number of
publications. While stocks and main indices comprise more than half of all
assets considered, certain asset classes, such as cryptocurrencies, exhibit a
much stronger growth trend. Machine learning models have become the most
popular methods in recent years. The study demonstrates the efficacy of LLMs in
refining datasets and addressing intricate questions about the analyzed
articles, such as comparing the efficiency of different models. Our research
shows that by decomposing tasks into smaller components and incorporating
reasoning steps, we can effectively tackle complex questions supported by case
analyses. This approach contributes to a deeper understanding of algorithmic
trading methodologies and underscores the potential of advanced NLP techniques
in literature reviews."	ArXiv
2253	KyrgyzNLP: Challenges, Progress, and Future	['Anton Alekseev', 'Timur Turatali']	2024-11-08 12:03:31+00:00	http://arxiv.org/abs/2411.05503v2	"Large language models (LLMs) have excelled in numerous benchmarks, advancing
AI applications in both linguistic and non-linguistic tasks. However, this has
primarily benefited well-resourced languages, leaving less-resourced ones
(LRLs) at a disadvantage. In this paper, we highlight the current state of the
NLP field in the specific LRL: kyrgyz tili.
  Human evaluation, including annotated datasets created by native speakers,
remains an irreplaceable component of reliable NLP performance, especially for
LRLs where automatic evaluations can fall short. In recent assessments of the
resources for Turkic languages, Kyrgyz is labeled with the status 'Scraping
By', a severely under-resourced language spoken by millions. This is concerning
given the growing importance of the language, not only in Kyrgyzstan but also
among diaspora communities where it holds no official status.
  We review prior efforts in the field, noting that many of the publicly
available resources have only recently been developed, with few exceptions
beyond dictionaries (the processed data used for the analysis is presented at
https://kyrgyznlp.github.io/). While recent papers have made some headway, much
more remains to be done. Despite interest and support from both business and
government sectors in the Kyrgyz Republic, the situation for Kyrgyz language
resources remains challenging. We stress the importance of community-driven
efforts to build these resources, ensuring the future advancement
sustainability. We then share our view of the most pressing challenges in
Kyrgyz NLP. Finally, we propose a roadmap for future development in terms of
research topics and language resources."	ArXiv
2254	IAE: Irony-based Adversarial Examples for Sentiment Analysis Systems	['Xiaoyin Yi', 'Jiacheng Huang']	2024-11-12 15:01:47+00:00	http://arxiv.org/abs/2411.07850v1	"Adversarial examples, which are inputs deliberately perturbed with
imperceptible changes to induce model errors, have raised serious concerns for
the reliability and security of deep neural networks (DNNs). While adversarial
attacks have been extensively studied in continuous data domains such as
images, the discrete nature of text presents unique challenges. In this paper,
we propose Irony-based Adversarial Examples (IAE), a method that transforms
straightforward sentences into ironic ones to create adversarial text. This
approach exploits the rhetorical device of irony, where the intended meaning is
opposite to the literal interpretation, requiring a deeper understanding of
context to detect. The IAE method is particularly challenging due to the need
to accurately locate evaluation words, substitute them with appropriate
collocations, and expand the text with suitable ironic elements while
maintaining semantic coherence. Our research makes the following key
contributions: (1) We introduce IAE, a strategy for generating textual
adversarial examples using irony. This method does not rely on pre-existing
irony corpora, making it a versatile tool for creating adversarial text in
various NLP tasks. (2) We demonstrate that the performance of several
state-of-the-art deep learning models on sentiment analysis tasks significantly
deteriorates when subjected to IAE attacks. This finding underscores the
susceptibility of current NLP systems to adversarial manipulation through
irony. (3) We compare the impact of IAE on human judgment versus NLP systems,
revealing that humans are less susceptible to the effects of irony in text."	ArXiv
2255	CamemBERT 2.0: A Smarter French Language Model Aged to Perfection	['Wissam Antoun', 'Francis Kulumba', 'Rian Touchent', 'Éric de la Clergerie', 'Benoît Sagot', 'Djamé Seddah']	2024-11-13 18:49:35+00:00	http://arxiv.org/abs/2411.08868v1	"French language models, such as CamemBERT, have been widely adopted across
industries for natural language processing (NLP) tasks, with models like
CamemBERT seeing over 4 million downloads per month. However, these models face
challenges due to temporal concept drift, where outdated training data leads to
a decline in performance, especially when encountering new topics and
terminology. This issue emphasizes the need for updated models that reflect
current linguistic trends. In this paper, we introduce two new versions of the
CamemBERT base model-CamemBERTav2 and CamemBERTv2-designed to address these
challenges. CamemBERTav2 is based on the DeBERTaV3 architecture and makes use
of the Replaced Token Detection (RTD) objective for better contextual
understanding, while CamemBERTv2 is built on RoBERTa, which uses the Masked
Language Modeling (MLM) objective. Both models are trained on a significantly
larger and more recent dataset with longer context length and an updated
tokenizer that enhances tokenization performance for French. We evaluate the
performance of these models on both general-domain NLP tasks and
domain-specific applications, such as medical field tasks, demonstrating their
versatility and effectiveness across a range of use cases. Our results show
that these updated models vastly outperform their predecessors, making them
valuable tools for modern NLP systems. All our new models, as well as
intermediate checkpoints, are made openly available on Huggingface."	ArXiv
2256	"Unveiling Topological Structures in Text: A Comprehensive Survey of
  Topological Data Analysis Applications in NLP"	['Adaku Uchendu', 'Thai Le']	2024-11-15 15:55:05+00:00	http://arxiv.org/abs/2411.10298v2	"The surge of data available on the internet has led to the adoption of
various computational methods to analyze and extract valuable insights from
this wealth of information. Among these, the field of Machine Learning (ML) has
thrived by leveraging data to extract meaningful insights. However, ML
techniques face notable challenges when dealing with real-world data, often due
to issues of imbalance, noise, insufficient labeling, and high dimensionality.
To address these limitations, some researchers advocate for the adoption of
Topological Data Analysis (TDA), a statistical approach that discerningly
captures the intrinsic shape of data despite noise. Despite its potential, TDA
has not gained as much traction within the Natural Language Processing (NLP)
domain compared to structurally distinct areas like computer vision.
Nevertheless, a dedicated community of researchers has been exploring the
application of TDA in NLP, yielding 87 papers we comprehensively survey in this
paper. Our findings categorize these efforts into theoretical and
non-theoretical approaches. Theoretical approaches aim to explain linguistic
phenomena from a topological viewpoint, while non-theoretical approaches merge
TDA with ML features, utilizing diverse numerical representation techniques. We
conclude by exploring the challenges and unresolved questions that persist in
this niche field. Resources and a list of papers on this topic can be found at:
https://github.com/AdaUchendu/AwesomeTDA4NLP."	ArXiv
2257	"Efficient Aspect-Based Summarization of Climate Change Reports with
  Small Language Models"	['Iacopo Ghinassi', 'Leonardo Catalano', 'Tommaso Colella']	2024-11-21 16:28:32+00:00	http://arxiv.org/abs/2411.14272v1	"The use of Natural Language Processing (NLP) for helping decision-makers with
Climate Change action has recently been highlighted as a use case aligning with
a broader drive towards NLP technologies for social good. In this context,
Aspect-Based Summarization (ABS) systems that extract and summarize relevant
information are particularly useful as they provide stakeholders with a
convenient way of finding relevant information in expert-curated reports. In
this work, we release a new dataset for ABS of Climate Change reports and we
employ different Large Language Models (LLMs) and so-called Small Language
Models (SLMs) to tackle this problem in an unsupervised way. Considering the
problem at hand, we also show how SLMs are not significantly worse for the
problem while leading to reduced carbon footprint; we do so by applying for the
first time an existing framework considering both energy efficiency and task
performance to the evaluation of zero-shot generative models for ABS. Overall,
our results show that modern language models, both big and small, can
effectively tackle ABS for Climate Change reports but more research is needed
when we frame the problem as a Retrieval Augmented Generation (RAG) problem and
our work and dataset will help foster efforts in this direction."	ArXiv
2258	"BERT or FastText? A Comparative Analysis of Contextual as well as
  Non-Contextual Embeddings"	['Abhay Shanbhag', 'Suramya Jadhav', 'Amogh Thakurdesai', 'Ridhima Sinare', 'Raviraj Joshi']	2024-11-26 18:25:57+00:00	http://arxiv.org/abs/2411.17661v2	"Natural Language Processing (NLP) for low-resource languages presents
significant challenges, particularly due to the scarcity of high-quality
annotated data and linguistic resources. The choice of embeddings plays a
critical role in enhancing the performance of NLP tasks, such as news
classification, sentiment analysis, and hate speech detection, especially for
low-resource languages like Marathi. In this study, we investigate the impact
of various embedding techniques- Contextual BERT-based, Non-Contextual
BERT-based, and FastText-based on NLP classification tasks specific to the
Marathi language. Our research includes a thorough evaluation of both
compressed and uncompressed embeddings, providing a comprehensive overview of
how these embeddings perform across different scenarios. Specifically, we
compare two BERT model embeddings, Muril and MahaBERT, as well as two FastText
model embeddings, IndicFT and MahaFT. Our evaluation includes applying
embeddings to a Multiple Logistic Regression (MLR) classifier for task
performance assessment, as well as TSNE visualizations to observe the spatial
distribution of these embeddings. The results demonstrate that contextual
embeddings outperform non-contextual embeddings. Furthermore, BERT-based
non-contextual embeddings extracted from the first BERT embedding layer yield
better results than FastText-based embeddings, suggesting a potential
alternative to FastText embeddings."	ArXiv
2259	"Automated Literature Review Using NLP Techniques and LLM-Based
  Retrieval-Augmented Generation"	['Nurshat Fateh Ali', 'Md. Mahdi Mohtasim', 'Shakil Mosharrof', 'T. Gopi Krishna']	2024-11-27 18:27:07+00:00	http://arxiv.org/abs/2411.18583v1	"This research presents and compares multiple approaches to automate the
generation of literature reviews using several Natural Language Processing
(NLP) techniques and retrieval-augmented generation (RAG) with a Large Language
Model (LLM). The ever-increasing number of research articles provides a huge
challenge for manual literature review. It has resulted in an increased demand
for automation. Developing a system capable of automatically generating the
literature reviews from only the PDF files as input is the primary objective of
this research work. The effectiveness of several Natural Language Processing
(NLP) strategies, such as the frequency-based method (spaCy), the transformer
model (Simple T5), and retrieval-augmented generation (RAG) with Large Language
Model (GPT-3.5-turbo), is evaluated to meet the primary objective. The SciTLDR
dataset is chosen for this research experiment and three distinct techniques
are utilized to implement three different systems for auto-generating the
literature reviews. The ROUGE scores are used for the evaluation of all three
systems. Based on the evaluation, the Large Language Model GPT-3.5-turbo
achieved the highest ROUGE-1 score, 0.364. The transformer model comes in
second place and spaCy is at the last position. Finally, a graphical user
interface is created for the best system based on the large language model."	ArXiv
2260	"Harnessing Transfer Learning from Swahili: Advancing Solutions for
  Comorian Dialects"	['Naira Abdou Mohamed', 'Zakarya Erraji', 'Abdessalam Bahafid', 'Imade Benelallam']	2024-12-09 22:47:41+00:00	http://arxiv.org/abs/2412.12143v1	"If today some African languages like Swahili have enough resources to develop
high-performing Natural Language Processing (NLP) systems, many other languages
spoken on the continent are still lacking such support. For these languages,
still in their infancy, several possibilities exist to address this critical
lack of data. Among them is Transfer Learning, which allows low-resource
languages to benefit from the good representation of other languages that are
similar to them. In this work, we adopt a similar approach, aiming to pioneer
NLP technologies for Comorian, a group of four languages or dialects belonging
to the Bantu family.
  Our approach is initially motivated by the hypothesis that if a human can
understand a different language from their native language with little or no
effort, it would be entirely possible to model this process on a machine. To
achieve this, we consider ways to construct Comorian datasets mixed with
Swahili. One thing to note here is that in terms of Swahili data, we only focus
on elements that are closest to Comorian by calculating lexical distances
between candidate and source data. We empirically test this hypothesis in two
use cases: Automatic Speech Recognition (ASR) and Machine Translation (MT). Our
MT model achieved ROUGE-1, ROUGE-2, and ROUGE-L scores of 0.6826, 0.42, and
0.6532, respectively, while our ASR system recorded a WER of 39.50\% and a CER
of 13.76\%. This research is crucial for advancing NLP in underrepresented
languages, with potential to preserve and promote Comorian linguistic heritage
in the digital age."	ArXiv
2261	Automated Robustness Testing for LLM-based NLP Software	['Mingxuan Xiao', 'Yan Xiao', 'Shunhui Ji', 'Hanbo Cai', 'Lei Xue', 'Pengcheng Zhang']	2024-12-30 15:33:34+00:00	http://arxiv.org/abs/2412.21016v1	"Benefiting from the advancements in LLMs, NLP software has undergone rapid
development. Such software is widely employed in various safety-critical tasks,
such as financial sentiment analysis, toxic content moderation, and log
generation. To our knowledge, there are no known automated robustness testing
methods specifically designed for LLM-based NLP software. Given the complexity
of LLMs and the unpredictability of real-world inputs (including prompts and
examples), it is essential to examine the robustness of overall inputs to
ensure the safety of such software.
  To this end, this paper introduces the first AutOmated Robustness Testing
frAmework, AORTA, which reconceptualizes the testing process into a
combinatorial optimization problem. Existing testing methods designed for
DNN-based software can be applied to LLM-based software by AORTA, but their
effectiveness is limited. To address this, we propose a novel testing method
for LLM-based software within AORTA called Adaptive Beam Search. ABS is
tailored for the expansive feature space of LLMs and improves testing
effectiveness through an adaptive beam width and the capability for
backtracking.
  We successfully embed 18 test methods in the designed framework AORTA and
compared the test validity of ABS with three datasets and five threat models.
ABS facilitates a more comprehensive and accurate robustness assessment before
software deployment, with an average test success rate of 86.138%. Compared to
the currently best-performing baseline PWWS, ABS significantly reduces the
computational overhead by up to 3441.895 seconds per successful test case and
decreases the number of queries by 218.762 times on average. Furthermore, test
cases generated by ABS exhibit greater naturalness and transferability."	ArXiv
2262	"Towards Multimodal Metaphor Understanding: A Chinese Dataset and Model
  for Metaphor Mapping Identification"	['Dongyu Zhang', 'Shengcheng Yin', 'Jingwei Yu', 'Zhiyao Wu', 'Zhen Li', 'Chengpei Xu', 'Xiaoxia Wang', 'Feng Xia']	2025-01-05 04:15:03+00:00	http://arxiv.org/abs/2501.02434v1	"Metaphors play a crucial role in human communication, yet their comprehension
remains a significant challenge for natural language processing (NLP) due to
the cognitive complexity involved. According to Conceptual Metaphor Theory
(CMT), metaphors map a target domain onto a source domain, and understanding
this mapping is essential for grasping the nature of metaphors. While existing
NLP research has focused on tasks like metaphor detection and sentiment
analysis of metaphorical expressions, there has been limited attention to the
intricate process of identifying the mappings between source and target
domains. Moreover, non-English multimodal metaphor resources remain largely
neglected in the literature, hindering a deeper understanding of the key
elements involved in metaphor interpretation. To address this gap, we developed
a Chinese multimodal metaphor advertisement dataset (namely CM3D) that includes
annotations of specific target and source domains. This dataset aims to foster
further research into metaphor comprehension, particularly in non-English
languages. Furthermore, we propose a Chain-of-Thought (CoT) Prompting-based
Metaphor Mapping Identification Model (CPMMIM), which simulates the human
cognitive process for identifying these mappings. Drawing inspiration from CoT
reasoning and Bi-Level Optimization (BLO), we treat the task as a hierarchical
identification problem, enabling more accurate and interpretable metaphor
mapping. Our experimental results demonstrate the effectiveness of CPMMIM,
highlighting its potential for advancing metaphor comprehension in NLP. Our
dataset and code are both publicly available to encourage further advancements
in this field."	ArXiv
2263	Using WordNet for Building WordNets	['Xavier Farreres', 'German Rigau', 'Horacio Rodriguez']	1998-06-23 17:26:41+00:00	http://arxiv.org/abs/cmp-lg/9806016v1	"This paper summarises a set of methodologies and techniques for the fast
construction of multilingual WordNets. The English WordNet is used in this
approach as a backbone for Catalan and Spanish WordNets and as a lexical
knowledge resource for several subtasks."	ArXiv
2264	Is Word Sense Disambiguation just one more NLP task?	['Yorick Wilks']	1999-02-25 14:41:32+00:00	http://arxiv.org/abs/cs/9902030v1	"This paper compares the tasks of part-of-speech (POS) tagging and
word-sense-tagging or disambiguation (WSD), and argues that the tasks are not
related by fineness of grain or anything like that, but are quite different
kinds of task, particularly becuase there is nothing in POS corresponding to
sense novelty. The paper also argues for the reintegration of sub-tasks that
are being separated for evaluation"	ArXiv
2265	Empirical Methods for Compound Splitting	['Philipp Koehn', 'Kevin Knight']	2003-02-22 23:37:26+00:00	http://arxiv.org/abs/cs/0302032v1	"Compounded words are a challenge for NLP applications such as machine
translation (MT). We introduce methods to learn splitting rules from
monolingual and parallel corpora. We evaluate them against a gold standard and
measure their impact on performance of statistical MT systems. Results show
accuracy of 99.1% and performance gains for MT of 0.039 BLEU on a
German-English noun phrase translation task."	ArXiv
2266	An OLAC Extension for Dravidian Languages	['B Prabhulla Chandran Pillai']	2009-08-30 23:20:41+00:00	http://arxiv.org/abs/0908.4431v1	"OLAC was founded in 2000 for creating online databases of language resources.
This paper intends to review the bottom-up distributed character of the project
and proposes an extension of the architecture for Dravidian languages. An
ontological structure is considered for effective natural language processing
(NLP) and its advantages over statistical methods are reviewed"	ArXiv
2267	From user requirements to UML class diagram	['Hatem Herchi', 'Wahiba Ben Abdessalem']	2012-11-04 19:35:11+00:00	http://arxiv.org/abs/1211.0713v1	"The transition from user requirements to UML diagrams is a difficult task for
the designer especially when he handles large texts expressing these needs.
Modeling class Diagram must be performed frequently, even during the
development of a simple application. This paper proposes an approach to
facilitate class diagram extraction from textual requirements using NLP
techniques and domain ontology."	ArXiv
2268	Extrapolation in NLP	['Jeff Mitchell', 'Pasquale Minervini', 'Pontus Stenetorp', 'Sebastian Riedel']	2018-05-17 08:29:09+00:00	http://arxiv.org/abs/1805.06648v1	"We argue that extrapolation to examples outside the training space will often
be easier for models that capture global structures, rather than just maximise
their local fit to the training data. We show that this is true for two popular
models: the Decomposable Attention Model and word2vec."	ArXiv
2269	Linguistic Characteristics of Censorable Language on SinaWeibo	['Kei Yin Ng', 'Anna Feldman', 'Jing Peng', 'Chris Leberknight']	2018-07-10 14:02:35+00:00	http://arxiv.org/abs/1807.03654v1	"This paper investigates censorship from a linguistic perspective. We collect
a corpus of censored and uncensored posts on a number of topics, build a
classifier that predicts censorship decisions independent of discussion topics.
Our investigation reveals that the strongest linguistic indicator of censored
content of our corpus is its readability."	ArXiv
2270	Concept-Based Embeddings for Natural Language Processing	['Yukun Ma', 'Erik Cambria']	2018-07-15 09:36:39+00:00	http://arxiv.org/abs/1807.05519v1	"In this work, we focus on effectively leveraging and integrating information
from concept-level as well as word-level via projecting concepts and words into
a lower dimensional space while retaining most critical semantics. In a broad
context of opinion understanding system, we investigate the use of the fused
embedding for several core NLP tasks: named entity detection and
classification, automatic speech recognition reranking, and targeted sentiment
analysis."	ArXiv
2271	"Proceedings of the 2018 Workshop on Compositional Approaches in Physics,
  NLP, and Social Sciences"	['Martha Lewis', 'Bob Coecke', 'Jules Hedges', 'Dimitri Kartsaklis', 'Dan Marsden']	2018-11-06 23:25:45+00:00	http://arxiv.org/abs/1811.02701v1	"The ability to compose parts to form a more complex whole, and to analyze a
whole as a combination of elements, is desirable across disciplines. This
workshop bring together researchers applying compositional approaches to
physics, NLP, cognitive science, and game theory. Within NLP, a long-standing
aim is to represent how words can combine to form phrases and sentences. Within
the framework of distributional semantics, words are represented as vectors in
vector spaces. The categorical model of Coecke et al. [2010], inspired by
quantum protocols, has provided a convincing account of compositionality in
vector space models of NLP. There is furthermore a history of vector space
models in cognitive science. Theories of categorization such as those developed
by Nosofsky [1986] and Smith et al. [1988] utilise notions of distance between
feature vectors. More recently G\""ardenfors [2004, 2014] has developed a model
of concepts in which conceptual spaces provide geometric structures, and
information is represented by points, vectors and regions in vector spaces. The
same compositional approach has been applied to this formalism, giving
conceptual spaces theory a richer model of compositionality than previously
[Bolt et al., 2018]. Compositional approaches have also been applied in the
study of strategic games and Nash equilibria. In contrast to classical game
theory, where games are studied monolithically as one global object,
compositional game theory works bottom-up by building large and complex games
from smaller components. Such an approach is inherently difficult since the
interaction between games has to be considered. Research into categorical
compositional methods for this field have recently begun [Ghani et al., 2018].
Moreover, the interaction between the three disciplines of cognitive science,
linguistics and game theory is a fertile ground for research. Game theory in
cognitive science is a well-established area [Camerer, 2011]. Similarly game
theoretic approaches have been applied in linguistics [J\""ager, 2008]. Lastly,
the study of linguistics and cognitive science is intimately intertwined
[Smolensky and Legendre, 2006, Jackendoff, 2007]. Physics supplies
compositional approaches via vector spaces and categorical quantum theory,
allowing the interplay between the three disciplines to be examined."	ArXiv
2272	Fine-tune BERT for Extractive Summarization	['Yang Liu']	2019-03-25 13:42:45+00:00	http://arxiv.org/abs/1903.10318v2	"BERT, a pre-trained Transformer model, has achieved ground-breaking
performance on multiple NLP tasks. In this paper, we describe BERTSUM, a simple
variant of BERT, for extractive summarization. Our system is the state of the
art on the CNN/Dailymail dataset, outperforming the previous best-performed
system by 1.65 on ROUGE-L. The codes to reproduce our results are available at
https://github.com/nlpyang/BertSum"	ArXiv
2273	Using NLP on news headlines to predict index trends	['Marc Velay', 'Fabrice Daniel']	2018-06-22 15:37:35+00:00	http://arxiv.org/abs/1806.09533v1	"This paper attempts to provide a state of the art in trend prediction using
news headlines. We present the research done on predicting DJIA trends using
Natural Language Processing. We will explain the different algorithms we have
used as well as the various embedding techniques attempted. We rely on
statistical and deep learning models in order to extract information from the
corpuses."	ArXiv
2274	Unsupervised Neural Hidden Markov Models	['Ke Tran', 'Yonatan Bisk', 'Ashish Vaswani', 'Daniel Marcu', 'Kevin Knight']	2016-09-28 16:55:52+00:00	http://arxiv.org/abs/1609.09007v1	"In this work, we present the first results for neuralizing an Unsupervised
Hidden Markov Model. We evaluate our approach on tag in- duction. Our approach
outperforms existing generative models and is competitive with the
state-of-the-art though with a simpler model easily extended to include
additional context."	ArXiv
2275	How to define co-occurrence in different domains of study?	['Mathieu Roche']	2019-04-16 23:16:56+00:00	http://arxiv.org/abs/1904.08010v1	"This position paper presents a comparative study of co-occurrences. Some
similarities and differences in the definition exist depending on the research
domain (e.g. linguistics, NLP, computer science). This paper discusses these
points, and deals with the methodological aspects in order to identify
co-occurrences in a multidisciplinary paradigm."	ArXiv
2276	"Training Models to Extract Treatment Plans from Clinical Notes Using
  Contents of Sections with Headings"	['Ananya Poddar', 'Bharath Dandala', 'Murthy Devarakonda']	2019-06-27 19:40:09+00:00	http://arxiv.org/abs/1906.11930v1	"Objective: Using natural language processing (NLP) to find sentences that
state treatment plans in a clinical note, would automate plan extraction and
would further enable their use in tools that help providers and care managers.
However, as in the most NLP tasks on clinical text, creating gold standard to
train and test NLP models is tedious and expensive. Fortuitously, sometimes but
not always clinical notes contain sections with a heading that identifies the
section as a plan. Leveraging contents of such labeled sections as a noisy
training data, we assessed accuracy of NLP models trained with the data.
  Methods: We used common variations of plan headings and rule-based heuristics
to find plan sections with headings in clinical notes, and we extracted
sentences from them and formed a noisy training data of plan sentences. We
trained Support Vector Machine (SVM) and Convolutional Neural Network (CNN)
models with the data. We measured accuracy of the trained models on the noisy
dataset using ten-fold cross validation and separately on a set-aside manually
annotated dataset.
  Results: About 13% of 117,730 clinical notes contained treatment plans
sections with recognizable headings in the 1001 longitudinal patient records
that were obtained from Cleveland Clinic under an IRB approval. We were able to
extract and create a noisy training data of 13,492 plan sentences from the
clinical notes. CNN achieved best F measures, 0.91 and 0.97 in the
cross-validation and set-aside evaluation experiments respectively. SVM
slightly underperformed with F measures of 0.89 and 0.96 in the same
experiments.
  Conclusion: Our study showed that the training supervised learning models
using noisy plan sentences was effective in identifying them in all clinical
notes. More broadly, sections with informal headings in clinical notes can be a
good source for generating effective training data."	ArXiv
2277	Explainable Natural Language Processing with Matrix Product States	['Jirawat Tangpanitanon', 'Chanatip Mangkang', 'Pradeep Bhadola', 'Yuichiro Minato', 'Dimitris G. Angelakis', 'Thiparat Chotibut']	2021-12-16 05:10:32+00:00	http://arxiv.org/abs/2112.08628v2	"Despite empirical successes of recurrent neural networks (RNNs) in natural
language processing (NLP), theoretical understanding of RNNs is still limited
due to intrinsically complex non-linear computations. We systematically analyze
RNNs' behaviors in a ubiquitous NLP task, the sentiment analysis of movie
reviews, via the mapping between a class of RNNs called recurrent arithmetic
circuits (RACs) and a matrix product state (MPS). Using the von-Neumann
entanglement entropy (EE) as a proxy for information propagation, we show that
single-layer RACs possess a maximum information propagation capacity, reflected
by the saturation of the EE. Enlarging the bond dimension beyond the EE
saturation threshold does not increase model prediction accuracies, so a
minimal model that best estimates the data statistics can be inferred. Although
the saturated EE is smaller than the maximum EE allowed by the area law, our
minimal model still achieves ~99% training accuracies in realistic sentiment
analysis data sets. Thus, low EE is not a warrant against the adoption of
single-layer RACs for NLP. Contrary to a common belief that long-range
information propagation is the main source of RNNs' successes, we show that
single-layer RACs harness high expressiveness from the subtle interplay between
the information propagation and the word vector embeddings. Our work sheds
light on the phenomenology of learning in RACs, and more generally on the
explainability of RNNs for NLP, using tools from many-body quantum physics."	ArXiv
2278	X575: writing rengas with web services	['Daniel Winterstein', 'Joseph Corneli']	2016-06-25 20:04:42+00:00	http://arxiv.org/abs/1606.07955v1	"Our software system simulates the classical collaborative Japanese poetry
form, renga, made of linked haikus. We used NLP methods wrapped up as web
services. Our experiments were only a partial success, since results fail to
satisfy classical constraints. To gather ideas for future work, we examine
related research in semiotics, linguistics, and computing."	ArXiv
2279	"EAT: a simple and versatile semantic representation format for
  multi-purpose NLP"	['Tommi Gröndahl']	2019-02-25 15:49:10+00:00	http://arxiv.org/abs/1902.09381v4	"Semantic representations are central in many NLP tasks that require
human-interpretable data. The conjunctivist framework - primarily developed by
Pietroski (2005, 2018) - obtains expressive representations with only a few
basic semantic types and relations systematically linked to syntactic
positions. While representational simplicity is crucial for computational
applications, such findings have not yet had major influence on NLP. We present
the first generic semantic representation format for NLP directly based on
these insights. We name the format EAT due to its basis in the Event-, Agent-,
and Theme arguments in Neo-Davidsonian logical forms. It builds on the idea
that similar tripartite argument relations are ubiquitous across categories,
and can be constructed from grammatical structure without additional lexical
information. We present a detailed exposition of EAT and how it relates to
other prevalent formats used in prior work, such as Abstract Meaning
Representation (AMR) and Minimal Recursion Semantics (MRS). EAT stands out in
two respects: simplicity and versatility. Uniquely, EAT discards semantic
metapredicates, and instead represents semantic roles entirely via positional
encoding. This is made possible by limiting the number of roles to only three;
a major decrease from the many dozens recognized in e.g. AMR and MRS. EAT's
simplicity makes it exceptionally versatile in application. First, we show that
drastically reducing semantic roles based on EAT benefits text generation from
MRS in the test settings of Hajdik et al. (2019). Second, we implement the
derivation of EAT from a syntactic parse, and apply this for parallel corpus
generation between grammatical classes. Third, we train an encoder-decoder LSTM
network to map EAT to English. Finally, we use both the encoder-decoder network
and a rule-based alternative to conduct grammatical transformation from
EAT-input."	ArXiv
2280	A Resource for Studying Chatino Verbal Morphology	['Hilaria Cruz', 'Gregory Stump', 'Antonios Anastasopoulos']	2020-04-05 03:30:01+00:00	http://arxiv.org/abs/2004.02083v1	"We present the first resource focusing on the verbal inflectional morphology
of San Juan Quiahije Chatino, a tonal mesoamerican language spoken in Mexico.
We provide a collection of complete inflection tables of 198 lemmata, with
morphological tags based on the UniMorph schema. We also provide baseline
results on three core NLP tasks: morphological analysis, lemmatization, and
morphological inflection."	ArXiv
2281	Low-resource Languages: A Review of Past Work and Future Challenges	['Alexandre Magueresse', 'Vincent Carles', 'Evan Heetderks']	2020-06-12 15:21:57+00:00	http://arxiv.org/abs/2006.07264v1	"A current problem in NLP is massaging and processing low-resource languages
which lack useful training attributes such as supervised data, number of native
speakers or experts, etc. This review paper concisely summarizes previous
groundbreaking achievements made towards resolving this problem, and analyzes
potential improvements in the context of the overall future research direction."	ArXiv
2282	diagNNose: A Library for Neural Activation Analysis	['Jaap Jumelet']	2020-11-13 09:19:48+00:00	http://arxiv.org/abs/2011.06819v1	"In this paper we introduce diagNNose, an open source library for analysing
the activations of deep neural networks. diagNNose contains a wide array of
interpretability techniques that provide fundamental insights into the inner
workings of neural networks. We demonstrate the functionality of diagNNose with
a case study on subject-verb agreement within language models. diagNNose is
available at https://github.com/i-machine-think/diagnnose."	ArXiv
2283	"EdgeBERT: Sentence-Level Energy Optimizations for Latency-Aware
  Multi-Task NLP Inference"	['Thierry Tambe', 'Coleman Hooper', 'Lillian Pentecost', 'Tianyu Jia', 'En-Yu Yang', 'Marco Donato', 'Victor Sanh', 'Paul N. Whatmough', 'Alexander M. Rush', 'David Brooks', 'Gu-Yeon Wei']	2020-11-28 19:21:47+00:00	http://arxiv.org/abs/2011.14203v5	"Transformer-based language models such as BERT provide significant accuracy
improvement for a multitude of natural language processing (NLP) tasks.
However, their hefty computational and memory demands make them challenging to
deploy to resource-constrained edge platforms with strict latency requirements.
We present EdgeBERT, an in-depth algorithm-hardware co-design for latency-aware
energy optimization for multi-task NLP. EdgeBERT employs entropy-based early
exit predication in order to perform dynamic voltage-frequency scaling (DVFS),
at a sentence granularity, for minimal energy consumption while adhering to a
prescribed target latency. Computation and memory footprint overheads are
further alleviated by employing a calibrated combination of adaptive attention
span, selective network pruning, and floating-point quantization. Furthermore,
in order to maximize the synergistic benefits of these algorithms in always-on
and intermediate edge computing settings, we specialize a 12nm scalable
hardware accelerator system, integrating a fast-switching low-dropout voltage
regulator (LDO), an all-digital phase-locked loop (ADPLL), as well as,
high-density embedded non-volatile memories (eNVMs) wherein the sparse
floating-point bit encodings of the shared multi-task parameters are carefully
stored. Altogether, latency-aware multi-task NLP inference acceleration on the
EdgeBERT hardware system generates up to 7x, 2.5x, and 53x lower energy
compared to the conventional inference without early stopping, the
latency-unbounded early exit approach, and CUDA adaptations on an Nvidia Jetson
Tegra X2 mobile GPU, respectively."	ArXiv
2284	"A Systematic Review of Natural Language Processing Applied to Radiology
  Reports"	['Arlene Casey', 'Emma Davidson', 'Michael Poon', 'Hang Dong', 'Daniel Duma', 'Andreas Grivas', 'Claire Grover', 'Víctor Suárez-Paniagua', 'Richard Tobin', 'William Whiteley', 'Honghan Wu', 'Beatrice Alex']	2021-02-18 18:54:41+00:00	http://arxiv.org/abs/2102.09553v1	"NLP has a significant role in advancing healthcare and has been found to be
key in extracting structured information from radiology reports. Understanding
recent developments in NLP application to radiology is of significance but
recent reviews on this are limited. This study systematically assesses recent
literature in NLP applied to radiology reports. Our automated literature search
yields 4,799 results using automated filtering, metadata enriching steps and
citation search combined with manual review. Our analysis is based on 21
variables including radiology characteristics, NLP methodology, performance,
study, and clinical application characteristics. We present a comprehensive
analysis of the 164 publications retrieved with each categorised into one of 6
clinical application categories. Deep learning use increases but conventional
machine learning approaches are still prevalent. Deep learning remains
challenged when data is scarce and there is little evidence of adoption into
clinical practice. Despite 17% of studies reporting greater than 0.85 F1
scores, it is hard to comparatively evaluate these approaches given that most
of them use different datasets. Only 14 studies made their data and 15 their
code available with 10 externally validating results. Automated understanding
of clinical narratives of the radiology reports has the potential to enhance
the healthcare process but reproducibility and explainability of models are
important if the domain is to move applications into clinical use. More could
be done to share code enabling validation of methods on different institutional
data and to reduce heterogeneity in reporting of study properties allowing
inter-study comparisons. Our results have significance for researchers
providing a systematic synthesis of existing work to build on, identify gaps,
opportunities for collaboration and avoid duplication."	ArXiv
2285	ExplainaBoard: An Explainable Leaderboard for NLP	['Pengfei Liu', 'Jinlan Fu', 'Yang Xiao', 'Weizhe Yuan', 'Shuaicheng Chang', 'Junqi Dai', 'Yixin Liu', 'Zihuiwen Ye', 'Zi-Yi Dou', 'Graham Neubig']	2021-04-13 17:45:50+00:00	http://arxiv.org/abs/2104.06387v2	"With the rapid development of NLP research, leaderboards have emerged as one
tool to track the performance of various systems on various NLP tasks. They are
effective in this goal to some extent, but generally present a rather
simplistic one-dimensional view of the submitted systems, communicated only
through holistic accuracy numbers. In this paper, we present a new
conceptualization and implementation of NLP evaluation: the ExplainaBoard,
which in addition to inheriting the functionality of the standard leaderboard,
also allows researchers to (i) diagnose strengths and weaknesses of a single
system (e.g.~what is the best-performing system bad at?) (ii) interpret
relationships between multiple systems. (e.g.~where does system A outperform
system B? What if we combine systems A, B, and C?) and (iii) examine prediction
results closely (e.g.~what are common errors made by multiple systems, or in
what contexts do particular errors occur?). So far, ExplainaBoard covers more
than 400 systems, 50 datasets, 40 languages, and 12 tasks. ExplainaBoard keeps
updated and is recently upgraded by supporting (1) multilingual multi-task
benchmark, (2) meta-evaluation, and (3) more complicated task: machine
translation, which reviewers also suggested.} We not only released an online
platform on the website \url{http://explainaboard.nlpedia.ai/} but also make
our evaluation tool an API with MIT Licence at Github
\url{https://github.com/neulab/explainaBoard} and PyPi
\url{https://pypi.org/project/interpret-eval/} that allows users to
conveniently assess their models offline. We additionally release all output
files from systems that we have run or collected to motivate ""output-driven""
research in the future."	ArXiv
2286	"[RE] Double-Hard Debias: Tailoring Word Embeddings for Gender Bias
  Mitigation"	['Haswanth Aekula', 'Sugam Garg', 'Animesh Gupta']	2021-04-14 16:56:14+00:00	http://arxiv.org/abs/2104.06973v1	"Despite widespread use in natural language processing (NLP) tasks, word
embeddings have been criticized for inheriting unintended gender bias from
training corpora. programmer is more closely associated with man and homemaker
is more closely associated with woman. Such gender bias has also been shown to
propagate in downstream tasks."	ArXiv
2287	Distilling BERT for low complexity network training	['Bansidhar Mangalwedhekar']	2021-05-13 19:09:22+00:00	http://arxiv.org/abs/2105.06514v1	"This paper studies the efficiency of transferring BERT learnings to low
complexity models like BiLSTM, BiLSTM with attention and shallow CNNs using
sentiment analysis on SST-2 dataset. It also compares the complexity of
inference of the BERT model with these lower complexity models and underlines
the importance of these techniques in enabling high performance NLP models on
edge devices like mobiles, tablets and MCU development boards like Raspberry Pi
etc. and enabling exciting new applications."	ArXiv
2288	"False perfection in machine prediction: Detecting and assessing
  circularity problems in machine learning"	['Michael Hagmann', 'Stefan Riezler']	2021-06-23 14:11:06+00:00	http://arxiv.org/abs/2106.12417v2	"This paper is an excerpt of an early version of Chapter 2 of the book
""Validity, Reliability, and Significance. Empirical Methods for NLP and Data
Science"", by Stefan Riezler and Michael Hagmann, published in December 2021 by
Morgan & Claypool. Please see the book's homepage at
https://www.morganclaypoolpublishers.com/catalog_Orig/product_info.php?products_id=1688
for a more recent and comprehensive discussion."	ArXiv
2289	"GatorTron: A Large Clinical Language Model to Unlock Patient Information
  from Unstructured Electronic Health Records"	['Xi Yang', 'Aokun Chen', 'Nima PourNejatian', 'Hoo Chang Shin', 'Kaleb E Smith', 'Christopher Parisien', 'Colin Compas', 'Cheryl Martin', 'Mona G Flores', 'Ying Zhang', 'Tanja Magoc', 'Christopher A Harle', 'Gloria Lipori', 'Duane A Mitchell', 'William R Hogan', 'Elizabeth A Shenkman', 'Jiang Bian', 'Yonghui Wu']	2022-02-02 14:28:51+00:00	http://arxiv.org/abs/2203.03540v3	"There is an increasing interest in developing artificial intelligence (AI)
systems to process and interpret electronic health records (EHRs). Natural
language processing (NLP) powered by pretrained language models is the key
technology for medical AI systems utilizing clinical narratives. However, there
are few clinical language models, the largest of which trained in the clinical
domain is comparatively small at 110 million parameters (compared with billions
of parameters in the general domain). It is not clear how large clinical
language models with billions of parameters can help medical AI systems utilize
unstructured EHRs. In this study, we develop from scratch a large clinical
language model - GatorTron - using >90 billion words of text (including >82
billion words of de-identified clinical text) and systematically evaluate it on
5 clinical NLP tasks including clinical concept extraction, medical relation
extraction, semantic textual similarity, natural language inference (NLI), and
medical question answering (MQA). We examine how (1) scaling up the number of
parameters and (2) scaling up the size of the training data could benefit these
NLP tasks. GatorTron models scale up the clinical language model from 110
million to 8.9 billion parameters and improve 5 clinical NLP tasks (e.g., 9.6%
and 9.5% improvement in accuracy for NLI and MQA), which can be applied to
medical AI systems to improve healthcare delivery. The GatorTron models are
publicly available at:
https://catalog.ngc.nvidia.com/orgs/nvidia/teams/clara/models/gatortron_og."	ArXiv
2290	"Super-NaturalInstructions: Generalization via Declarative Instructions
  on 1600+ NLP Tasks"	['Yizhong Wang', 'Swaroop Mishra', 'Pegah Alipoormolabashi', 'Yeganeh Kordi', 'Amirreza Mirzaei', 'Anjana Arunkumar', 'Arjun Ashok', 'Arut Selvan Dhanasekaran', 'Atharva Naik', 'David Stap', 'Eshaan Pathak', 'Giannis Karamanolakis', 'Haizhi Gary Lai', 'Ishan Purohit', 'Ishani Mondal', 'Jacob Anderson', 'Kirby Kuznia', 'Krima Doshi', 'Maitreya Patel', 'Kuntal Kumar Pal', 'Mehrad Moradshahi', 'Mihir Parmar', 'Mirali Purohit', 'Neeraj Varshney', 'Phani Rohitha Kaza', 'Pulkit Verma', 'Ravsehaj Singh Puri', 'Rushang Karia', 'Shailaja Keyur Sampat', 'Savan Doshi', 'Siddhartha Mishra', 'Sujan Reddy', 'Sumanta Patro', 'Tanay Dixit', 'Xudong Shen', 'Chitta Baral', 'Yejin Choi', 'Noah A. Smith', 'Hannaneh Hajishirzi', 'Daniel Khashabi']	2022-04-16 03:12:30+00:00	http://arxiv.org/abs/2204.07705v3	"How well can NLP models generalize to a variety of unseen tasks when provided
with task instructions? To address this question, we first introduce
Super-NaturalInstructions, a benchmark of 1,616 diverse NLP tasks and their
expert-written instructions. Our collection covers 76 distinct task types,
including but not limited to classification, extraction, infilling, sequence
tagging, text rewriting, and text composition. This large and diverse
collection of tasks enables rigorous benchmarking of cross-task generalization
under instructions -- training models to follow instructions on a subset of
tasks and evaluating them on the remaining unseen ones. Furthermore, we build
Tk-Instruct, a transformer model trained to follow a variety of in-context
instructions (plain language task definitions or k-shot examples). Our
experiments show that Tk-Instruct outperforms existing instruction-following
models such as InstructGPT by over 9% on our benchmark despite being an order
of magnitude smaller. We further analyze generalization as a function of
various scaling parameters, such as the number of observed tasks, the number of
instances per task, and model sizes. We hope our dataset and model facilitate
future progress towards more general-purpose NLP models."	ArXiv
2291	An Exploratory Study on Code Attention in BERT	['Rishab Sharma', 'Fuxiang Chen', 'Fatemeh Fard', 'David Lo']	2022-04-05 21:23:10+00:00	http://arxiv.org/abs/2204.10200v1	"Many recent models in software engineering introduced deep neural models
based on the Transformer architecture or use transformer-based Pre-trained
Language Models (PLM) trained on code. Although these models achieve the state
of the arts results in many downstream tasks such as code summarization and bug
detection, they are based on Transformer and PLM, which are mainly studied in
the Natural Language Processing (NLP) field. The current studies rely on the
reasoning and practices from NLP for these models in code, despite the
differences between natural languages and programming languages. There is also
limited literature on explaining how code is modeled.
  Here, we investigate the attention behavior of PLM on code and compare it
with natural language. We pre-trained BERT, a Transformer based PLM, on code
and explored what kind of information it learns, both semantic and syntactic.
We run several experiments to analyze the attention values of code constructs
on each other and what BERT learns in each layer. Our analyses show that BERT
pays more attention to syntactic entities, specifically identifiers and
separators, in contrast to the most attended token [CLS] in NLP. This
observation motivated us to leverage identifiers to represent the code sequence
instead of the [CLS] token when used for code clone detection. Our results show
that employing embeddings from identifiers increases the performance of BERT by
605% and 4% F1-score in its lower layers and the upper layers, respectively.
When identifiers' embeddings are used in CodeBERT, a code-based PLM, the
performance is improved by 21-24% in the F1-score of clone detection. The
findings can benefit the research community by using code-specific
representations instead of applying the common embeddings used in NLP, and open
new directions for developing smaller models with similar performance."	ArXiv
2292	"Design and Implementation of a Quantum Kernel for Natural Language
  Processing"	['Matt Wright']	2022-05-13 00:45:46+00:00	http://arxiv.org/abs/2205.06409v1	"Natural language processing (NLP) is the field that attempts to make human
language accessible to computers, and it relies on applying a mathematical
model to express the meaning of symbolic language. One such model, DisCoCat,
defines how to express both the meaning of individual words as well as their
compositional nature. This model can be naturally implemented on quantum
computers, leading to the field quantum NLP (QNLP). Recent experimental work
used quantum machine learning techniques to map from text to class label using
the expectation value of the quantum encoded sentence. Theoretical work has
been done on computing the similarity of sentences but relies on an unrealized
quantum memory store. The main goal of this thesis is to leverage the DisCoCat
model to design a quantum-based kernel function that can be used by a support
vector machine (SVM) for NLP tasks. Two similarity measures were studied: (i)
the transition amplitude approach and (ii) the SWAP test. A simple NLP meaning
classification task from previous work was used to train the word embeddings
and evaluate the performance of both models. The Python module lambeq and its
related software stack was used for implementation. The explicit model from
previous work was used to train word embeddings and achieved a testing accuracy
of $93.09 \pm 0.01$%. It was shown that both the SVM variants achieved a higher
testing accuracy of $95.72 \pm 0.01$% for approach (i) and $97.14 \pm 0.01$%
for (ii). The SWAP test was then simulated under a noise model defined by the
real quantum device, ibmq_guadalupe. The explicit model achieved an accuracy of
$91.94 \pm 0.01$% while the SWAP test SVM achieved 96.7% on the testing
dataset, suggesting that the kernelized classifiers are resilient to noise.
These are encouraging results and motivate further investigations of our
proposed kernelized QNLP paradigm."	ArXiv
2293	"The Use of NLP-Based Text Representation Techniques to Support
  Requirement Engineering Tasks: A Systematic Mapping Review"	['Riad Sonbol', 'Ghaida Rebdawi', 'Nada Ghneim']	2022-05-17 02:47:26+00:00	http://arxiv.org/abs/2206.00421v1	"Natural Language Processing (NLP) is widely used to support the automation of
different Requirements Engineering (RE) tasks. Most of the proposed approaches
start with various NLP steps that analyze requirements statements, extract
their linguistic information, and convert them to easy-to-process
representations, such as lists of features or embedding-based vector
representations. These NLP-based representations are usually used at a later
stage as inputs for machine learning techniques or rule-based methods. Thus,
requirements representations play a major role in determining the accuracy of
different approaches. In this paper, we conducted a survey in the form of a
systematic literature mapping (classification) to find out (1) what are the
representations used in RE tasks literature, (2) what is the main focus of
these works, (3) what are the main research directions in this domain, and (4)
what are the gaps and potential future directions. After compiling an initial
pool of 2,227 papers, and applying a set of inclusion/exclusion criteria, we
obtained a final pool containing 104 relevant papers. Our survey shows that the
research direction has changed from the use of lexical and syntactic features
to the use of advanced embedding techniques, especially in the last two years.
Using advanced embedding representations has proved its effectiveness in most
RE tasks (such as requirement analysis, extracting requirements from reviews
and forums, and semantic-level quality tasks). However, representations that
are based on lexical and syntactic features are still more appropriate for
other RE tasks (such as modeling and syntax-level quality tasks) since they
provide the required information for the rules and regular expressions used
when handling these tasks. In addition, we identify four gaps in the existing
literature, why they matter, and how future research can begin to address them."	ArXiv
2294	"The Harvard USPTO Patent Dataset: A Large-Scale, Well-Structured, and
  Multi-Purpose Corpus of Patent Applications"	['Mirac Suzgun', 'Luke Melas-Kyriazi', 'Suproteem K. Sarkar', 'Scott Duke Kominers', 'Stuart M. Shieber']	2022-07-08 17:57:15+00:00	http://arxiv.org/abs/2207.04043v1	"Innovation is a major driver of economic and social development, and
information about many kinds of innovation is embedded in semi-structured data
from patents and patent applications. Although the impact and novelty of
innovations expressed in patent data are difficult to measure through
traditional means, ML offers a promising set of techniques for evaluating
novelty, summarizing contributions, and embedding semantics. In this paper, we
introduce the Harvard USPTO Patent Dataset (HUPD), a large-scale,
well-structured, and multi-purpose corpus of English-language patent
applications filed to the United States Patent and Trademark Office (USPTO)
between 2004 and 2018. With more than 4.5 million patent documents, HUPD is two
to three times larger than comparable corpora. Unlike previously proposed
patent datasets in NLP, HUPD contains the inventor-submitted versions of patent
applications--not the final versions of granted patents--thereby allowing us to
study patentability at the time of filing using NLP methods for the first time.
It is also novel in its inclusion of rich structured metadata alongside the
text of patent filings: By providing each application's metadata along with all
of its text fields, the dataset enables researchers to perform new sets of NLP
tasks that leverage variation in structured covariates. As a case study on the
types of research HUPD makes possible, we introduce a new task to the NLP
community--namely, binary classification of patent decisions. We additionally
show the structured metadata provided in the dataset enables us to conduct
explicit studies of concept shifts for this task. Finally, we demonstrate how
HUPD can be used for three additional tasks: multi-class classification of
patent subject areas, language modeling, and summarization."	ArXiv
2295	STI: Turbocharge NLP Inference at the Edge via Elastic Pipelining	['Liwei Guo', 'Wonkyo Choe', 'Felix Xiaozhu Lin']	2022-07-11 17:15:57+00:00	http://arxiv.org/abs/2207.05022v3	"Natural Language Processing (NLP) inference is seeing increasing adoption by
mobile applications, where on-device inference is desirable for crucially
preserving user data privacy and avoiding network roundtrips. Yet, the
unprecedented size of an NLP model stresses both latency and memory, creating a
tension between the two key resources of a mobile device. To meet a target
latency, holding the whole model in memory launches execution as soon as
possible but increases one app's memory footprints by several times, limiting
its benefits to only a few inferences before being recycled by mobile memory
management. On the other hand, loading the model from storage on demand incurs
IO as long as a few seconds, far exceeding the delay range satisfying to a
user; pipelining layerwise model loading and execution does not hide IO either,
due to the high skewness between IO and computation delays.
  To this end, we propose Speedy Transformer Inference (STI). Built on the key
idea of maximizing IO/compute resource utilization on the most important parts
of a model, STI reconciles the latency v.s. memory tension via two novel
techniques. First, model sharding. STI manages model parameters as
independently tunable shards, and profiles their importance to accuracy.
Second, elastic pipeline planning with a preload buffer. STI instantiates an
IO/compute pipeline and uses a small buffer for preload shards to bootstrap
execution without stalling at early stages; it judiciously selects, tunes, and
assembles shards per their importance for resource-elastic execution,
maximizing inference accuracy.
  Atop two commodity SoCs, we build STI and evaluate it against a wide range of
NLP tasks, under a practical range of target latencies, and on both CPU and
GPU. We demonstrate that STI delivers high accuracies with 1-2 orders of
magnitude lower memory, outperforming competitive baselines."	ArXiv
2296	Keywords for Bias	['Abdurrezak Efe', 'Gizem Gezici', 'Aysenur Uzun', 'Uygar Kurt']	2022-10-31 18:19:04+00:00	http://arxiv.org/abs/2211.00075v2	"This work proposes to analyse some keywords for bias analysis. For this, we
are using several NLP approaches and compare them based on their capability of
detecting keywords to analyse bias. The overall findings show that our proposed
approach gives comparable results with the state-of-the-art approaches on
different benchmark datasets."	ArXiv
2297	"VTCC-NLP at NL4Opt competition subtask 1: An Ensemble Pre-trained
  language models for Named Entity Recognition"	['Xuan-Dung Doan']	2022-12-14 13:41:36+00:00	http://arxiv.org/abs/2212.07219v1	"We propose a combined three pre-trained language models (XLM-R, BART, and
DeBERTa-V3) as an empower of contextualized embedding for named entity
recognition. Our model achieves a 92.9% F1 score on the test set and ranks 5th
on the leaderboard at NL4Opt competition subtask 1."	ArXiv
2298	Language Models sounds the Death Knell of Knowledge Graphs	['Kunal Suri', 'Atul Singh', 'Prakhar Mishra', 'Swapna Sourav Rout', 'Rajesh Sabapathy']	2023-01-10 14:20:15+00:00	http://arxiv.org/abs/2301.03980v1	"Healthcare domain generates a lot of unstructured and semi-structured text.
Natural Language processing (NLP) has been used extensively to process this
data. Deep Learning based NLP especially Large Language Models (LLMs) such as
BERT have found broad acceptance and are used extensively for many
applications. A Language Model is a probability distribution over a word
sequence. Self-supervised Learning on a large corpus of data automatically
generates deep learning-based language models. BioBERT and Med-BERT are
language models pre-trained for the healthcare domain. Healthcare uses typical
NLP tasks such as question answering, information extraction, named entity
recognition, and search to simplify and improve processes. However, to ensure
robust application of the results, NLP practitioners need to normalize and
standardize them. One of the main ways of achieving normalization and
standardization is the use of Knowledge Graphs. A Knowledge Graph captures
concepts and their relationships for a specific domain, but their creation is
time-consuming and requires manual intervention from domain experts, which can
prove expensive. SNOMED CT (Systematized Nomenclature of Medicine -- Clinical
Terms), Unified Medical Language System (UMLS), and Gene Ontology (GO) are
popular ontologies from the healthcare domain. SNOMED CT and UMLS capture
concepts such as disease, symptoms and diagnosis and GO is the world's largest
source of information on the functions of genes. Healthcare has been dealing
with an explosion in information about different types of drugs, diseases, and
procedures. This paper argues that using Knowledge Graphs is not the best
solution for solving problems in this domain. We present experiments using LLMs
for the healthcare domain to demonstrate that language models provide the same
functionality as knowledge graphs, thereby making knowledge graphs redundant."	ArXiv
2299	"Step by Step Loss Goes Very Far: Multi-Step Quantization for Adversarial
  Text Attacks"	['Piotr Gaiński', 'Klaudia Bałazy']	2023-02-10 08:50:51+00:00	http://arxiv.org/abs/2302.05120v1	"We propose a novel gradient-based attack against transformer-based language
models that searches for an adversarial example in a continuous space of token
probabilities. Our algorithm mitigates the gap between adversarial loss for
continuous and discrete text representations by performing multi-step
quantization in a quantization-compensation loop. Experiments show that our
method significantly outperforms other approaches on various natural language
processing (NLP) tasks."	ArXiv
2300	CroSentiNews 2.0: A Sentence-Level News Sentiment Corpus	['Gaurish Thakkar', 'Nives Mikelic Preradović', 'Marko Tadić']	2023-05-14 15:53:54+00:00	http://arxiv.org/abs/2305.08187v1	"This article presents a sentence-level sentiment dataset for the Croatian
news domain. In addition to the 3K annotated texts already present, our dataset
contains 14.5K annotated sentence occurrences that have been tagged with 5
classes. We provide baseline scores in addition to the annotation process and
inter-annotator agreement."	ArXiv
2301	On Robustness of Finetuned Transformer-based NLP Models	['Pavan Kalyan Reddy Neerudu', 'Subba Reddy Oota', 'Mounika Marreddy', 'Venkateswara Rao Kagita', 'Manish Gupta']	2023-05-23 18:25:18+00:00	http://arxiv.org/abs/2305.14453v2	"Transformer-based pretrained models like BERT, GPT-2 and T5 have been
finetuned for a large number of natural language processing (NLP) tasks, and
have been shown to be very effective. However, while finetuning, what changes
across layers in these models with respect to pretrained checkpoints is
under-studied. Further, how robust are these models to perturbations in input
text? Does the robustness vary depending on the NLP task for which the models
have been finetuned? While there exists some work on studying the robustness of
BERT finetuned for a few NLP tasks, there is no rigorous study that compares
this robustness across encoder only, decoder only and encoder-decoder models.
In this paper, we characterize changes between pretrained and finetuned
language model representations across layers using two metrics: CKA and STIR.
Further, we study the robustness of three language models (BERT, GPT-2 and T5)
with eight different text perturbations on classification tasks from the
General Language Understanding Evaluation (GLUE) benchmark, and generation
tasks like summarization, free-form generation and question generation. GPT-2
representations are more robust than BERT and T5 across multiple types of input
perturbation. Although models exhibit good robustness broadly, dropping nouns,
verbs or changing characters are the most impactful. Overall, this study
provides valuable insights into perturbation-specific weaknesses of popular
Transformer-based models, which should be kept in mind when passing inputs. We
make the code and models publicly available
[https://github.com/PavanNeerudu/Robustness-of-Transformers-models]."	ArXiv
2302	"Natural Language Processing for Requirements Formalization: How to
  Derive New Approaches?"	['Viju Sudhi', 'Libin Kutty', 'Robin Gröpler']	2023-09-23 05:45:19+00:00	http://arxiv.org/abs/2309.13272v1	"It is a long-standing desire of industry and research to automate the
software development and testing process as much as possible. In this process,
requirements engineering (RE) plays a fundamental role for all other steps that
build on it. Model-based design and testing methods have been developed to
handle the growing complexity and variability of software systems. However,
major effort is still required to create specification models from a large set
of functional requirements provided in natural language. Numerous approaches
based on natural language processing (NLP) have been proposed in the literature
to generate requirements models using mainly syntactic properties. Recent
advances in NLP show that semantic quantities can also be identified and used
to provide better assistance in the requirements formalization process. In this
work, we present and discuss principal ideas and state-of-the-art methodologies
from the field of NLP in order to guide the readers on how to create a set of
rules and methods for the semi-automated formalization of requirements
according to their specific use case and needs. We discuss two different
approaches in detail and highlight the iterative development of rule sets. The
requirements models are represented in a human- and machine-readable format in
the form of pseudocode. The presented methods are demonstrated on two
industrial use cases from the automotive and railway domains. It shows that
using current pre-trained NLP models requires less effort to create a set of
rules and can be easily adapted to specific use cases and domains. In addition,
findings and shortcomings of this research area are highlighted and an outlook
on possible future developments is given."	ArXiv
2303	"DaG LLM ver 1.0: Pioneering Instruction-Tuned Language Modeling for
  Korean NLP"	['Dongjun Jang', 'Sangah Lee', 'Sungjoo Byun', 'Jinwoong Kim', 'Jean Seo', 'Minseok Kim', 'Soyeon Kim', 'Chaeyoung Oh', 'Jaeyoon Kim', 'Hyemi Jo', 'Hyopil Shin']	2023-11-23 03:03:54+00:00	http://arxiv.org/abs/2311.13784v1	"This paper presents the DaG LLM (David and Goliath Large Language Model), a
language model specialized for Korean and fine-tuned through Instruction Tuning
across 41 tasks within 13 distinct categories."	ArXiv
2304	"Optimal Strategies to Perform Multilingual Analysis of Social Content
  for a Novel Dataset in the Tourism Domain"	['Maxime Masson', 'Rodrigo Agerri', 'Christian Sallaberry', 'Marie-Noelle Bessagnet', 'Annig Le Parc Lacayrelle', 'Philippe Roose']	2023-11-20 13:08:21+00:00	http://arxiv.org/abs/2311.14727v1	"The rising influence of social media platforms in various domains, including
tourism, has highlighted the growing need for efficient and automated natural
language processing (NLP) approaches to take advantage of this valuable
resource. However, the transformation of multilingual, unstructured, and
informal texts into structured knowledge often poses significant challenges.
  In this work, we evaluate and compare few-shot, pattern-exploiting and
fine-tuning machine learning techniques on large multilingual language models
(LLMs) to establish the best strategy to address the lack of annotated data for
3 common NLP tasks in the tourism domain: (1) Sentiment Analysis, (2) Named
Entity Recognition, and (3) Fine-grained Thematic Concept Extraction (linked to
a semantic resource). Furthermore, we aim to ascertain the quantity of
annotated examples required to achieve good performance in those 3 tasks,
addressing a common challenge encountered by NLP researchers in the
construction of domain-specific datasets.
  Extensive experimentation on a newly collected and annotated multilingual
(French, English, and Spanish) dataset composed of tourism-related tweets shows
that current few-shot learning techniques allow us to obtain competitive
results for all three tasks with very little annotation data: 5 tweets per
label (15 in total) for Sentiment Analysis, 10% of the tweets for location
detection (around 160) and 13% (200 approx.) of the tweets annotated with
thematic concepts, a highly fine-grained sequence labeling task based on an
inventory of 315 classes.
  This comparative analysis, grounded in a novel dataset, paves the way for
applying NLP to new domain-specific applications, reducing the need for manual
annotations and circumventing the complexities of rule-based, ad hoc solutions."	ArXiv
2305	"Information Extraction from Unstructured data using Augmented-AI and
  Computer Vision"	['Aditya Parikh']	2023-12-15 15:27:41+00:00	http://arxiv.org/abs/2312.09880v1	"Process of information extraction (IE) is often used to extract meaningful
information from unstructured and unlabeled data. Conventional methods of data
extraction including application of OCR and passing extraction engine, are
inefficient on large data and have their limitation. In this paper, a peculiar
technique of information extraction is proposed using A2I and computer vision
technologies, which also includes NLP."	ArXiv
2306	"Development of an NLP-driven computer-based test guide for visually
  impaired students"	['Tubo Faustinah Nemieboka', 'Ikechukwu E. Onyenwe', 'Doris C. Asogwa']	2024-01-22 21:59:00+00:00	http://arxiv.org/abs/2401.12375v1	"In recent years, advancements in Natural Language Processing (NLP) techniques
have revolutionized the field of accessibility and exclusivity of testing,
particularly for visually impaired students (VIS). CBT has shown in years back
its relevance in terms of administering exams electronically, making the test
process easier, providing quicker and more accurate results, and offering
greater flexibility and accessibility for candidates. Yet, its relevance was
not felt by the visually impaired students as they cannot access printed
documents. Hence, in this paper, we present an NLP-driven Computer-Based Test
guide for visually impaired students. It employs a speech technology
pre-trained methods to provide real-time assistance and support to visually
impaired students. The system utilizes NLP technologies to convert the
text-based questions and the associated options in a machine-readable format.
Subsequently, the speech technology pre-trained model processes the converted
text enabling the VIS to comprehend and analyze the content. Furthermore, we
validated that this pre-trained model is not perverse by testing for accuracy
using sample audio datasets labels (A, B, C, D, E, F, G) to compare with the
voice recordings obtained from 20 VIS which is been predicted by the system to
attain values for precision, recall, and F1-scores. These metrics are used to
assess the performance of the pre-trained model and have indicated that it is
proficient enough to give its better performance to the evaluated system. The
methodology adopted for this system is Object Oriented Analysis and Design
Methodology (OOADM) where Objects are discussed and built by modeling
real-world instances."	ArXiv
2307	"SemRel2024: A Collection of Semantic Textual Relatedness Datasets for 13
  Languages"	['Nedjma Ousidhoum', 'Shamsuddeen Hassan Muhammad', 'Mohamed Abdalla', 'Idris Abdulmumin', 'Ibrahim Said Ahmad', 'Sanchit Ahuja', 'Alham Fikri Aji', 'Vladimir Araujo', 'Abinew Ali Ayele', 'Pavan Baswani', 'Meriem Beloucif', 'Chris Biemann', 'Sofia Bourhim', 'Christine De Kock', 'Genet Shanko Dekebo', 'Oumaima Hourrane', 'Gopichand Kanumolu', 'Lokesh Madasu', 'Samuel Rutunda', 'Manish Shrivastava', 'Thamar Solorio', 'Nirmal Surange', 'Hailegnaw Getaneh Tilaye', 'Krishnapriya Vishnubhotla', 'Genta Winata', 'Seid Muhie Yimam', 'Saif M. Mohammad']	2024-02-13 18:04:53+00:00	http://arxiv.org/abs/2402.08638v5	"Exploring and quantifying semantic relatedness is central to representing
language and holds significant implications across various NLP tasks. While
earlier NLP research primarily focused on semantic similarity, often within the
English language context, we instead investigate the broader phenomenon of
semantic relatedness. In this paper, we present \textit{SemRel}, a new semantic
relatedness dataset collection annotated by native speakers across 13
languages: \textit{Afrikaans, Algerian Arabic, Amharic, English, Hausa, Hindi,
Indonesian, Kinyarwanda, Marathi, Moroccan Arabic, Modern Standard Arabic,
Spanish,} and \textit{Telugu}. These languages originate from five distinct
language families and are predominantly spoken in Africa and Asia -- regions
characterised by a relatively limited availability of NLP resources. Each
instance in the SemRel datasets is a sentence pair associated with a score that
represents the degree of semantic textual relatedness between the two
sentences. The scores are obtained using a comparative annotation framework. We
describe the data collection and annotation processes, challenges when building
the datasets, baseline experiments, and their impact and utility in NLP."	ArXiv
2308	"Improving Clinical NLP Performance through Language Model-Generated
  Synthetic Clinical Data"	['Shan Chen', 'Jack Gallifant', 'Marco Guevara', 'Yanjun Gao', 'Majid Afshar', 'Timothy Miller', 'Dmitriy Dligach', 'Danielle S. Bitterman']	2024-03-28 15:44:18+00:00	http://arxiv.org/abs/2403.19511v1	"Generative models have been showing potential for producing data in mass.
This study explores the enhancement of clinical natural language processing
performance by utilizing synthetic data generated from advanced language
models. Promising results show feasible applications in such a high-stakes
domain."	ArXiv
2309	"Beyond One-Size-Fits-All: Multi-Domain, Multi-Task Framework for
  Embedding Model Selection"	['Vivek Khetan']	2024-03-30 19:45:04+00:00	http://arxiv.org/abs/2404.00458v2	"This position paper proposes a systematic approach towards developing a
framework to help select the most effective embedding models for natural
language processing (NLP) tasks, addressing the challenge posed by the
proliferation of both proprietary and open-source encoder models."	ArXiv
2310	Transforming Hidden States into Binary Semantic Features	['Tomáš Musil', 'David Mareček']	2024-09-29 22:23:52+00:00	http://arxiv.org/abs/2409.19813v1	"Large language models follow a lineage of many NLP applications that were
directly inspired by distributional semantics, but do not seem to be closely
related to it anymore. In this paper, we propose to employ the distributional
theory of meaning once again. Using Independent Component Analysis to overcome
some of its challenging aspects, we show that large language models represent
semantic features in their hidden states."	ArXiv
2311	Reliable, Reproducible, and Really Fast Leaderboards with Evalica	['Dmitry Ustalov']	2024-12-15 21:22:46+00:00	http://arxiv.org/abs/2412.11314v1	"The rapid advancement of natural language processing (NLP) technologies, such
as instruction-tuned large language models (LLMs), urges the development of
modern evaluation protocols with human and machine feedback. We introduce
Evalica, an open-source toolkit that facilitates the creation of reliable and
reproducible model leaderboards. This paper presents its design, evaluates its
performance, and demonstrates its usability through its Web interface,
command-line interface, and Python API."	ArXiv
2312	The Compactness of Construction Grammars	['Wlodek Zadrozny']	1995-05-15 18:39:27+00:00	http://arxiv.org/abs/cmp-lg/9505031v1	"We present an argument for {\em construction grammars} based on the minimum
description length (MDL) principle (a formal version of the Ockham Razor). The
argument consists in using linguistic and computational evidence in setting up
a formal model, and then applying the MDL principle to prove its superiority
with respect to alternative models. We show that construction-based
representations are at least an order of magnitude more compact that the
corresponding lexicalized representations of the same linguistic data.
  The result is significant for our understanding of the relationship between
syntax and semantics, and consequently for choosing NLP architectures. For
instance, whether the processing should proceed in a pipeline from syntax to
semantics to pragmatics, and whether all linguistic information should be
combined in a set of constraints. From a broader perspective, this paper does
not only argue for a certain model of processing, but also provides a
methodology for determining advantages of different approaches to NLP."	ArXiv
2313	Context and ontology in understanding of dialogs	['Wlodek Zadrozny']	1995-05-15 18:54:56+00:00	http://arxiv.org/abs/cmp-lg/9505032v1	"We present a model of NLP in which ontology and context are directly included
in a grammar. The model is based on the concept of {\em construction},
consisting of a set of features of form, a set of semantic and pragmatic
conditions describing its application context, and a description of its
meaning. In this model ontology is embedded into the grammar; e.g. the
hierarchy of {\it np} constructions is based on the corresponding ontology.
Ontology is also used in defining contextual parameters; e.g. $\left[
current\_question \ time(\_) \right] $.
  A parser based on this model allowed us to build a set of dialog
understanding systems that include an on-line calendar, a banking machine, and
an insurance quote system. The proposed approach is an alternative to the
standard ""pipeline"" design of morphology-syntax-semantics-pragmatics; the
account of meaning conforms to our intuitions about compositionality, but there
is no homomorphism from syntax to semantics."	ArXiv
2314	Natural Language Processing: Structure and Complexity	['Wlodek Zadrozny']	1996-07-13 21:31:43+00:00	http://arxiv.org/abs/cmp-lg/9607017v1	"We introduce a method for analyzing the complexity of natural language
processing tasks, and for predicting the difficulty new NLP tasks.
  Our complexity measures are derived from the Kolmogorov complexity of a class
of automata --- {\it meaning automata}, whose purpose is to extract relevant
pieces of information from sentences. Natural language semantics is defined
only relative to the set of questions an automaton can answer.
  The paper shows examples of complexity estimates for various NLP programs and
tasks, and some recipes for complexity management. It positions natural
language processing as a subdomain of software engineering, and lays down its
formal foundation."	ArXiv
2315	TSNLP - Test Suites for Natural Language Processing	['Sabine Lehmann', 'Stephan Oepen', 'Sylvie Regnier-Prost', 'Klaus Netter', 'Veronika Lux', 'Judith Klein', 'Kirsten Falkedal', 'Frederik Fouvry', 'Dominique Estival', 'Eva Dauphin', 'Herve Compagnion', 'Judith Baur', 'Judith Baur', 'Lorna Balkan', 'Doug Arnold']	1996-07-15 10:28:12+00:00	http://arxiv.org/abs/cmp-lg/9607018v1	"The TSNLP project has investigated various aspects of the construction,
maintenance and application of systematic test suites as diagnostic and
evaluation tools for NLP applications. The paper summarizes the motivation and
main results of the project: besides the solid methodological foundation, TSNLP
has produced substantial multi-purpose and multi-user test suites for three
European languages together with a set of specialized tools that facilitate the
construction, extension, maintenance, retrieval, and customization of the test
data. As TSNLP results, including the data and technology, are made publicly
available, the project presents a valuable linguistic resourc e that has the
potential of providing a wide-spread pre-standard diagnostic and evaluation
tool for both developers and users of NLP applications."	ArXiv
2316	Probabilistic Event Categorization	['Janyce Wiebe', 'Rebecca Bruce', 'Lei Duan']	1997-10-30 21:59:07+00:00	http://arxiv.org/abs/cmp-lg/9710008v2	"This paper describes the automation of a new text categorization task. The
categories assigned in this task are more syntactically, semantically, and
contextually complex than those typically assigned by fully automatic systems
that process unseen test data. Our system for assigning these categories is a
probabilistic classifier, developed with a recent method for formulating a
probabilistic model from a predefined set of potential features. This paper
focuses on feature selection. It presents a number of fully automatic features.
It identifies and evaluates various approaches to organizing collocational
properties into features, and presents the results of experiments covarying
type of organization and type of property. We find that one organization is not
best for all kinds of properties, so this is an experimental parameter worth
investigating in NLP systems. In addition, the results suggest a way to take
advantage of properties that are low frequency but strongly indicative of a
class. The problems of recognizing and organizing the various kinds of
contextual information required to perform a linguistically complex
categorization task have rarely been systematically investigated in NLP."	ArXiv
2317	Combining a self-organising map with memory-based learning	['James Hammerton', 'Erik F. Tjong Kim Sang']	2001-07-15 13:32:36+00:00	http://arxiv.org/abs/cs/0107018v1	"Memory-based learning (MBL) has enjoyed considerable success in corpus-based
natural language processing (NLP) tasks and is thus a reliable method of
getting a high-level of performance when building corpus-based NLP systems.
However there is a bottleneck in MBL whereby any novel testing item has to be
compared against all the training items in memory base. For this reason there
has been some interest in various forms of memory editing whereby some method
of selecting a subset of the memory base is employed to reduce the number of
comparisons. This paper investigates the use of a modified self-organising map
(SOM) to select a subset of the memory items for comparison. This method
involves reducing the number of comparisons to a value proportional to the
square root of the number of training items. The method is tested on the
identification of base noun-phrases in the Wall Street Journal corpus, using
sections 15 to 18 for training and section 20 for testing."	ArXiv
2318	"Autogenic Training With Natural Language Processing Modules: A Recent
  Tool For Certain Neuro Cognitive Studies"	['S. Ravichandran', 'M. N. Karthik']	2004-07-02 20:15:02+00:00	http://arxiv.org/abs/cs/0407008v1	"Learning to respond to voice-text input involves the subject's ability in
understanding the phonetic and text based contents and his/her ability to
communicate based on his/her experience. The neuro-cognitive facility of the
subject has to support two important domains in order to make the learning
process complete. In many cases, though the understanding is complete, the
response is partial. This is one valid reason why we need to support the
information from the subject with scalable techniques such as Natural Language
Processing (NLP) for abstraction of the contents from the output. This paper
explores the feasibility of using NLP modules interlaced with Neural Networks
to perform the required task in autogenic training related to medical
applications."	ArXiv
2319	"The comparison of Wiktionary thesauri transformed into the
  machine-readable format"	['A. A. Krizhanovsky']	2010-06-25 18:51:13+00:00	http://arxiv.org/abs/1006.5040v1	"Wiktionary is a unique, peculiar, valuable and original resource for natural
language processing (NLP). The paper describes an open-source Wiktionary
parser: its architecture and requirements followed by a description of
Wiktionary features to be taken into account, some open problems of Wiktionary
and the parser. The current implementation of the parser extracts the
definitions, semantic relations, and translations from English and Russian
Wiktionaries. The paper's goal is to interest researchers (1) in using the
constructed machine-readable dictionary for different NLP tasks, (2) in
extending the software to parse 170 still unused Wiktionaries. The comparison
of a number and types of semantic relations, a number of definitions, and a
number of translations in the English Wiktionary and the Russian Wiktionary has
been carried out. It was found that the number of semantic relations in the
English Wiktionary is larger by 1.57 times than in Russian (157 and 100
thousands). But the Russian Wiktionary has more ""rich"" entries (with a big
number of semantic relations), e.g. the number of entries with three or more
semantic relations is larger by 1.63 times than in the English Wiktionary. Upon
comparison, it was found out the methodological shortcomings of the Wiktionary."	ArXiv
2320	Extending the adverbial coverage of a NLP oriented resource for French	['Elsa Tolone', 'Voyatzi Stavroula']	2011-11-15 09:24:36+00:00	http://arxiv.org/abs/1111.3462v1	"This paper presents a work on extending the adverbial entries of LGLex: a NLP
oriented syntactic resource for French. Adverbs were extracted from the
Lexicon-Grammar tables of both simple adverbs ending in -ment '-ly' (Molinier
and Levrier, 2000) and compound adverbs (Gross, 1986; 1990). This work relies
on the exploitation of fine-grained linguistic information provided in existing
resources. Various features are encoded in both LG tables and they haven't been
exploited yet. They describe the relations of deleting, permuting, intensifying
and paraphrasing that associate, on the one hand, the simple and compound
adverbs and, on the other hand, different types of compound adverbs. The
resulting syntactic resource is manually evaluated and freely available under
the LGPL-LR license."	ArXiv
2321	Adversarial Evaluation for Models of Natural Language	['Noah A. Smith']	2012-07-01 21:13:05+00:00	http://arxiv.org/abs/1207.0245v2	"We now have a rich and growing set of modeling tools and algorithms for
inducing linguistic structure from text that is less than fully annotated. In
this paper, we discuss some of the weaknesses of our current methodology. We
present a new abstract framework for evaluating natural language processing
(NLP) models in general and unsupervised NLP models in particular. The central
idea is to make explicit certain adversarial roles among researchers, so that
the different roles in an evaluation are more clearly defined and performers of
all roles are offered ways to make measurable contributions to the larger goal.
Adopting this approach may help to characterize model successes and failures by
encouraging earlier consideration of error analysis. The framework can be
instantiated in a variety of ways, simulating some familiar intrinsic and
extrinsic evaluations as well as some new evaluations."	ArXiv
2322	Polyglot: Distributed Word Representations for Multilingual NLP	['Rami Al-Rfou', 'Bryan Perozzi', 'Steven Skiena']	2013-07-05 16:52:09+00:00	http://arxiv.org/abs/1307.1662v2	"Distributed word representations (word embeddings) have recently contributed
to competitive performance in language modeling and several NLP tasks. In this
work, we train word embeddings for more than 100 languages using their
corresponding Wikipedias. We quantitatively demonstrate the utility of our word
embeddings by using them as the sole features for training a part of speech
tagger for a subset of these languages. We find their performance to be
competitive with near state-of-art methods in English, Danish and Swedish.
Moreover, we investigate the semantic features captured by these embeddings
through the proximity of word groupings. We will release these embeddings
publicly to help researchers in the development and enhancement of multilingual
applications."	ArXiv
2323	"Extended reverse-convex programming: an approximate enumeration approach
  to global optimization"	['Gene A. Bunin']	2013-08-13 11:51:04+00:00	http://arxiv.org/abs/1308.2828v4	"A new approach to solving a large class of factorable nonlinear programming
(NLP) problems to global optimality is presented in this paper. Unlike the
traditional strategy of partitioning the decision-variable space employed in
many branch-and-bound methods, the proposed approach approximates the NLP
problem by a reverse-convex programming (RCP) problem to a controlled
precision, with the latter then solved by an enumerative search. To establish
the theoretical guarantees of the method, the notion of ""RCP regularity"" is
introduced and it is proven that enumeration is guaranteed to yield a global
optimum when the RCP problem is regular. An extended RCP algorithmic framework
is then presented and its performance is examined for a small set of test
problems."	ArXiv
2324	Integer-ambiguity resolution in astronomy and geodesy	['André Lannes', 'Jean-Louis Prieur']	2013-12-17 19:58:07+00:00	http://arxiv.org/abs/1312.4920v1	"Recent theoretical developments in astronomical aperture synthesis have
revealed the existence of integer-ambiguity problems. Those problems, which
appear in the self-calibration procedures of radio imaging, have been shown to
be similar to the nearest-lattice point (NLP) problems encountered in
high-precision geodetic positioning, and in global navigation satellite
systems. In this paper, we analyse the theoretical aspects of the matter and
propose new methods for solving those NLP problems. The related optimization
aspects concern both the preconditioning stage, and the discrete-search stage
in which the integer ambiguities are finally fixed. Our algorithms, which are
described in an explicit manner, can easily be implemented. They lead to
substantial gains in the processing time of both stages. Their efficiency was
shown via intensive numerical tests."	ArXiv
2325	Multilingual Distributed Representations without Word Alignment	['Karl Moritz Hermann', 'Phil Blunsom']	2013-12-20 23:13:38+00:00	http://arxiv.org/abs/1312.6173v4	"Distributed representations of meaning are a natural way to encode covariance
relationships between words and phrases in NLP. By overcoming data sparsity
problems, as well as providing information about semantic relatedness which is
not available in discrete representations, distributed representations have
proven useful in many NLP tasks. Recent work has shown how compositional
semantic representations can successfully be applied to a number of monolingual
applications such as sentiment analysis. At the same time, there has been some
initial success in work on learning shared word-level representations across
languages. We combine these two approaches by proposing a method for learning
distributed representations in a multilingual setup. Our model learns to assign
similar embeddings to aligned sentences and dissimilar ones to sentence which
are not aligned while not requiring word alignments. We show that our
representations are semantically informative and apply them to a cross-lingual
document classification task where we outperform the previous state of the art.
Further, by employing parallel corpora of multiple language pairs we find that
our model learns representations that capture semantic relationships across
languages for which no parallel data was used."	ArXiv
2326	Topic Segmentation and Labeling in Asynchronous Conversations	['Shafiq Rayhan Joty', 'Giuseppe Carenini', 'Raymond T Ng']	2014-02-04 01:43:35+00:00	http://arxiv.org/abs/1402.0586v1	"Topic segmentation and labeling is often considered a prerequisite for
higher-level conversation analysis and has been shown to be useful in many
Natural Language Processing (NLP) applications. We present two new corpora of
email and blog conversations annotated with topics, and evaluate annotator
reliability for the segmentation and labeling tasks in these asynchronous
conversations. We propose a complete computational framework for topic
segmentation and labeling in asynchronous conversations. Our approach extends
state-of-the-art methods by considering a fine-grained structure of an
asynchronous conversation, along with other conversational features by applying
recent graph-based methods for NLP. For topic segmentation, we propose two
novel unsupervised models that exploit the fine-grained conversational
structure, and a novel graph-theoretic supervised model that combines lexical,
conversational and topic features. For topic labeling, we propose two novel
(unsupervised) random walk models that respectively capture conversation
specific clues from two different sources: the leading sentences and the
fine-grained conversational structure. Empirical evaluation shows that the
segmentation and the labeling performed by our best models beat the
state-of-the-art, and are highly correlated with human annotations."	ArXiv
2327	Factorized power expansion for high-$p_T$ heavy quarkonium production	['Yan-Qing Ma', 'Jian-Wei Qiu', 'George Sterman', 'Hong Zhang']	2014-07-01 19:53:58+00:00	http://arxiv.org/abs/1407.0383v2	"We show that when the factorized cross section for heavy quarkonium
production includes next-to-leading power (NLP) contributions associated with
the production of the heavy quark pair at short distances, it naturally
reproduces all high $p_T$ results calculated in non-relativistic QCD (NRQCD)
factorization. This extended formalism requires fragmentation functions for
heavy quark pairs, as well as for light partons. When these fragmentation
functions are themselves calculated using NRQCD, we find that two of the four
leading NRQCD production channels, ${^3\hspace{-0.6mm}S_{1}^{[1]}}$ and
${^1\hspace{-0.6mm}S_{0}^{[8]}}$, are dominated by the NLP contributions for a
very wide $p_T$ range. The large next-to-leading order corrections of NRQCD are
absorbed into the leading order of the first power correction. The impact of
this finding on the heavy quarkonium production and its polarization is
discussed."	ArXiv
2328	Training for Fast Sequential Prediction Using Dynamic Feature Selection	['Emma Strubell', 'Luke Vilnis', 'Andrew McCallum']	2014-10-30 19:02:48+00:00	http://arxiv.org/abs/1410.8498v2	"We present paired learning and inference algorithms for significantly
reducing computation and increasing speed of the vector dot products in the
classifiers that are at the heart of many NLP components. This is accomplished
by partitioning the features into a sequence of templates which are ordered
such that high confidence can often be reached using only a small fraction of
all features. Parameter estimation is arranged to maximize accuracy and early
confidence in this sequence. We present experiments in left-to-right
part-of-speech tagging on WSJ, demonstrating that we can preserve accuracy
above 97% with over a five-fold reduction in run-time."	ArXiv
2329	Bayesian Optimization of Text Representations	['Dani Yogatama', 'Noah A. Smith']	2015-03-02 20:23:18+00:00	http://arxiv.org/abs/1503.00693v1	"When applying machine learning to problems in NLP, there are many choices to
make about how to represent input texts. These choices can have a big effect on
performance, but they are often uninteresting to researchers or practitioners
who simply need a module that performs well. We propose an approach to
optimizing over this space of choices, formulating the problem as global
optimization. We apply a sequential model-based optimization technique and show
that our method makes standard linear models competitive with more
sophisticated, expensive state-of-the-art methods based on latent variable
models or neural networks on various topic classification and sentiment
analysis problems. Our approach is a first step towards black-box NLP systems
that work with raw text and do not require manual tuning."	ArXiv
2330	"Nonlinear-Programming-Based Model of Power System Marginal States:
  Theoretical Substantiation"	['Boris I. Ayuev', 'Viktor V. Davydov', 'Petr M. Erokhin']	2015-05-15 09:05:45+00:00	http://arxiv.org/abs/1505.03991v1	"In order to maintain the security of power system at an appropriate level and
at low cost, it is essential to accurately assess the steady-state stability
limits and power flow feasibility boundaries, i.e., the power system marginal
states (MS). This paper is devoted to creation and theoretical substantiation
of the MS model based on nonlinear programming (NLP-MS model), its research to
reveal MS properties which promote better MS understanding, to evolution of the
theory of power systems and MS, to elaboration of more effective algorithms of
MS problem solution. The proposed NLP-MS model is universal and allows to
determine and to take into account various MS, including the MS in a given
direction of power change, the closest MS, a moving the power system state into
a power flow feasibility region, etc."	ArXiv
2331	Learning Dynamic Feature Selection for Fast Sequential Prediction	['Emma Strubell', 'Luke Vilnis', 'Kate Silverstein', 'Andrew McCallum']	2015-05-22 18:28:21+00:00	http://arxiv.org/abs/1505.06169v1	"We present paired learning and inference algorithms for significantly
reducing computation and increasing speed of the vector dot products in the
classifiers that are at the heart of many NLP components. This is accomplished
by partitioning the features into a sequence of templates which are ordered
such that high confidence can often be reached using only a small fraction of
all features. Parameter estimation is arranged to maximize accuracy and early
confidence in this sequence. Our approach is simpler and better suited to NLP
than other related cascade methods. We present experiments in left-to-right
part-of-speech tagging, named entity recognition, and transition-based
dependency parsing. On the typical benchmarking datasets we can preserve POS
tagging accuracy above 97% and parsing LAS above 88.5% both with over a
five-fold reduction in run-time, and NER F1 above 88 with more than 2x increase
in speed."	ArXiv
2332	Modeling Order in Neural Word Embeddings at Scale	['Andrew Trask', 'David Gilmore', 'Matthew Russell']	2015-06-08 02:21:46+00:00	http://arxiv.org/abs/1506.02338v3	"Natural Language Processing (NLP) systems commonly leverage bag-of-words
co-occurrence techniques to capture semantic and syntactic word relationships.
The resulting word-level distributed representations often ignore morphological
information, though character-level embeddings have proven valuable to NLP
tasks. We propose a new neural language model incorporating both word order and
character order in its embedding. The model produces several vector spaces with
meaningful substructure, as evidenced by its performance of 85.8% on a recent
word-analogy task, exceeding best published syntactic word-analogy scores by a
58% error margin. Furthermore, the model includes several parallel training
methods, most notably allowing a skip-gram network with 160 billion parameters
to be trained overnight on 3 multi-core CPUs, 14x larger than the previous
largest neural network."	ArXiv
2333	"Editorial for the First Workshop on Mining Scientific Papers:
  Computational Linguistics and Bibliometrics"	['Iana Atanassova', 'Marc Bertin', 'Philipp Mayr']	2015-06-17 18:03:25+00:00	http://arxiv.org/abs/1506.05402v1	"The workshop ""Mining Scientific Papers: Computational Linguistics and
Bibliometrics"" (CLBib 2015), co-located with the 15th International Society of
Scientometrics and Informetrics Conference (ISSI 2015), brought together
researchers in Bibliometrics and Computational Linguistics in order to study
the ways Bibliometrics can benefit from large-scale text analytics and sense
mining of scientific papers, thus exploring the interdisciplinarity of
Bibliometrics and Natural Language Processing (NLP). The goals of the workshop
were to answer questions like: How can we enhance author network analysis and
Bibliometrics using data obtained by text analytics? What insights can NLP
provide on the structure of scientific writing, on citation networks, and on
in-text citation analysis? This workshop is the first step to foster the
reflection on the interdisciplinarity and the benefits that the two disciplines
Bibliometrics and Natural Language Processing can drive from it."	ArXiv
2334	Word Representations, Tree Models and Syntactic Functions	['Simon Šuster', 'Gertjan van Noord', 'Ivan Titov']	2015-08-31 07:52:50+00:00	http://arxiv.org/abs/1508.07709v2	"Word representations induced from models with discrete latent variables
(e.g.\ HMMs) have been shown to be beneficial in many NLP applications. In this
work, we exploit labeled syntactic dependency trees and formalize the induction
problem as unsupervised learning of tree-structured hidden Markov models.
Syntactic functions are used as additional observed variables in the model,
influencing both transition and emission components. Such syntactic information
can potentially lead to capturing more fine-grain and functional distinctions
between words, which, in turn, may be desirable in many NLP applications. We
evaluate the word representations on two tasks -- named entity recognition and
semantic frame identification. We observe improvements from exploiting
syntactic function information in both cases, and the results rivaling those of
state-of-the-art representation learning methods. Additionally, we revisit the
relationship between sequential and unlabeled-tree models and find that the
advantage of the latter is not self-evident."	ArXiv
2335	Problems With Evaluation of Word Embeddings Using Word Similarity Tasks	['Manaal Faruqui', 'Yulia Tsvetkov', 'Pushpendre Rastogi', 'Chris Dyer']	2016-05-08 05:09:28+00:00	http://arxiv.org/abs/1605.02276v3	"Lacking standardized extrinsic evaluation methods for vector representations
of words, the NLP community has relied heavily on word similarity tasks as a
proxy for intrinsic evaluation of word vectors. Word similarity evaluation,
which correlates the distance between vectors and human judgments of semantic
similarity is attractive, because it is computationally inexpensive and fast.
In this paper we present several problems associated with the evaluation of
word vectors on word similarity datasets, and summarize existing solutions. Our
study suggests that the use of word similarity tasks for evaluation of word
vectors is not sustainable and calls for further research on evaluation
methods."	ArXiv
2336	Capturing divergence in dependency trees to improve syntactic projection	['Ryan Georgi', 'Fei Xia', 'William D. Lewis']	2016-05-14 22:11:07+00:00	http://arxiv.org/abs/1605.04475v1	"Obtaining syntactic parses is a crucial part of many NLP pipelines. However,
most of the world's languages do not have large amounts of syntactically
annotated corpora available for building parsers. Syntactic projection
techniques attempt to address this issue by using parallel corpora consisting
of resource-poor and resource-rich language pairs, taking advantage of a parser
for the resource-rich language and word alignment between the languages to
project the parses onto the data for the resource-poor language. These
projection methods can suffer, however, when the two languages are divergent.
In this paper, we investigate the possibility of using small, parallel,
annotated corpora to automatically detect divergent structural patterns between
two languages. These patterns can then be used to improve structural projection
algorithms, allowing for better performing NLP tools for resource-poor
languages, in particular those that may not have large amounts of annotated
data necessary for traditional, fully-supervised methods. While this detection
process is not exhaustive, we demonstrate that common patterns of divergence
can be identified automatically without prior knowledge of a given language
pair, and the patterns can be used to improve performance of projection
algorithms."	ArXiv
2337	"Belief Space Planning Simplified: Trajectory-Optimized LQG (T-LQG)
  (Extended Report)"	['Mohammadhussein Rafieisakhaei', 'Suman Chakravorty', 'P. R. Kumar']	2016-08-10 00:41:34+00:00	http://arxiv.org/abs/1608.03013v2	"Planning under motion and observation uncertainties requires solution of a
stochastic control problem in the space of feedback policies. In this paper, we
reduce the general (n^2+n)-dimensional belief space planning problem to an
(n)-dimensional problem by obtaining a Linear Quadratic Gaussian (LQG) design
with the best nominal performance. Then, by taking the underlying trajectory of
the LQG controller as the decision variable, we pose a coupled design of
trajectory, estimator, and controller design through a Non-Linear Program (NLP)
that can be solved by a general NLP solver. We prove that under a first-order
approximation and a careful usage of the separation principle, our
approximations are valid. We give an analysis on the existing major belief
space planning methods and show that our algorithm has the lowest computational
burden. Finally, we extend our solution to contain general state and control
constraints. Our simulation results support our design."	ArXiv
2338	"Sentence Segmentation in Narrative Transcripts from Neuropsychological
  Tests using Recurrent Convolutional Neural Networks"	['Marcos Vinícius Treviso', 'Christopher Shulby', 'Sandra Maria Aluísio']	2016-10-02 00:49:15+00:00	http://arxiv.org/abs/1610.00211v2	"Automated discourse analysis tools based on Natural Language Processing (NLP)
aiming at the diagnosis of language-impairing dementias generally extract
several textual metrics of narrative transcripts. However, the absence of
sentence boundary segmentation in the transcripts prevents the direct
application of NLP methods which rely on these marks to function properly, such
as taggers and parsers. We present the first steps taken towards automatic
neuropsychological evaluation based on narrative discourse analysis, presenting
a new automatic sentence segmentation method for impaired speech. Our model
uses recurrent convolutional neural networks with prosodic, Part of Speech
(PoS) features, and word embeddings. It was evaluated intrinsically on
impaired, spontaneous speech, as well as, normal, prepared speech, and presents
better results for healthy elderly (CTL) (F1 = 0.74) and Mild Cognitive
Impairment (MCI) patients (F1 = 0.70) than the Conditional Random Fields method
(F1 = 0.55 and 0.53, respectively) used in the same context of our study. The
results suggest that our model is robust for impaired speech and can be used in
automated discourse analysis tools to differentiate narratives produced by MCI
and CTL."	ArXiv
2339	Neural Structural Correspondence Learning for Domain Adaptation	['Yftah Ziser', 'Roi Reichart']	2016-10-05 19:57:21+00:00	http://arxiv.org/abs/1610.01588v3	"Domain adaptation, adapting models from domains rich in labeled training data
to domains poor in such data, is a fundamental NLP challenge. We introduce a
neural network model that marries together ideas from two prominent strands of
research on domain adaptation through representation learning: structural
correspondence learning (SCL, (Blitzer et al., 2006)) and autoencoder neural
networks. Particularly, our model is a three-layer neural network that learns
to encode the nonpivot features of an input example into a low-dimensional
representation, so that the existence of pivot features (features that are
prominent in both domains and convey useful information for the NLP task) in
the example can be decoded from that representation. The low-dimensional
representation is then employed in a learning algorithm for the task. Moreover,
we show how to inject pre-trained word embeddings into our model in order to
improve generalization across examples with similar pivot features. On the task
of cross-domain product sentiment classification (Blitzer et al., 2007),
consisting of 12 domain pairs, our model outperforms both the SCL and the
marginalized stacked denoising autoencoder (MSDA, (Chen et al., 2012)) methods
by 3.77% and 2.17% respectively, on average across domain pairs."	ArXiv
2340	Challenges of Computational Processing of Code-Switching	['Özlem Çetinoğlu', 'Sarah Schulz', 'Ngoc Thang Vu']	2016-10-07 10:22:26+00:00	http://arxiv.org/abs/1610.02213v1	"This paper addresses challenges of Natural Language Processing (NLP) on
non-canonical multilingual data in which two or more languages are mixed. It
refers to code-switching which has become more popular in our daily life and
therefore obtains an increasing amount of attention from the research
community. We report our experience that cov- ers not only core NLP tasks such
as normalisation, language identification, language modelling, part-of-speech
tagging and dependency parsing but also more downstream ones such as machine
translation and automatic speech recognition. We highlight and discuss the key
problems for each of the tasks with supporting examples from different language
pairs and relevant previous work."	ArXiv
2341	Translation Quality Estimation using Recurrent Neural Network	['Raj Nath Patel', 'Sasikumar M']	2016-10-16 10:54:23+00:00	http://arxiv.org/abs/1610.04841v2	"This paper describes our submission to the shared task on word/phrase level
Quality Estimation (QE) in the First Conference on Statistical Machine
Translation (WMT16). The objective of the shared task was to predict if the
given word/phrase is a correct/incorrect (OK/BAD) translation in the given
sentence. In this paper, we propose a novel approach for word level Quality
Estimation using Recurrent Neural Network Language Model (RNN-LM) architecture.
RNN-LMs have been found very effective in different Natural Language Processing
(NLP) applications. RNN-LM is mainly used for vector space language modeling
for different NLP problems. For this task, we modify the architecture of
RNN-LM. The modified system predicts a label (OK/BAD) in the slot rather than
predicting the word. The input to the system is a word sequence, similar to the
standard RNN-LM. The approach is language independent and requires only the
translated text for QE. To estimate the phrase level quality, we use the output
of the word level QE system."	ArXiv
2342	Statistical Machine Translation for Indian Languages: Mission Hindi	['Raj Nath Patel', 'Prakash B. Pimpale', 'Sasikumar M']	2016-10-24 14:06:31+00:00	http://arxiv.org/abs/1610.07418v1	"This paper discusses Centre for Development of Advanced Computing Mumbai's
(CDACM) submission to the NLP Tools Contest on Statistical Machine Translation
in Indian Languages (ILSMT) 2014 (collocated with ICON 2014). The objective of
the contest was to explore the effectiveness of Statistical Machine Translation
(SMT) for Indian language to Indian language and English-Hindi machine
translation. In this paper, we have proposed that suffix separation and word
splitting for SMT from agglutinative languages to Hindi significantly improves
over the baseline (BL). We have also shown that the factored model with
reordering outperforms the phrase-based SMT for English-Hindi (\enhi). We
report our work on all five pairs of languages, namely Bengali-Hindi (\bnhi),
Marathi-Hindi (\mrhi), Tamil-Hindi (\tahi), Telugu-Hindi (\tehi), and \enhi for
Health, Tourism, and General domains."	ArXiv
2343	Statistical Machine Translation for Indian Languages: Mission Hindi 2	['Raj Nath Patel', 'Prakash B. Pimpale']	2016-10-25 18:20:08+00:00	http://arxiv.org/abs/1610.08000v1	"This paper presents Centre for Development of Advanced Computing Mumbai's
(CDACM) submission to NLP Tools Contest on Statistical Machine Translation in
Indian Languages (ILSMT) 2015 (collocated with ICON 2015). The aim of the
contest was to collectively explore the effectiveness of Statistical Machine
Translation (SMT) while translating within Indian languages and between English
and Indian languages. In this paper, we report our work on all five language
pairs, namely Bengali-Hindi (\bnhi), Marathi-Hindi (\mrhi), Tamil-Hindi
(\tahi), Telugu-Hindi (\tehi), and English-Hindi (\enhi) for Health, Tourism,
and General domains. We have used suffix separation, compound splitting and
preordering prior to SMT training and testing."	ArXiv
2344	Balotage in Argentina 2015, a sentiment analysis of tweets	['Daniel Robins', 'Fernando Emmanuel Frati', 'Jonatan Alvarez', 'Jose Texier']	2016-11-07 23:05:40+00:00	http://arxiv.org/abs/1611.02337v1	"Twitter social network contains a large amount of information generated by
its users. That information is composed of opinions and comments that may
reflect trends in social behavior. There is talk of trend when it is possible
to identify opinions and comments geared towards the same shared by a lot of
people direction. To determine if two or more written opinions share the same
address, techniques Natural Language Processing (NLP) are used. This paper
proposes a methodology for predicting reflected in Twitter from the use of
sentiment analysis functions NLP based on social behaviors. The case study was
selected the 2015 Presidential in Argentina, and a software architecture Big
Data composed Vertica data base with the component called Pulse was used.
Through the analysis it was possible to detect trends in voting intentions with
regard to the presidential candidates, achieving greater accuracy in predicting
that achieved with traditional systems surveys."	ArXiv
2345	"Visualizing and Understanding Curriculum Learning for Long Short-Term
  Memory Networks"	['Volkan Cirik', 'Eduard Hovy', 'Louis-Philippe Morency']	2016-11-18 19:38:59+00:00	http://arxiv.org/abs/1611.06204v1	"Curriculum Learning emphasizes the order of training instances in a
computational learning setup. The core hypothesis is that simpler instances
should be learned early as building blocks to learn more complex ones. Despite
its usefulness, it is still unknown how exactly the internal representation of
models are affected by curriculum learning. In this paper, we study the effect
of curriculum learning on Long Short-Term Memory (LSTM) networks, which have
shown strong competency in many Natural Language Processing (NLP) problems. Our
experiments on sentiment analysis task and a synthetic task similar to sequence
prediction tasks in NLP show that curriculum learning has a positive effect on
the LSTM's internal states by biasing the model towards building constructive
representations i.e. the internal representation at the previous timesteps are
used as building blocks for the final prediction. We also find that smaller
models significantly improves when they are trained with curriculum learning.
Lastly, we show that curriculum learning helps more when the amount of training
data is limited."	ArXiv
2346	Improving Document Clustering by Eliminating Unnatural Language	['Myungha Jang', 'Jinho D. Choi', 'James Allan']	2017-03-16 16:32:06+00:00	http://arxiv.org/abs/1703.05706v2	"Technical documents contain a fair amount of unnatural language, such as
tables, formulas, pseudo-codes, etc. Unnatural language can be an important
factor of confusing existing NLP tools. This paper presents an effective method
of distinguishing unnatural language from natural language, and evaluates the
impact of unnatural language detection on NLP tasks such as document
clustering. We view this problem as an information extraction task and build a
multiclass classification model identifying unnatural language components into
four categories. First, we create a new annotated corpus by collecting slides
and papers in various formats, PPT, PDF, and HTML, where unnatural language
components are annotated into four categories. We then explore features
available from plain text to build a statistical model that can handle any
format as long as it is converted into plain text. Our experiments show that
removing unnatural language components gives an absolute improvement in
document clustering up to 15%. Our corpus and tool are publicly available."	ArXiv
2347	Semi-supervised sequence tagging with bidirectional language models	['Matthew E. Peters', 'Waleed Ammar', 'Chandra Bhagavatula', 'Russell Power']	2017-04-29 01:13:04+00:00	http://arxiv.org/abs/1705.00108v1	"Pre-trained word embeddings learned from unlabeled text have become a
standard component of neural network architectures for NLP tasks. However, in
most cases, the recurrent network that operates on word-level representations
to produce context sensitive representations is trained on relatively little
labeled data. In this paper, we demonstrate a general semi-supervised approach
for adding pre- trained context embeddings from bidirectional language models
to NLP systems and apply it to sequence labeling tasks. We evaluate our model
on two standard datasets for named entity recognition (NER) and chunking, and
in both cases achieve state of the art results, surpassing previous systems
that use other forms of transfer or joint learning with additional labeled data
and task specific gazetteers."	ArXiv
2348	"Supervised Learning of Universal Sentence Representations from Natural
  Language Inference Data"	['Alexis Conneau', 'Douwe Kiela', 'Holger Schwenk', 'Loic Barrault', 'Antoine Bordes']	2017-05-05 18:54:39+00:00	http://arxiv.org/abs/1705.02364v5	"Many modern NLP systems rely on word embeddings, previously trained in an
unsupervised manner on large corpora, as base features. Efforts to obtain
embeddings for larger chunks of text, such as sentences, have however not been
so successful. Several attempts at learning unsupervised representations of
sentences have not reached satisfactory enough performance to be widely
adopted. In this paper, we show how universal sentence representations trained
using the supervised data of the Stanford Natural Language Inference datasets
can consistently outperform unsupervised methods like SkipThought vectors on a
wide range of transfer tasks. Much like how computer vision uses ImageNet to
obtain features, which can then be transferred to other tasks, our work tends
to indicate the suitability of natural language inference for transfer learning
to other NLP tasks. Our encoder is publicly available."	ArXiv
2349	"Learning Distributed Representations of Texts and Entities from
  Knowledge Base"	['Ikuya Yamada', 'Hiroyuki Shindo', 'Hideaki Takeda', 'Yoshiyasu Takefuji']	2017-05-06 15:11:30+00:00	http://arxiv.org/abs/1705.02494v3	"We describe a neural network model that jointly learns distributed
representations of texts and knowledge base (KB) entities. Given a text in the
KB, we train our proposed model to predict entities that are relevant to the
text. Our model is designed to be generic with the ability to address various
NLP tasks with ease. We train the model using a large corpus of texts and their
entity annotations extracted from Wikipedia. We evaluated the model on three
important NLP tasks (i.e., sentence textual similarity, entity linking, and
factoid question answering) involving both unsupervised and supervised
settings. As a result, we achieved state-of-the-art results on all three of
these tasks. Our code and trained models are publicly available for further
academic research."	ArXiv
2350	"Drug-drug Interaction Extraction via Recurrent Neural Network with
  Multiple Attention Layers"	['Zibo Yi', 'Shasha Li', 'Jie Yu', 'Qingbo Wu']	2017-05-09 10:22:48+00:00	http://arxiv.org/abs/1705.03261v2	"Drug-drug interaction (DDI) is a vital information when physicians and
pharmacists intend to co-administer two or more drugs. Thus, several DDI
databases are constructed to avoid mistakenly combined use. In recent years,
automatically extracting DDIs from biomedical text has drawn researchers'
attention. However, the existing work utilize either complex feature
engineering or NLP tools, both of which are insufficient for sentence
comprehension. Inspired by the deep learning approaches in natural language
processing, we propose a recur- rent neural network model with multiple
attention layers for DDI classification. We evaluate our model on 2013 SemEval
DDIExtraction dataset. The experiments show that our model classifies most of
the drug pairs into correct DDI categories, which outperforms the existing NLP
or deep learning methods."	ArXiv
2351	Mixed Membership Word Embeddings for Computational Social Science	['James Foulds']	2017-05-20 23:45:54+00:00	http://arxiv.org/abs/1705.07368v3	"Word embeddings improve the performance of NLP systems by revealing the
hidden structural relationships between words. Despite their success in many
applications, word embeddings have seen very little use in computational social
science NLP tasks, presumably due to their reliance on big data, and to a lack
of interpretability. I propose a probabilistic model-based word embedding
method which can recover interpretable embeddings, without big data. The key
insight is to leverage mixed membership modeling, in which global
representations are shared, but individual entities (i.e. dictionary words) are
free to use these representations to uniquely differing degrees. I show how to
train the model using a combination of state-of-the-art training techniques for
word embeddings and topic models. The experimental results show an improvement
in predictive language modeling of up to 63% in MRR over the skip-gram, and
demonstrate that the representations are beneficial for supervised learning. I
illustrate the interpretability of the models with computational social science
case studies on State of the Union addresses and NIPS articles."	ArXiv
2352	Neural Embeddings of Graphs in Hyperbolic Space	['Benjamin Paul Chamberlain', 'James Clough', 'Marc Peter Deisenroth']	2017-05-29 18:47:30+00:00	http://arxiv.org/abs/1705.10359v1	"Neural embeddings have been used with great success in Natural Language
Processing (NLP). They provide compact representations that encapsulate word
similarity and attain state-of-the-art performance in a range of linguistic
tasks. The success of neural embeddings has prompted significant amounts of
research into applications in domains other than language. One such domain is
graph-structured data, where embeddings of vertices can be learned that
encapsulate vertex similarity and improve performance on tasks including edge
prediction and vertex labelling. For both NLP and graph based tasks, embeddings
have been learned in high-dimensional Euclidean spaces. However, recent work
has shown that the appropriate isometric space for embedding complex networks
is not the flat Euclidean space, but negatively curved, hyperbolic space. We
present a new concept that exploits these recent insights and propose learning
neural embeddings of graphs in hyperbolic space. We provide experimental
evidence that embedding graphs in their natural geometry significantly improves
performance on downstream tasks for several real-world public datasets."	ArXiv
2353	"Big Data and Learning Analytics in Higher Education: Demystifying
  Variety, Acquisition, Storage, NLP and Analytics"	['Amal S. Alblawi']	2018-01-03 22:26:17+00:00	http://arxiv.org/abs/1801.06052v1	"Different sectors have sought to take advantage of opportunities to invest in
big data analytics and Natural language processing, in order to improve their
productivity and competitiveness. Current challenges facing the higher
education sector include a rapidly changing and evolving environment, which
necessitates the development of new ways of thinking. Interest has therefore
increased in analytics as part of the solution to many issues in higher
education, including the rate of student attrition and learner support. This
study provides a comprehensive discussion of big data, learning analytics and
use of NLP in higher education. In addition, it introduces an integrated
learning analytics solution leveraging a distributed technology system capable
of supporting academic authorities and advisors at educational institutions in
making decisions concerning individual students."	ArXiv
2354	Universal Language Model Fine-tuning for Text Classification	['Jeremy Howard', 'Sebastian Ruder']	2018-01-18 17:54:52+00:00	http://arxiv.org/abs/1801.06146v5	"Inductive transfer learning has greatly impacted computer vision, but
existing approaches in NLP still require task-specific modifications and
training from scratch. We propose Universal Language Model Fine-tuning
(ULMFiT), an effective transfer learning method that can be applied to any task
in NLP, and introduce techniques that are key for fine-tuning a language model.
Our method significantly outperforms the state-of-the-art on six text
classification tasks, reducing the error by 18-24% on the majority of datasets.
Furthermore, with only 100 labeled examples, it matches the performance of
training from scratch on 100x more data. We open-source our pretrained models
and code."	ArXiv
2355	HappyDB: A Corpus of 100,000 Crowdsourced Happy Moments	['Akari Asai', 'Sara Evensen', 'Behzad Golshan', 'Alon Halevy', 'Vivian Li', 'Andrei Lopatenko', 'Daniela Stepanov', 'Yoshihiko Suhara', 'Wang-Chiew Tan', 'Yinzhan Xu']	2018-01-23 19:49:58+00:00	http://arxiv.org/abs/1801.07746v2	"The science of happiness is an area of positive psychology concerned with
understanding what behaviors make people happy in a sustainable fashion.
Recently, there has been interest in developing technologies that help
incorporate the findings of the science of happiness into users' daily lives by
steering them towards behaviors that increase happiness. With the goal of
building technology that can understand how people express their happy moments
in text, we crowd-sourced HappyDB, a corpus of 100,000 happy moments that we
make publicly available. This paper describes HappyDB and its properties, and
outlines several important NLP problems that can be studied with the help of
the corpus. We also apply several state-of-the-art analysis techniques to
analyze HappyDB. Our results demonstrate the need for deeper NLP techniques to
be developed which makes HappyDB an exciting resource for follow-on research."	ArXiv
2356	"Pilot study for the COST Action ""Reassembling the Republic of Letters"":
  language-driven network analysis of letters from the Hartlib's Papers"	['Barbara McGillivray', 'Federico Sangati']	2018-01-30 08:50:26+00:00	http://arxiv.org/abs/1801.09896v1	"The present report summarizes an exploratory study which we carried out in
the context of the COST Action IS1310 ""Reassembling the Republic of Letters,
1500-1800"", and which is relevant to the activities of Working Group 3 ""Texts
and Topics"" and Working Group 2 ""People and Networks"". In this study we
investigated the use of Natural Language Processing (NLP) and Network Text
Analysis on a small sample of seventeenth-century letters selected from Hartlib
Papers, whose records are in one of the catalogues of Early Modern Letters
Online (EMLO) and whose online edition is available on the website of the
Humanities Research Institute at the University of Sheffield
(http://www.hrionline.ac.uk/hartlib/). We outline the NLP pipeline used to
automatically process the texts into a network representation, in order to
identify the texts' ""narrative centrality"", i.e. the most central entities in
the texts, and the relations between them."	ArXiv
2357	"A Deep Learning Model with Hierarchical LSTMs and Supervised Attention
  for Anti-Phishing"	['Minh Nguyen', 'Toan Nguyen', 'Thien Huu Nguyen']	2018-05-03 21:53:09+00:00	http://arxiv.org/abs/1805.01554v1	"Anti-phishing aims to detect phishing content/documents in a pool of textual
data. This is an important problem in cybersecurity that can help to guard
users from fraudulent information. Natural language processing (NLP) offers a
natural solution for this problem as it is capable of analyzing the textual
content to perform intelligent recognition. In this work, we investigate
state-of-the-art techniques for text categorization in NLP to address the
problem of anti-phishing for emails (i.e, predicting if an email is phishing or
not). These techniques are based on deep learning models that have attracted
much attention from the community recently. In particular, we present a
framework with hierarchical long short-term memory networks (H-LSTMs) and
attention mechanisms to model the emails simultaneously at the word and the
sentence level. Our expectation is to produce an effective model for
anti-phishing and demonstrate the effectiveness of deep learning for problems
in cybersecurity."	ArXiv
2358	Interpretable Adversarial Perturbation in Input Embedding Space for Text	['Motoki Sato', 'Jun Suzuki', 'Hiroyuki Shindo', 'Yuji Matsumoto']	2018-05-08 09:27:46+00:00	http://arxiv.org/abs/1805.02917v1	"Following great success in the image processing field, the idea of
adversarial training has been applied to tasks in the natural language
processing (NLP) field. One promising approach directly applies adversarial
training developed in the image processing field to the input word embedding
space instead of the discrete input space of texts. However, this approach
abandons such interpretability as generating adversarial texts to significantly
improve the performance of NLP tasks. This paper restores interpretability to
such methods by restricting the directions of perturbations toward the existing
words in the input embedding space. As a result, we can straightforwardly
reconstruct each input with perturbations to an actual text by considering the
perturbations to be the replacement of words in the sentence while maintaining
or even improving the task performance."	ArXiv
2359	"Marrying up Regular Expressions with Neural Networks: A Case Study for
  Spoken Language Understanding"	['Bingfeng Luo', 'Yansong Feng', 'Zheng Wang', 'Songfang Huang', 'Rui Yan', 'Dongyan Zhao']	2018-05-15 06:40:44+00:00	http://arxiv.org/abs/1805.05588v1	"The success of many natural language processing (NLP) tasks is bound by the
number and quality of annotated data, but there is often a shortage of such
training data. In this paper, we ask the question: ""Can we combine a neural
network (NN) with regular expressions (RE) to improve supervised learning for
NLP?"". In answer, we develop novel methods to exploit the rich expressiveness
of REs at different levels within a NN, showing that the combination
significantly enhances the learning effectiveness when a small number of
training examples are available. We evaluate our approach by applying it to
spoken language understanding for intent detection and slot filling.
Experimental results show that our approach is highly effective in exploiting
the available training data, giving a clear boost to the RE-unaware NN."	ArXiv
2360	A Corpus of English-Hindi Code-Mixed Tweets for Sarcasm Detection	['Sahil Swami', 'Ankush Khandelwal', 'Vinay Singh', 'Syed Sarfaraz Akhtar', 'Manish Shrivastava']	2018-05-30 09:08:54+00:00	http://arxiv.org/abs/1805.11869v1	"Social media platforms like twitter and facebook have be- come two of the
largest mediums used by people to express their views to- wards different
topics. Generation of such large user data has made NLP tasks like sentiment
analysis and opinion mining much more important. Using sarcasm in texts on
social media has become a popular trend lately. Using sarcasm reverses the
meaning and polarity of what is implied by the text which poses challenge for
many NLP tasks. The task of sarcasm detection in text is gaining more and more
importance for both commer- cial and security services. We present the first
English-Hindi code-mixed dataset of tweets marked for presence of sarcasm and
irony where each token is also annotated with a language tag. We present a
baseline su- pervised classification system developed using the same dataset
which achieves an average F-score of 78.4 after using random forest classifier
and performing 10-fold cross validation."	ArXiv
2361	Jointly Embedding Entities and Text with Distant Supervision	['Denis Newman-Griffis', 'Albert M. Lai', 'Eric Fosler-Lussier']	2018-07-09 21:40:53+00:00	http://arxiv.org/abs/1807.03399v1	"Learning representations for knowledge base entities and concepts is becoming
increasingly important for NLP applications. However, recent entity embedding
methods have relied on structured resources that are expensive to create for
new domains and corpora. We present a distantly-supervised method for jointly
learning embeddings of entities and text from an unnanotated corpus, using only
a list of mappings between entities and surface forms. We learn embeddings from
open-domain and biomedical corpora, and compare against prior methods that rely
on human-annotated text or large knowledge graph structure. Our embeddings
capture entity similarity and relatedness better than prior work, both in
existing biomedical datasets and a new Wikipedia-based dataset that we release
to the community. Results on analogy completion and entity sense disambiguation
indicate that entities and words capture complementary information that can be
effectively combined for downstream use."	ArXiv
2362	Structured Synthesis for Probabilistic Systems	['Nils Jansen', 'Laura Humphrey', 'Jana Tumova', 'Ufuk Topcu']	2018-07-16 20:55:41+00:00	http://arxiv.org/abs/1807.06106v1	"We introduce the concept of structured synthesis for Markov decision
processes where the structure is induced from finitely many pre-specified
options for a system configuration. The resulting synthesis problem is in
general a nonlinear programming problem (NLP) with integer variables. As
solving NLPs is in general not feasible, we present an alternative approach. We
present a transformation of models specified in the {PRISM} probabilistic
programming language to models that account for all possible system
configurations by means of nondeterministic choices. Together with a control
module that ensures consistent configurations throughout the system, this
transformation enables the use of optimized tools for model checking in a
black-box fashion. While this transformation increases the size of a model,
experiments with standard benchmarks show that the method provides a feasible
approach for structured synthesis. Moreover, we demonstrate the usefulness
along a realistic case study involving surveillance by unmanned aerial vehicles
in a shipping facility."	ArXiv
2363	Power Networks: A Novel Neural Architecture to Predict Power Relations	['Michelle Lam', 'Catherina Xu', 'Angela Kong', 'Vinodkumar Prabhakaran']	2018-07-17 17:04:52+00:00	http://arxiv.org/abs/1807.06557v1	"Can language analysis reveal the underlying social power relations that exist
between participants of an interaction? Prior work within NLP has shown promise
in this area, but the performance of automatically predicting power relations
using NLP analysis of social interactions remains wanting. In this paper, we
present a novel neural architecture that captures manifestations of power
within individual emails which are then aggregated in an order-preserving way
in order to infer the direction of power between pairs of participants in an
email thread. We obtain an accuracy of 80.4%, a 10.1% improvement over
state-of-the-art methods, in this task. We further apply our model to the task
of predicting power relations between individuals based on the entire set of
messages exchanged between them; here also, our model significantly outperforms
the70.0% accuracy using prior state-of-the-art techniques, obtaining an
accuracy of 83.0%."	ArXiv
2364	Gender Bias in Neural Natural Language Processing	['Kaiji Lu', 'Piotr Mardziel', 'Fangjing Wu', 'Preetam Amancharla', 'Anupam Datta']	2018-07-31 09:27:27+00:00	http://arxiv.org/abs/1807.11714v2	"We examine whether neural natural language processing (NLP) systems reflect
historical biases in training data. We define a general benchmark to quantify
gender bias in a variety of neural NLP tasks. Our empirical evaluation with
state-of-the-art neural coreference resolution and textbook RNN-based language
models trained on benchmark datasets finds significant gender bias in how
models view occupations. We then mitigate bias with CDA: a generic methodology
for corpus augmentation via causal interventions that breaks associations
between gendered and gender-neutral words. We empirically show that CDA
effectively decreases gender bias while preserving accuracy. We also explore
the space of mitigation strategies with CDA, a prior approach to word embedding
debiasing (WED), and their compositions. We show that CDA outperforms WED,
drastically so when word embeddings are trained. For pre-trained embeddings,
the two methods can be effectively composed. We also find that as training
proceeds on the original data set with gradient descent the gender bias grows
as the loss reduces, indicating that the optimization encourages bias; CDA
mitigates this behavior."	ArXiv
2365	Hierarchical Attention: What Really Counts in Various NLP Tasks	['Zehao Dou', 'Zhihua Zhang']	2018-08-10 23:28:33+00:00	http://arxiv.org/abs/1808.03728v1	"Attention mechanisms in sequence to sequence models have shown great ability
and wonderful performance in various natural language processing (NLP) tasks,
such as sentence embedding, text generation, machine translation, machine
reading comprehension, etc. Unfortunately, existing attention mechanisms only
learn either high-level or low-level features. In this paper, we think that the
lack of hierarchical mechanisms is a bottleneck in improving the performance of
the attention mechanisms, and propose a novel Hierarchical Attention Mechanism
(Ham) based on the weighted sum of different layers of a multi-level attention.
Ham achieves a state-of-the-art BLEU score of 0.26 on Chinese poem generation
task and a nearly 6.5% averaged improvement compared with the existing machine
reading comprehension models such as BIDAF and Match-LSTM. Furthermore, our
experiments and theorems reveal that Ham has greater generalization and
representation ability than existing attention mechanisms."	ArXiv
2366	Learning to Compose over Tree Structures via POS Tags	['Gehui Shen', 'Zhi-Hong Deng', 'Ting Huang', 'Xi Chen']	2018-08-18 11:53:24+00:00	http://arxiv.org/abs/1808.06075v2	"Recursive Neural Network (RecNN), a type of models which compose words or
phrases recursively over syntactic tree structures, has been proven to have
superior ability to obtain sentence representation for a variety of NLP tasks.
However, RecNN is born with a thorny problem that a shared compositional
function for each node of trees can't capture the complex semantic
compositionality so that the expressive power of model is limited. In this
paper, in order to address this problem, we propose Tag-Guided
HyperRecNN/TreeLSTM (TG-HRecNN/TreeLSTM), which introduces hypernetwork into
RecNNs to take as inputs Part-of-Speech (POS) tags of word/phrase and generate
the semantic composition parameters dynamically. Experimental results on five
datasets for two typical NLP tasks show proposed models both obtain significant
improvement compared with RecNN and TreeLSTM consistently. Our TG-HTreeLSTM
outperforms all existing RecNN-based models and achieves or is competitive with
state-of-the-art on four sentence classification benchmarks. The effectiveness
of our models is also demonstrated by qualitative analysis."	ArXiv
2367	Dissecting Contextual Word Embeddings: Architecture and Representation	['Matthew E. Peters', 'Mark Neumann', 'Luke Zettlemoyer', 'Wen-tau Yih']	2018-08-27 17:54:29+00:00	http://arxiv.org/abs/1808.08949v2	"Contextual word representations derived from pre-trained bidirectional
language models (biLMs) have recently been shown to provide significant
improvements to the state of the art for a wide range of NLP tasks. However,
many questions remain as to how and why these models are so effective. In this
paper, we present a detailed empirical study of how the choice of neural
architecture (e.g. LSTM, CNN, or self attention) influences both end task
accuracy and qualitative properties of the representations that are learned. We
show there is a tradeoff between speed and accuracy, but all architectures
learn high quality contextual representations that outperform word embeddings
for four challenging NLP tasks. Additionally, all architectures learn
representations that vary with network depth, from exclusively morphological
based at the word embedding layer through local syntax based in the lower
contextual layers to longer range semantics such coreference at the upper
layers. Together, these results suggest that unsupervised biLMs, independent of
architecture, are learning much more about the structure of language than
previously appreciated."	ArXiv
2368	Inexact cuts in Stochastic Dual Dynamic Programming	['Vincent Guigues']	2018-09-04 23:46:08+00:00	http://arxiv.org/abs/1809.02007v4	"We introduce an extension of Stochastic Dual Dynamic Programming (SDDP) to
solve stochastic convex dynamic programming equations. This extension applies
when some or all primal and dual subproblems to be solved along the forward and
backward passes of the method are solved with bounded errors (inexactly). This
inexact variant of SDDP is described both for linear problems (the
corresponding variant being denoted by ISDDP-LP) and nonlinear problems (the
corresponding variant being denoted by ISDDP-NLP). We prove convergence
theorems for ISDDP-LP and ISDDP-NLP both for bounded and asymptotically
vanishing errors. Finally, we present the results of numerical experiments
comparing SDDP and ISDDP-LP on portfolio problem with direct transaction costs
modelled as a multistage stochastic linear optimization problem. On these
experiments, ISDDP-LP allows us to obtain a good policy faster than SDDP."	ArXiv
2369	How much should you ask? On the question structure in QA systems	['Dominika Basaj', 'Barbara Rychalska', 'Przemyslaw Biecek', 'Anna Wroblewska']	2018-09-11 08:26:36+00:00	http://arxiv.org/abs/1809.03734v1	"Datasets that boosted state-of-the-art solutions for Question Answering (QA)
systems prove that it is possible to ask questions in natural language manner.
However, users are still used to query-like systems where they type in keywords
to search for answer. In this study we validate which parts of questions are
essential for obtaining valid answer. In order to conclude that, we take
advantage of LIME - a framework that explains prediction by local
approximation. We find that grammar and natural language is disregarded by QA.
State-of-the-art model can answer properly even if 'asked' only with a few
words with high coefficients calculated with LIME. According to our knowledge,
it is the first time that QA model is being explained by LIME."	ArXiv
2370	Can LSTM Learn to Capture Agreement? The Case of Basque	['Shauli Ravfogel', 'Francis M. Tyers', 'Yoav Goldberg']	2018-09-11 16:44:02+00:00	http://arxiv.org/abs/1809.04022v4	"Sequential neural networks models are powerful tools in a variety of Natural
Language Processing (NLP) tasks. The sequential nature of these models raises
the questions: to what extent can these models implicitly learn hierarchical
structures typical to human language, and what kind of grammatical phenomena
can they acquire?
  We focus on the task of agreement prediction in Basque, as a case study for a
task that requires implicit understanding of sentence structure and the
acquisition of a complex but consistent morphological system. Analyzing
experimental results from two syntactic prediction tasks -- verb number
prediction and suffix recovery -- we find that sequential models perform worse
on agreement prediction in Basque than one might expect on the basis of a
previous agreement prediction work in English. Tentative findings based on
diagnostic classifiers suggest the network makes use of local heuristics as a
proxy for the hierarchical structure of the sentence. We propose the Basque
agreement prediction task as challenging benchmark for models that attempt to
learn regularities in human language."	ArXiv
2371	Understanding Convolutional Neural Networks for Text Classification	['Alon Jacovi', 'Oren Sar Shalom', 'Yoav Goldberg']	2018-09-21 11:03:48+00:00	http://arxiv.org/abs/1809.08037v3	"We present an analysis into the inner workings of Convolutional Neural
Networks (CNNs) for processing text. CNNs used for computer vision can be
interpreted by projecting filters into image space, but for discrete sequence
inputs CNNs remain a mystery. We aim to understand the method by which the
networks process and classify text. We examine common hypotheses to this
problem: that filters, accompanied by global max-pooling, serve as ngram
detectors. We show that filters may capture several different semantic classes
of ngrams by using different activation patterns, and that global max-pooling
induces behavior which separates important ngrams from the rest. Finally, we
show practical use cases derived from our findings in the form of model
interpretability (explaining a trained model by deriving a concrete identity
for each filter, bridging the gap between visualization tools in vision tasks
and NLP) and prediction interpretability (explaining predictions). Code
implementation is available online at
github.com/sayaendo/interpreting-cnn-for-text."	ArXiv
2372	"A Deep Learning Architecture for De-identification of Patient Notes:
  Implementation and Evaluation"	['Kaung Khin', 'Philipp Burckhardt', 'Rema Padman']	2018-10-03 02:53:04+00:00	http://arxiv.org/abs/1810.01570v1	"De-identification is the process of removing 18 protected health information
(PHI) from clinical notes in order for the text to be considered not
individually identifiable. Recent advances in natural language processing (NLP)
has allowed for the use of deep learning techniques for the task of
de-identification. In this paper, we present a deep learning architecture that
builds on the latest NLP advances by incorporating deep contextualized word
embeddings and variational drop out Bi-LSTMs. We test this architecture on two
gold standard datasets and show that the architecture achieves state-of-the-art
performance on both data sets while also converging faster than other systems
without the use of dictionaries or other knowledge sources."	ArXiv
2373	Open Vocabulary Learning on Source Code with a Graph-Structured Cache	['Milan Cvitkovic', 'Badal Singh', 'Anima Anandkumar']	2018-10-18 23:33:11+00:00	http://arxiv.org/abs/1810.08305v2	"Machine learning models that take computer program source code as input
typically use Natural Language Processing (NLP) techniques. However, a major
challenge is that code is written using an open, rapidly changing vocabulary
due to, e.g., the coinage of new variable and method names. Reasoning over such
a vocabulary is not something for which most NLP methods are designed. We
introduce a Graph-Structured Cache to address this problem; this cache contains
a node for each new word the model encounters with edges connecting each word
to its occurrences in the code. We find that combining this graph-structured
cache strategy with recent Graph-Neural-Network-based models for supervised
learning on code improves the models' performance on a code completion task and
a variable naming task --- with over $100\%$ relative improvement on the latter
--- at the cost of a moderate increase in computation time."	ArXiv
2374	BioSentVec: creating sentence embeddings for biomedical texts	['Qingyu Chen', 'Yifan Peng', 'Zhiyong Lu']	2018-10-22 14:10:01+00:00	http://arxiv.org/abs/1810.09302v6	"Sentence embeddings have become an essential part of today's natural language
processing (NLP) systems, especially together advanced deep learning methods.
Although pre-trained sentence encoders are available in the general domain,
none exists for biomedical texts to date. In this work, we introduce
BioSentVec: the first open set of sentence embeddings trained with over 30
million documents from both scholarly articles in PubMed and clinical notes in
the MIMIC-III Clinical Database. We evaluate BioSentVec embeddings in two
sentence pair similarity tasks in different text genres. Our benchmarking
results demonstrate that the BioSentVec embeddings can better capture sentence
semantics compared to the other competitive alternatives and achieve
state-of-the-art performance in both tasks. We expect BioSentVec to facilitate
the research and development in biomedical text mining and to complement the
existing resources in biomedical word embeddings. BioSentVec is publicly
available at https://github.com/ncbi-nlp/BioSentVec"	ArXiv
2375	"Learning Cross-Lingual Sentence Representations via a Multi-task
  Dual-Encoder Model"	['Muthuraman Chidambaram', 'Yinfei Yang', 'Daniel Cer', 'Steve Yuan', 'Yun-Hsuan Sung', 'Brian Strope', 'Ray Kurzweil']	2018-10-30 16:18:05+00:00	http://arxiv.org/abs/1810.12836v4	"A significant roadblock in multilingual neural language modeling is the lack
of labeled non-English data. One potential method for overcoming this issue is
learning cross-lingual text representations that can be used to transfer the
performance from training on English tasks to non-English tasks, despite little
to no task-specific non-English data. In this paper, we explore a natural setup
for learning cross-lingual sentence representations: the dual-encoder. We
provide a comprehensive evaluation of our cross-lingual representations on a
number of monolingual, cross-lingual, and zero-shot/few-shot learning tasks,
and also give an analysis of different learned cross-lingual embedding spaces."	ArXiv
2376	"Towards Explainable NLP: A Generative Explanation Framework for Text
  Classification"	['Hui Liu', 'Qingyu Yin', 'William Yang Wang']	2018-11-01 02:45:57+00:00	http://arxiv.org/abs/1811.00196v2	"Building explainable systems is a critical problem in the field of Natural
Language Processing (NLP), since most machine learning models provide no
explanations for the predictions. Existing approaches for explainable machine
learning systems tend to focus on interpreting the outputs or the connections
between inputs and outputs. However, the fine-grained information is often
ignored, and the systems do not explicitly generate the human-readable
explanations. To better alleviate this problem, we propose a novel generative
explanation framework that learns to make classification decisions and generate
fine-grained explanations at the same time. More specifically, we introduce the
explainable factor and the minimum risk training approach that learn to
generate more reasonable explanations. We construct two new datasets that
contain summaries, rating scores, and fine-grained reasons. We conduct
experiments on both datasets, comparing with several strong neural network
baseline systems. Experimental results show that our method surpasses all
baselines on both datasets, and is able to generate concise explanations at the
same time."	ArXiv
2377	"Learning Semantic Representations for Novel Words: Leveraging Both Form
  and Context"	['Timo Schick', 'Hinrich Schütze']	2018-11-09 11:44:05+00:00	http://arxiv.org/abs/1811.03866v1	"Word embeddings are a key component of high-performing natural language
processing (NLP) systems, but it remains a challenge to learn good
representations for novel words on the fly, i.e., for words that did not occur
in the training data. The general problem setting is that word embeddings are
induced on an unlabeled training corpus and then a model is trained that embeds
novel words into this induced embedding space. Currently, two approaches for
learning embeddings of novel words exist: (i) learning an embedding from the
novel word's surface-form (e.g., subword n-grams) and (ii) learning an
embedding from the context in which it occurs. In this paper, we propose an
architecture that leverages both sources of information - surface-form and
context - and show that it results in large increases in embedding quality. Our
architecture obtains state-of-the-art results on the Definitional Nonce and
Contextual Rare Words datasets. As input, we only require an embedding set and
an unlabeled corpus for training our architecture to produce embeddings
appropriate for the induced embedding space. Thus, our model can easily be
integrated into any existing NLP system and enhance its capability to handle
novel words."	ArXiv
2378	ReDecode Framework for Iterative Improvement in Paraphrase Generation	['Milan Aggarwal', 'Nupur Kumari', 'Ayush Bansal', 'Balaji Krishnamurthy']	2018-11-11 19:02:50+00:00	http://arxiv.org/abs/1811.04454v1	"Generating paraphrases, that is, different variations of a sentence conveying
the same meaning, is an important yet challenging task in NLP. Automatically
generating paraphrases has its utility in many NLP tasks like question
answering, information retrieval, conversational systems to name a few. In this
paper, we introduce iterative refinement of generated paraphrases within VAE
based generation framework. Current sequence generation models lack the
capability to (1) make improvements once the sentence is generated; (2) rectify
errors made while decoding. We propose a technique to iteratively refine the
output using multiple decoders, each one attending on the output sentence
generated by the previous decoder. We improve current state of the art results
significantly - with over 9% and 28% absolute increase in METEOR scores on
Quora question pairs and MSCOCO datasets respectively. We also show
qualitatively through examples that our re-decoding approach generates better
paraphrases compared to a single decoder by rectifying errors and making
improvements in paraphrase structure, inducing variations and introducing new
but semantically coherent information."	ArXiv
2379	"Syntax Helps ELMo Understand Semantics: Is Syntax Still Relevant in a
  Deep Neural Architecture for SRL?"	['Emma Strubell', 'Andrew McCallum']	2018-11-12 15:16:12+00:00	http://arxiv.org/abs/1811.04773v1	"Do unsupervised methods for learning rich, contextualized token
representations obviate the need for explicit modeling of linguistic structure
in neural network models for semantic role labeling (SRL)? We address this
question by incorporating the massively successful ELMo embeddings (Peters et
al., 2018) into LISA (Strubell et al., 2018), a strong, linguistically-informed
neural network architecture for SRL. In experiments on the CoNLL-2005 shared
task we find that though ELMo out-performs typical word embeddings, beginning
to close the gap in F1 between LISA with predicted and gold syntactic parses,
syntactically-informed models still out-perform syntax-free models when both
use ELMo, especially on out-of-domain data. Our results suggest that linguistic
structures are indeed still relevant in this golden age of deep learning for
NLP."	ArXiv
2380	"A Hierarchical Multi-task Approach for Learning Embeddings from Semantic
  Tasks"	['Victor Sanh', 'Thomas Wolf', 'Sebastian Ruder']	2018-11-14 19:42:03+00:00	http://arxiv.org/abs/1811.06031v2	"Much effort has been devoted to evaluate whether multi-task learning can be
leveraged to learn rich representations that can be used in various Natural
Language Processing (NLP) down-stream applications. However, there is still a
lack of understanding of the settings in which multi-task learning has a
significant effect. In this work, we introduce a hierarchical model trained in
a multi-task learning setup on a set of carefully selected semantic tasks. The
model is trained in a hierarchical fashion to introduce an inductive bias by
supervising a set of low level tasks at the bottom layers of the model and more
complex tasks at the top layers of the model. This model achieves
state-of-the-art results on a number of tasks, namely Named Entity Recognition,
Entity Mention Detection and Relation Extraction without hand-engineered
features or external NLP tools like syntactic parsers. The hierarchical
training supervision induces a set of shared semantic representations at lower
layers of the model. We show that as we move from the bottom to the top layers
of the model, the hidden states of the layers tend to represent more complex
semantic information."	ArXiv
2381	"HYPE: A High Performing NLP System for Automatically Detecting
  Hypoglycemia Events from Electronic Health Record Notes"	['Yonghao Jin', 'Fei Li', 'Hong Yu']	2018-11-29 03:40:55+00:00	http://arxiv.org/abs/1811.11945v1	"Hypoglycemia is common and potentially dangerous among those treated for
diabetes. Electronic health records (EHRs) are important resources for
hypoglycemia surveillance. In this study, we report the development and
evaluation of deep learning-based natural language processing systems to
automatically detect hypoglycemia events from the EHR narratives. Experts in
Public Health annotated 500 EHR notes from patients with diabetes. We used this
annotated dataset to train and evaluate HYPE, supervised NLP systems for
hypoglycemia detection. In our experiment, the convolutional neural network
model yielded promising performance $Precision=0.96 \pm 0.03, Recall=0.86 \pm
0.03, F1=0.91 \pm 0.03$ in a 10-fold cross-validation setting. Despite the
annotated data is highly imbalanced, our CNN-based HYPE system still achieved a
high performance for hypoglycemia detection. HYPE could be used for EHR-based
hypoglycemia surveillance and to facilitate clinicians for timely treatment of
high-risk patients."	ArXiv
2382	"A Tweet Dataset Annotated for Named Entity Recognition and Stance
  Detection"	['Dilek Küçük', 'Fazli Can']	2019-01-15 12:16:13+00:00	http://arxiv.org/abs/1901.04787v2	"Annotated datasets in different domains are critical for many supervised
learning-based solutions to related problems and for the evaluation of the
proposed solutions. Topics in natural language processing (NLP) similarly
require annotated datasets to be used for such purposes. In this paper, we
target at two NLP problems, named entity recognition and stance detection, and
present the details of a tweet dataset in Turkish annotated for named entity
and stance information. Within the course of the current study, both the named
entity and stance annotations of the included tweets are made publicly
available, although previously the dataset has been publicly shared with stance
annotations only. We believe that this dataset will be useful for uncovering
the possible relationships between named entity recognition and stance
detection in tweets."	ArXiv
2383	"Sentence transition matrix: An efficient approach that preserves
  sentence semantics"	['Myeongjun Jang', 'Pilsung Kang']	2019-01-16 10:40:18+00:00	http://arxiv.org/abs/1901.05219v1	"Sentence embedding is a significant research topic in the field of natural
language processing (NLP). Generating sentence embedding vectors reflecting the
intrinsic meaning of a sentence is a key factor to achieve an enhanced
performance in various NLP tasks such as sentence classification and document
summarization. Therefore, various sentence embedding models based on supervised
and unsupervised learning have been proposed after the advent of researches
regarding the distributed representation of words. They were evaluated through
semantic textual similarity (STS) tasks, which measure the degree of semantic
preservation of a sentence and neural network-based supervised embedding models
generally yielded state-of-the-art performance. However, these models have a
limitation in that they have multiple parameters to update, thereby requiring a
tremendous amount of labeled training data. In this study, we propose an
efficient approach that learns a transition matrix that refines a sentence
embedding vector to reflect the latent semantic meaning of a sentence. The
proposed method has two practical advantages; (1) it can be applied to any
sentence embedding method, and (2) it can achieve robust performance in STS
tasks irrespective of the number of training examples."	ArXiv
2384	It's Only Words And Words Are All I Have	['Manash Pratim Barman', 'Kavish Dahekar', 'Abhinav Anshuman', 'Amit Awekar']	2019-01-16 10:58:22+00:00	http://arxiv.org/abs/1901.05227v1	"The central idea of this paper is to demonstrate the strength of lyrics for
music mining and natural language processing (NLP) tasks using the distributed
representation paradigm. For music mining, we address two prediction tasks for
songs: genre and popularity. Existing works for both these problems have two
major bottlenecks. First, they represent lyrics using handcrafted features that
require intricate knowledge of language and music. Second, they consider lyrics
as a weak indicator of genre and popularity. We overcome both the bottlenecks
by representing lyrics using distributed representation. In our work, genre
identification is a multi-class classification task whereas popularity
prediction is a binary classification task. We achieve an F1 score of around
0.6 for both the tasks using only lyrics. Distributed representation of words
is now heavily used for various NLP algorithms. We show that lyrics can be used
to improve the quality of this representation."	ArXiv
2385	"Semantic Relation Classification via Bidirectional LSTM Networks with
  Entity-aware Attention using Latent Entity Typing"	['Joohong Lee', 'Sangwoo Seo', 'Yong Suk Choi']	2019-01-23 23:19:45+00:00	http://arxiv.org/abs/1901.08163v1	"Classifying semantic relations between entity pairs in sentences is an
important task in Natural Language Processing (NLP). Most previous models for
relation classification rely on the high-level lexical and syntactic features
obtained by NLP tools such as WordNet, dependency parser, part-of-speech (POS)
tagger, and named entity recognizers (NER). In addition, state-of-the-art
neural models based on attention mechanisms do not fully utilize information of
entity that may be the most crucial features for relation classification. To
address these issues, we propose a novel end-to-end recurrent neural model
which incorporates an entity-aware attention mechanism with a latent entity
typing (LET) method. Our model not only utilizes entities and their latent
types as features effectively but also is more interpretable by visualizing
attention mechanisms applied to our model and results of LET. Experimental
results on the SemEval-2010 Task 8, one of the most popular relation
classification task, demonstrate that our model outperforms existing
state-of-the-art models without any high-level features."	ArXiv
2386	A detailed comparative study of open source deep learning frameworks	['Ghadeer Al-Bdour', 'Raffi Al-Qurran', 'Mahmoud Al-Ayyoub', 'Ali Shatnawi']	2019-02-25 20:10:54+00:00	http://arxiv.org/abs/1903.00102v2	"Deep Learning (DL) is one of the hottest trends in machine learning as DL
approaches produced results superior to the state-of-the-art in problematic
areas such as image processing and natural language processing (NLP). To foster
the growth of DL, several open source frameworks appeared providing
implementations of the most common DL algorithms. These frameworks vary in the
algorithms they support and in the quality of their implementations. The
purpose of this work is to provide a qualitative and quantitative comparison
among three of the most popular and most comprehensive DL frameworks (namely
Google's TensorFlow, University of Montreal's Theano and Microsoft's CNTK). The
ultimate goal of this work is to help end users make an informed decision about
the best DL framework that suits their needs and resources. To ensure that our
study is as comprehensive as possible, we conduct several experiments using
multiple benchmark datasets from different fields (image processing, NLP, etc.)
and measure the performance of the frameworks' implementations of different DL
algorithms. For most of our experiments, we find out that CNTK's
implementations are superior to the other ones under consideration."	ArXiv
2387	"Predicting and interpreting embeddings for out of vocabulary words in
  downstream tasks"	['Nicolas Garneau', 'Jean-Samuel Leboeuf', 'Luc Lamontagne']	2019-03-02 15:32:39+00:00	http://arxiv.org/abs/1903.00724v1	"We propose a novel way to handle out of vocabulary (OOV) words in downstream
natural language processing (NLP) tasks. We implement a network that predicts
useful embeddings for OOV words based on their morphology and on the context in
which they appear. Our model also incorporates an attention mechanism
indicating the focus allocated to the left context words, the right context
words or the word's characters, hence making the prediction more interpretable.
The model is a ``drop-in'' module that is jointly trained with the downstream
task's neural network, thus producing embeddings specialized for the task at
hand. When the task is mostly syntactical, we observe that our model aims most
of its attention on surface form characters. On the other hand, for tasks more
semantical, the network allocates more attention to the surrounding words. In
all our tests, the module helps the network to achieve better performances in
comparison to the use of simple random embeddings."	ArXiv
2388	"A Type-coherent, Expressive Representation as an Initial Step to
  Language Understanding"	['Gene Louis Kim', 'Lenhart Schubert']	2019-03-22 03:06:36+00:00	http://arxiv.org/abs/1903.09333v2	"A growing interest in tasks involving language understanding by the NLP
community has led to the need for effective semantic parsing and inference.
Modern NLP systems use semantic representations that do not quite fulfill the
nuanced needs for language understanding: adequately modeling language
semantics, enabling general inferences, and being accurately recoverable. This
document describes underspecified logical forms (ULF) for Episodic Logic (EL),
which is an initial form for a semantic representation that balances these
needs. ULFs fully resolve the semantic type structure while leaving issues such
as quantifier scope, word sense, and anaphora unresolved; they provide a
starting point for further resolution into EL, and enable certain structural
inferences without further resolution. This document also presents preliminary
results of creating a hand-annotated corpus of ULFs for the purpose of training
a precise ULF parser, showing a three-person pairwise interannotator agreement
of 0.88 on confident annotations. We hypothesize that a divide-and-conquer
approach to semantic parsing starting with derivation of ULFs will lead to
semantic analyses that do justice to subtle aspects of linguistic meaning, and
will enable construction of more accurate semantic parsers."	ArXiv
2389	An end-to-end Neural Network Framework for Text Clustering	['Jie Zhou', 'Xingyi Cheng', 'Jinchao Zhang']	2019-03-22 09:54:36+00:00	http://arxiv.org/abs/1903.09424v1	"The unsupervised text clustering is one of the major tasks in natural
language processing (NLP) and remains a difficult and complex problem.
Conventional \mbox{methods} generally treat this task using separated steps,
including text representation learning and clustering the representations. As
an improvement, neural methods have also been introduced for continuous
representation learning to address the sparsity problem. However, the
multi-step process still deviates from the unified optimization target.
Especially the second step of cluster is generally performed with conventional
methods such as k-Means. We propose a pure neural framework for text clustering
in an end-to-end manner. It jointly learns the text representation and the
clustering model. Our model works well when the context can be obtained, which
is nearly always the case in the field of NLP. We have our method
\mbox{evaluated} on two widely used benchmarks: IMDB movie reviews for
sentiment classification and $20$-Newsgroup for topic categorization. Despite
its simplicity, experiments show the model outperforms previous clustering
methods by a large margin. Furthermore, the model is also verified on English
wiki dataset as a large corpus."	ArXiv
2390	"Cyclical Annealing Schedule: A Simple Approach to Mitigating KL
  Vanishing"	['Hao Fu', 'Chunyuan Li', 'Xiaodong Liu', 'Jianfeng Gao', 'Asli Celikyilmaz', 'Lawrence Carin']	2019-03-25 06:28:24+00:00	http://arxiv.org/abs/1903.10145v3	"Variational autoencoders (VAEs) with an auto-regressive decoder have been
applied for many natural language processing (NLP) tasks. The VAE objective
consists of two terms, (i) reconstruction and (ii) KL regularization, balanced
by a weighting hyper-parameter \beta. One notorious training difficulty is that
the KL term tends to vanish. In this paper we study scheduling schemes for
\beta, and show that KL vanishing is caused by the lack of good latent codes in
training the decoder at the beginning of optimization. To remedy this, we
propose a cyclical annealing schedule, which repeats the process of increasing
\beta multiple times. This new procedure allows the progressive learning of
more meaningful latent codes, by leveraging the informative representations of
previous cycles as warm re-starts. The effectiveness of cyclical annealing is
validated on a broad range of NLP tasks, including language modeling, dialog
response generation and unsupervised language pre-training."	ArXiv
2391	SciBERT: A Pretrained Language Model for Scientific Text	['Iz Beltagy', 'Kyle Lo', 'Arman Cohan']	2019-03-26 05:11:46+00:00	http://arxiv.org/abs/1903.10676v3	"Obtaining large-scale annotated data for NLP tasks in the scientific domain
is challenging and expensive. We release SciBERT, a pretrained language model
based on BERT (Devlin et al., 2018) to address the lack of high-quality,
large-scale labeled scientific data. SciBERT leverages unsupervised pretraining
on a large multi-domain corpus of scientific publications to improve
performance on downstream scientific NLP tasks. We evaluate on a suite of tasks
including sequence tagging, sentence classification and dependency parsing,
with datasets from a variety of scientific domains. We demonstrate
statistically significant improvements over BERT and achieve new
state-of-the-art results on several of these tasks. The code and pretrained
models are available at https://github.com/allenai/scibert/."	ArXiv
2392	"A General FOFE-net Framework for Simple and Effective Question Answering
  over Knowledge Bases"	['Dekun Wu', 'Nana Nosirova', 'Hui Jiang', 'Mingbin Xu']	2019-03-29 05:15:58+00:00	http://arxiv.org/abs/1903.12356v1	"Question answering over knowledge base (KB-QA) has recently become a popular
research topic in NLP. One popular way to solve the KB-QA problem is to make
use of a pipeline of several NLP modules, including entity discovery and
linking (EDL) and relation detection. Recent success on KB-QA task usually
involves complex network structures with sophisticated heuristics. Inspired by
a previous work that builds a strong KB-QA baseline, we propose a simple but
general neural model composed of fixed-size ordinally forgetting encoding
(FOFE) and deep neural networks, called FOFE-net to solve KB-QA problem at
different stages. For evaluation, we use two popular KB-QA datasets,
SimpleQuestions and WebQSP, and a newly created dataset, FreebaseQA. The
experimental results show that FOFE-net performs well on KB-QA subtasks, entity
discovery and linking (EDL) and relation detection, and in turn pushing overall
KB-QA system to achieve strong results on all datasets."	ArXiv
2393	"A Robust Linguistic Platform for Efficient and Domain specific Web
  Content Analysis"	['Thierry Hamon', 'Adeline Nazarenko', 'Thierry Poibeau', 'Sophie Aubin', 'Julien Derivière']	2007-06-29 08:58:02+00:00	http://arxiv.org/abs/0706.4375v1	"Web semantic access in specific domains calls for specialized search engines
with enhanced semantic querying and indexing capacities, which pertain both to
information retrieval (IR) and to information extraction (IE). A rich
linguistic analysis is required either to identify the relevant semantic units
to index and weight them according to linguistic specific statistical
distribution, or as the basis of an information extraction process. Recent
developments make Natural Language Processing (NLP) techniques reliable enough
to process large collections of documents and to enrich them with semantic
annotations. This paper focuses on the design and the development of a text
processing platform, Ogmios, which has been developed in the ALVIS project. The
Ogmios platform exploits existing NLP modules and resources, which may be tuned
to specific domains and produces linguistically annotated documents. We show
how the three constraints of genericity, domain semantic awareness and
performance can be handled all together."	ArXiv
2394	"Navigating with Graph Representations for Fast and Scalable Decoding of
  Neural Language Models"	['Minjia Zhang', 'Xiaodong Liu', 'Wenhan Wang', 'Jianfeng Gao', 'Yuxiong He']	2018-06-11 18:57:49+00:00	http://arxiv.org/abs/1806.04189v1	"Neural language models (NLMs) have recently gained a renewed interest by
achieving state-of-the-art performance across many natural language processing
(NLP) tasks. However, NLMs are very computationally demanding largely due to
the computational cost of the softmax layer over a large vocabulary. We observe
that, in decoding of many NLP tasks, only the probabilities of the top-K
hypotheses need to be calculated preciously and K is often much smaller than
the vocabulary size. This paper proposes a novel softmax layer approximation
algorithm, called Fast Graph Decoder (FGD), which quickly identifies, for a
given context, a set of K words that are most likely to occur according to a
NLM. We demonstrate that FGD reduces the decoding time by an order of magnitude
while attaining close to the full softmax baseline accuracy on neural machine
translation and language modeling tasks. We also prove the theoretical
guarantee on the softmax approximation quality."	ArXiv
2395	"Approach for Semi-automatic Construction of Anti-infective Drug Ontology
  Based on Entity Linking"	['Ying Shen', 'Yang Deng', 'Kaiqi Yuan', 'Li Liu', 'Yong Liu']	2018-12-05 10:08:29+00:00	http://arxiv.org/abs/1812.01887v1	"Ontology can be used for the interpretation of natural language. To construct
an anti-infective drug ontology, one needs to design and deploy a
methodological step to carry out the entity discovery and linking. Medical
synonym resources have been an important part of medical natural language
processing (NLP). However, there are problems such as low precision and low
recall rate. In this study, an NLP approach is adopted to generate candidate
entities. Open ontology is analyzed to extract semantic relations. Six-word
vector features and word-level features are selected to perform the entity
linking. The extraction results of synonyms with a single feature and different
combinations of features are studied. Experiments show that our selected
features have achieved a precision rate of 86.77%, a recall rate of 89.03% and
an F1 score of 87.89%. This paper finally presents the structure of the
proposed ontology and its relevant statistical data."	ArXiv
2396	Towards a General-Purpose Linguistic Annotation Backend	['Graham Neubig', 'Patrick Littell', 'Chian-Yu Chen', 'Jean Lee', 'Zirui Li', 'Yu-Hsiang Lin', 'Yuyan Zhang']	2018-12-13 05:33:11+00:00	http://arxiv.org/abs/1812.05272v1	"Language documentation is inherently a time-intensive process; transcription,
glossing, and corpus management consume a significant portion of documentary
linguists' work. Advances in natural language processing can help to accelerate
this work, using the linguists' past decisions as training material, but
questions remain about how to prioritize human involvement. In this extended
abstract, we describe the beginnings of a new project that will attempt to ease
this language documentation process through the use of natural language
processing (NLP) technology. It is based on (1) methods to adapt NLP tools to
new languages, based on recent advances in massively multilingual neural
networks, and (2) backend APIs and interfaces that allow linguists to upload
their data. We then describe our current progress on two fronts: automatic
phoneme transcription, and glossing. Finally, we briefly describe our future
directions."	ArXiv
2397	Caveats in Generating Medical Imaging Labels from Radiology Reports	['Tobi Olatunji', 'Li Yao', 'Ben Covington', 'Alexander Rhodes', 'Anthony Upton']	2019-05-06 22:38:18+00:00	http://arxiv.org/abs/1905.02283v1	"Acquiring high-quality annotations in medical imaging is usually a costly
process. Automatic label extraction with natural language processing (NLP) has
emerged as a promising workaround to bypass the need of expert annotation.
Despite the convenience, the limitation of such an approximation has not been
carefully examined and is not well understood. With a challenging set of 1,000
chest X-ray studies and their corresponding radiology reports, we show that
there exists a surprisingly large discrepancy between what radiologists
visually perceive and what they clinically report. Furthermore, with inherently
flawed report as ground truth, the state-of-the-art medical NLP fails to
produce high-fidelity labels."	ArXiv
2398	"What do you learn from context? Probing for sentence structure in
  contextualized word representations"	['Ian Tenney', 'Patrick Xia', 'Berlin Chen', 'Alex Wang', 'Adam Poliak', 'R Thomas McCoy', 'Najoung Kim', 'Benjamin Van Durme', 'Samuel R. Bowman', 'Dipanjan Das', 'Ellie Pavlick']	2019-05-15 17:48:56+00:00	http://arxiv.org/abs/1905.06316v1	"Contextualized representation models such as ELMo (Peters et al., 2018a) and
BERT (Devlin et al., 2018) have recently achieved state-of-the-art results on a
diverse array of downstream NLP tasks. Building on recent token-level probing
work, we introduce a novel edge probing task design and construct a broad suite
of sub-sentence tasks derived from the traditional structured NLP pipeline. We
probe word-level contextual representations from four recent models and
investigate how they encode sentence structure across a range of syntactic,
semantic, local, and long-range phenomena. We find that existing models trained
on language modeling and translation produce strong representations for
syntactic phenomena, but only offer comparably small improvements on semantic
tasks over a non-contextual baseline."	ArXiv
2399	ERNIE: Enhanced Language Representation with Informative Entities	['Zhengyan Zhang', 'Xu Han', 'Zhiyuan Liu', 'Xin Jiang', 'Maosong Sun', 'Qun Liu']	2019-05-17 06:24:16+00:00	http://arxiv.org/abs/1905.07129v3	"Neural language representation models such as BERT pre-trained on large-scale
corpora can well capture rich semantic patterns from plain text, and be
fine-tuned to consistently improve the performance of various NLP tasks.
However, the existing pre-trained language models rarely consider incorporating
knowledge graphs (KGs), which can provide rich structured knowledge facts for
better language understanding. We argue that informative entities in KGs can
enhance language representation with external knowledge. In this paper, we
utilize both large-scale textual corpora and KGs to train an enhanced language
representation model (ERNIE), which can take full advantage of lexical,
syntactic, and knowledge information simultaneously. The experimental results
have demonstrated that ERNIE achieves significant improvements on various
knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art
model BERT on other common NLP tasks. The source code of this paper can be
obtained from https://github.com/thunlp/ERNIE."	ArXiv
2400	"Enriching Pre-trained Language Model with Entity Information for
  Relation Classification"	['Shanchan Wu', 'Yifan He']	2019-05-20 18:22:18+00:00	http://arxiv.org/abs/1905.08284v1	"Relation classification is an important NLP task to extract relations between
entities. The state-of-the-art methods for relation classification are
primarily based on Convolutional or Recurrent Neural Networks. Recently, the
pre-trained BERT model achieves very successful results in many NLP
classification / sequence labeling tasks. Relation classification differs from
those tasks in that it relies on information of both the sentence and the two
target entities. In this paper, we propose a model that both leverages the
pre-trained BERT language model and incorporates information from the target
entities to tackle the relation classification task. We locate the target
entities and transfer the information through the pre-trained architecture and
incorporate the corresponding encoding of the two entities. We achieve
significant improvement over the state-of-the-art method on the SemEval-2010
task 8 relational dataset."	ArXiv
2401	DSReg: Using Distant Supervision as a Regularizer	['Yuxian Meng', 'Muyu Li', 'Xiaoya Li', 'Wei Wu', 'Jiwei Li']	2019-05-28 07:46:50+00:00	http://arxiv.org/abs/1905.11658v3	"In this paper, we aim at tackling a general issue in NLP tasks where some of
the negative examples are highly similar to the positive examples, i.e.,
hard-negative examples. We propose the distant supervision as a regularizer
(DSReg) approach to tackle this issue. The original task is converted to a
multi-task learning problem, in which distant supervision is used to retrieve
hard-negative examples. The obtained hard-negative examples are then used as a
regularizer. The original target objective of distinguishing positive examples
from negative examples is jointly optimized with the auxiliary task objective
of distinguishing softened positive (i.e., hard-negative examples plus positive
examples) from easy-negative examples. In the neural context, this can be done
by outputting the same representation from the last neural layer to different
$softmax$ functions. Using this strategy, we can improve the performance of
baseline models in a range of different NLP tasks, including text
classification, sequence labeling and reading comprehension."	ArXiv
2402	"CGPOPS: A C++ Software for Solving Multiple-Phase Optimal Control
  Problems Using Adaptive Gaussian Quadrature Collocation and Sparse Nonlinear
  Programming"	['Yunus M. Agamawi', 'Anil V. Rao']	2019-05-28 15:50:10+00:00	http://arxiv.org/abs/1905.11898v2	"A general-purpose C++ software program called $\mathbb{CGPOPS}$ is described
for solving multiple-phase optimal control problems using adaptive Gaussian
quadrature collocation. The software employs a Legendre-Gauss-Radau direct
orthogonal collocation method to transcribe the continuous-time optimal control
problem into a large sparse nonlinear programming problem. A class of $hp$ mesh
refinement methods are implemented which determine the number of mesh intervals
and the degree of the approximating polynomial within each mesh interval to
achieve a specified accuracy tolerance. The software is interfaced with the
open source Newton NLP solver IPOPT. All derivatives required by the NLP solver
are computed using either central finite differencing, bicomplex-step
derivative approximation, hyper-dual derivative approximation, or automatic
differentiation. The key components of the software are described in detail and
the utility of the software is demonstrated on five optimal control problems of
varying complexity. The software described in this article provides a
computationally efficient and accurate approach for solving a wide variety of
complex constrained optimal control problems."	ArXiv
2403	Identification of primary and collateral tracks in stuttered speech	['Rachid Riad', 'Anne-Catherine Bachoud-Lévi', 'Frank Rudzicz', 'Emmanuel Dupoux']	2020-03-02 16:50:33+00:00	http://arxiv.org/abs/2003.01018v1	"Disfluent speech has been previously addressed from two main perspectives:
the clinical perspective focusing on diagnostic, and the Natural Language
Processing (NLP) perspective aiming at modeling these events and detect them
for downstream tasks. In addition, previous works often used different metrics
depending on whether the input features are text or speech, making it difficult
to compare the different contributions. Here, we introduce a new evaluation
framework for disfluency detection inspired by the clinical and NLP perspective
together with the theory of performance from \cite{clark1996using} which
distinguishes between primary and collateral tracks. We introduce a novel
forced-aligned disfluency dataset from a corpus of semi-directed interviews,
and present baseline results directly comparing the performance of text-based
features (word and span information) and speech-based (acoustic-prosodic
information). Finally, we introduce new audio features inspired by the
word-based span features. We show experimentally that using these features
outperformed the baselines for speech-based predictions on the present dataset."	ArXiv
2404	"Kleister: A novel task for Information Extraction involving Long
  Documents with Complex Layout"	['Filip Graliński', 'Tomasz Stanisławek', 'Anna Wróblewska', 'Dawid Lipiński', 'Agnieszka Kaliska', 'Paulina Rosalska', 'Bartosz Topolski', 'Przemysław Biecek']	2020-03-04 22:45:22+00:00	http://arxiv.org/abs/2003.02356v2	"State-of-the-art solutions for Natural Language Processing (NLP) are able to
capture a broad range of contexts, like the sentence-level context or
document-level context for short documents. But these solutions are still
struggling when it comes to longer, real-world documents with the information
encoded in the spatial structure of the document, such as page elements like
tables, forms, headers, openings or footers; complex page layout or presence of
multiple pages.
  To encourage progress on deeper and more complex Information Extraction (IE)
we introduce a new task (named Kleister) with two new datasets. Utilizing both
textual and structural layout features, an NLP system must find the most
important information, about various types of entities, in long formal
documents. We propose Pipeline method as a text-only baseline with different
Named Entity Recognition architectures (Flair, BERT, RoBERTa). Moreover, we
checked the most popular PDF processing tools for text extraction (pdf2djvu,
Tesseract and Textract) in order to analyze behavior of IE system in presence
of errors introduced by these tools."	ArXiv
2405	NYTWIT: A Dataset of Novel Words in the New York Times	['Yuval Pinter', 'Cassandra L. Jacobs', 'Max Bittker']	2020-03-06 21:19:44+00:00	http://arxiv.org/abs/2003.03444v3	"We present the New York Times Word Innovation Types dataset, or NYTWIT, a
collection of over 2,500 novel English words published in the New York Times
between November 2017 and March 2019, manually annotated for their class of
novelty (such as lexical derivation, dialectal variation, blending, or
compounding). We present baseline results for both uncontextual and contextual
prediction of novelty class, showing that there is room for improvement even
for state-of-the-art NLP systems. We hope this resource will prove useful for
linguists and NLP practitioners by providing a real-world environment of novel
word appearance."	ArXiv
2406	On the Convergence of the Dynamic Inner PCA Algorithm	['Sungho Shin', 'Alex D. Smith', 'S. Joe Qin', 'Victor M. Zavala']	2020-03-12 17:50:34+00:00	http://arxiv.org/abs/2003.05928v1	"Dynamic inner principal component analysis (DiPCA) is a powerful method for
the analysis of time-dependent multivariate data. DiPCA extracts dynamic latent
variables that capture the most dominant temporal trends by solving a
large-scale, dense, and nonconvex nonlinear program (NLP). A scalable
decomposition algorithm has been recently proposed in the literature to solve
these challenging NLPs. The decomposition algorithm performs well in practice
but its convergence properties are not well understood. In this work, we show
that this algorithm is a specialized variant of a coordinate maximization
algorithm. This observation allows us to explain why the decomposition
algorithm might work (or not) in practice and can guide improvements. We
compare the performance of the decomposition strategies with that of the
off-the-shelf solver Ipopt. The results show that decomposition is more
scalable and, surprisingly, delivers higher quality solutions."	ArXiv
2407	Automated Service Discovery for Social Internet-of-Things Systems	['Abdullah Khanfor', 'Hakim Ghazzai', 'Ye Yang', 'Mohammad Rafiqul Haider', 'Yehia Massoud']	2020-03-21 20:57:42+00:00	http://arxiv.org/abs/2003.11524v1	"In this paper, we propose to design an automated service discovery process to
allow mobile crowdsourcing task requesters select a small set of devices out of
a large-scale Internet-of-things (IoT) network to execute their tasks. To this
end, we proceed by dividing the large-scale IoT network into several virtual
communities whose members share strong social IoT relations. Two community
detection algorithms, namely Louvain and order statistics local method (OSLOM)
algorithms, are investigated and applied to a real-world IoT dataset to form
non-overlapping and overlapping IoT devices groups. Afterwards, a natural
language process (NLP)-based approach is executed to handle crowdsourcing
textual requests and accordingly find the list of IoT devices capable of
effectively accomplishing the tasks. This is performed by matching the NLP
outputs, e.g., type of application, location, required trustworthiness level,
with the different detected communities. The proposed approach effectively
helps in automating and reducing the service discovery procedure and
recruitment process for mobile crowdsourcing applications."	ArXiv
2408	QRMine: A python package for triangulation in Grounded Theory	['Bell Raj Eapen', 'Norm Archer', 'Kamran Sartipi']	2020-03-30 14:45:51+00:00	http://arxiv.org/abs/2003.13519v1	"Grounded theory (GT) is a qualitative research method for building theory
grounded in data. GT uses textual and numeric data and follows various stages
of coding or tagging data for sense-making, such as open coding and selective
coding. Machine Learning (ML) techniques, including natural language processing
(NLP), can assist the researchers in the coding process. Triangulation is the
process of combining various types of data. ML can facilitate deriving insights
from numerical data for corroborating findings from the textual interview
transcripts. We present an open-source python package (QRMine) that
encapsulates various ML and NLP libraries to support coding and triangulation
in GT. QRMine enables researchers to use these methods on their data with
minimal effort. Researchers can install QRMine from the python package index
(PyPI) and can contribute to its development. We believe that the concept of
computational triangulation will make GT relevant in the realm of big data."	ArXiv
2409	"Nonconvex Consensus ADMM for Cooperative Lane Change Maneuvers of
  Connected Automated Vehicles"	['Alexander Katriniok']	2020-03-31 13:36:30+00:00	http://arxiv.org/abs/2003.14199v2	"Connected and automated vehicles (CAVs) offer huge potential to improve the
performance of automated vehicles (AVs) without communication capabilities,
especially in situations when the vehicles (or agents) need to be cooperative
to accomplish their maneuver. Lane change maneuvers in dense traffic, e.g., are
very challenging for non-connected AVs. To alleviate this problem, we propose a
holistic distributed lane change control scheme for CAVs which relies on
vehicle-to-vehicle communication. The originally centralized optimal control
problem is embedded into a consensus-based Alternating Direction Method of
Multipliers framework to solve it in a distributed receding horizon fashion.
Although agent dynamics render the underlying optimal control problem
nonconvex, we propose a problem reformulation that allows to derive convergence
guarantees. In the distributed setting, every agent needs to solve a nonlinear
program (NLP) locally. To obtain a real-time solution of the local NLPs, we
utilize the optimization engine OpEn which implements the proximal averaged
Newton method for optimal control (PANOC). Simulation results prove the
efficacy and real-time capability of our approach."	ArXiv
