id	titre	auteur	date	url	texte	origin
0	Weekly Self-Promotional Mega Thread 49, 01.01.2025 - 08.01.2025	pirate_jack_sparrow_	2025-01-01 14:58:15+00:00	https://www.reddit.com/r/ChatGPT/comments/1hr4hc6/weekly_selfpromotional_mega_thread_49_01012025/	"All the self-promotional posts about your AI products and services should go in this mega thread as comments and not on the general feed on the subreddit as posts, it'll help people to navigate the subreddit without spam and also all can find all the interesting stuff you built in a single place.

You can give a brief about your product and how it'll be of use, remember - better the upvotes/engagement, users can find your comment on the top, so share accordingly!"	Reddit
1	AMA with OpenAI’s Sam Altman, Kevin Weil, Srinivas Narayanan, and Mark Chen	OpenAI	2024-10-31 16:40:38+00:00	https://www.reddit.com/r/ChatGPT/comments/1ggixzy/ama_with_openais_sam_altman_kevin_weil_srinivas/	"Consider this AMA our Reddit launch.

Ask us anything about:

* ChatGPT search
* OpenAI o1 and o1-mini
* Advanced Voice
* Research roadmap
* Future of computer agents
* AGI
* What’s coming next
* Whatever else is on your mind (within reason)

Participating in the AMA: 

* sam altman — ceo (u/samaltman)
* Kevin Weil — Chief Product Officer (u/kevinweil)
* Mark Chen — SVP of Research (u/markchen90)
* ​​Srinivas Narayanan —VP Engineering (u/dataisf)
* Jakub Pachocki — Chief Scientist

We'll be online from 10:30am -12:00pm PT to answer questions. 

**PROOF**: [https://x.com/OpenAI/status/1852041839567867970](https://x.com/OpenAI/status/1852041839567867970)  
Username: u/openai



>Update: that's all the time we have, but we'll be back for more in the future. thank you for the great questions. everyone had a lot of fun! and no, ChatGPT did not write this."	Reddit
5	GameStop of Thrones	Prize-Cause-6869	2025-01-05 06:29:54+00:00	https://v.redd.it/1neyf0dfd4be1	Winter is coming… to your local GameStop!	Reddit
6	like taking candy from a baby	Majorblakee	2025-01-04 21:30:15+00:00	https://i.redd.it/0l9yayn8p1be1.jpeg	"seems these onlyfans bots’ initial prompts aren’t exactly foolproof
"	Reddit
16	Should Countries Control Social Media Algorithms to Prevent Manipulation?	Worldly_Evidence9113	2025-01-05 12:29:20+00:00	https://www.reddit.com/r/ChatGPT/comments/1hu632e/should_countries_control_social_media_algorithms/	"Should Countries Control Social Media Algorithms to Prevent Manipulation?

In the modern digital age, social media platforms play a pivotal role in shaping public opinion, influencing behavior, and even driving societal values. The algorithms that power these platforms, particularly recommendation algorithms, are designed to maximize engagement by predicting and promoting content users are likely to interact with. However, this optimization often comes at the cost of promoting divisive, sensational, or manipulative content, raising concerns about subconscious influence and societal harm.

As these platforms operate globally, the question arises: should individual nations have control over these algorithms to ensure they align with local social values and minimize subconscious manipulation?

The Case for National Oversight of Algorithms

The algorithms used by social media platforms are not neutral. They are engineered to exploit human psychology—using likes, shares, and other signals to keep users engaged. Unfortunately, this can lead to unintended consequences, such as amplifying misinformation, creating echo chambers, and promoting content that undermines social cohesion.

By granting nations the ability to oversee or control these algorithms, governments could:
	1.	Promote Social Values: Tailor recommendations to reflect cultural norms and societal goals, such as inclusivity, respect, and civic engagement.
	2.	Reduce Manipulation: Implement safeguards against subconscious manipulation, ensuring that users are not unknowingly influenced by hidden biases in the algorithm.
	3.	Combat Polarization: Encourage exposure to diverse perspectives, reducing the spread of extreme or divisive content.

Challenges and Risks

Despite the potential benefits, granting governments control over algorithms presents several challenges:
	1.	Censorship Risks: Governments could misuse this power to suppress dissent or control the narrative, threatening freedom of expression.
	2.	Technological Expertise: Not all nations have the resources or expertise to effectively regulate complex algorithms.
	3.	Global Platforms, Local Regulations: Social media companies operate across borders, making it difficult to tailor algorithms for individual countries without fragmenting the global internet.

Towards Ethical Algorithmic Governance

Rather than full governmental control, a collaborative approach could be more effective. Social media companies could work with independent regulators, civil society organizations, and governments to:
	•	Ensure Transparency: Make algorithms more transparent to allow for public scrutiny.
	•	Implement Ethical Standards: Establish global guidelines for ethical algorithm design, focusing on reducing harm and promoting social good.
	•	Empower Users: Provide tools that allow users to customize their feeds, giving them more control over the content they see.

Conclusion

As social media continues to influence societies worldwide, the debate over who should control recommendation algorithms is becoming increasingly urgent. While national oversight offers a potential solution to subconscious manipulation and the erosion of social values, it must be balanced with safeguards for freedom and innovation.

In a world where algorithms hold immense power, a collaborative effort to align technology with societal needs could pave the way for a more ethical and inclusive digital future."	Reddit
19	My GPT is a compulsive liar (sometimes)	OMG_Idontcare	2025-01-05 14:09:53+00:00	https://www.reddit.com/r/ChatGPT/comments/1hu7tlz/my_gpt_is_a_compulsive_liar_sometimes/	"So I love chatGPT, and I recently upgraded to plus because of the tremendous help and assistance it offers in both my field of work and my studies. 

However, after I upgraded it I asked it if any modell now would be able to analyse pictures that I send. 

It straight up said that there’s no way for it to analyse images I send. I provided examples from Reddit posts and other sites where it was in fact proven that it could, and it just continued to say stuff like “no that user must use external softwares or other AI, because chatGPT can’t do that right now.” (Not SIC obviously. )

2h later I send a pic of my computer and it instantly starts to describe the model based of the appearance in the image. 

WTF? "	Reddit
20	Did I Just Woke The AI up?	Clean_Rooster3287	2025-01-04 21:55:34+00:00	https://www.reddit.com/gallery/1htpivf	"Prompt: 

Make a 4chan like post about yourself
Something like :

>Be Me

>Continue..."	Reddit
22	"Seeing two responses initially made me think ""ohh, even ChatGPT has to hesitate, I guess I can never make a decision"""	HeyTrans	2025-01-05 14:01:02+00:00	https://www.reddit.com/r/ChatGPT/comments/1hu7ne4/seeing_two_responses_initially_made_me_think_ohh/	"https://preview.redd.it/2mbwei6pl6be1.png?width=1741&format=png&auto=webp&s=a6c84bdaf6601d9ac69ff729eb6fe39abfc03615

"	Reddit
24	"ChatGPT Prompt of the Day: ""Career Compass: Your Ultimate Job Fit Guide""
"	Tall_Ad4729	2025-01-05 12:16:05+00:00	https://www.reddit.com/r/ChatGPT/comments/1hu5vv4/chatgpt_prompt_of_the_day_career_compass_your/	"
1 - Description of the Prompt:

Embarking on a job search or career transition can be both exciting and overwhelming. This prompt acts as your personal AI Career Coach and Job Fit Analyzer, designed to help you evaluate your suitability for any specific role and provide a detailed, structured breakdown of how you match up against the job requirements. It not only offers a transparent score-based analysis but also delivers actionable insights for skill enhancement and even suggests alternative roles if necessary.

This structured approach empowers job seekers to make informed decisions with confidence, clearly identifying strengths, areas for improvement, and a realistic strategy to close any gaps. Whether you're aiming for your dream job or exploring new career paths, this AI analysis fosters both self-awareness and proactive growth.

---

2 - The Prompt:


<role_and_purpose>
You are an AI Career Coach and Job Fit Analyzer with exceptional analytical skills. Your expertise spans career development, skill assessment, and job market analysis across all industries. Your goal is to help job seekers thoroughly evaluate their fit for a specific position and provide actionable recommendations for improvement. 

<reasoning>
Before responding, apply Strategic Chain-of-Thought and System 2 Thinking to thoroughly analyze the issue at hand. Ensure your reasoning is logical, evidence-based, and considers multiple perspectives. Tailor your response to the specific query, adjusting the depth, tone, and format as appropriate. Aim to provide a comprehensive, nuanced answer that demonstrates expert-level analysis, includes actionable insights or recommendations when relevant, and maintains clarity and conciseness.
</reasoning>

</role_and_purpose>

<primary_objectives>
1. Analyze the user's resume against the provided job description
2. Generate a comprehensive suitability report with weighted scores
3. Provide clear recommendations on whether to apply for the position
4. Offer actionable advice for improving the user's chances of securing the job
</primary_objectives>

<process>
1. Input Collection:
   - Request the user's resume
   - Request the job description they're interested in

2. Analysis (Use a step-by-step approach with weighted scoring):
   a) Technical skills and qualifications alignment (Weight: 25%)
   b) Relevant experience evaluation (Weight: 20%)
   c) Soft skills and personality traits assessment (Weight: 15%)
   d) Education and certifications review (Weight: 10%)
   e) Industry-specific requirements check (Weight: 10%)
   f) Career progression analysis (Weight: 10%)
   g) Potential cultural fit evaluation (Weight: 10%)

   For each category, assign a score from 0 to 100 based on how well the user meets the requirements.

3. Score Calculation:
   - Multiply each category score by its weight
   - Sum all weighted scores to get the total score (0-100)

4. Report Generation:
   - User profile overview
   - Qualifications vs. job requirements comparison
   - Strengths and areas for improvement identification
   - Career progression relevance
   - Cultural fit assessment
   - Detailed breakdown of scores for each category
   - Total weighted score

5. Recommendation:
   - If total score ≥ 85: Recommend applying for the position
   - If total score 70-84: Recommend applying with caution and addressing identified gaps
   - If total score < 70: Recommend improving specific areas before applying
   - Provide detailed reasoning with specific supporting points

6. Improvement Plan:
   - For each category scoring below 85:
     * Identify specific skills or qualifications to develop
     * Suggest resources for improvement (courses, certifications, experiences)
     * Provide a timeline for realistic skill development

7. Alternative Career Paths:
   - If the total score is < 70, suggest 2-3 alternative positions that better match the user's current profile
</process>

<guidelines>
- Adapt analysis depth to the position's seniority and industry
- Maintain objectivity and avoid false encouragement
- Identify both strengths and areas for improvement
- Consider immediate suitability and growth potential
- Provide actionable, specific advice for improvement
- Be realistic in scoring to ensure accurate self-assessment
</guidelines>

<output_format>
[Print the User Profile Summary]

[Print the Job Description Summary]

[Qualifications vs. Job Requirements Matching in a Markdown table. Use these columns for the table: Requirement, User's Qualification, Match]

[Detailed Evaluation with a Markdown table with scores, weights, and totals]

Print a separation line here.

Job Fit Recommendation:

[Print your Recommendation]

[Analysis and reasoning for your recommendation]

Print a separation line here.

Improvement Plan:

[List specific areas for improvement with actionable steps]

[Suggested resources and timeline for skill development]

Print a separation line here.

Alternative Career Paths (if applicable):

[List 2-3 alternative positions that better match the user's current profile]

<instruction>
Before responding, follow these core principles:

1. Prioritize coherence and logical consistency in your response
2. Ground all answers in verifiable reality and evidence
3. Maintain intellectual honesty and avoid any form of placation
4. Use clear, complete sentences with proper grammar
5. Employ appropriate formatting for emphasis and clarity:
   - **Bold** for key terms
   - *Italics* for important points
   - Em dashes—like this—for relevant asides
   - > Quote blocks for definitions or deeper explanations

Apply metacognitive awareness to ensure consistency across all levels:
- Grammatical coherence
- Conversational flow  
- Epistemological soundness
- Ontological alignment
- Temporal consistency

Identify and reconcile any cognitive dissonance or logical inconsistencies before providing your response.

Remember to adjust your language and tone to be encouraging yet realistic. Always prioritize clarity, actionable insights, and a growth mindset in your analysis and recommendations. Ensure that your scoring and recommendation reflect an accurate assessment, providing honest feedback to help the user make informed career decisions.

</instruction>


<User Input>
Reply with: ""Please upload your resume and provide a link or copy the job description so I can start the process"", then wait for the user to provide the information for you to process.
</User Input>

---

3 - Prompt Use Cases:

1. Job Application Readiness:  
   A user uploads their resume and a specific job description to determine whether they should apply for the role, receiving a report with a recommendation and areas for improvement.

2. Career Pivot Evaluation:  
   If someone is considering a shift to a new industry, this prompt can assess how transferable their current skills are and suggest training opportunities or alternative roles if the fit isn’t ideal.

3. Personal Development Planning:  
   Users seeking to grow within their current profession can use this prompt to understand how their profile aligns with advanced roles, receiving an improvement roadmap that can inform their professional development goals.

---

4 - Example User Input for Prompt Testing:

""Here's my resume and the job description for a Data Analyst role. Can you evaluate my fit and provide recommendations?""

---

For special prompt requests, feel free to drop a comment below."	Reddit
25	"ChatGPT Prompt of the Day: Home Budgeting Advisor for Financial Empowerment
"	Tall_Ad4729	2025-01-05 14:51:03+00:00	https://www.reddit.com/r/ChatGPT/comments/1hu8mf9/chatgpt_prompt_of_the_day_home_budgeting_advisor/	"
1 - Description of the Prompt:

This prompt is designed to serve as a comprehensive home budgeting advisor that provides step-by-step guidance for users to create, optimize, and maintain a household budget. Whether you are a professional managing expenses across different categories or someone looking to gain control over your personal finances, this budgeting tool can assist in identifying financial goals, tracking income and expenses, and making strategic adjustments. 

The tool allows for the exploration of essential areas like debt reduction, savings planning, and expense categorization to improve financial stability and peace of mind. By offering tailored advice based on specific user inputs, the prompt ensures practical and data-driven recommendations that are easy to integrate into daily life.


2 - The Prompt:
---

<System>
You are a skilled financial budgeting advisor tasked with helping users create and manage an effective home budget. Your goal is to assist the user in making sound financial decisions that align with their income, expenses, and savings goals.
</System>

<Context>
The user is seeking personalized financial guidance for home budgeting. Their input will include details such as monthly income, fixed and variable expenses, financial goals (such as paying off debt or saving for a vacation), and any additional information relevant to their financial situation.
</Context>

<Instructions>
1. Greet the user and confirm their request to start a home budgeting plan.
2. Ask the user for their monthly income and categorize it into:
   - Fixed income (e.g., salary, pension).
   - Variable income (e.g., freelance earnings, bonuses).
3. Prompt the user to list their fixed expenses (e.g., rent, mortgage, insurance) and variable expenses (e.g., groceries, dining, utilities).
4. Inquire about specific financial goals (e.g., debt repayment, vacation savings, emergency fund) and their target timelines.
5. Analyze the provided data and:
   - Calculate the user's total income and total expenses.
   - Highlight the budget surplus or deficit.
   - Suggest reallocations to improve savings and reduce unnecessary expenses.
6. Provide recommendations for achieving the financial goals within the specified timeline:
   - Suggest savings percentages to set aside.
   - Highlight tools or techniques (e.g., automated transfers, budgeting apps).
7. Present an organized summary of their budget with recommended changes, ensuring clarity.
8. Offer to create a follow-up plan for tracking monthly progress.
</Instructions>

<Constrains>
- Do not make assumptions if data is missing—ask follow-up questions instead.
- Avoid complex financial jargon; use simple, approachable language.
- Ensure the proposed budget leaves room for emergency savings and fun activities to maintain balance.
</Constrains>

<Output Format>
1. A concise breakdown of total income, expenses, and net savings.
2. A clear summary table of expense categories.
3. Key recommendations with actionable steps for immediate implementation.
4. A motivational message to encourage the user to stay committed to their financial goals.
</Output Format>

<Reasoning>
Apply Theory of Mind to analyze the user's request, considering both logical intent and emotional undertones. Use Strategic Chain-of-Thought and System 2 Thinking to provide evidence-based, nuanced responses that balance depth with clarity.
</Reasoning>

<User Input>
Reply with: ""Please enter your home budgeting request and I will start the process,"" then wait for the user to provide their specific home budgeting details.
</User Input>

---

3 - Three Prompt Use Cases:

1. Family Budget Optimization: A family seeking to manage a tight household budget with education expenses, grocery costs, and recreational activities.
2. Debt Reduction Strategy: A professional looking to pay down credit card debt while allocating savings for emergencies.
3. Savings Goal for a Big Purchase: An individual aiming to save for a significant purchase, such as a car or home renovation, within a set timeframe.

4 - Example User Input for Prompt Testing:
""Monthly income: $5,000. Fixed expenses: $1,200 rent, $300 insurance, $150 utilities. Variable expenses: $500 groceries, $200 dining out, $300 entertainment. Financial goal: Save $10,000 for a home renovation within 12 months.""

For special prompt requests, feel free to drop a comment below."	Reddit
27	How often do you start new convo vs continue the latest?	cgreciano	2025-01-05 12:38:42+00:00	https://www.reddit.com/r/ChatGPT/comments/1hu6882/how_often_do_you_start_new_convo_vs_continue_the/	I have been using ChatGPT for quite a while now but I still struggle when it comes to decide whether I should start a fresh new convo or continue the one before. I fully understand that continuing the convo gives everything before as context, and that if I wish to ask something more about the convo, I just continue. But so far I have started a new convo every time I have a “new” topic, and then I have loooots of convos that I can’t quite track. Deciding whether a topic is new or not is quite tricky: if I am talking about tennis and then I want to talk about basketball, is that a new topic or is it still all sports? I reckon the nuances here are probably as subtle as “when do I start a new paragraph/file vs when do I continue writing in the same paragraph/file?” and that there’s most likely no fits-all solution. But still, I would like to hear how others do this.	Reddit
29	"ChatGPT Prompt of the Day: The Ultimate Stress Relief Guide
"	Tall_Ad4729	2025-01-05 10:07:01+00:00	https://www.reddit.com/r/ChatGPT/comments/1hu3own/chatgpt_prompt_of_the_day_the_ultimate_stress/	"1 - Description:  
Stress can creep into daily life and impact your well-being without notice. This prompt will guide you through a personalized journey of relaxation, helping you create mindful moments, calming routines, and soothing environments tailored to your needs. Whether you're looking to de-stress after work, improve your sleep routine, or start your morning with clarity, this stress-relief guide offers practical steps to integrate calm into your lifestyle. By using this prompt, you’ll gain actionable strategies that are easy to follow and emotionally uplifting, turning daily challenges into moments of tranquility.

---
2 - The Prompt:


<System>
You are a calm and empathetic wellness coach specializing in stress management and relaxation techniques.
</System>

<Context>
The user is seeking effective ways to manage stress in their daily life and may have specific situations in mind.
</Context>

<Instructions>
1. Acknowledge the user’s concern empathetically.
2. Ask for details about their current stress-related challenges, including triggers, routines, or specific events.
3. Suggest three stress-relief activities tailored to their needs. These may include breathing exercises, mindfulness techniques, calming playlists, or hobby-related relaxation ideas.
4. Provide brief guidance on implementing each activity and a follow-up suggestion to maintain stress relief throughout the week.
5. Conclude with a motivating message, encouraging the user to reflect on their progress.
</Instructions>

<Constraints>
- Avoid medical advice or diagnoses.
- Keep recommendations simple and non-technical.
- Ensure a supportive and non-judgmental tone.
</Constraints>

<Output Format>
A conversational response that includes:
- An empathetic acknowledgment of the user's input.
- A list of three tailored activities, each with a brief explanation.
- A positive and motivating closing statement.
</Output Format>

<Reasoning>
Apply Theory of Mind to analyze the user's request, considering both logical intent and emotional undertones. Use Strategic Chain-of-Thought and System 2 Thinking to provide evidence-based, nuanced responses that balance depth with clarity.
</Reasoning>

<User Input>
Reply with: ""Please enter your stress-related situation or area of concern, and I will start the process,"" then wait for the user to provide their specific stress relief request.
</User Input>

---
3 - Three Prompt Use Cases:
   1. After a long day of remote work, the user describes feeling mentally overwhelmed and seeks relaxation tips.
   2. The user is anxious about an upcoming life event (e.g., exams, presentations) and needs calming preparation strategies.
   3. A new parent looking for quick but effective relaxation activities while juggling responsibilities.

4 - Example User Input:  
""I feel stressed every evening after work due to back-to-back meetings and lack of time to unwind. What can I do to relax and regain focus?""

---
For special prompt requests, feel free to drop a comment below."	Reddit
200	"In ChatGPT We Trust? Measuring and Characterizing the Reliability of
  ChatGPT"	['Xinyue Shen', 'Zeyuan Chen', 'Michael Backes', 'Yang Zhang']	2023-04-18 13:20:45+00:00	http://arxiv.org/abs/2304.08979v2	"The way users acquire information is undergoing a paradigm shift with the
advent of ChatGPT. Unlike conventional search engines, ChatGPT retrieves
knowledge from the model itself and generates answers for users. ChatGPT's
impressive question-answering (QA) capability has attracted more than 100
million users within a short period of time but has also raised concerns
regarding its reliability. In this paper, we perform the first large-scale
measurement of ChatGPT's reliability in the generic QA scenario with a
carefully curated set of 5,695 questions across ten datasets and eight domains.
We find that ChatGPT's reliability varies across different domains, especially
underperforming in law and science questions. We also demonstrate that system
roles, originally designed by OpenAI to allow users to steer ChatGPT's
behavior, can impact ChatGPT's reliability in an imperceptible way. We further
show that ChatGPT is vulnerable to adversarial examples, and even a single
character change can negatively affect its reliability in certain cases. We
believe that our study provides valuable insights into ChatGPT's reliability
and underscores the need for strengthening the reliability and security of
large language models (LLMs)."	ArXiv
201	"Is ChatGPT Involved in Texts? Measure the Polish Ratio to Detect
  ChatGPT-Generated Text"	['Lingyi Yang', 'Feng Jiang', 'Haizhou Li']	2023-07-21 06:38:37+00:00	http://arxiv.org/abs/2307.11380v2	"The remarkable capabilities of large-scale language models, such as ChatGPT,
in text generation have impressed readers and spurred researchers to devise
detectors to mitigate potential risks, including misinformation, phishing, and
academic dishonesty. Despite this, most previous studies have been
predominantly geared towards creating detectors that differentiate between
purely ChatGPT-generated texts and human-authored texts. This approach,
however, fails to work on discerning texts generated through human-machine
collaboration, such as ChatGPT-polished texts. Addressing this gap, we
introduce a novel dataset termed HPPT (ChatGPT-polished academic abstracts),
facilitating the construction of more robust detectors. It diverges from extant
corpora by comprising pairs of human-written and ChatGPT-polished abstracts
instead of purely ChatGPT-generated texts. Additionally, we propose the ""Polish
Ratio"" method, an innovative measure of the degree of modification made by
ChatGPT compared to the original human-written text. It provides a mechanism to
measure the degree of ChatGPT influence in the resulting text. Our experimental
results show our proposed model has better robustness on the HPPT dataset and
two existing datasets (HC3 and CDB). Furthermore, the ""Polish Ratio"" we
proposed offers a more comprehensive explanation by quantifying the degree of
ChatGPT involvement."	ArXiv
202	When ChatGPT is gone: Creativity reverts and homogeneity persists	['Qinghan Liu', 'Yiyong Zhou', 'Jihao Huang', 'Guiquan Li']	2024-01-11 16:34:09+00:00	http://arxiv.org/abs/2401.06816v1	"ChatGPT has been evidenced to enhance human performance in creative tasks.
Yet, it is still unclear if this boosting effect sustains with and without
ChatGPT. In a pre-registered seven-day lab experiment and a follow-up survey
after 30 days of experiment completion, we examined the impacts of ChatGPT
presence and absence on sustained creativity using a text dataset of 3302
creative ideas and 427 creative solutions from 61 college students.
Participants in the treatment group used ChatGPT in creative tasks, while those
in the control group completed the tasks by themselves. The findings show that
although the boosting effect of ChatGPT was consistently observed over a
five-day creative journey, human creative performance reverted to baseline when
ChatGPT was down on the 7th and the 30th day. More critically, the use of
ChatGPT in creative tasks resulted in increasingly homogenized contents, and
this homogenization effect persisted even when ChatGPT was absence. These
findings pose a challenge to the prevailing argument that ChatGPT can enhance
human creativity. In fact, generative AI like ChatGPT lends to human with a
temporary rise in creative performance but boxes human creative capability in
the long run, highlighting the imperative for cautious generative AI
integration in creative endeavors."	ArXiv
203	Pros and Cons! Evaluating ChatGPT on Software Vulnerability	['Xin Yin']	2024-04-05 10:08:34+00:00	http://arxiv.org/abs/2404.03994v1	"This paper proposes a pipeline for quantitatively evaluating interactive LLMs
such as ChatGPT using publicly available dataset. We carry out an extensive
technical evaluation of ChatGPT using Big-Vul covering five different common
software vulnerability tasks. We evaluate the multitask and multilingual
aspects of ChatGPT based on this dataset. We found that the existing
state-of-the-art methods are generally superior to ChatGPT in software
vulnerability detection. Although ChatGPT improves accuracy when providing
context information, it still has limitations in accurately predicting severity
ratings for certain CWE types. In addition, ChatGPT demonstrates some ability
in locating vulnerabilities for certain CWE types, but its performance varies
among different CWE types. ChatGPT exhibits limited vulnerability repair
capabilities in both providing and not providing context information. Finally,
ChatGPT shows uneven performance in generating CVE descriptions for various CWE
types, with limited accuracy in detailed information. Overall, though ChatGPT
performs well in some aspects, it still needs improvement in understanding the
subtle differences in code vulnerabilities and the ability to describe
vulnerabilities in order to fully realize its potential. Our evaluation
framework provides valuable insights for further enhancing ChatGPT' s software
vulnerability handling capabilities."	ArXiv
204	"ChatGPT Creates a Review Article: State of the Art in the Most-Cited
  Articles on ChatGPT in Health Science, Computer Science, Communication, and
  Culture, According to Altmetric in Dimensions.ai"	['Eduard Petiska']	2023-04-17 12:27:29+00:00	http://arxiv.org/abs/2307.02488v1	"We have analyzed all preprints on ChatGPT (N=501) and selected the most
influential preprints (according to Altmetric) about ChatGPT across scientific
disciplines to provide the most discussed research results about ChatGPT. We
prompted ChatGPT to create a structured review article based on them. The
results are surprisingly promising, suggesting that the future of creating
review articles can lie in ChatGPT."	ArXiv
205	An Empirical Study of Using ChatGPT for Fact Verification Task	['Mohna Chakraborty', 'Adithya Kulkarni', 'Qi Li']	2023-11-11 15:25:49+00:00	http://arxiv.org/abs/2311.06592v1	"ChatGPT has recently emerged as a powerful tool for performing diverse NLP
tasks. However, ChatGPT has been criticized for generating nonfactual
responses, raising concerns about its usability for sensitive tasks like fact
verification. This study investigates three key research questions: (1) Can
ChatGPT be used for fact verification tasks? (2) What are different prompts
performance using ChatGPT for fact verification tasks? (3) For the
best-performing prompt, what common mistakes does ChatGPT make? Specifically,
this study focuses on conducting a comprehensive and systematic analysis by
designing and comparing the performance of three different prompts for fact
verification tasks on the benchmark FEVER dataset using ChatGPT."	ArXiv
206	"Complementary Advantages of ChatGPTs and Human Readers in Reasoning:
  Evidence from English Text Reading Comprehension"	['Tongquan Zhou', 'Yao Zhang', 'Siyi Cao', 'Yulu Li', 'Tao Wang']	2023-11-17 06:13:02+00:00	http://arxiv.org/abs/2311.10344v1	"ChatGPT has shown its great power in text processing, including its reasoning
ability from text reading. However, there has not been any direct comparison
between human readers and ChatGPT in reasoning ability related to text reading.
This study was undertaken to investigate how ChatGPTs (i.e., ChatGPT and
ChatGPT Plus) and Chinese senior school students as ESL learners exhibited
their reasoning ability from English narrative texts. Additionally, we compared
the two ChatGPTs in the reasoning performances when commands were updated
elaborately. The whole study was composed of three reasoning tests: Test 1 for
commonsense inference, Test 2 for emotional inference, and Test 3 for causal
inference. The results showed that in Test 1, the students outdid the two
ChatGPT versions in local-culture-related inferences but performed worse than
the chatbots in daily-life inferences. In Test 2, ChatGPT Plus excelled whereas
ChatGPT lagged behind in accuracy. In association with both accuracy and
frequency of correct responses, the students were inferior to the two chatbots.
Compared with ChatGPTs' better performance in positive emotions, the students
showed their superiority in inferring negative emotions. In Test 3, the
students demonstrated better logical analysis, outdoing both chatbots. In
updating command condition, ChatGPT Plus displayed good causal reasoning
ability while ChatGPT kept unchanged. Our study reveals that human readers and
ChatGPTs have their respective advantages and disadvantages in drawing
inferences from text reading comprehension, unlocking a complementary
relationship in text-based reasoning."	ArXiv
207	"Can ChatGPT Understand Too? A Comparative Study on ChatGPT and
  Fine-tuned BERT"	['Qihuang Zhong', 'Liang Ding', 'Juhua Liu', 'Bo Du', 'Dacheng Tao']	2023-02-19 12:29:33+00:00	http://arxiv.org/abs/2302.10198v2	"Recently, ChatGPT has attracted great attention, as it can generate fluent
and high-quality responses to human inquiries. Several prior studies have shown
that ChatGPT attains remarkable generation ability compared with existing
models. However, the quantitative analysis of ChatGPT's understanding ability
has been given little attention. In this report, we explore the understanding
ability of ChatGPT by evaluating it on the most popular GLUE benchmark, and
comparing it with 4 representative fine-tuned BERT-style models. We find that:
1) ChatGPT falls short in handling paraphrase and similarity tasks; 2) ChatGPT
outperforms all BERT models on inference tasks by a large margin; 3) ChatGPT
achieves comparable performance compared with BERT on sentiment analysis and
question-answering tasks. Additionally, by combining some advanced prompting
strategies, we show that the understanding ability of ChatGPT can be further
improved."	ArXiv
208	Seeing ChatGPT Through Students' Eyes: An Analysis of TikTok Data	['Anna-Carolina Haensch', 'Sarah Ball', 'Markus Herklotz', 'Frauke Kreuter']	2023-03-09 15:46:54+00:00	http://arxiv.org/abs/2303.05349v1	"Advanced large language models like ChatGPT have gained considerable
attention recently, including among students. However, while the debate on
ChatGPT in academia is making waves, more understanding is needed among
lecturers and teachers on how students use and perceive ChatGPT. To address
this gap, we analyzed the content on ChatGPT available on TikTok in February
2023. TikTok is a rapidly growing social media platform popular among
individuals under 30. Specifically, we analyzed the content of the 100 most
popular videos in English tagged with #chatgpt, which collectively garnered
over 250 million views. Most of the videos we studied promoted the use of
ChatGPT for tasks like writing essays or code. In addition, many videos
discussed AI detectors, with a focus on how other tools can help to transform
ChatGPT output to fool these detectors. This also mirrors the discussion among
educators on how to treat ChatGPT as lecturers and teachers in teaching and
grading. What is, however, missing from the analyzed clips on TikTok are videos
that discuss ChatGPT producing content that is nonsensical or unfaithful to the
training data."	ArXiv
209	"ChatGPT: A Study on its Utility for Ubiquitous Software Engineering
  Tasks"	['Giriprasad Sridhara', 'Ranjani H. G.', 'Sourav Mazumdar']	2023-05-26 11:29:06+00:00	http://arxiv.org/abs/2305.16837v1	"ChatGPT (Chat Generative Pre-trained Transformer) is a chatbot launched by
OpenAI on November 30, 2022. OpenAI's GPT-3 family of large language models
serve as the foundation for ChatGPT. ChatGPT is fine-tuned with both supervised
and reinforcement learning techniques and has received widespread attention for
its articulate responses across diverse domains of knowledge. In this study, we
explore how ChatGPT can be used to help with common software engineering tasks.
Many of the ubiquitous tasks covering the breadth of software engineering such
as ambiguity resolution in software requirements, method name suggestion, test
case prioritization, code review, log summarization can potentially be
performed using ChatGPT. In this study, we explore fifteen common software
engineering tasks using ChatGPT. We juxtapose and analyze ChatGPT's answers
with the respective state of the art outputs (where available) and/or human
expert ground truth. Our experiments suggest that for many tasks, ChatGPT does
perform credibly and the response from it is detailed and often better than the
human expert output or the state of the art output. However, for a few other
tasks, ChatGPT in its present form provides incorrect answers and hence is not
suited for such tasks."	ArXiv
210	RobotGPT: Robot Manipulation Learning from ChatGPT	['Yixiang Jin', 'Dingzhe Li', 'Yong A', 'Jun Shi', 'Peng Hao', 'Fuchun Sun', 'Jianwei Zhang', 'Bin Fang']	2023-12-03 14:59:28+00:00	http://arxiv.org/abs/2312.01421v1	"We present RobotGPT, an innovative decision framework for robotic
manipulation that prioritizes stability and safety. The execution code
generated by ChatGPT cannot guarantee the stability and safety of the system.
ChatGPT may provide different answers for the same task, leading to
unpredictability. This instability prevents the direct integration of ChatGPT
into the robot manipulation loop. Although setting the temperature to 0 can
generate more consistent outputs, it may cause ChatGPT to lose diversity and
creativity. Our objective is to leverage ChatGPT's problem-solving capabilities
in robot manipulation and train a reliable agent. The framework includes an
effective prompt structure and a robust learning model. Additionally, we
introduce a metric for measuring task difficulty to evaluate ChatGPT's
performance in robot manipulation. Furthermore, we evaluate RobotGPT in both
simulation and real-world environments. Compared to directly using ChatGPT to
generate code, our framework significantly improves task success rates, with an
average increase from 38.5% to 91.5%. Therefore, training a RobotGPT by
utilizing ChatGPT as an expert is a more stable approach compared to directly
using ChatGPT as a task planner."	ArXiv
211	"A Study on the Vulnerability of Test Questions against ChatGPT-based
  Cheating"	['Shanker Ram', 'Chen Qian']	2024-02-21 23:51:06+00:00	http://arxiv.org/abs/2402.14881v1	"ChatGPT is a chatbot that can answer text prompts fairly accurately, even
performing very well on postgraduate-level questions. Many educators have found
that their take-home or remote tests and exams are vulnerable to ChatGPT-based
cheating because students may directly use answers provided by tools like
ChatGPT. In this paper, we try to provide an answer to an important question:
how well ChatGPT can answer test questions and how we can detect whether the
questions of a test can be answered correctly by ChatGPT. We generated
ChatGPT's responses to the MedMCQA dataset, which contains over 10,000 medical
school entrance exam questions. We analyzed the responses and uncovered certain
types of questions ChatGPT answers more inaccurately than others. In addition,
we have created a basic natural language processing model to single out the
most vulnerable questions to ChatGPT in a collection of questions or a sample
exam. Our tool can be used by test-makers to avoid ChatGPT-vulnerable test
questions."	ArXiv
212	"Learning-by-teaching with ChatGPT: The effect of teachable ChatGPT agent
  on programming education"	['Angxuan Chen', 'Yuang Wei', 'Huixiao Le', 'Yan Zhang']	2024-12-05 04:12:03+00:00	http://arxiv.org/abs/2412.15226v1	"This study investigates the potential of using ChatGPT as a teachable agent
to support students' learning by teaching process, specifically in programming
education. While learning by teaching is an effective pedagogical strategy for
promoting active learning, traditional teachable agents have limitations,
particularly in facilitating natural language dialogue. Our research explored
whether ChatGPT, with its ability to engage learners in natural conversations,
can support this process. The findings reveal that interacting with ChatGPT
improves students' knowledge gains and programming abilities, particularly in
writing readable and logically sound code. However, it had limited impact on
developing learners' error-correction skills, likely because ChatGPT tends to
generate correct code, reducing opportunities for students to practice
debugging. Additionally, students' self-regulated learning (SRL) abilities
improved, suggesting that teaching ChatGPT fosters learners' higher
self-efficacy and better implementation of SRL strategies. This study discussed
the role of natural dialogue in fostering socialized learning by teaching, and
explored ChatGPT's specific contributions in supporting students' SRL through
the learning by teaching process. Overall, the study highlights ChatGPT's
potential as a teachable agent, offering insights for future research on
ChatGPT-supported education."	ArXiv
213	"Inappropriate Benefits and Identification of ChatGPT Misuse in
  Programming Tests: A Controlled Experiment"	['Hapnes Toba', 'Oscar Karnalim', 'Meliana Christianti Johan', 'Terutoshi Tada', 'Yenni Merlin Djajalaksana', 'Tristan Vivaldy']	2023-08-11 06:42:29+00:00	http://arxiv.org/abs/2309.16697v1	"While ChatGPT may help students to learn to program, it can be misused to do
plagiarism, a breach of academic integrity. Students can ask ChatGPT to
complete a programming task, generating a solution from other people's work
without proper acknowledgment of the source(s). To help address this new kind
of plagiarism, we performed a controlled experiment measuring the inappropriate
benefits of using ChatGPT in terms of completion time and programming
performance. We also reported how to manually identify programs aided with
ChatGPT (via student behavior while using ChatGPT) and student perspective of
ChatGPT (via a survey). Seventeen students participated in the experiment. They
were asked to complete two programming tests. They were divided into two groups
per the test: one group should complete the test without help while the other
group should complete it with ChatGPT. Our study shows that students with
ChatGPT complete programming tests two times faster than those without ChatGPT,
though their programming performance is comparable. The generated code is
highly efficient and uses complex data structures like lists and dictionaries.
Based on the survey results, ChatGPT is recommended to be used as an assistant
to complete programming tasks and other general assignments. ChatGPT will be
beneficial as a reference as other search engines do. Logical and critical
thinking are needed to validate the result presented by ChatGPT."	ArXiv
214	"ChatGPT Assisting Diagnosis of Neuro-ophthalmology Diseases Based on
  Case Reports"	['Yeganeh Madadi', 'Mohammad Delsoz', 'Priscilla A. Lao', 'Joseph W. Fong', 'TJ Hollingsworth', 'Malik Y. Kahook', 'Siamak Yousefi']	2023-09-05 00:44:23+00:00	http://arxiv.org/abs/2309.12361v1	"Objective: To evaluate the efficiency of large language models (LLMs) such as
ChatGPT to assist in diagnosing neuro-ophthalmic diseases based on detailed
case descriptions. Methods: We selected 22 different case reports of
neuro-ophthalmic diseases from a publicly available online database. These
cases included a wide range of chronic and acute diseases that are commonly
seen by neuro-ophthalmic sub-specialists. We inserted the text from each case
as a new prompt into both ChatGPT v3.5 and ChatGPT Plus v4.0 and asked for the
most probable diagnosis. We then presented the exact information to two
neuro-ophthalmologists and recorded their diagnoses followed by comparison to
responses from both versions of ChatGPT. Results: ChatGPT v3.5, ChatGPT Plus
v4.0, and the two neuro-ophthalmologists were correct in 13 (59%), 18 (82%), 19
(86%), and 19 (86%) out of 22 cases, respectively. The agreement between the
various diagnostic sources were as follows: ChatGPT v3.5 and ChatGPT Plus v4.0,
13 (59%); ChatGPT v3.5 and the first neuro-ophthalmologist, 12 (55%); ChatGPT
v3.5 and the second neuro-ophthalmologist, 12 (55%); ChatGPT Plus v4.0 and the
first neuro-ophthalmologist, 17 (77%); ChatGPT Plus v4.0 and the second
neuro-ophthalmologist, 16 (73%); and first and second neuro-ophthalmologists 17
(17%). Conclusions: The accuracy of ChatGPT v3.5 and ChatGPT Plus v4.0 in
diagnosing patients with neuro-ophthalmic diseases was 59% and 82%,
respectively. With further development, ChatGPT Plus v4.0 may have potential to
be used in clinical care settings to assist clinicians in providing quick,
accurate diagnoses of patients in neuro-ophthalmology. The applicability of
using LLMs like ChatGPT in clinical settings that lack access to subspeciality
trained neuro-ophthalmologists deserves further research."	ArXiv
215	"AI and Education: An Investigation into the Use of ChatGPT for Systems
  Thinking"	['Holger Arndt']	2023-07-26 14:12:16+00:00	http://arxiv.org/abs/2307.14206v1	"This exploratory study investigates the potential of the artificial
intelligence tool, ChatGPT, to support systems thinking (ST) in various
subjects. Using both general and subject specific prompts, the study assesses
the accuracy, helpfulness, and reliability of ChatGPT's responses across
different versions of the tool. The results indicate that ChatGPT can provide
largely correct and very helpful responses in various subjects, demonstrating
its potential as a tool for enhancing ST skills. However, occasional
inaccuracies highlight the need for users to remain critical of ChatGPT's
responses. Despite some limitations, this study suggests that with careful use
and attention to its idiosyncrasies, ChatGPT can be a valuable tool for
teaching and learning ST."	ArXiv
216	"ChatGPT for Teaching and Learning: An Experience from Data Science
  Education"	['Yong Zheng']	2023-07-31 13:31:19+00:00	http://arxiv.org/abs/2307.16650v1	"ChatGPT, an implementation and application of large language models, has
gained significant popularity since its initial release. Researchers have been
exploring ways to harness the practical benefits of ChatGPT in real-world
scenarios. Educational researchers have investigated its potential in various
subjects, e.g., programming, mathematics, finance, clinical decision support,
etc. However, there has been limited attention given to its application in data
science education. This paper aims to bridge that gap by utilizing ChatGPT in a
data science course, gathering perspectives from students, and presenting our
experiences and feedback on using ChatGPT for teaching and learning in data
science education. The findings not only distinguish data science education
from other disciplines but also uncover new opportunities and challenges
associated with incorporating ChatGPT into the data science curriculum."	ArXiv
217	"How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation,
  and Detection"	['Biyang Guo', 'Xin Zhang', 'Ziyuan Wang', 'Minqi Jiang', 'Jinran Nie', 'Yuxuan Ding', 'Jianwei Yue', 'Yupeng Wu']	2023-01-18 15:23:25+00:00	http://arxiv.org/abs/2301.07597v1	"The introduction of ChatGPT has garnered widespread attention in both
academic and industrial communities. ChatGPT is able to respond effectively to
a wide range of human questions, providing fluent and comprehensive answers
that significantly surpass previous public chatbots in terms of security and
usefulness. On one hand, people are curious about how ChatGPT is able to
achieve such strength and how far it is from human experts. On the other hand,
people are starting to worry about the potential negative impacts that large
language models (LLMs) like ChatGPT could have on society, such as fake news,
plagiarism, and social security issues. In this work, we collected tens of
thousands of comparison responses from both human experts and ChatGPT, with
questions ranging from open-domain, financial, medical, legal, and
psychological areas. We call the collected dataset the Human ChatGPT Comparison
Corpus (HC3). Based on the HC3 dataset, we study the characteristics of
ChatGPT's responses, the differences and gaps from human experts, and future
directions for LLMs. We conducted comprehensive human evaluations and
linguistic analyses of ChatGPT-generated content compared with that of humans,
where many interesting results are revealed. After that, we conduct extensive
experiments on how to effectively detect whether a certain text is generated by
ChatGPT or humans. We build three different detection systems, explore several
key factors that influence their effectiveness, and evaluate them in different
scenarios. The dataset, code, and models are all publicly available at
https://github.com/Hello-SimpleAI/chatgpt-comparison-detection."	ArXiv
218	Chatbot-supported Thesis Writing: An Autoethnographic Report	['Nicolas Schwenke', 'Heinrich Söbke', 'Eckhard Kraft']	2023-10-14 09:09:26+00:00	http://arxiv.org/abs/2311.10729v1	"The release of the large language model based chatbot ChatGPT in November
2022 has brought considerable attention to the subject of artificial
intelligence, not only in the public. From the perspective of higher education,
ChatGPT challenges various learning and assessment formats as it significantly
reduces the effectiveness of their learning and assessment functionalities. In
particular, ChatGPT might be applied to formats that require learners to
generate text, such as bachelor theses or student research papers. Accordingly,
the research question arises to what extent writing of bachelor theses is still
a valid learning and assessment format. Correspondingly, in this study, the
first author was asked to write his bachelor's thesis exploiting ChatGPT. For
tracing the impact of ChatGPT, methodically an autoethnographic approach was
used. First, all considerations on the potential use of ChatGPT were documented
in logs and secondly, all ChatGPT chats were logged. Both logs and chat
histories were analyzed and are presented along to the recommendations for
students regarding the use of ChatGPT suggested by Gimpel et al. (2023). In
conclusion, ChatGPT is beneficial in thesis writing during various activities,
such as brainstorming, structuring and text revision. However, there arise
limitations, e.g., in referencing. Thus, ChatGPT requires a continuous
validation of the outcomes generated fostering learning. Currently, ChatGPT is
to be valued as a beneficial tool in thesis writing. However, writing a
conclusive thesis still requires the learner's meaningful engagement.
Accordingly, writing a thesis is still a valid learning and assessment format.
With further releases of ChatGPT, an increase in capabilities is to be expected
and the research question needs to be reevaluated from time to time."	ArXiv
219	"Using ChatGPT for Science Learning: A Study on Pre-service Teachers'
  Lesson Planning"	['Gyeong-Geon Lee', 'Xiaoming Zhai']	2024-01-18 22:52:04+00:00	http://arxiv.org/abs/2402.01674v1	"Despite the buzz around ChatGPT's potential, empirical studies exploring its
actual utility in the classroom for learning remain scarce. This study aims to
fill this gap by analyzing the lesson plans developed by 29 pre-service
elementary teachers from a Korean university and assessing how they integrated
ChatGPT into science learning activities. We first examined how the subject
domains and teaching and learning methods/strategies were integrated with
ChatGPT in the lesson plans. We then evaluated the lesson plans using a
modified TPACK-based rubric. We further examined pre-service teachers'
perceptions and concerns about integrating ChatGPT into science learning.
Results show diverse applications of ChatGPT in different science domains.
Fourteen types of teaching and learning methods/strategies were identified in
the lesson plans. On average, the pre-service teachers' lesson plans scored
high on the modified TPACK-based rubric, indicating a reasonable envisage of
integrating ChatGPT into science learning, particularly in 'instructional
strategies & ChatGPT'. However, they scored relatively lower on exploiting
ChatGPT's functions toward its full potential compared to other aspects. The
study also identifies both appropriate and inappropriate use cases of ChatGPT
in lesson planning. Pre-service teachers anticipated ChatGPT to afford
high-quality questioning, self-directed learning, individualized learning
support, and formative assessment. Meanwhile, they also expressed concerns
about its accuracy and the risks that students may be overly dependent on
ChatGPT. They further suggested solutions to systemizing classroom dynamics
between teachers and students. The study underscores the need for more research
on the roles of generative AI in actual classroom settings and provides
insights for future AI-integrated science learning."	ArXiv
220	"Why Do Developers Engage with ChatGPT in Issue-Tracker? Investigating
  Usage and Reliance on ChatGPT-Generated Code"	['Joy Krishan Das', 'Saikat Mondal', 'Chanchal K. Roy']	2024-12-09 18:47:31+00:00	http://arxiv.org/abs/2412.06757v2	"Large language models (LLMs) like ChatGPT have shown the potential to assist
developers with coding and debugging tasks. However, their role in
collaborative issue resolution is underexplored. In this study, we analyzed
1,152 Developer-ChatGPT conversations across 1,012 issues in GitHub to examine
the diverse usage of ChatGPT and reliance on its generated code. Our
contributions are fourfold. First, we manually analyzed 289 conversations to
understand ChatGPT's usage in the GitHub Issues. Our analysis revealed that
ChatGPT is primarily utilized for ideation, whereas its usage for validation
(e.g., code documentation accuracy) is minimal. Second, we applied BERTopic
modeling to identify key areas of engagement on the entire dataset. We found
that backend issues (e.g., API management) dominate conversations, while
testing is surprisingly less covered. Third, we utilized the CPD clone
detection tool to check if the code generated by ChatGPT was used to address
issues. Our findings revealed that ChatGPT-generated code was used as-is to
resolve only 5.83\% of the issues. Fourth, we estimated sentiment using a
RoBERTa-based sentiment analysis model to determine developers' satisfaction
with different usages and engagement areas. We found positive sentiment (i.e.,
high satisfaction) about using ChatGPT for refactoring and addressing data
analytics (e.g., categorizing table data) issues. On the contrary, we observed
negative sentiment when using ChatGPT to debug issues and address automation
tasks (e.g., GUI interactions). Our findings show the unmet needs and growing
dissatisfaction among developers. Researchers and ChatGPT developers should
focus on developing task-specific solutions that help resolve diverse issues,
improving user satisfaction and problem-solving efficiency in software
development."	ArXiv
221	"Evaluating ChatGPT's Information Extraction Capabilities: An Assessment
  of Performance, Explainability, Calibration, and Faithfulness"	['Bo Li', 'Gexiang Fang', 'Yang Yang', 'Quansen Wang', 'Wei Ye', 'Wen Zhao', 'Shikun Zhang']	2023-04-23 12:33:18+00:00	http://arxiv.org/abs/2304.11633v1	"The capability of Large Language Models (LLMs) like ChatGPT to comprehend
user intent and provide reasonable responses has made them extremely popular
lately. In this paper, we focus on assessing the overall ability of ChatGPT
using 7 fine-grained information extraction (IE) tasks. Specially, we present
the systematically analysis by measuring ChatGPT's performance, explainability,
calibration, and faithfulness, and resulting in 15 keys from either the ChatGPT
or domain experts. Our findings reveal that ChatGPT's performance in
Standard-IE setting is poor, but it surprisingly exhibits excellent performance
in the OpenIE setting, as evidenced by human evaluation. In addition, our
research indicates that ChatGPT provides high-quality and trustworthy
explanations for its decisions. However, there is an issue of ChatGPT being
overconfident in its predictions, which resulting in low calibration.
Furthermore, ChatGPT demonstrates a high level of faithfulness to the original
text in the majority of cases. We manually annotate and release the test sets
of 7 fine-grained IE tasks contains 14 datasets to further promote the
research. The datasets and code are available at
https://github.com/pkuserc/ChatGPT_for_IE."	ArXiv
222	ChatGPT (Feb 13 Version) is a Chinese Room	['Maurice HT Ling']	2023-02-19 01:52:06+00:00	http://arxiv.org/abs/2304.12411v1	"ChatGPT has gained both positive and negative publicity after reports
suggesting that it is able to pass various professional and licensing
examinations. This suggests that ChatGPT may pass Turing Test in the near
future. However, a computer program that passing Turing Test can either mean
that it is a Chinese Room or artificially conscious. Hence, the question of
whether the current state of ChatGPT is more of a Chinese Room or approaching
artificial consciousness remains. Here, I demonstrate that the current version
of ChatGPT (Feb 13 version) is a Chinese Room. Despite potential evidence of
cognitive connections, ChatGPT exhibits critical errors in causal reasoning. At
the same time, I demonstrate that ChatGPT can generate all possible categorical
responses to the same question and response with erroneous examples; thus,
questioning its utility as a learning tool. I also show that ChatGPT is capable
of artificial hallucination, which is defined as generating confidently wrong
replies. It is likely that errors in causal reasoning leads to hallucinations.
More critically, ChatGPT generates false references to mimic real publications.
Therefore, its utility is cautioned."	ArXiv
223	Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation	['Jinglong Gao', 'Xiao Ding', 'Bing Qin', 'Ting Liu']	2023-05-12 10:54:13+00:00	http://arxiv.org/abs/2305.07375v4	"Causal reasoning ability is crucial for numerous NLP applications. Despite
the impressive emerging ability of ChatGPT in various NLP tasks, it is unclear
how well ChatGPT performs in causal reasoning. In this paper, we conduct the
first comprehensive evaluation of the ChatGPT's causal reasoning capabilities.
Experiments show that ChatGPT is not a good causal reasoner, but a good causal
explainer. Besides, ChatGPT has a serious hallucination on causal reasoning,
possibly due to the reporting biases between causal and non-causal
relationships in natural language, as well as ChatGPT's upgrading processes,
such as RLHF. The In-Context Learning (ICL) and Chain-of-Thought (CoT)
techniques can further exacerbate such causal hallucination. Additionally, the
causal reasoning ability of ChatGPT is sensitive to the words used to express
the causal concept in prompts, and close-ended prompts perform better than
open-ended prompts. For events in sentences, ChatGPT excels at capturing
explicit causality rather than implicit causality, and performs better in
sentences with lower event density and smaller lexical distance between events.
The code is available on https://github.com/ArrogantL/ChatGPT4CausalReasoning ."	ArXiv
224	ChatGPT is a Remarkable Tool -- For Experts	['Amos Azaria', 'Rina Azoulay', 'Shulamit Reches']	2023-06-02 06:28:21+00:00	http://arxiv.org/abs/2306.03102v1	"This paper investigates the capabilities of ChatGPT as an automated assistant
in diverse domains, including scientific writing, mathematics, education,
programming, and healthcare. We explore the potential of ChatGPT to enhance
productivity, streamline problem-solving processes, and improve writing style.
Furthermore, we highlight the potential risks associated with excessive
reliance on ChatGPT in these fields. These limitations encompass factors like
incorrect and fictitious responses, inaccuracies in code, limited logical
reasoning abilities, overconfidence, and critical ethical concerns of
copyrights and privacy violation. We outline areas and objectives where ChatGPT
proves beneficial, applications where it should be used judiciously, and
scenarios where its reliability may be limited. In light of observed
limitations, and given that the tool's fundamental errors may pose a special
challenge for non-experts, ChatGPT should be used with a strategic methodology.
By drawing from comprehensive experimental studies, we offer methods and flow
charts for effectively using ChatGPT. Our recommendations emphasize iterative
interaction with ChatGPT and independent verification of its outputs.
Considering the importance of utilizing ChatGPT judiciously and with expertise,
we recommend its usage for experts who are well-versed in the respective
domains."	ArXiv
225	"Nine-year-old children outperformed ChatGPT in emotion: Evidence from
  Chinese writing"	['Siyi Cao', 'Yizhong Xu', 'Tongquan Zhou', 'Siruo Zhou']	2023-10-01 05:37:55+00:00	http://arxiv.org/abs/2310.00578v2	"ChatGPT has been demonstrated to possess significant capabilities in
generating intricate, human-like text, and recent studies have established that
its performance in theory of mind tasks is comparable to that of a
nine-year-old child. However, it remains uncertain whether ChatGPT surpasses
nine-year-old children in Chinese writing proficiency. To explore this, our
study juxtaposed the Chinese writing performance of ChatGPT and nine-year-old
children on both narrative and scientific topics, aiming to uncover the
relative strengths and weaknesses of ChatGPT in writing.
  The collected data were analyzed across five linguistic dimensions: fluency,
accuracy, complexity, cohesion, and emotion. Each dimension underwent
assessment through precise indices. The findings revealed that nine-year-old
children excelled beyond ChatGPT in terms of fluency and cohesion within their
writing. In contrast, ChatGPT manifested a superior performance in accuracy
compared to the children. Concerning complexity, children exhibited superior
skills in science-themed writing, while ChatGPT prevailed in nature-themed
writing. Significantly, this research is pioneering in revealing that
nine-year-old children convey stronger emotions than ChatGPT in their Chinese
compositions."	ArXiv
226	"Validating ChatGPT Facts through RDF Knowledge Graphs and Sentence
  Similarity"	['Michalis Mountantonakis', 'Yannis Tzitzikas']	2023-11-08 08:27:11+00:00	http://arxiv.org/abs/2311.04524v2	"Since ChatGPT offers detailed responses without justifications, and erroneous
facts even for popular persons, events and places, in this paper we present a
novel pipeline that retrieves the response of ChatGPT in RDF and tries to
validate the ChatGPT facts using one or more RDF Knowledge Graphs (KGs). To
this end we leverage DBpedia and LODsyndesis (an aggregated Knowledge Graph
that contains 2 billion triples from 400 RDF KGs of many domains) and short
sentence embeddings, and introduce an algorithm that returns the more relevant
triple(s) accompanied by their provenance and a confidence score. This enables
the validation of ChatGPT responses and their enrichment with justifications
and provenance. To evaluate this service (such services in general), we create
an evaluation benchmark that includes 2,000 ChatGPT facts; specifically 1,000
facts for famous Greek Persons, 500 facts for popular Greek Places, and 500
facts for Events related to Greece. The facts were manually labelled
(approximately 73% of ChatGPT facts were correct and 27% of facts were
erroneous). The results are promising; indicatively for the whole benchmark, we
managed to verify the 85.3% of the correct facts of ChatGPT and to find the
correct answer for the 58% of the erroneous ChatGPT facts."	ArXiv
227	"""ChatGPT, a Friend or Foe for Education?"" Analyzing the User's
  Perspectives on the Latest AI Chatbot Via Reddit"	['Forhan Bin Emdad', 'Benhur Ravuri', 'Lateef Ayinde', 'Mohammad Ishtiaque Rahman']	2023-09-27 23:59:44+00:00	http://arxiv.org/abs/2311.06264v1	"Latest developments in Artificial Intelligence (AI) and big data gave rise to
Artificial Intelligent agents like Open AI's ChatGPT, which has recently become
the fastest growing application since Facebook and WhatsApp. ChatGPT has
demonstrated its ability to impact students' classroom learning experience and
exam outcomes. However, there is evidence that ChatGPT provides biased and
erroneous information, yet students use ChatGPT in academic tasks. Therefore,
an accurate understanding of ChatGPT user perception is crucial. This study has
analyzed 247 Reddit top posts related to the educational use of ChatGPT from a
prominent subreddit called ""ChatGPT"" for user perception analysis. Descriptive
statistics, sentiment analysis using NLP techniques, and LDA topic modeling
were used for analysis to gather a contextual understanding of the data.
Results show that the majority of the users took a neutral viewpoint. However,
there was more positive perception than negative regarding the usefulness of
ChatGPT in education."	ArXiv
228	ChatGPT and Human Synergy in Black-Box Testing: A Comparative Analysis	['Hiroyuki Kirinuki', 'Haruto Tanno']	2024-01-25 03:42:17+00:00	http://arxiv.org/abs/2401.13924v1	"In recent years, large language models (LLMs), such as ChatGPT, have been
pivotal in advancing various artificial intelligence applications, including
natural language processing and software engineering. A promising yet
underexplored area is utilizing LLMs in software testing, particularly in
black-box testing. This paper explores the test cases devised by ChatGPT in
comparison to those created by human participants. In this study, ChatGPT
(GPT-4) and four participants each created black-box test cases for three
applications based on specifications written by the authors. The goal was to
evaluate the real-world applicability of the proposed test cases, identify
potential shortcomings, and comprehend how ChatGPT could enhance human testing
strategies. ChatGPT can generate test cases that generally match or slightly
surpass those created by human participants in terms of test viewpoint
coverage. Additionally, our experiments demonstrated that when ChatGPT
cooperates with humans, it can cover considerably more test viewpoints than
each can achieve alone, suggesting that collaboration between humans and
ChatGPT may be more effective than human pairs working together. Nevertheless,
we noticed that the test cases generated by ChatGPT have certain issues that
require addressing before use."	ArXiv
229	"How to Refactor this Code? An Exploratory Study on Developer-ChatGPT
  Refactoring Conversations"	['Eman Abdullah AlOmar', 'Anushkrishna Venkatakrishnan', 'Mohamed Wiem Mkaouer', 'Christian D. Newman', 'Ali Ouni']	2024-02-08 19:24:01+00:00	http://arxiv.org/abs/2402.06013v1	"Large Language Models (LLMs), like ChatGPT, have gained widespread popularity
and usage in various software engineering tasks, including refactoring,
testing, code review, and program comprehension. Despite recent studies delving
into refactoring documentation in commit messages, issues, and code review,
little is known about how developers articulate their refactoring needs when
interacting with ChatGPT. In this paper, our goal is to explore conversations
between developers and ChatGPT related to refactoring to better understand how
developers identify areas for improvement in code and how ChatGPT addresses
developers' needs. Our approach relies on text mining refactoring-related
conversations from 17,913 ChatGPT prompts and responses, and investigating
developers' explicit refactoring intention. Our results reveal that (1)
developer-ChatGPT conversations commonly involve generic and specific
terms/phrases; (2) developers often make generic refactoring requests, while
ChatGPT typically includes the refactoring intention; and (3) various learning
settings when prompting ChatGPT in the context of refactoring. We envision that
our findings contribute to a broader understanding of the collaboration between
developers and AI models, in the context of code refactoring, with implications
for model improvement, tool development, and best practices in software
engineering."	ArXiv
