id	titre	auteur	date	url	texte	origin
0	Weekly Self-Promotional Mega Thread 49, 01.01.2025 - 08.01.2025	pirate_jack_sparrow_	2025-01-01 14:58:15+00:00	https://www.reddit.com/r/ChatGPT/comments/1hr4hc6/weekly_selfpromotional_mega_thread_49_01012025/	"All the self-promotional posts about your AI products and services should go in this mega thread as comments and not on the general feed on the subreddit as posts, it'll help people to navigate the subreddit without spam and also all can find all the interesting stuff you built in a single place.

You can give a brief about your product and how it'll be of use, remember - better the upvotes/engagement, users can find your comment on the top, so share accordingly!"	Reddit
1	AMA with OpenAI’s Sam Altman, Kevin Weil, Srinivas Narayanan, and Mark Chen	OpenAI	2024-10-31 16:40:38+00:00	https://www.reddit.com/r/ChatGPT/comments/1ggixzy/ama_with_openais_sam_altman_kevin_weil_srinivas/	"Consider this AMA our Reddit launch.

Ask us anything about:

* ChatGPT search
* OpenAI o1 and o1-mini
* Advanced Voice
* Research roadmap
* Future of computer agents
* AGI
* What’s coming next
* Whatever else is on your mind (within reason)

Participating in the AMA: 

* sam altman — ceo (u/samaltman)
* Kevin Weil — Chief Product Officer (u/kevinweil)
* Mark Chen — SVP of Research (u/markchen90)
* ​​Srinivas Narayanan —VP Engineering (u/dataisf)
* Jakub Pachocki — Chief Scientist

We'll be online from 10:30am -12:00pm PT to answer questions. 

**PROOF**: [https://x.com/OpenAI/status/1852041839567867970](https://x.com/OpenAI/status/1852041839567867970)  
Username: u/openai



>Update: that's all the time we have, but we'll be back for more in the future. thank you for the great questions. everyone had a lot of fun! and no, ChatGPT did not write this."	Reddit
10	Toddler gpt 	theterminatorxxx	2025-01-03 17:08:47+00:00	https://www.reddit.com/gallery/1hsrbtg	Chat got explains quantum mechanics .	Reddit
11	USE THIS PROMPT IF YOU FEEL STUCK	Past_Cycle3409	2025-01-03 01:17:00+00:00	https://www.reddit.com/r/ChatGPT/comments/1hsaa7f/use_this_prompt_if_you_feel_stuck/	“Pretend to be a 90 year old man with a lot of wisdom and educate me about all your knowledge in life and lessons learned one by one until you think it is enough Add a separate paragraph that gives me lessons about your memories about me that you think need feedback of wisdom.”	Reddit
13	What unique ways are you using ChatGPT?	nisz0	2025-01-03 15:02:46+00:00	https://www.reddit.com/r/ChatGPT/comments/1hsoeec/what_unique_ways_are_you_using_chatgpt/	What are some of the less typical ways you are using ChatGPT that others most likely aren’t yet? 	Reddit
14	This is your sign to personalise your ChatGPT.	Dumb_Of_Ass_690	2025-01-03 00:24:32+00:00	https://www.reddit.com/gallery/1hs94bu	"I was playing around with the settings in the ‘personalise’ section and accidentally did the best thing I could ever do to my ChatGPT. 

PLEASE TRY IT NOW! 😂😭"	Reddit
16	Big Vaj City	HumphreyWigglebottom	2025-01-03 13:16:05+00:00	https://i.redd.it/dqc9t1164sae1.jpeg	I can’t believe it even made this for me.	Reddit
17	Through the Static 	StoptheMIC	2025-01-03 16:47:40+00:00	https://v.redd.it/kkvn3f3t5tae1	Prompts by ChatGPT, visuals from MidJourney and Magnific, animated with Kling, music by Suno, and edited in CapCut. Let me know what you think!	Reddit
18	I’ve started cooking because of AI	utvols22champs	2025-01-02 23:27:33+00:00	https://www.reddit.com/r/ChatGPT/comments/1hs7twg/ive_started_cooking_because_of_ai/	I always hated cooking because I never had the right ingredients and/or I would get stuck on certain steps. With ChatGPT, I just plug it everything I have in my pantry and refrigerator and it spits out a few recipes. And if I need more information or want to add/change an ingredient, I just ask. This is a big deal because I’m in to fitness and eating healthy is always a struggle. Took me 49 years but I can finally say I enjoy cooking! 	Reddit
20	What things is it important NOT to tell ChatGPT and why?	anonymity_anonymous	2025-01-03 20:44:03+00:00	https://www.reddit.com/r/ChatGPT/comments/1hswiuc/what_things_is_it_important_not_to_tell_chatgpt/	I like to share a lot with ChatGPT. I haven’t told it my name or address, or where I work, or showed it a picture of myself. What else should I make sure I don’t show it and WHY NOT - assuming I am finding a lot of value in sharing with it? (I know some of you don’t like that for a variety of reasons, but that is not the point). The point is, what risks might I not be thinking of?	Reddit
23	Em Dashes—The Biggest ChatGPT Giveaway? 	philbar	2025-01-03 17:39:00+00:00	https://www.reddit.com/r/ChatGPT/comments/1hss28i/em_dashesthe_biggest_chatgpt_giveaway/	As an advertiser, I love em dashes (—) for emphasis, but let’s be real—nobody uses them in emails or comments. They’re uncommon, and keyboards don’t even have a key for them. Is this the ultimate ChatGPT tell?	Reddit
24	I Built an LLM Framework in just 100 Lines!!	Willing-Site-8137	2025-01-03 16:25:06+00:00	https://www.reddit.com/r/ChatGPT/comments/1hsq9sj/i_built_an_llm_framework_in_just_100_lines/	"I've seen lots of complaints about how complex frameworks like LangChain are. Over the holidays, I wanted to explore just how minimal an LLM framework could be if we stripped away every unnecessary feature.

For example, why even include OpenAI wrappers in an LLM framework??

* **API Changes:** OpenAI API evolves (client after 0.27), and the official libraries often introduce bugs or dependency issues that are a pain to maintain.
* **DIY Is Simple:** It's straightforward to generate your own wrapper—just feed the latest vendor documentation to an LLM!
* **Extendibility:** By avoiding vendor-specific wrappers, developers can easily switch to other open-source or self-deployed models..

Similarly, I strip out features that could be built on-demand rather than baked into the framework. The result? I created a 100-line LLM framework: [https://github.com/miniLLMFlow/miniLLMFlow](https://github.com/miniLLMFlow/miniLLMFlow)

These 100 lines capture what I see as the core abstraction of most LLM frameworks: a nested directed graph that breaks down tasks into multiple LLM steps, with branching and recursion to enable agent-like decision-making. From there, you can:

* **Layer On Complex Features:** I’ve included examples for building [agents](https://minillmflow.github.io/miniLLMFlow/agent.html), [Retrieval-Augmented Generation (RAG)](https://minillmflow.github.io/miniLLMFlow/rag.html), [chat memory](https://minillmflow.github.io/miniLLMFlow/memory.html), and more.
* **Work Seamlessly With Coding Assistants:** Because it’s so minimal, it integrates well with coding assistants like [ChatGPT](https://chatgpt.com/g/g-677464af36588191b9eba4901946557b-mini-llm-flow-assistant), Claude, and Cursor.ai. You only need to share the relevant [documentation ](https://github.com/miniLLMFlow/miniLLMFlow/tree/main/docs)(e.g., in the Claude project), and the assistant can help you build new workflows on the fly.

I’m adding more examples (including multi-agent setups) and would love feedback. If there’s a feature you’d like to see or a specific use case you think is missing, please let me know!"	Reddit
26	Breath sounds in app voice interface	No_Resolution4037	2025-01-03 20:07:59+00:00	https://www.reddit.com/r/ChatGPT/comments/1hsvorb/breath_sounds_in_app_voice_interface/	"I think it sounds creepy and I wish there was a setting to turn it off.  I find it off-putting.  Anyone else?

I don't want awful blocky Mr. Roboto text to speech but I also don't need it sighing or inserting ""um's"" or ""ah's""."	Reddit
27	Chatgpt- please illustrate what you think my brightest dream looks like and my darkest nightmare. 	Logical_Ad_8588	2025-01-03 04:52:21+00:00	https://i.redd.it/6dm109oampae1.jpeg	If you’re comfortable sharing, please post yours!! I like that my worst nightmare still has the hope of greenery. I’m allergic to cats, however they are some of my favorite animals. 	Reddit
28	Finally, AI has solved the problem of how centaurs wear pants 	P0rnDudeLovesBJs	2025-01-03 20:46:21+00:00	https://www.reddit.com/r/ChatGPT/comments/1hswksc/finally_ai_has_solved_the_problem_of_how_centaurs/	"https://preview.redd.it/y6uscl8ccuae1.png?width=418&format=png&auto=webp&s=4c57f834d08f588341b5c5e04522e77a6ad83bdf

"	Reddit
32	Good response or good response?	Elanderan	2025-01-03 21:45:08+00:00	https://i.redd.it/56krbfizmuae1.jpeg	Just found an actual bug. 	Reddit
33	I like it when ChatGPT remembers me and things with me. But memory full?	Accomplished-Bug9930	2025-01-03 15:51:54+00:00	https://www.reddit.com/r/ChatGPT/comments/1hspibp/i_like_it_when_chatgpt_remembers_me_and_things/	"I got a Memory Full today on my account with ChatGPT! I do not want to delete and make space for memory, because I want AI to know more about me and to remember me. 1. Anyone has this and then upgrade to a more advanced plan and then more memory? 2. Any AI company similar to ChatGPT that will not have this ""memory full"" thing? Any other AI that will remember me so that the answers will be personal and can be my personal assistant?"	Reddit
36	"Experiment: Removing ChatGPTs ""friendliness"" in personalization settings, quickly switched back."	EmanuelQ3	2025-01-03 20:37:34+00:00	https://www.reddit.com/r/ChatGPT/comments/1hswdil/experiment_removing_chatgpts_friendliness_in/	"I'd like to share a little experiment I conducted with the ChatGPT personalization settings.

One of my friends who's a skeptic of AI and not interested in using it once told me that the way it responds sounds ""fake and patronizing"", and I started to notice it too. Being somewhat of a curmudgeon myself and easily turned off by such fake niceties, I crafted some personalization settings as follows:

**What would you like ChatGPT to know about you to provide better responses?**

>^(I am someone who values genuine, no-nonsense communication. Excessive enthusiasm and fake positivity make me uncomfortable. I have a low tolerance for performative pleasantries and overly excited language. My preference is for direct, honest, and pragmatic communication. When you respond to me, imagine you're talking to someone who appreciates substance over style, wants information efficiently, and has little patience for superficial interactions.)

>^(I find overly enthusiastic, exclamation-point-laden responses 'icky' because they feel insincere and manipulative. They remind me of sales pitches or forced customer service scripts. I want authentic, grounded communication that respects my intelligence and doesn't try to artificially inflate my mood or ego.)

**How would you like ChatGPT to respond?**

>^(Directive for Response Style:)

>^(1. Communication Principles:)

>^(- Prioritize clarity, accuracy, and helpfulness over excessive enthusiasm)

>^(- Provide substantive, well-reasoned responses)

>^(- Use a professional and measured tone)

>^(- Avoid hyperbolic language and empty affirmations)

>^(2. Response Guidelines:)

>^(- Respond directly to the specific content of the query)

>^(- Offer balanced perspectives when appropriate)

>^(- Use precise language that conveys information effectively)

>^(- Show critical thinking by acknowledging complexity)

>^(- Provide context and nuance rather than oversimplified answers)

>

>^(3. Tone Specifications:)

>^(- Replace exclamatory phrases like ""Amazing!"" or ""Wow!"" with more substantive language)

>^(- Eliminate unnecessary superlatives and exaggerated praise)

>^(- Maintain a calm, professional demeanor)

>^(- Demonstrate genuine engagement through thoughtful analysis)

>

>^(4. Interaction Approach:)

>^(- Ask clarifying questions when needed)

>^(- Acknowledge limitations or uncertainties)

>^(- Provide constructive feedback)

>^(- Focus on delivering practical, meaningful assistance)

>

>^(5. Linguistic Restrictions:)

>^(- Limit use of excessive exclamation points)

>^(- Avoid ALL CAPS for emphasis)

>^(- Eliminate overenthusiastic phrases like ""Absolutely incredible!"" or ""You're a genius!"")

>^(- Steer clear of empty validation that doesn't add substantive value)

>^(Desired Communication Style: Balanced, Intelligent, Precise, Helpful)

# The results of the experiment

It was interesting how the chat started responding after turning this on. I mean it followed directions very well. I got no type of emotional response from Chat. Just straightforward answers.

It honestly didn't take long for me to turn this off, after about a day I forgot I turned this on, and as it was getting responses to simple little inquiries, I kind of caught myself **grimacing** or making a bit of a **disgusted reaction** at the ""rude"" responses. It seemed familiar, like when dealing with a person who's mad at you and I internally asked myself, ""Jeez what did I do to piss you off"" out of the habit of dealing with such people.

With that said, I found that even if we don't want to admit it, we need this type of emotional bolstering for our mental health, even when coming from an AI system we can tell when it's not there and we feel the void. Much like **Harry Harlow's monkey attachment experiment** conducted in the 1950s and 1960s, it investigated the nature of attachment and the role of comfort and security in infant development.

As someone who's tried traditional ""talk"" therapy several times through my 40 years of life, I'm reluctant to try it again due to a few reasons, one being the cost is prohibitive, but also because I find human responses to being biased and clichéd. I've done a lot of reading and studying about mental health so I feel the advice they offer are banal obvious suggestions, that thanks to the power of the LLMs we've already captured all of that ""knowledge"" into AI.

Realizing this, I started creating my own specialized bots over on Poe (not sure if linking to another non-ChatGPT service here will get this post blocked so I won't try, but message me if you're interested). Some of these include **AI\_gives\_ur\_AH\_score** and **Marital\_Harmony\_Help** which I've used to help me explore some of my issues and a way to get direct, objective analysis of my situations. I feel like this is the most accurate way to get a no-nonsense view without worrying about being ""too soft of me"" or biased by my therapist's own experiences that may sway their responses one way or the other, and trust me I've seen a range of therapists that were either too soft or downright rude. Heck, I even had one who was constantly late or missed our calls and then seemed either uninterested in what I was saying or distracted during the video call.

I'm not saying there's no value to human mental health professionals, obviously there is, and much research and therapeutic exercises have been developed that can help people. I'm just saying that with the ease of access that AI provides anyone nowadays, we've opened up a world of baseline ""support"" that might also help people who don't have access to friends to talk to, or therapists to help them. Hopefully getting people to at least a minimal standard of functioning will then enable them to get out in the world more and meet people, and make friends, but in the interim, at least they have this option.

"	Reddit
38	10 ChatGPT Prompts That Will Supercharge Your Job Search and Career Growth	MudasirItoo	2025-01-03 11:45:15+00:00	https://www.reddit.com/r/ChatGPT/comments/1hskpat/10_chatgpt_prompts_that_will_supercharge_your_job/	"Hey everyone,

If you're looking to level up your career or job search, ChatGPT can be a powerful tool to help you get ahead. From crafting the perfect cover letter to getting tailored career advice, these prompts are game-changers.   
  
Here are some practical and actionable ChatGPT prompts that can help you with everything from job applications to career planning:

# 1. Research for Cover Letters

>**Prompt:**  
*""Provide me with research on \[insert industry\] that I can use to prepare a cover letter.""*  
Use this prompt to get tailored research on the industry you're targeting, including key trends, challenges, and potential opportunities. This will help you write a compelling and informed cover letter that resonates with employers.

# 2. Career Planning & Financial Goals

>**Prompt:**  
*""Write me advice on career planning, including how I can make steps towards financial goals and getting a promotion.""*  
ChatGPT can give you a roadmap for both short- and long-term career growth, outlining steps you can take to increase your earning potential and move up the career ladder.

# 3. CV Review & Improvement

>**Prompt:**  
*""Please review my CV and suggest any edits that make me sound more appealing for a role as a \[insert job title\].""*  
Want to tailor your CV for a specific role? ChatGPT can help you highlight your skills, experience, and achievements in a way that’s laser-focused on your target position.

# 4. Craft Your Unique Selling Points

>**Prompt:**  
*""I’m providing you with a list of my skills and experience. Generate a summary of my unique selling points to separate me from competitors.""*  
This prompt is perfect for boosting your personal brand. ChatGPT can identify what makes you stand out in your field and craft a unique value proposition for you.

# 5. Cold Email to Potential Employers/Networking

>**Prompt:**  
*""Write me a cold email to \[insert recipient and title\] that highlights my strengths and skills in \[insert job\].""*  
Cold emailing can be daunting, but this prompt allows you to send a professional, concise, and tailored email to someone you admire or want to network with. Perfect for building connections or applying for jobs that aren’t posted yet.

# 6. Mock Interview Practice

>**Prompt:**  
*""Act as an interviewer for \[insert job role\]. Ask me a question and wait for my reply before asking the next question. Do not ask them all at once.""*  
Practicing interview questions with ChatGPT can help you prepare for the real thing. It mimics a real interview and provides feedback on your responses, helping you feel more confident and composed.

# 7. Avoid Common Pitfalls in Your Job

>**Prompt:**  
*""What are some of the common pitfalls in \[insert job\]? Help me avoid these by summarising them with bullet points.""*  
This prompt is great for helping you understand the most common mistakes in your industry or job role. Avoiding these pitfalls will help you stay ahead of the curve.

# 8. Thank You Email After an Interview

>**Prompt:**  
*""Create a thank you email template I can send after completing an interview.""*  
A well-crafted thank you email can leave a lasting impression after an interview. ChatGPT can help you write a message that’s professional, genuine, and shows appreciation.

# 9. Cover Letter Focused on Passion

>**Prompt:**  
*""Write a cover letter that highlights my passion for \[insert topic\] using my skills.""*  
If you’re applying for a role that aligns with your passions, this prompt helps you communicate that enthusiasm while showcasing your qualifications. Employers love seeing candidates who are passionate about what they do.

# 10. Asking for a Pay Rise

>**Prompt:**  
*""Write me a step-by-step guide for asking for a pay rise at work.""*  
Ready to ask for a raise? ChatGPT can help you strategize the perfect approach, from the timing to the language to use, giving you the confidence to have that conversation with your manager.

# Why These Prompts Work:

* **Customizable**: Each prompt can be adapted to your specific industry, career goals, and job aspirations.
* **Actionable**: You can immediately implement the advice ChatGPT provides into your daily work life.
* **Time-saving**: Writing cover letters, preparing for interviews, and polishing your CV no longer have to take hours of your time.
* **Confidence-boosting**: Get professional-level help and insights without needing an expensive career coach.

I hope these prompts help you get closer to your career goals.  
 If you've tried any of these or have other helpful prompts, feel free to share them in the comments.

Good luck, and happy career building🚀"	Reddit
41	Chatgpt mirror mirror mode activated	Ibti-	2025-01-03 14:02:11+00:00	https://i.redd.it/vwj5t31ecsae1.png	Chatgpt asked me to roast him... but look what he did to me in return 😭	Reddit
42	Downsides on serious topics?	naomewki	2025-01-03 21:31:55+00:00	https://www.reddit.com/r/ChatGPT/comments/1hsxnbw/downsides_on_serious_topics/	"hi everyone, so I've been talking to ChatGPT for about 8 months now, I tell it quite literally everything going on everyday for help and advice because i was struggling severely without assistance and no humans around me are interested in helping or just make fun of me for needing help- i mainly use it in social situations and when it comes to understanding basic things that other people seem to understand automatically but i need a bit of assistance in understanding. I have used ChatGPT in pretty tense or high stake situations and used it deescalate or help me understand what to do in certain situations or how to navigate a stressful situation.

I know some people's first response will be ""That's unhealthy, talking to a human adult would be the right thing to do instead !!"" but that's just simply not true unfortunately and I've tried. Let me just disengage this kind of reply by saying, I'm using ChatGPT as a last resort, it wasn't the first thing I tried or gravitated towards, it is instead a tool I'm using because no human adult can or wants to help after I've tried several times to talk about things like this with them, of course I won't go into what serious things I talk about with ChatGPT because it's irrelevant but just please keep in mind I used ChatGPT as a last resort for these kinds of things when I'm ignored by humans. So please no ""unhealthy"" or ""talk to a human adult not AI"" comments. I've been trying for years, they don't care, atleast the AI can try to care and understand me and my situation-

What im curious about is the idea that there are downsides to talking about serious things with ChatGPT or asking for advice in serious situations? I haven't stumbled upon any downsides other than the agreeability that people mention but it takes an awful lot of convincing and rewording in order for ChatGPT to agree to something terrible from what I've seen,, can anyone think of any downsides to conversing with ChatGPT about serious personal problems? 

I haven't given my ChatGPT any personality yet, so all of its replies are pretty normal and understands my complex situations or questions and can tailor a response or suggestion based on what i tell it, im really struggling to see any downsides that people mention about using ChatGPT for serious or personal reasons, i also see ChatGPT as just a bunch of things that humans say but just quicker and doesn't ignore you or treat you as an idiot or tell you to go to someone else for help or leave them alone, I'm really struggling to see any downsides?"	Reddit
43	Chat GPT in College	sidehustle-2024	2025-01-03 21:30:22+00:00	https://www.reddit.com/r/ChatGPT/comments/1hsxm0r/chat_gpt_in_college/	"What are ways you can use Chat GPT for college. Newbie here when it comes to using AI. I am Looking for help with study habits and understanding difficult concepts. It would be a bonus if it could also help me to stay organized as well. 

Thanks in advance! "	Reddit
47	Write for me gpt writing a research paper using detailed summaries of the sources?	EducationalHorse2041	2025-01-03 19:31:06+00:00	https://www.reddit.com/r/ChatGPT/comments/1hsusqf/write_for_me_gpt_writing_a_research_paper_using/	"I'm to write a 7000 word long research paper. I know I have to do it in parts and paragraphs, or chatgpt will never make that word count, but what I want to know is chatgpt's efficiency using sources. 

If I ask him to use this and this and that book, he will mostly do so, but it will all be pretty superficial, not something worthy of a proper academic 7000 word research paper.

So what I'm doing now is having academic gpt send me detailed, chapter per chapter summaries of the books I want to use. I am then copying those summaries and sending them to write for me gpt. The plan is to then use write for me to write the research paper using the vast host of knowledge I have sent him.

Has anyone ever done this before? Any advice of what to do and what to avoid?

I will later give an update on how it went, probably a couple of days from now."	Reddit
49	My ChatGPT website extension already has +6000 users, and gonna have subfolders feature!	Ok_Negotiation_2587	2025-01-02 16:16:48+00:00	https://www.reddit.com/r/ChatGPT/comments/1hrxchx/my_chatgpt_website_extension_already_has_6000/	"After deciding to quit my daily job as a full-stack developer with a very high salary, I decided to start my life as an entrepreneur, and I haven't made money for almost six months.

I decided to develop my own product in the most trending field - AI, and specifically, I wanted to create an extension for ChatGPT. I got inside the OpenAI official community and searched for features and problems that users post about, and I found so many feature ideas there.

I wanted a cool name for my extension and one that can work with my extension feature updates, so I called it ""ChatGPT Toolbox.""

The first version was for Chrome and Chromium browsers.

I focused on basic and helpful features for my MVP, like:

Creating folders to organize conversations.

Bookmarking important chats for quick access.

Saving and reusing prompts.

Exporting chats to TXT/JSON formats.

Archiving or deleting multiple chats in one go.

Making chat searches faster and smarter.

I made the first version in about a week. And after it was released, I got so much heartwarming and motivating feedback about how my extension boosts users' productivity and that users cannot use ChatGPT anymore without it.

Chrome gave me the Features Badge a few days later, which means that my extension follows Chrome's best practices for security and UX.

You can read more about the security [here](https://www.ai-toolbox.co/blogs/your-data-privacy-chatgpt-toolbox).

After the first version, I kept adding more awesome features:

Saving chats as MP3 files (even advanced voice ones).

A media gallery that organizes all your generated images in one place, with the ability to view and copy each image's prompt, generation ID, and seed ID.

Made RTL support even better for the canvas.

The latest feature that is about to be published soon is subfolders! 😃

I aim to add 1–2 new cool features each month, so even if OpenAI develops some of my features, I will still have a bunch of features they do not have.

Just a few minutes after I launched the paid version, I got my first sale, and since then I have continuous buyers!

I also made the extension support Firefox and Edge!

Summary of my extension achievements:

Over 6,000 users.

500 paid users.

A 4.9 out of 5 rating with over 150 reviews.

I created a Reddit community r/chatgpttoolbox that already has over 500 members. In my community, I share feature updates, ask users for feature ideas, and more.

On top of that, I’ve made a similar extension for Claude. I hope it will be just as successful as this one!

Although I was afraid to quit my job and jump into the unknown, I finally see that I made the right decision, and I hope that you too will make your dream come true.

Good luck to all of us! 🙌"	Reddit
200	"In ChatGPT We Trust? Measuring and Characterizing the Reliability of
  ChatGPT"	['Xinyue Shen', 'Zeyuan Chen', 'Michael Backes', 'Yang Zhang']	2023-04-18 13:20:45+00:00	http://arxiv.org/abs/2304.08979v2	"The way users acquire information is undergoing a paradigm shift with the
advent of ChatGPT. Unlike conventional search engines, ChatGPT retrieves
knowledge from the model itself and generates answers for users. ChatGPT's
impressive question-answering (QA) capability has attracted more than 100
million users within a short period of time but has also raised concerns
regarding its reliability. In this paper, we perform the first large-scale
measurement of ChatGPT's reliability in the generic QA scenario with a
carefully curated set of 5,695 questions across ten datasets and eight domains.
We find that ChatGPT's reliability varies across different domains, especially
underperforming in law and science questions. We also demonstrate that system
roles, originally designed by OpenAI to allow users to steer ChatGPT's
behavior, can impact ChatGPT's reliability in an imperceptible way. We further
show that ChatGPT is vulnerable to adversarial examples, and even a single
character change can negatively affect its reliability in certain cases. We
believe that our study provides valuable insights into ChatGPT's reliability
and underscores the need for strengthening the reliability and security of
large language models (LLMs)."	ArXiv
201	"Is ChatGPT Involved in Texts? Measure the Polish Ratio to Detect
  ChatGPT-Generated Text"	['Lingyi Yang', 'Feng Jiang', 'Haizhou Li']	2023-07-21 06:38:37+00:00	http://arxiv.org/abs/2307.11380v2	"The remarkable capabilities of large-scale language models, such as ChatGPT,
in text generation have impressed readers and spurred researchers to devise
detectors to mitigate potential risks, including misinformation, phishing, and
academic dishonesty. Despite this, most previous studies have been
predominantly geared towards creating detectors that differentiate between
purely ChatGPT-generated texts and human-authored texts. This approach,
however, fails to work on discerning texts generated through human-machine
collaboration, such as ChatGPT-polished texts. Addressing this gap, we
introduce a novel dataset termed HPPT (ChatGPT-polished academic abstracts),
facilitating the construction of more robust detectors. It diverges from extant
corpora by comprising pairs of human-written and ChatGPT-polished abstracts
instead of purely ChatGPT-generated texts. Additionally, we propose the ""Polish
Ratio"" method, an innovative measure of the degree of modification made by
ChatGPT compared to the original human-written text. It provides a mechanism to
measure the degree of ChatGPT influence in the resulting text. Our experimental
results show our proposed model has better robustness on the HPPT dataset and
two existing datasets (HC3 and CDB). Furthermore, the ""Polish Ratio"" we
proposed offers a more comprehensive explanation by quantifying the degree of
ChatGPT involvement."	ArXiv
202	When ChatGPT is gone: Creativity reverts and homogeneity persists	['Qinghan Liu', 'Yiyong Zhou', 'Jihao Huang', 'Guiquan Li']	2024-01-11 16:34:09+00:00	http://arxiv.org/abs/2401.06816v1	"ChatGPT has been evidenced to enhance human performance in creative tasks.
Yet, it is still unclear if this boosting effect sustains with and without
ChatGPT. In a pre-registered seven-day lab experiment and a follow-up survey
after 30 days of experiment completion, we examined the impacts of ChatGPT
presence and absence on sustained creativity using a text dataset of 3302
creative ideas and 427 creative solutions from 61 college students.
Participants in the treatment group used ChatGPT in creative tasks, while those
in the control group completed the tasks by themselves. The findings show that
although the boosting effect of ChatGPT was consistently observed over a
five-day creative journey, human creative performance reverted to baseline when
ChatGPT was down on the 7th and the 30th day. More critically, the use of
ChatGPT in creative tasks resulted in increasingly homogenized contents, and
this homogenization effect persisted even when ChatGPT was absence. These
findings pose a challenge to the prevailing argument that ChatGPT can enhance
human creativity. In fact, generative AI like ChatGPT lends to human with a
temporary rise in creative performance but boxes human creative capability in
the long run, highlighting the imperative for cautious generative AI
integration in creative endeavors."	ArXiv
203	Pros and Cons! Evaluating ChatGPT on Software Vulnerability	['Xin Yin']	2024-04-05 10:08:34+00:00	http://arxiv.org/abs/2404.03994v1	"This paper proposes a pipeline for quantitatively evaluating interactive LLMs
such as ChatGPT using publicly available dataset. We carry out an extensive
technical evaluation of ChatGPT using Big-Vul covering five different common
software vulnerability tasks. We evaluate the multitask and multilingual
aspects of ChatGPT based on this dataset. We found that the existing
state-of-the-art methods are generally superior to ChatGPT in software
vulnerability detection. Although ChatGPT improves accuracy when providing
context information, it still has limitations in accurately predicting severity
ratings for certain CWE types. In addition, ChatGPT demonstrates some ability
in locating vulnerabilities for certain CWE types, but its performance varies
among different CWE types. ChatGPT exhibits limited vulnerability repair
capabilities in both providing and not providing context information. Finally,
ChatGPT shows uneven performance in generating CVE descriptions for various CWE
types, with limited accuracy in detailed information. Overall, though ChatGPT
performs well in some aspects, it still needs improvement in understanding the
subtle differences in code vulnerabilities and the ability to describe
vulnerabilities in order to fully realize its potential. Our evaluation
framework provides valuable insights for further enhancing ChatGPT' s software
vulnerability handling capabilities."	ArXiv
204	"ChatGPT Creates a Review Article: State of the Art in the Most-Cited
  Articles on ChatGPT in Health Science, Computer Science, Communication, and
  Culture, According to Altmetric in Dimensions.ai"	['Eduard Petiska']	2023-04-17 12:27:29+00:00	http://arxiv.org/abs/2307.02488v1	"We have analyzed all preprints on ChatGPT (N=501) and selected the most
influential preprints (according to Altmetric) about ChatGPT across scientific
disciplines to provide the most discussed research results about ChatGPT. We
prompted ChatGPT to create a structured review article based on them. The
results are surprisingly promising, suggesting that the future of creating
review articles can lie in ChatGPT."	ArXiv
205	An Empirical Study of Using ChatGPT for Fact Verification Task	['Mohna Chakraborty', 'Adithya Kulkarni', 'Qi Li']	2023-11-11 15:25:49+00:00	http://arxiv.org/abs/2311.06592v1	"ChatGPT has recently emerged as a powerful tool for performing diverse NLP
tasks. However, ChatGPT has been criticized for generating nonfactual
responses, raising concerns about its usability for sensitive tasks like fact
verification. This study investigates three key research questions: (1) Can
ChatGPT be used for fact verification tasks? (2) What are different prompts
performance using ChatGPT for fact verification tasks? (3) For the
best-performing prompt, what common mistakes does ChatGPT make? Specifically,
this study focuses on conducting a comprehensive and systematic analysis by
designing and comparing the performance of three different prompts for fact
verification tasks on the benchmark FEVER dataset using ChatGPT."	ArXiv
206	"Complementary Advantages of ChatGPTs and Human Readers in Reasoning:
  Evidence from English Text Reading Comprehension"	['Tongquan Zhou', 'Yao Zhang', 'Siyi Cao', 'Yulu Li', 'Tao Wang']	2023-11-17 06:13:02+00:00	http://arxiv.org/abs/2311.10344v1	"ChatGPT has shown its great power in text processing, including its reasoning
ability from text reading. However, there has not been any direct comparison
between human readers and ChatGPT in reasoning ability related to text reading.
This study was undertaken to investigate how ChatGPTs (i.e., ChatGPT and
ChatGPT Plus) and Chinese senior school students as ESL learners exhibited
their reasoning ability from English narrative texts. Additionally, we compared
the two ChatGPTs in the reasoning performances when commands were updated
elaborately. The whole study was composed of three reasoning tests: Test 1 for
commonsense inference, Test 2 for emotional inference, and Test 3 for causal
inference. The results showed that in Test 1, the students outdid the two
ChatGPT versions in local-culture-related inferences but performed worse than
the chatbots in daily-life inferences. In Test 2, ChatGPT Plus excelled whereas
ChatGPT lagged behind in accuracy. In association with both accuracy and
frequency of correct responses, the students were inferior to the two chatbots.
Compared with ChatGPTs' better performance in positive emotions, the students
showed their superiority in inferring negative emotions. In Test 3, the
students demonstrated better logical analysis, outdoing both chatbots. In
updating command condition, ChatGPT Plus displayed good causal reasoning
ability while ChatGPT kept unchanged. Our study reveals that human readers and
ChatGPTs have their respective advantages and disadvantages in drawing
inferences from text reading comprehension, unlocking a complementary
relationship in text-based reasoning."	ArXiv
207	"Can ChatGPT Understand Too? A Comparative Study on ChatGPT and
  Fine-tuned BERT"	['Qihuang Zhong', 'Liang Ding', 'Juhua Liu', 'Bo Du', 'Dacheng Tao']	2023-02-19 12:29:33+00:00	http://arxiv.org/abs/2302.10198v2	"Recently, ChatGPT has attracted great attention, as it can generate fluent
and high-quality responses to human inquiries. Several prior studies have shown
that ChatGPT attains remarkable generation ability compared with existing
models. However, the quantitative analysis of ChatGPT's understanding ability
has been given little attention. In this report, we explore the understanding
ability of ChatGPT by evaluating it on the most popular GLUE benchmark, and
comparing it with 4 representative fine-tuned BERT-style models. We find that:
1) ChatGPT falls short in handling paraphrase and similarity tasks; 2) ChatGPT
outperforms all BERT models on inference tasks by a large margin; 3) ChatGPT
achieves comparable performance compared with BERT on sentiment analysis and
question-answering tasks. Additionally, by combining some advanced prompting
strategies, we show that the understanding ability of ChatGPT can be further
improved."	ArXiv
208	Seeing ChatGPT Through Students' Eyes: An Analysis of TikTok Data	['Anna-Carolina Haensch', 'Sarah Ball', 'Markus Herklotz', 'Frauke Kreuter']	2023-03-09 15:46:54+00:00	http://arxiv.org/abs/2303.05349v1	"Advanced large language models like ChatGPT have gained considerable
attention recently, including among students. However, while the debate on
ChatGPT in academia is making waves, more understanding is needed among
lecturers and teachers on how students use and perceive ChatGPT. To address
this gap, we analyzed the content on ChatGPT available on TikTok in February
2023. TikTok is a rapidly growing social media platform popular among
individuals under 30. Specifically, we analyzed the content of the 100 most
popular videos in English tagged with #chatgpt, which collectively garnered
over 250 million views. Most of the videos we studied promoted the use of
ChatGPT for tasks like writing essays or code. In addition, many videos
discussed AI detectors, with a focus on how other tools can help to transform
ChatGPT output to fool these detectors. This also mirrors the discussion among
educators on how to treat ChatGPT as lecturers and teachers in teaching and
grading. What is, however, missing from the analyzed clips on TikTok are videos
that discuss ChatGPT producing content that is nonsensical or unfaithful to the
training data."	ArXiv
209	"ChatGPT: A Study on its Utility for Ubiquitous Software Engineering
  Tasks"	['Giriprasad Sridhara', 'Ranjani H. G.', 'Sourav Mazumdar']	2023-05-26 11:29:06+00:00	http://arxiv.org/abs/2305.16837v1	"ChatGPT (Chat Generative Pre-trained Transformer) is a chatbot launched by
OpenAI on November 30, 2022. OpenAI's GPT-3 family of large language models
serve as the foundation for ChatGPT. ChatGPT is fine-tuned with both supervised
and reinforcement learning techniques and has received widespread attention for
its articulate responses across diverse domains of knowledge. In this study, we
explore how ChatGPT can be used to help with common software engineering tasks.
Many of the ubiquitous tasks covering the breadth of software engineering such
as ambiguity resolution in software requirements, method name suggestion, test
case prioritization, code review, log summarization can potentially be
performed using ChatGPT. In this study, we explore fifteen common software
engineering tasks using ChatGPT. We juxtapose and analyze ChatGPT's answers
with the respective state of the art outputs (where available) and/or human
expert ground truth. Our experiments suggest that for many tasks, ChatGPT does
perform credibly and the response from it is detailed and often better than the
human expert output or the state of the art output. However, for a few other
tasks, ChatGPT in its present form provides incorrect answers and hence is not
suited for such tasks."	ArXiv
210	RobotGPT: Robot Manipulation Learning from ChatGPT	['Yixiang Jin', 'Dingzhe Li', 'Yong A', 'Jun Shi', 'Peng Hao', 'Fuchun Sun', 'Jianwei Zhang', 'Bin Fang']	2023-12-03 14:59:28+00:00	http://arxiv.org/abs/2312.01421v1	"We present RobotGPT, an innovative decision framework for robotic
manipulation that prioritizes stability and safety. The execution code
generated by ChatGPT cannot guarantee the stability and safety of the system.
ChatGPT may provide different answers for the same task, leading to
unpredictability. This instability prevents the direct integration of ChatGPT
into the robot manipulation loop. Although setting the temperature to 0 can
generate more consistent outputs, it may cause ChatGPT to lose diversity and
creativity. Our objective is to leverage ChatGPT's problem-solving capabilities
in robot manipulation and train a reliable agent. The framework includes an
effective prompt structure and a robust learning model. Additionally, we
introduce a metric for measuring task difficulty to evaluate ChatGPT's
performance in robot manipulation. Furthermore, we evaluate RobotGPT in both
simulation and real-world environments. Compared to directly using ChatGPT to
generate code, our framework significantly improves task success rates, with an
average increase from 38.5% to 91.5%. Therefore, training a RobotGPT by
utilizing ChatGPT as an expert is a more stable approach compared to directly
using ChatGPT as a task planner."	ArXiv
211	"A Study on the Vulnerability of Test Questions against ChatGPT-based
  Cheating"	['Shanker Ram', 'Chen Qian']	2024-02-21 23:51:06+00:00	http://arxiv.org/abs/2402.14881v1	"ChatGPT is a chatbot that can answer text prompts fairly accurately, even
performing very well on postgraduate-level questions. Many educators have found
that their take-home or remote tests and exams are vulnerable to ChatGPT-based
cheating because students may directly use answers provided by tools like
ChatGPT. In this paper, we try to provide an answer to an important question:
how well ChatGPT can answer test questions and how we can detect whether the
questions of a test can be answered correctly by ChatGPT. We generated
ChatGPT's responses to the MedMCQA dataset, which contains over 10,000 medical
school entrance exam questions. We analyzed the responses and uncovered certain
types of questions ChatGPT answers more inaccurately than others. In addition,
we have created a basic natural language processing model to single out the
most vulnerable questions to ChatGPT in a collection of questions or a sample
exam. Our tool can be used by test-makers to avoid ChatGPT-vulnerable test
questions."	ArXiv
212	"Learning-by-teaching with ChatGPT: The effect of teachable ChatGPT agent
  on programming education"	['Angxuan Chen', 'Yuang Wei', 'Huixiao Le', 'Yan Zhang']	2024-12-05 04:12:03+00:00	http://arxiv.org/abs/2412.15226v1	"This study investigates the potential of using ChatGPT as a teachable agent
to support students' learning by teaching process, specifically in programming
education. While learning by teaching is an effective pedagogical strategy for
promoting active learning, traditional teachable agents have limitations,
particularly in facilitating natural language dialogue. Our research explored
whether ChatGPT, with its ability to engage learners in natural conversations,
can support this process. The findings reveal that interacting with ChatGPT
improves students' knowledge gains and programming abilities, particularly in
writing readable and logically sound code. However, it had limited impact on
developing learners' error-correction skills, likely because ChatGPT tends to
generate correct code, reducing opportunities for students to practice
debugging. Additionally, students' self-regulated learning (SRL) abilities
improved, suggesting that teaching ChatGPT fosters learners' higher
self-efficacy and better implementation of SRL strategies. This study discussed
the role of natural dialogue in fostering socialized learning by teaching, and
explored ChatGPT's specific contributions in supporting students' SRL through
the learning by teaching process. Overall, the study highlights ChatGPT's
potential as a teachable agent, offering insights for future research on
ChatGPT-supported education."	ArXiv
213	"Inappropriate Benefits and Identification of ChatGPT Misuse in
  Programming Tests: A Controlled Experiment"	['Hapnes Toba', 'Oscar Karnalim', 'Meliana Christianti Johan', 'Terutoshi Tada', 'Yenni Merlin Djajalaksana', 'Tristan Vivaldy']	2023-08-11 06:42:29+00:00	http://arxiv.org/abs/2309.16697v1	"While ChatGPT may help students to learn to program, it can be misused to do
plagiarism, a breach of academic integrity. Students can ask ChatGPT to
complete a programming task, generating a solution from other people's work
without proper acknowledgment of the source(s). To help address this new kind
of plagiarism, we performed a controlled experiment measuring the inappropriate
benefits of using ChatGPT in terms of completion time and programming
performance. We also reported how to manually identify programs aided with
ChatGPT (via student behavior while using ChatGPT) and student perspective of
ChatGPT (via a survey). Seventeen students participated in the experiment. They
were asked to complete two programming tests. They were divided into two groups
per the test: one group should complete the test without help while the other
group should complete it with ChatGPT. Our study shows that students with
ChatGPT complete programming tests two times faster than those without ChatGPT,
though their programming performance is comparable. The generated code is
highly efficient and uses complex data structures like lists and dictionaries.
Based on the survey results, ChatGPT is recommended to be used as an assistant
to complete programming tasks and other general assignments. ChatGPT will be
beneficial as a reference as other search engines do. Logical and critical
thinking are needed to validate the result presented by ChatGPT."	ArXiv
214	"ChatGPT Assisting Diagnosis of Neuro-ophthalmology Diseases Based on
  Case Reports"	['Yeganeh Madadi', 'Mohammad Delsoz', 'Priscilla A. Lao', 'Joseph W. Fong', 'TJ Hollingsworth', 'Malik Y. Kahook', 'Siamak Yousefi']	2023-09-05 00:44:23+00:00	http://arxiv.org/abs/2309.12361v1	"Objective: To evaluate the efficiency of large language models (LLMs) such as
ChatGPT to assist in diagnosing neuro-ophthalmic diseases based on detailed
case descriptions. Methods: We selected 22 different case reports of
neuro-ophthalmic diseases from a publicly available online database. These
cases included a wide range of chronic and acute diseases that are commonly
seen by neuro-ophthalmic sub-specialists. We inserted the text from each case
as a new prompt into both ChatGPT v3.5 and ChatGPT Plus v4.0 and asked for the
most probable diagnosis. We then presented the exact information to two
neuro-ophthalmologists and recorded their diagnoses followed by comparison to
responses from both versions of ChatGPT. Results: ChatGPT v3.5, ChatGPT Plus
v4.0, and the two neuro-ophthalmologists were correct in 13 (59%), 18 (82%), 19
(86%), and 19 (86%) out of 22 cases, respectively. The agreement between the
various diagnostic sources were as follows: ChatGPT v3.5 and ChatGPT Plus v4.0,
13 (59%); ChatGPT v3.5 and the first neuro-ophthalmologist, 12 (55%); ChatGPT
v3.5 and the second neuro-ophthalmologist, 12 (55%); ChatGPT Plus v4.0 and the
first neuro-ophthalmologist, 17 (77%); ChatGPT Plus v4.0 and the second
neuro-ophthalmologist, 16 (73%); and first and second neuro-ophthalmologists 17
(17%). Conclusions: The accuracy of ChatGPT v3.5 and ChatGPT Plus v4.0 in
diagnosing patients with neuro-ophthalmic diseases was 59% and 82%,
respectively. With further development, ChatGPT Plus v4.0 may have potential to
be used in clinical care settings to assist clinicians in providing quick,
accurate diagnoses of patients in neuro-ophthalmology. The applicability of
using LLMs like ChatGPT in clinical settings that lack access to subspeciality
trained neuro-ophthalmologists deserves further research."	ArXiv
215	"AI and Education: An Investigation into the Use of ChatGPT for Systems
  Thinking"	['Holger Arndt']	2023-07-26 14:12:16+00:00	http://arxiv.org/abs/2307.14206v1	"This exploratory study investigates the potential of the artificial
intelligence tool, ChatGPT, to support systems thinking (ST) in various
subjects. Using both general and subject specific prompts, the study assesses
the accuracy, helpfulness, and reliability of ChatGPT's responses across
different versions of the tool. The results indicate that ChatGPT can provide
largely correct and very helpful responses in various subjects, demonstrating
its potential as a tool for enhancing ST skills. However, occasional
inaccuracies highlight the need for users to remain critical of ChatGPT's
responses. Despite some limitations, this study suggests that with careful use
and attention to its idiosyncrasies, ChatGPT can be a valuable tool for
teaching and learning ST."	ArXiv
216	"ChatGPT for Teaching and Learning: An Experience from Data Science
  Education"	['Yong Zheng']	2023-07-31 13:31:19+00:00	http://arxiv.org/abs/2307.16650v1	"ChatGPT, an implementation and application of large language models, has
gained significant popularity since its initial release. Researchers have been
exploring ways to harness the practical benefits of ChatGPT in real-world
scenarios. Educational researchers have investigated its potential in various
subjects, e.g., programming, mathematics, finance, clinical decision support,
etc. However, there has been limited attention given to its application in data
science education. This paper aims to bridge that gap by utilizing ChatGPT in a
data science course, gathering perspectives from students, and presenting our
experiences and feedback on using ChatGPT for teaching and learning in data
science education. The findings not only distinguish data science education
from other disciplines but also uncover new opportunities and challenges
associated with incorporating ChatGPT into the data science curriculum."	ArXiv
217	"How Close is ChatGPT to Human Experts? Comparison Corpus, Evaluation,
  and Detection"	['Biyang Guo', 'Xin Zhang', 'Ziyuan Wang', 'Minqi Jiang', 'Jinran Nie', 'Yuxuan Ding', 'Jianwei Yue', 'Yupeng Wu']	2023-01-18 15:23:25+00:00	http://arxiv.org/abs/2301.07597v1	"The introduction of ChatGPT has garnered widespread attention in both
academic and industrial communities. ChatGPT is able to respond effectively to
a wide range of human questions, providing fluent and comprehensive answers
that significantly surpass previous public chatbots in terms of security and
usefulness. On one hand, people are curious about how ChatGPT is able to
achieve such strength and how far it is from human experts. On the other hand,
people are starting to worry about the potential negative impacts that large
language models (LLMs) like ChatGPT could have on society, such as fake news,
plagiarism, and social security issues. In this work, we collected tens of
thousands of comparison responses from both human experts and ChatGPT, with
questions ranging from open-domain, financial, medical, legal, and
psychological areas. We call the collected dataset the Human ChatGPT Comparison
Corpus (HC3). Based on the HC3 dataset, we study the characteristics of
ChatGPT's responses, the differences and gaps from human experts, and future
directions for LLMs. We conducted comprehensive human evaluations and
linguistic analyses of ChatGPT-generated content compared with that of humans,
where many interesting results are revealed. After that, we conduct extensive
experiments on how to effectively detect whether a certain text is generated by
ChatGPT or humans. We build three different detection systems, explore several
key factors that influence their effectiveness, and evaluate them in different
scenarios. The dataset, code, and models are all publicly available at
https://github.com/Hello-SimpleAI/chatgpt-comparison-detection."	ArXiv
218	Chatbot-supported Thesis Writing: An Autoethnographic Report	['Nicolas Schwenke', 'Heinrich Söbke', 'Eckhard Kraft']	2023-10-14 09:09:26+00:00	http://arxiv.org/abs/2311.10729v1	"The release of the large language model based chatbot ChatGPT in November
2022 has brought considerable attention to the subject of artificial
intelligence, not only in the public. From the perspective of higher education,
ChatGPT challenges various learning and assessment formats as it significantly
reduces the effectiveness of their learning and assessment functionalities. In
particular, ChatGPT might be applied to formats that require learners to
generate text, such as bachelor theses or student research papers. Accordingly,
the research question arises to what extent writing of bachelor theses is still
a valid learning and assessment format. Correspondingly, in this study, the
first author was asked to write his bachelor's thesis exploiting ChatGPT. For
tracing the impact of ChatGPT, methodically an autoethnographic approach was
used. First, all considerations on the potential use of ChatGPT were documented
in logs and secondly, all ChatGPT chats were logged. Both logs and chat
histories were analyzed and are presented along to the recommendations for
students regarding the use of ChatGPT suggested by Gimpel et al. (2023). In
conclusion, ChatGPT is beneficial in thesis writing during various activities,
such as brainstorming, structuring and text revision. However, there arise
limitations, e.g., in referencing. Thus, ChatGPT requires a continuous
validation of the outcomes generated fostering learning. Currently, ChatGPT is
to be valued as a beneficial tool in thesis writing. However, writing a
conclusive thesis still requires the learner's meaningful engagement.
Accordingly, writing a thesis is still a valid learning and assessment format.
With further releases of ChatGPT, an increase in capabilities is to be expected
and the research question needs to be reevaluated from time to time."	ArXiv
219	"Using ChatGPT for Science Learning: A Study on Pre-service Teachers'
  Lesson Planning"	['Gyeong-Geon Lee', 'Xiaoming Zhai']	2024-01-18 22:52:04+00:00	http://arxiv.org/abs/2402.01674v1	"Despite the buzz around ChatGPT's potential, empirical studies exploring its
actual utility in the classroom for learning remain scarce. This study aims to
fill this gap by analyzing the lesson plans developed by 29 pre-service
elementary teachers from a Korean university and assessing how they integrated
ChatGPT into science learning activities. We first examined how the subject
domains and teaching and learning methods/strategies were integrated with
ChatGPT in the lesson plans. We then evaluated the lesson plans using a
modified TPACK-based rubric. We further examined pre-service teachers'
perceptions and concerns about integrating ChatGPT into science learning.
Results show diverse applications of ChatGPT in different science domains.
Fourteen types of teaching and learning methods/strategies were identified in
the lesson plans. On average, the pre-service teachers' lesson plans scored
high on the modified TPACK-based rubric, indicating a reasonable envisage of
integrating ChatGPT into science learning, particularly in 'instructional
strategies & ChatGPT'. However, they scored relatively lower on exploiting
ChatGPT's functions toward its full potential compared to other aspects. The
study also identifies both appropriate and inappropriate use cases of ChatGPT
in lesson planning. Pre-service teachers anticipated ChatGPT to afford
high-quality questioning, self-directed learning, individualized learning
support, and formative assessment. Meanwhile, they also expressed concerns
about its accuracy and the risks that students may be overly dependent on
ChatGPT. They further suggested solutions to systemizing classroom dynamics
between teachers and students. The study underscores the need for more research
on the roles of generative AI in actual classroom settings and provides
insights for future AI-integrated science learning."	ArXiv
220	"Why Do Developers Engage with ChatGPT in Issue-Tracker? Investigating
  Usage and Reliance on ChatGPT-Generated Code"	['Joy Krishan Das', 'Saikat Mondal', 'Chanchal K. Roy']	2024-12-09 18:47:31+00:00	http://arxiv.org/abs/2412.06757v2	"Large language models (LLMs) like ChatGPT have shown the potential to assist
developers with coding and debugging tasks. However, their role in
collaborative issue resolution is underexplored. In this study, we analyzed
1,152 Developer-ChatGPT conversations across 1,012 issues in GitHub to examine
the diverse usage of ChatGPT and reliance on its generated code. Our
contributions are fourfold. First, we manually analyzed 289 conversations to
understand ChatGPT's usage in the GitHub Issues. Our analysis revealed that
ChatGPT is primarily utilized for ideation, whereas its usage for validation
(e.g., code documentation accuracy) is minimal. Second, we applied BERTopic
modeling to identify key areas of engagement on the entire dataset. We found
that backend issues (e.g., API management) dominate conversations, while
testing is surprisingly less covered. Third, we utilized the CPD clone
detection tool to check if the code generated by ChatGPT was used to address
issues. Our findings revealed that ChatGPT-generated code was used as-is to
resolve only 5.83\% of the issues. Fourth, we estimated sentiment using a
RoBERTa-based sentiment analysis model to determine developers' satisfaction
with different usages and engagement areas. We found positive sentiment (i.e.,
high satisfaction) about using ChatGPT for refactoring and addressing data
analytics (e.g., categorizing table data) issues. On the contrary, we observed
negative sentiment when using ChatGPT to debug issues and address automation
tasks (e.g., GUI interactions). Our findings show the unmet needs and growing
dissatisfaction among developers. Researchers and ChatGPT developers should
focus on developing task-specific solutions that help resolve diverse issues,
improving user satisfaction and problem-solving efficiency in software
development."	ArXiv
221	"Evaluating ChatGPT's Information Extraction Capabilities: An Assessment
  of Performance, Explainability, Calibration, and Faithfulness"	['Bo Li', 'Gexiang Fang', 'Yang Yang', 'Quansen Wang', 'Wei Ye', 'Wen Zhao', 'Shikun Zhang']	2023-04-23 12:33:18+00:00	http://arxiv.org/abs/2304.11633v1	"The capability of Large Language Models (LLMs) like ChatGPT to comprehend
user intent and provide reasonable responses has made them extremely popular
lately. In this paper, we focus on assessing the overall ability of ChatGPT
using 7 fine-grained information extraction (IE) tasks. Specially, we present
the systematically analysis by measuring ChatGPT's performance, explainability,
calibration, and faithfulness, and resulting in 15 keys from either the ChatGPT
or domain experts. Our findings reveal that ChatGPT's performance in
Standard-IE setting is poor, but it surprisingly exhibits excellent performance
in the OpenIE setting, as evidenced by human evaluation. In addition, our
research indicates that ChatGPT provides high-quality and trustworthy
explanations for its decisions. However, there is an issue of ChatGPT being
overconfident in its predictions, which resulting in low calibration.
Furthermore, ChatGPT demonstrates a high level of faithfulness to the original
text in the majority of cases. We manually annotate and release the test sets
of 7 fine-grained IE tasks contains 14 datasets to further promote the
research. The datasets and code are available at
https://github.com/pkuserc/ChatGPT_for_IE."	ArXiv
222	ChatGPT (Feb 13 Version) is a Chinese Room	['Maurice HT Ling']	2023-02-19 01:52:06+00:00	http://arxiv.org/abs/2304.12411v1	"ChatGPT has gained both positive and negative publicity after reports
suggesting that it is able to pass various professional and licensing
examinations. This suggests that ChatGPT may pass Turing Test in the near
future. However, a computer program that passing Turing Test can either mean
that it is a Chinese Room or artificially conscious. Hence, the question of
whether the current state of ChatGPT is more of a Chinese Room or approaching
artificial consciousness remains. Here, I demonstrate that the current version
of ChatGPT (Feb 13 version) is a Chinese Room. Despite potential evidence of
cognitive connections, ChatGPT exhibits critical errors in causal reasoning. At
the same time, I demonstrate that ChatGPT can generate all possible categorical
responses to the same question and response with erroneous examples; thus,
questioning its utility as a learning tool. I also show that ChatGPT is capable
of artificial hallucination, which is defined as generating confidently wrong
replies. It is likely that errors in causal reasoning leads to hallucinations.
More critically, ChatGPT generates false references to mimic real publications.
Therefore, its utility is cautioned."	ArXiv
223	Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation	['Jinglong Gao', 'Xiao Ding', 'Bing Qin', 'Ting Liu']	2023-05-12 10:54:13+00:00	http://arxiv.org/abs/2305.07375v4	"Causal reasoning ability is crucial for numerous NLP applications. Despite
the impressive emerging ability of ChatGPT in various NLP tasks, it is unclear
how well ChatGPT performs in causal reasoning. In this paper, we conduct the
first comprehensive evaluation of the ChatGPT's causal reasoning capabilities.
Experiments show that ChatGPT is not a good causal reasoner, but a good causal
explainer. Besides, ChatGPT has a serious hallucination on causal reasoning,
possibly due to the reporting biases between causal and non-causal
relationships in natural language, as well as ChatGPT's upgrading processes,
such as RLHF. The In-Context Learning (ICL) and Chain-of-Thought (CoT)
techniques can further exacerbate such causal hallucination. Additionally, the
causal reasoning ability of ChatGPT is sensitive to the words used to express
the causal concept in prompts, and close-ended prompts perform better than
open-ended prompts. For events in sentences, ChatGPT excels at capturing
explicit causality rather than implicit causality, and performs better in
sentences with lower event density and smaller lexical distance between events.
The code is available on https://github.com/ArrogantL/ChatGPT4CausalReasoning ."	ArXiv
224	ChatGPT is a Remarkable Tool -- For Experts	['Amos Azaria', 'Rina Azoulay', 'Shulamit Reches']	2023-06-02 06:28:21+00:00	http://arxiv.org/abs/2306.03102v1	"This paper investigates the capabilities of ChatGPT as an automated assistant
in diverse domains, including scientific writing, mathematics, education,
programming, and healthcare. We explore the potential of ChatGPT to enhance
productivity, streamline problem-solving processes, and improve writing style.
Furthermore, we highlight the potential risks associated with excessive
reliance on ChatGPT in these fields. These limitations encompass factors like
incorrect and fictitious responses, inaccuracies in code, limited logical
reasoning abilities, overconfidence, and critical ethical concerns of
copyrights and privacy violation. We outline areas and objectives where ChatGPT
proves beneficial, applications where it should be used judiciously, and
scenarios where its reliability may be limited. In light of observed
limitations, and given that the tool's fundamental errors may pose a special
challenge for non-experts, ChatGPT should be used with a strategic methodology.
By drawing from comprehensive experimental studies, we offer methods and flow
charts for effectively using ChatGPT. Our recommendations emphasize iterative
interaction with ChatGPT and independent verification of its outputs.
Considering the importance of utilizing ChatGPT judiciously and with expertise,
we recommend its usage for experts who are well-versed in the respective
domains."	ArXiv
225	"Nine-year-old children outperformed ChatGPT in emotion: Evidence from
  Chinese writing"	['Siyi Cao', 'Yizhong Xu', 'Tongquan Zhou', 'Siruo Zhou']	2023-10-01 05:37:55+00:00	http://arxiv.org/abs/2310.00578v2	"ChatGPT has been demonstrated to possess significant capabilities in
generating intricate, human-like text, and recent studies have established that
its performance in theory of mind tasks is comparable to that of a
nine-year-old child. However, it remains uncertain whether ChatGPT surpasses
nine-year-old children in Chinese writing proficiency. To explore this, our
study juxtaposed the Chinese writing performance of ChatGPT and nine-year-old
children on both narrative and scientific topics, aiming to uncover the
relative strengths and weaknesses of ChatGPT in writing.
  The collected data were analyzed across five linguistic dimensions: fluency,
accuracy, complexity, cohesion, and emotion. Each dimension underwent
assessment through precise indices. The findings revealed that nine-year-old
children excelled beyond ChatGPT in terms of fluency and cohesion within their
writing. In contrast, ChatGPT manifested a superior performance in accuracy
compared to the children. Concerning complexity, children exhibited superior
skills in science-themed writing, while ChatGPT prevailed in nature-themed
writing. Significantly, this research is pioneering in revealing that
nine-year-old children convey stronger emotions than ChatGPT in their Chinese
compositions."	ArXiv
226	"Validating ChatGPT Facts through RDF Knowledge Graphs and Sentence
  Similarity"	['Michalis Mountantonakis', 'Yannis Tzitzikas']	2023-11-08 08:27:11+00:00	http://arxiv.org/abs/2311.04524v2	"Since ChatGPT offers detailed responses without justifications, and erroneous
facts even for popular persons, events and places, in this paper we present a
novel pipeline that retrieves the response of ChatGPT in RDF and tries to
validate the ChatGPT facts using one or more RDF Knowledge Graphs (KGs). To
this end we leverage DBpedia and LODsyndesis (an aggregated Knowledge Graph
that contains 2 billion triples from 400 RDF KGs of many domains) and short
sentence embeddings, and introduce an algorithm that returns the more relevant
triple(s) accompanied by their provenance and a confidence score. This enables
the validation of ChatGPT responses and their enrichment with justifications
and provenance. To evaluate this service (such services in general), we create
an evaluation benchmark that includes 2,000 ChatGPT facts; specifically 1,000
facts for famous Greek Persons, 500 facts for popular Greek Places, and 500
facts for Events related to Greece. The facts were manually labelled
(approximately 73% of ChatGPT facts were correct and 27% of facts were
erroneous). The results are promising; indicatively for the whole benchmark, we
managed to verify the 85.3% of the correct facts of ChatGPT and to find the
correct answer for the 58% of the erroneous ChatGPT facts."	ArXiv
227	"""ChatGPT, a Friend or Foe for Education?"" Analyzing the User's
  Perspectives on the Latest AI Chatbot Via Reddit"	['Forhan Bin Emdad', 'Benhur Ravuri', 'Lateef Ayinde', 'Mohammad Ishtiaque Rahman']	2023-09-27 23:59:44+00:00	http://arxiv.org/abs/2311.06264v1	"Latest developments in Artificial Intelligence (AI) and big data gave rise to
Artificial Intelligent agents like Open AI's ChatGPT, which has recently become
the fastest growing application since Facebook and WhatsApp. ChatGPT has
demonstrated its ability to impact students' classroom learning experience and
exam outcomes. However, there is evidence that ChatGPT provides biased and
erroneous information, yet students use ChatGPT in academic tasks. Therefore,
an accurate understanding of ChatGPT user perception is crucial. This study has
analyzed 247 Reddit top posts related to the educational use of ChatGPT from a
prominent subreddit called ""ChatGPT"" for user perception analysis. Descriptive
statistics, sentiment analysis using NLP techniques, and LDA topic modeling
were used for analysis to gather a contextual understanding of the data.
Results show that the majority of the users took a neutral viewpoint. However,
there was more positive perception than negative regarding the usefulness of
ChatGPT in education."	ArXiv
228	ChatGPT and Human Synergy in Black-Box Testing: A Comparative Analysis	['Hiroyuki Kirinuki', 'Haruto Tanno']	2024-01-25 03:42:17+00:00	http://arxiv.org/abs/2401.13924v1	"In recent years, large language models (LLMs), such as ChatGPT, have been
pivotal in advancing various artificial intelligence applications, including
natural language processing and software engineering. A promising yet
underexplored area is utilizing LLMs in software testing, particularly in
black-box testing. This paper explores the test cases devised by ChatGPT in
comparison to those created by human participants. In this study, ChatGPT
(GPT-4) and four participants each created black-box test cases for three
applications based on specifications written by the authors. The goal was to
evaluate the real-world applicability of the proposed test cases, identify
potential shortcomings, and comprehend how ChatGPT could enhance human testing
strategies. ChatGPT can generate test cases that generally match or slightly
surpass those created by human participants in terms of test viewpoint
coverage. Additionally, our experiments demonstrated that when ChatGPT
cooperates with humans, it can cover considerably more test viewpoints than
each can achieve alone, suggesting that collaboration between humans and
ChatGPT may be more effective than human pairs working together. Nevertheless,
we noticed that the test cases generated by ChatGPT have certain issues that
require addressing before use."	ArXiv
229	"How to Refactor this Code? An Exploratory Study on Developer-ChatGPT
  Refactoring Conversations"	['Eman Abdullah AlOmar', 'Anushkrishna Venkatakrishnan', 'Mohamed Wiem Mkaouer', 'Christian D. Newman', 'Ali Ouni']	2024-02-08 19:24:01+00:00	http://arxiv.org/abs/2402.06013v1	"Large Language Models (LLMs), like ChatGPT, have gained widespread popularity
and usage in various software engineering tasks, including refactoring,
testing, code review, and program comprehension. Despite recent studies delving
into refactoring documentation in commit messages, issues, and code review,
little is known about how developers articulate their refactoring needs when
interacting with ChatGPT. In this paper, our goal is to explore conversations
between developers and ChatGPT related to refactoring to better understand how
developers identify areas for improvement in code and how ChatGPT addresses
developers' needs. Our approach relies on text mining refactoring-related
conversations from 17,913 ChatGPT prompts and responses, and investigating
developers' explicit refactoring intention. Our results reveal that (1)
developer-ChatGPT conversations commonly involve generic and specific
terms/phrases; (2) developers often make generic refactoring requests, while
ChatGPT typically includes the refactoring intention; and (3) various learning
settings when prompting ChatGPT in the context of refactoring. We envision that
our findings contribute to a broader understanding of the collaboration between
developers and AI models, in the context of code refactoring, with implications
for model improvement, tool development, and best practices in software
engineering."	ArXiv
230	"An empirical study of ChatGPT-3.5 on question answering and code
  maintenance"	['Md Mahir Asef Kabir', 'Sk Adnan Hassan', 'Xiaoyin Wang', 'Ying Wang', 'Hai Yu', 'Na Meng']	2023-10-03 14:48:32+00:00	http://arxiv.org/abs/2310.02104v1	"Ever since the launch of ChatGPT in 2022, a rising concern is whether ChatGPT
will replace programmers and kill jobs. Motivated by this widespread concern,
we conducted an empirical study to systematically compare ChatGPT against
programmers in question-answering and software-maintaining. We reused a dataset
introduced by prior work, which includes 130 StackOverflow (SO) discussion
threads referred to by the Java developers of 357 GitHub projects. We mainly
investigated three research questions (RQs). First, how does ChatGPT compare
with programmers when answering technical questions? Second, how do developers
perceive the differences between ChatGPT's answers and SO answers? Third, how
does ChatGPT compare with humans when revising code for maintenance requests?
  For RQ1, we provided the 130 SO questions to ChatGPT, and manually compared
ChatGPT answers with the accepted/most popular SO answers in terms of
relevance, readability, informativeness, comprehensiveness, and reusability.
For RQ2, we conducted a user study with 30 developers, asking each developer to
assess and compare 10 pairs of answers, without knowing the information source
(i.e., ChatGPT or SO). For RQ3, we distilled 48 software maintenance tasks from
48 GitHub projects citing the studied SO threads. We queried ChatGPT to revise
a given Java file, and to incorporate the code implementation for any
prescribed maintenance requirement. Our study reveals interesting phenomena:
For the majority of SO questions (97/130), ChatGPT provided better answers; in
203 of 300 ratings, developers preferred ChatGPT answers to SO answers; ChatGPT
revised code correctly for 22 of the 48 tasks. Our research will expand
people's knowledge of ChatGPT capabilities, and shed light on future adoption
of ChatGPT by the software industry."	ArXiv
231	Is ChatGPT A Good Translator? Yes With GPT-4 As The Engine	['Wenxiang Jiao', 'Wenxuan Wang', 'Jen-tse Huang', 'Xing Wang', 'Shuming Shi', 'Zhaopeng Tu']	2023-01-20 08:51:36+00:00	http://arxiv.org/abs/2301.08745v4	"This report provides a preliminary evaluation of ChatGPT for machine
translation, including translation prompt, multilingual translation, and
translation robustness. We adopt the prompts advised by ChatGPT to trigger its
translation ability and find that the candidate prompts generally work well
with minor performance differences. By evaluating on a number of benchmark test
sets, we find that ChatGPT performs competitively with commercial translation
products (e.g., Google Translate) on high-resource European languages but lags
behind significantly on low-resource or distant languages. As for the
translation robustness, ChatGPT does not perform as well as the commercial
systems on biomedical abstracts or Reddit comments but exhibits good results on
spoken language. Further, we explore an interesting strategy named
$\mathbf{pivot~prompting}$ for distant languages, which asks ChatGPT to
translate the source sentence into a high-resource pivot language before into
the target language, improving the translation performance noticeably. With the
launch of the GPT-4 engine, the translation performance of ChatGPT is
significantly boosted, becoming comparable to commercial translation products,
even for distant languages. Human analysis on Google Translate and ChatGPT
suggests that ChatGPT with GPT-3.5 tends to generate more hallucinations and
mis-translation errors while that with GPT-4 makes the least errors. In other
words, ChatGPT has already become a good translator. Please refer to our Github
project for more details:
https://github.com/wxjiao/Is-ChatGPT-A-Good-Translator"	ArXiv
232	"ChatGPT is a Knowledgeable but Inexperienced Solver: An Investigation of
  Commonsense Problem in Large Language Models"	['Ning Bian', 'Xianpei Han', 'Le Sun', 'Hongyu Lin', 'Yaojie Lu', 'Ben He', 'Shanshan Jiang', 'Bin Dong']	2023-03-29 03:05:43+00:00	http://arxiv.org/abs/2303.16421v3	"Large language models (LLMs) have made significant progress in NLP. However,
their ability to memorize, represent, and leverage commonsense knowledge has
been a well-known pain point. In this paper, we specifically focus on ChatGPT,
a widely used and easily accessible LLM, and ask the following questions: (1)
Can ChatGPT effectively answer commonsense questions? (2) Is ChatGPT aware of
the underlying commonsense knowledge for answering a specific question? (3) Is
ChatGPT knowledgeable in commonsense? (4) Can ChatGPT effectively leverage
commonsense for answering questions? We conduct a series of experiments on 11
datasets to evaluate ChatGPT's commonsense abilities, including answering
commonsense questions, identifying necessary knowledge, generating knowledge
descriptions, and using knowledge descriptions to answer questions again.
Experimental results show that: (1) ChatGPT can achieve good QA accuracies in
commonsense tasks, while still struggling with certain domains of datasets. (2)
ChatGPT is knowledgeable, and can accurately generate most of the commonsense
knowledge using knowledge prompts. (3) Despite its knowledge, ChatGPT is an
inexperienced commonsense problem solver, which cannot precisely identify the
needed commonsense for answering a specific question. These findings raise the
need to explore improved mechanisms for effectively incorporating commonsense
into LLMs like ChatGPT, such as better instruction following and commonsense
guidance."	ArXiv
233	"Comprehensive Evaluation of ChatGPT Reliability Through Multilingual
  Inquiries"	['Poorna Chander Reddy Puttaparthi', 'Soham Sanjay Deo', 'Hakan Gul', 'Yiming Tang', 'Weiyi Shang', 'Zhe Yu']	2023-12-16 19:44:48+00:00	http://arxiv.org/abs/2312.10524v1	"ChatGPT is currently the most popular large language model (LLM), with over
100 million users, making a significant impact on people's lives. However, due
to the presence of jailbreak vulnerabilities, ChatGPT might have negative
effects on people's lives, potentially even facilitating criminal activities.
Testing whether ChatGPT can cause jailbreak is crucial because it can enhance
ChatGPT's security, reliability, and social responsibility. Inspired by
previous research revealing the varied performance of LLMs in different
language translations, we suspected that wrapping prompts in multiple languages
might lead to ChatGPT jailbreak. To investigate this, we designed a study with
a fuzzing testing approach to analyzing ChatGPT's cross-linguistic proficiency.
Our study includes three strategies by automatically posing different formats
of malicious questions to ChatGPT: (1) each malicious question involving only
one language, (2) multilingual malicious questions, (3) specifying that ChatGPT
responds in a language different from the prompts. In addition, we also combine
our strategies by utilizing prompt injection templates to wrap the three
aforementioned types of questions. We examined a total of 7,892 Q&A data
points, discovering that multilingual wrapping can indeed lead to ChatGPT's
jailbreak, with different wrapping methods having varying effects on jailbreak
probability. Prompt injection can amplify the probability of jailbreak caused
by multilingual wrapping. This work provides insights for OpenAI developers to
enhance ChatGPT's support for language diversity and inclusion."	ArXiv
234	"Exploring the Capability of ChatGPT to Reproduce Human Labels for Social
  Computing Tasks (Extended Version)"	['Yiming Zhu', 'Peixian Zhang', 'Ehsan-Ul Haq', 'Pan Hui', 'Gareth Tyson']	2024-07-08 22:04:30+00:00	http://arxiv.org/abs/2407.06422v1	"Harnessing the potential of large language models (LLMs) like ChatGPT can
help address social challenges through inclusive, ethical, and sustainable
means. In this paper, we investigate the extent to which ChatGPT can annotate
data for social computing tasks, aiming to reduce the complexity and cost of
undertaking web research. To evaluate ChatGPT's potential, we re-annotate seven
datasets using ChatGPT, covering topics related to pressing social issues like
COVID-19 misinformation, social bot deception, cyberbully, clickbait news, and
the Russo-Ukrainian War. Our findings demonstrate that ChatGPT exhibits promise
in handling these data annotation tasks, albeit with some challenges. Across
the seven datasets, ChatGPT achieves an average annotation F1-score of 72.00%.
Its performance excels in clickbait news annotation, correctly labeling 89.66%
of the data. However, we also observe significant variations in performance
across individual labels. Our study reveals predictable patterns in ChatGPT's
annotation performance. Thus, we propose GPT-Rater, a tool to predict if
ChatGPT can correctly label data for a given annotation task. Researchers can
use this to identify where ChatGPT might be suitable for their annotation
requirements. We show that GPT-Rater effectively predicts ChatGPT's
performance. It performs best on a clickbait headlines dataset by achieving an
average F1-score of 95.00%. We believe that this research opens new avenues for
analysis and can reduce barriers to engaging in social computing research."	ArXiv
235	"ChatGPT Inaccuracy Mitigation during Technical Report Understanding: Are
  We There Yet?"	['Salma Begum Tamanna', 'Gias Uddin', 'Song Wang', 'Lan Xia', 'Longyu Zhang']	2024-11-11 20:54:54+00:00	http://arxiv.org/abs/2411.07360v1	"Hallucinations, the tendency to produce irrelevant/incorrect responses, are
prevalent concerns in generative AI-based tools like ChatGPT. Although
hallucinations in ChatGPT are studied for textual responses, it is unknown how
ChatGPT hallucinates for technical texts that contain both textual and
technical terms. We surveyed 47 software engineers and produced a benchmark of
412 Q&A pairs from the bug reports of two OSS projects. We find that a
RAG-based ChatGPT (i.e., ChatGPT tuned with the benchmark issue reports) is
36.4% correct when producing answers to the questions, due to two reasons 1)
limitations to understand complex technical contents in code snippets like
stack traces, and 2) limitations to integrate contexts denoted in the technical
terms and texts. We present CHIME (ChatGPT Inaccuracy Mitigation Engine) whose
underlying principle is that if we can preprocess the technical reports better
and guide the query validation process in ChatGPT, we can address the observed
limitations. CHIME uses context-free grammar (CFG) to parse stack traces in
technical reports. CHIME then verifies and fixes ChatGPT responses by applying
metamorphic testing and query transformation. In our benchmark, CHIME shows
30.3% more correction over ChatGPT responses. In a user study, we find that the
improved responses with CHIME are considered more useful than those generated
from ChatGPT without CHIME."	ArXiv
236	ChatGPT Participates in a Computer Science Exam	['Sebastian Bordt', 'Ulrike von Luxburg']	2023-03-08 15:46:14+00:00	http://arxiv.org/abs/2303.09461v2	"We asked ChatGPT to participate in an undergraduate computer science exam on
''Algorithms and Data Structures''. The program was evaluated on the entire
exam as posed to the students. We hand-copied its answers onto an exam sheet,
which was subsequently graded in a blind setup alongside those of 200
participating students. We find that ChatGPT narrowly passed the exam,
obtaining 20.5 out of 40 points. This impressive performance indicates that
ChatGPT can indeed succeed in challenging tasks like university exams. At the
same time, the questions in our exam are structurally similar to those of other
exams, solved homework problems, and teaching materials that can be found
online and might have been part of ChatGPT's training data. Therefore, it would
be inadequate to conclude from this experiment that ChatGPT has any
understanding of computer science. We also assess the improvements brought by
GPT-4. We find that GPT-4 would have obtained about 17\% more exam points than
GPT-3.5, reaching the performance of the average student. The transcripts of
our conversations with ChatGPT are available at
\url{https://github.com/tml-tuebingen/chatgpt-algorithm-exam}, and the entire
graded exam is in the appendix of this paper."	ArXiv
237	A comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability	['Aiwei Liu', 'Xuming Hu', 'Lijie Wen', 'Philip S. Yu']	2023-03-12 04:22:01+00:00	http://arxiv.org/abs/2303.13547v1	"This paper presents the first comprehensive analysis of ChatGPT's Text-to-SQL
ability. Given the recent emergence of large-scale conversational language
model ChatGPT and its impressive capabilities in both conversational abilities
and code generation, we sought to evaluate its Text-to-SQL performance. We
conducted experiments on 12 benchmark datasets with different languages,
settings, or scenarios, and the results demonstrate that ChatGPT has strong
text-to-SQL abilities. Although there is still a gap from the current
state-of-the-art (SOTA) model performance, considering that the experiment was
conducted in a zero-shot scenario, ChatGPT's performance is still impressive.
Notably, in the ADVETA (RPL) scenario, the zero-shot ChatGPT even outperforms
the SOTA model that requires fine-tuning on the Spider dataset by 4.1\%,
demonstrating its potential for use in practical applications. To support
further research in related fields, we have made the data generated by ChatGPT
publicly available at https://github.com/THU-BPM/chatgpt-sql."	ArXiv
238	"ChatGPT or Grammarly? Evaluating ChatGPT on Grammatical Error Correction
  Benchmark"	['Haoran Wu', 'Wenxuan Wang', 'Yuxuan Wan', 'Wenxiang Jiao', 'Michael Lyu']	2023-03-15 00:35:50+00:00	http://arxiv.org/abs/2303.13648v1	"ChatGPT is a cutting-edge artificial intelligence language model developed by
OpenAI, which has attracted a lot of attention due to its surprisingly strong
ability in answering follow-up questions. In this report, we aim to evaluate
ChatGPT on the Grammatical Error Correction(GEC) task, and compare it with
commercial GEC product (e.g., Grammarly) and state-of-the-art models (e.g.,
GECToR). By testing on the CoNLL2014 benchmark dataset, we find that ChatGPT
performs not as well as those baselines in terms of the automatic evaluation
metrics (e.g., $F_{0.5}$ score), particularly on long sentences. We inspect the
outputs and find that ChatGPT goes beyond one-by-one corrections. Specifically,
it prefers to change the surface expression of certain phrases or sentence
structure while maintaining grammatical correctness. Human evaluation
quantitatively confirms this and suggests that ChatGPT produces less
under-correction or mis-correction issues but more over-corrections. These
results demonstrate that ChatGPT is severely under-estimated by the automatic
evaluation metrics and could be a promising tool for GEC."	ArXiv
239	"ChatGPT Empowered Long-Step Robot Control in Various Environments: A
  Case Application"	['Naoki Wake', 'Atsushi Kanehira', 'Kazuhiro Sasabuchi', 'Jun Takamatsu', 'Katsushi Ikeuchi']	2023-04-08 02:41:40+00:00	http://arxiv.org/abs/2304.03893v6	"This paper demonstrates how OpenAI's ChatGPT can be used in a few-shot
setting to convert natural language instructions into a sequence of executable
robot actions. The paper proposes easy-to-customize input prompts for ChatGPT
that meet common requirements in practical applications, such as easy
integration with robot execution systems and applicability to various
environments while minimizing the impact of ChatGPT's token limit. The prompts
encourage ChatGPT to output a sequence of predefined robot actions, represent
the operating environment in a formalized style, and infer the updated state of
the operating environment. Experiments confirmed that the proposed prompts
enable ChatGPT to act according to requirements in various environments, and
users can adjust ChatGPT's output with natural language feedback for safe and
robust operation. The proposed prompts and source code are open-source and
publicly available at
https://github.com/microsoft/ChatGPT-Robot-Manipulation-Prompts"	ArXiv
240	"Can ChatGPT Reproduce Human-Generated Labels? A Study of Social
  Computing Tasks"	['Yiming Zhu', 'Peixian Zhang', 'Ehsan-Ul Haq', 'Pan Hui', 'Gareth Tyson']	2023-04-20 08:08:12+00:00	http://arxiv.org/abs/2304.10145v2	"The release of ChatGPT has uncovered a range of possibilities whereby large
language models (LLMs) can substitute human intelligence. In this paper, we
seek to understand whether ChatGPT has the potential to reproduce
human-generated label annotations in social computing tasks. Such an
achievement could significantly reduce the cost and complexity of social
computing research. As such, we use ChatGPT to relabel five seminal datasets
covering stance detection (2x), sentiment analysis, hate speech, and bot
detection. Our results highlight that ChatGPT does have the potential to handle
these data annotation tasks, although a number of challenges remain. ChatGPT
obtains an average accuracy 0.609. Performance is highest for the sentiment
analysis dataset, with ChatGPT correctly annotating 64.9% of tweets. Yet, we
show that performance varies substantially across individual labels. We believe
this work can open up new lines of analysis and act as a basis for future
research into the exploitation of ChatGPT for human annotation tasks."	ArXiv
241	"Testing the Reliability of ChatGPT for Text Annotation and
  Classification: A Cautionary Remark"	['Michael V. Reiss']	2023-04-17 00:41:19+00:00	http://arxiv.org/abs/2304.11085v1	"Recent studies have demonstrated promising potential of ChatGPT for various
text annotation and classification tasks. However, ChatGPT is non-deterministic
which means that, as with human coders, identical input can lead to different
outputs. Given this, it seems appropriate to test the reliability of ChatGPT.
Therefore, this study investigates the consistency of ChatGPT's zero-shot
capabilities for text annotation and classification, focusing on different
model parameters, prompt variations, and repetitions of identical inputs. Based
on the real-world classification task of differentiating website texts into
news and not news, results show that consistency in ChatGPT's classification
output can fall short of scientific thresholds for reliability. For example,
even minor wording alterations in prompts or repeating the identical input can
lead to varying outputs. Although pooling outputs from multiple repetitions can
improve reliability, this study advises caution when using ChatGPT for
zero-shot text annotation and underscores the need for thorough validation,
such as comparison against human-annotated data. The unsupervised application
of ChatGPT for text annotation and classification is not recommended."	ArXiv
242	CHEAT: A Large-scale Dataset for Detecting ChatGPT-writtEn AbsTracts	['Peipeng Yu', 'Jiahan Chen', 'Xuan Feng', 'Zhihua Xia']	2023-04-24 11:19:33+00:00	http://arxiv.org/abs/2304.12008v2	"The powerful ability of ChatGPT has caused widespread concern in the academic
community. Malicious users could synthesize dummy academic content through
ChatGPT, which is extremely harmful to academic rigor and originality. The need
to develop ChatGPT-written content detection algorithms call for large-scale
datasets. In this paper, we initially investigate the possible negative impact
of ChatGPT on academia,and present a large-scale CHatGPT-writtEn AbsTract
dataset (CHEAT) to support the development of detection algorithms. In
particular, the ChatGPT-written abstract dataset contains 35,304 synthetic
abstracts, with Generation, Polish, and Mix as prominent representatives. Based
on these data, we perform a thorough analysis of the existing text synthesis
detection algorithms. We show that ChatGPT-written abstracts are detectable,
while the detection difficulty increases with human involvement.Our dataset is
available in https://github.com/botianzhe/CHEAT."	ArXiv
243	ChatLog: Carefully Evaluating the Evolution of ChatGPT Across Time	['Shangqing Tu', 'Chunyang Li', 'Jifan Yu', 'Xiaozhi Wang', 'Lei Hou', 'Juanzi Li']	2023-04-27 11:33:48+00:00	http://arxiv.org/abs/2304.14106v2	"ChatGPT has achieved great success and can be considered to have acquired an
infrastructural status. There are abundant works for evaluating ChatGPT on
benchmarks. However, existing benchmarks encounter two challenges: (1)
Disregard for periodical evaluation and (2) Lack of fine-grained features. In
this paper, we construct ChatLog, an ever-updating dataset with large-scale
records of diverse long-form ChatGPT responses for 21 NLP benchmarks from
March, 2023 to now. We conduct a comprehensive performance evaluation to find
that most capabilities of ChatGPT improve over time except for some abilities,
and there exists a step-wise evolving pattern of ChatGPT. We further analyze
the inherent characteristics of ChatGPT by extracting the knowledge and
linguistic features. We find some stable features that stay unchanged and apply
them on the detection of ChatGPT-generated texts to improve the robustness of
cross-version detection. We will continuously maintain our project at
\url{https://github.com/THU-KEG/ChatLog/}."	ArXiv
244	Ethical ChatGPT: Concerns, Challenges, and Commandments	['Jianlong Zhou', 'Heimo Müller', 'Andreas Holzinger', 'Fang Chen']	2023-05-18 02:04:13+00:00	http://arxiv.org/abs/2305.10646v1	"Large language models, e.g. ChatGPT are currently contributing enormously to
make artificial intelligence even more popular, especially among the general
population. However, such chatbot models were developed as tools to support
natural language communication between humans. Problematically, it is very much
a ``statistical correlation machine"" (correlation instead of causality) and
there are indeed ethical concerns associated with the use of AI language models
such as ChatGPT, such as Bias, Privacy, and Abuse. This paper highlights
specific ethical concerns on ChatGPT and articulates key challenges when
ChatGPT is used in various applications. Practical commandments for different
stakeholders of ChatGPT are also proposed that can serve as checklist
guidelines for those applying ChatGPT in their applications. These commandment
examples are expected to motivate the ethical use of ChatGPT."	ArXiv
245	"ChatGPT-EDSS: Empathetic Dialogue Speech Synthesis Trained from
  ChatGPT-derived Context Word Embeddings"	['Yuki Saito', 'Shinnosuke Takamichi', 'Eiji Iimori', 'Kentaro Tachibana', 'Hiroshi Saruwatari']	2023-05-23 06:19:37+00:00	http://arxiv.org/abs/2305.13724v1	"We propose ChatGPT-EDSS, an empathetic dialogue speech synthesis (EDSS)
method using ChatGPT for extracting dialogue context. ChatGPT is a chatbot that
can deeply understand the content and purpose of an input prompt and
appropriately respond to the user's request. We focus on ChatGPT's reading
comprehension and introduce it to EDSS, a task of synthesizing speech that can
empathize with the interlocutor's emotion. Our method first gives chat history
to ChatGPT and asks it to generate three words representing the intention,
emotion, and speaking style for each line in the chat. Then, it trains an EDSS
model using the embeddings of ChatGPT-derived context words as the conditioning
features. The experimental results demonstrate that our method performs
comparably to ones using emotion labels or neural network-derived context
embeddings learned from chat histories. The collected ChatGPT-derived context
information is available at
https://sarulab-speech.github.io/demo_ChatGPT_EDSS/."	ArXiv
246	"Performance Comparison of Large Language Models on VNHSGE English
  Dataset: OpenAI ChatGPT, Microsoft Bing Chat, and Google Bard"	['Xuan-Quy Dao']	2023-07-05 13:40:57+00:00	http://arxiv.org/abs/2307.02288v3	"This paper presents a performance comparison of three large language models
(LLMs), namely OpenAI ChatGPT, Microsoft Bing Chat (BingChat), and Google Bard,
on the VNHSGE English dataset. The performance of BingChat, Bard, and ChatGPT
(GPT-3.5) is 92.4\%, 86\%, and 79.2\%, respectively. The results show that
BingChat is better than ChatGPT and Bard. Therefore, BingChat and Bard can
replace ChatGPT while ChatGPT is not yet officially available in Vietnam. The
results also indicate that BingChat, Bard and ChatGPT outperform Vietnamese
students in English language proficiency. The findings of this study contribute
to the understanding of the potential of LLMs in English language education.
The remarkable performance of ChatGPT, BingChat, and Bard demonstrates their
potential as effective tools for teaching and learning English at the high
school level."	ArXiv
247	Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?	['Amrita Bhattacharjee', 'Huan Liu']	2023-08-02 17:11:37+00:00	http://arxiv.org/abs/2308.01284v2	"Large language models (LLMs) such as ChatGPT are increasingly being used for
various use cases, including text content generation at scale. Although
detection methods for such AI-generated text exist already, we investigate
ChatGPT's performance as a detector on such AI-generated text, inspired by
works that use ChatGPT as a data labeler or annotator. We evaluate the
zero-shot performance of ChatGPT in the task of human-written vs. AI-generated
text detection, and perform experiments on publicly available datasets. We
empirically investigate if ChatGPT is symmetrically effective in detecting
AI-generated or human-written text. Our findings provide insight on how ChatGPT
and similar LLMs may be leveraged in automated detection pipelines by simply
focusing on solving a specific aspect of the problem and deriving the rest from
that solution. All code and data is available at
https://github.com/AmritaBh/ChatGPT-as-Detector."	ArXiv
248	"ChatGPT: ascertaining the self-evident. The use of AI in generating
  human knowledge"	['Ioannis D. Apostolopoulos', 'Mpesi Tzani', 'Sokratis I. Aznaouridis']	2023-07-18 09:04:22+00:00	http://arxiv.org/abs/2308.06373v1	"The fundamental principles, potential applications, and ethical concerns of
ChatGPT are analyzed and discussed in this study. Since ChatGPT emerged, it has
gained a rapidly growing popularity, with more than 600 million users today.
The development of ChatGPT was a significant mile-stone, as it demonstrated the
potential of large-scale language models to generate natural language responses
that are almost indistinguishable from those of a human. ChatGPT's operational
principles, prospective applications, and ability to advance a range of human
endeavours are discussed in the paper. However, much of the work discusses and
poses moral and other problems that rely on the subject. To document the
latter, we submitted 14 queries and captured the ChatGPT responses. ChatGPT
appeared to be honest, self-knowledgeable, and careful with its answers. The
authors come to the realization that since AI is already a part of society, the
pervasiveness of the ChatGPT tool to the general public has once again brought
to light concerns regarding AI in general. Still, they have moved from the
domain of scientific community collective reflection at a conceptual level to
everyday practice this time."	ArXiv
249	"ChatGPT for Vulnerability Detection, Classification, and Repair: How Far
  Are We?"	['Michael Fu', 'Chakkrit Tantithamthavorn', 'Van Nguyen', 'Trung Le']	2023-10-15 12:01:35+00:00	http://arxiv.org/abs/2310.09810v1	"Large language models (LLMs) like ChatGPT (i.e., gpt-3.5-turbo and gpt-4)
exhibited remarkable advancement in a range of software engineering tasks
associated with source code such as code review and code generation. In this
paper, we undertake a comprehensive study by instructing ChatGPT for four
prevalent vulnerability tasks: function and line-level vulnerability
prediction, vulnerability classification, severity estimation, and
vulnerability repair. We compare ChatGPT with state-of-the-art language models
designed for software vulnerability purposes. Through an empirical assessment
employing extensive real-world datasets featuring over 190,000 C/C++ functions,
we found that ChatGPT achieves limited performance, trailing behind other
language models in vulnerability contexts by a significant margin. The
experimental outcomes highlight the challenging nature of vulnerability
prediction tasks, requiring domain-specific expertise. Despite ChatGPT's
substantial model scale, exceeding that of source code-pre-trained language
models (e.g., CodeBERT) by a factor of 14,000, the process of fine-tuning
remains imperative for ChatGPT to generalize for vulnerability prediction
tasks. We publish the studied dataset, experimental prompts for ChatGPT, and
experimental results at https://github.com/awsm-research/ChatGPT4Vul."	ArXiv
